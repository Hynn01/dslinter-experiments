#!/usr/bin/env python
# coding: utf-8

# # üåÉ üåá üèô –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –ª–∏—Ü–∞
# * –í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω —Å–ø–æ—Å–æ–± –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å–≤—É—é—â–∏–º–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è–º–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –ª–∏—Ü–∞.
# * –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É [Albumentations](https://albumentations.ai/), –≤ –∫–æ—Ç–æ—Ä–æ–π —É–∂–µ –µ—Å—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ ([—Å–º–æ—Ç—Ä–µ—Ç—å —Ç—É—Ç](https://albumentations.ai/docs/getting_started/keypoints_augmentation/)).
# 

# ### 1Ô∏è‚É£ –°–º–æ—Ç—Ä–∏–º –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –∑–∞–¥–∞–¥–∏–º —Ç—Ä–µ–±—É–µ–º—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã:

# In[ ]:


import numpy as np
import matplotlib.pyplot as plt
import cv2
import torch
from torchvision import transforms
import os
import copy

# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫
import albumentations as A 

PATH_DATA = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/"
PATH_TRAIN = os.path.join(PATH_DATA, "train")
PATH_TRAIN_IMAGE = os.path.join(PATH_TRAIN, "images")
PATH_TRAIN_LANDMARK = os.path.join(PATH_TRAIN, "landmarks.csv")


# –§—É–Ω–∫—Ü–∏—è, –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ü–≤–µ—Ç–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫:

# In[ ]:


def draw_landmarks(img, landmarks):
    """
    –†–∏—Å—É–µ—Ç —Ü–≤–µ—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –Ω–∞ –ª–∏—Ü–µ.
    landmarks: np.array.
    """
    image = np.copy(img) # —á—Ç–æ–±—ã –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –º–µ–Ω—è–ª–æ—Å—å
    for i, point in enumerate(landmarks):
        if 0 <= i and i < 273:    # –û–í–ê–õ –õ–ò–¶–ê
            color = (0, 0, 255)
        elif 273 <= i and i < 401: # –ë–†–û–í–ò
            color = (128, 0, 0)
        elif 401 <= i and i < 587: # –ù–û–°
            color = (255, 255, 0)
        elif 587 <= i and i < 841: # –ì–õ–ê–ó–ê
            color = (0, 255, 255)
        elif 841 <= i and i < 969: # –†–û–¢
            color = (255, 0, 0)
        elif 969 <= i < 971: # –ó–†–ê–ß–ö–ò
            color = (0, 0, 0)
        x, y = point.astype(np.int32)
        cv2.circle(img=image, center=(x, y), radius=1, color=color, thickness=-1)
    return image


# –ó–∞–¥–∞—ë–º –ø—É—Ç–∏ –¥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å:

# In[ ]:


dwayne_johnson_img_path = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/train/images/acf8a79eb7f4c7709c8b9b22ad7dcf91.jpg"
fifty_cent_img_path = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/train/images/83b604d583d5b01e2f102f86598017ba.jpg"
robert_de_niro_img_path = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/train/images/3ce64cc92545b9c33424f2ef65bb86f0.jpg"
james_franco_img_path = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/train/images/b0748b70cd104dcd65f0ac378214cf85.jpg"
alla_pugacheva_img_path  = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/train/images/be7751607fec67570ea892e1c48de642.jpg"
andrey_arshavin_img_path = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/train/images/1b41c68d084922d281cb5e1ee6a65c59.jpg"
brad_pitt_img_path3 = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/train/images/d5a277caf04a277113cbdf6590bb1f6f.jpg"
zendaya_img_path = "/kaggle/input/vkcv2022-contest-01-facial-landmarks/contest01_data/train/images/910ec52a981b5fd07577501e8bc7a040.jpg"


train_images_for_visualization_path = set([
    dwayne_johnson_img_path,
    fifty_cent_img_path,
    robert_de_niro_img_path,
    james_franco_img_path,
    alla_pugacheva_img_path,
    andrey_arshavin_img_path,
    brad_pitt_img_path3,
    zendaya_img_path,
])


# –ù–∞—Ö–æ–¥–∏–º `img` –∏ `landmarks` —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø—É—Ç—è–º:

# In[ ]:


train_samples_for_visualization = []
img_paths = []
img_landmarks = []

with open(PATH_TRAIN_LANDMARK, "rt") as fp:
    for i, line in enumerate(fp):
        if i == 0:
            continue  # skip header
        
        elements = line.strip().split("\t")
        image_name = os.path.join(PATH_TRAIN_IMAGE, elements[0])
        
        if image_name in train_images_for_visualization_path:
            
            img_paths.append(image_name)
            
            landmarks = list(map(np.int32, elements[1:]))
            landmarks = np.array(landmarks, dtype=np.int32).reshape((len(landmarks) // 2, 2))
            
            img_landmarks.append(landmarks)

img_landmarks = torch.as_tensor(img_landmarks)

for i, img_name in enumerate(img_paths):
    sample = {}
    
    image = cv2.imread(img_name)                   # —á–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # –ø–µ—Ä–µ–≤–æ–¥ –≤ –¥—Ä—É–≥–æ–µ —Ü–≤–µ—Ç–æ–≤–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
    
    sample["image"] = image
    sample["landmarks"] = img_landmarks[i]
    
    train_samples_for_visualization.append(sample)


# –†–∏—Å—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:

# In[ ]:


NUM_COLS = 4
NUM_ROWS = 2

plt.figure(figsize=(25, NUM_ROWS * 8))

for i in range(len(train_samples_for_visualization)):
    sample = copy.deepcopy(train_samples_for_visualization[i])
    img_tmp = draw_landmarks(sample["image"], np.array(sample["landmarks"]))
    plt.subplot(NUM_ROWS, NUM_COLS, i + 1)
    plt.imshow(img_tmp)

plt.tight_layout() # –æ—Ç—Å—Ç—É–ø—ã –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Ä–∏—Å—É–Ω–∫–∞–º–∏
plt.show()


# –ù–∞–¥–µ—é—Å—å, —á—Ç–æ –í—ã –≤—Å–µ—Ö —É–∑–Ω–∞–ª–∏ üòä

# ### 2Ô∏è‚É£ –ó–∞–¥–∞—ë–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
# * –°—Ç–æ–∏—Ç –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –º–µ–Ω—è—é—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ (–≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è), –∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ—Ç.
# * –Ø —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ —É–∫–∞–∂—É –±–æ–ª—å—à—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π, —á—Ç–æ–±—ã –í—ã —Å–º–æ–≥–ª–∏ —É–≤–∏–¥–µ—Ç—å –∏—Ö –≤—Å–µ —Å—Ä–∞–∑—É –ø—Ä–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.

# –ó–∞–¥–∞—ë–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–µ–Ω—è—é—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫:
# * –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–ø–µ—Ü–∏–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä `keypoint_params`

# In[ ]:


augmentations1 = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.Rotate([-25, 25], p=0.5),
],  keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))


# –ó–∞–¥–∞—ë–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –º–µ–Ω—è—é—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫:

# In[ ]:


augmentations2 = A.Compose([
    A.GaussNoise(p=0.5, var_limit=(10.0, 30.0)),
    A.RandomBrightnessContrast(p=0.5),
    # –ß—ë—Ä–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏ - –∏–º–∏—Ç–∞—Ü–∏—è –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –ø—Ä–µ–¥–º–µ—Ç–æ–≤.
    A.CoarseDropout(p=0.5, min_holes=4, max_holes=10, min_width=20, max_width=50, min_height=20, max_height=50), 
    A.ToGray(p=0.3), 
])


# ### 3Ô∏è‚É£ –°–º–æ—Ç—Ä–∏–º –Ω–∞ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:

# In[ ]:


NUM_COLS = 4
NUM_ROWS = 2

plt.figure(figsize=(25, NUM_ROWS * 8))

for i in range(len(train_samples_for_visualization)):
    sample = copy.deepcopy(train_samples_for_visualization[i])
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –º–µ–Ω—è—é—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫.
    transformed = augmentations1(image=np.array(sample['image']), keypoints=np.array(sample["landmarks"]).reshape(-1, 2))
    sample['image'], sample["landmarks"] = transformed['image'], torch.Tensor(transformed['keypoints'])
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –º–µ–Ω—è—é—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫.
    transformed = augmentations2(image=np.array(sample['image']))
    sample['image'] = transformed['image']
    
    # –†–∏—Å—É–µ–º.
    img_tmp = draw_landmarks(sample["image"], np.array(sample["landmarks"]).reshape(-1, 2))
    plt.subplot(NUM_ROWS, NUM_COLS, i + 1)
    plt.imshow(img_tmp)

plt.tight_layout() # –æ—Ç—Å—Ç—É–ø—ã –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Ä–∏—Å—É–Ω–∫–∞–º–∏
plt.show()


# #### –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –∏–∑–º–µ–Ω–∏–ª–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç—Ä–µ–±—É–µ–º—ã–º –æ–±—Ä–∞–∑–æ–º. –ú—ã –¥–æ—Å—Ç–∏–≥–ª–∏ —Å–≤–æ–µ–π —Ü–µ–ª–∏! üéâ
