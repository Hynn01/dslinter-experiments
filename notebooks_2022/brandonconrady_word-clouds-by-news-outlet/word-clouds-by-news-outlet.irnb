{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"library(tidyverse)\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nlibrary(tm)\nlibrary(wordcloud)\nlibrary(wordcloud2)\n\narticles <- read_csv(\"../input/covid19-vaccine-articles/COVID-19_Vaccine.csv\")","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2022-04-29T03:37:18.824908Z","iopub.execute_input":"2022-04-29T03:37:18.826515Z","iopub.status.idle":"2022-04-29T03:37:18.914479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Word Cloud for CNN articles\ncnn <- articles %>%\n    filter(Website == \"CNN\")\ncnn_docs <- Corpus(VectorSource(cnn$ArticleText))\n\ncnn_docs <- cnn_docs %>%\n  tm_map(removeNumbers) %>%\n  tm_map(removePunctuation) %>%\n  tm_map(stripWhitespace)\ncnn_docs <- tm_map(cnn_docs, content_transformer(tolower))\ncnn_docs <- tm_map(cnn_docs, removeWords, stopwords(\"english\"))\n\ndtm <- TermDocumentMatrix(cnn_docs) \nmatrix <- as.matrix(dtm) \nwords <- sort(rowSums(matrix),decreasing=TRUE) \ncnn_df <- data.frame(word = names(words),freq=words)\n\nset.seed(420) # for reproducibility \nwordcloud(words = cnn_df$word, freq = cnn_df$freq, min.freq = 1,\n          max.words=200, random.order=FALSE, rot.per=0.35,\n          colors=brewer.pal(8, \"Dark2\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T03:41:06.094328Z","iopub.execute_input":"2022-04-29T03:41:06.095944Z","iopub.status.idle":"2022-04-29T03:41:07.400326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Word Cloud for Fox articles\nfox <- articles %>%\n    filter(Website == \"Fox\")\nfox_docs <- Corpus(VectorSource(fox$ArticleText))\n\nfox_docs <- fox_docs %>%\n  tm_map(removeNumbers) %>%\n  tm_map(removePunctuation) %>%\n  tm_map(stripWhitespace)\nfox_docs <- tm_map(fox_docs, content_transformer(tolower))\nfox_docs <- tm_map(fox_docs, removeWords, stopwords(\"english\"))\n\ndtm <- TermDocumentMatrix(fox_docs) \nmatrix <- as.matrix(dtm) \nwords <- sort(rowSums(matrix),decreasing=TRUE) \nfox_df <- data.frame(word = names(words),freq=words)\n\nset.seed(420) # for reproducibility \nwordcloud(words = fox_df$word, freq = fox_df$freq, min.freq = 1,\n          max.words=200, random.order=FALSE, rot.per=0.35,\n          colors=brewer.pal(8, \"Dark2\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T03:42:26.387074Z","iopub.execute_input":"2022-04-29T03:42:26.388793Z","iopub.status.idle":"2022-04-29T03:42:27.437112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Word Cloud for ABC articles\nabc <- articles %>%\n    filter(Website == \"ABC\")\nabc_docs <- Corpus(VectorSource(abc$ArticleText))\n\nabc_docs <- abc_docs %>%\n  tm_map(removeNumbers) %>%\n  tm_map(removePunctuation) %>%\n  tm_map(stripWhitespace)\nabc_docs <- tm_map(abc_docs, content_transformer(tolower))\nabc_docs <- tm_map(abc_docs, removeWords, stopwords(\"english\"))\n\ndtm <- TermDocumentMatrix(abc_docs) \nmatrix <- as.matrix(dtm) \nwords <- sort(rowSums(matrix),decreasing=TRUE) \nabc_df <- data.frame(word = names(words),freq=words)\n\nset.seed(420) # for reproducibility \nwordcloud(words = abc_df$word, freq = abc_df$freq, min.freq = 1,\n          max.words=200, random.order=FALSE, rot.per=0.35,\n          colors=brewer.pal(8, \"Dark2\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T03:43:46.522267Z","iopub.execute_input":"2022-04-29T03:43:46.524017Z","iopub.status.idle":"2022-04-29T03:43:47.732546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Word Cloud for MSNBC articles\nmsnbc <- articles %>%\n    filter(Website == \"MSNBC\")\nmsnbc_docs <- Corpus(VectorSource(msnbc$ArticleText))\n\nmsnbc_docs <- msnbc_docs %>%\n  tm_map(removeNumbers) %>%\n  tm_map(removePunctuation) %>%\n  tm_map(stripWhitespace)\nmsnbc_docs <- tm_map(msnbc_docs, content_transformer(tolower))\nmsnbc_docs <- tm_map(msnbc_docs, removeWords, stopwords(\"english\"))\n\ndtm <- TermDocumentMatrix(msnbc_docs) \nmatrix <- as.matrix(dtm) \nwords <- sort(rowSums(matrix),decreasing=TRUE) \nmsnbc_df <- data.frame(word = names(words),freq=words)\n\nset.seed(420) # for reproducibility \nwordcloud(words = msnbc_df$word, freq = msnbc_df$freq, min.freq = 1,\n          max.words=200, random.order=FALSE, rot.per=0.35,\n          colors=brewer.pal(8, \"Dark2\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T03:44:42.899549Z","iopub.execute_input":"2022-04-29T03:44:42.901428Z","iopub.status.idle":"2022-04-29T03:44:44.100544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Word Cloud for BBC articles\nbbc <- articles %>%\n    filter(Website == \"BBC\")\nbbc_docs <- Corpus(VectorSource(bbc$ArticleText))\n\nbbc_docs <- bbc_docs %>%\n  tm_map(removeNumbers) %>%\n  tm_map(removePunctuation) %>%\n  tm_map(stripWhitespace)\nbbc_docs <- tm_map(bbc_docs, content_transformer(tolower))\nbbc_docs <- tm_map(bbc_docs, removeWords, stopwords(\"english\"))\n\ndtm <- TermDocumentMatrix(bbc_docs) \nmatrix <- as.matrix(dtm) \nwords <- sort(rowSums(matrix),decreasing=TRUE) \nbbc_df <- data.frame(word = names(words),freq=words)\n\nset.seed(420) # for reproducibility \nwordcloud(words = bbc_df$word, freq = bbc_df$freq, min.freq = 1,\n          max.words=200, random.order=FALSE, rot.per=0.35,\n          colors=brewer.pal(8, \"Dark2\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T03:46:05.793168Z","iopub.execute_input":"2022-04-29T03:46:05.794819Z","iopub.status.idle":"2022-04-29T03:46:06.745388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Word Cloud for Guardian articles\nguardian <- articles %>%\n    filter(Website == \"Guardian\")\nguardian_docs <- Corpus(VectorSource(guardian$ArticleText))\n\nguardian_docs <- guardian_docs %>%\n  tm_map(removeNumbers) %>%\n  tm_map(removePunctuation) %>%\n  tm_map(stripWhitespace)\nguardian_docs <- tm_map(guardian_docs, content_transformer(tolower))\nguardian_docs <- tm_map(guardian_docs, removeWords, stopwords(\"english\"))\n\ndtm <- TermDocumentMatrix(guardian_docs) \nmatrix <- as.matrix(dtm) \nwords <- sort(rowSums(matrix),decreasing=TRUE) \nguardian_df <- data.frame(word = names(words),freq=words)\n\nset.seed(420) # for reproducibility \nwordcloud(words = guardian_df$word, freq = guardian_df$freq, min.freq = 1,\n          max.words=200, random.order=FALSE, rot.per=0.35,\n          colors=brewer.pal(8, \"Dark2\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T03:47:01.643326Z","iopub.execute_input":"2022-04-29T03:47:01.644968Z","iopub.status.idle":"2022-04-29T03:47:02.569977Z"},"trusted":true},"execution_count":null,"outputs":[]}]}