#!/usr/bin/env python
# coding: utf-8

# # This Was An Early Version of Material Now Shown on Kaggle Learn
# **This best starting point for most users is [Kaggle Learn](https://www.kaggle.com/learn)**.  This list you are viewing is from before Kaggle Learn was launched, but it is now out-of-date. **[Go here](https://www.kaggle.com/learn)** for the best and most up-to-date resource about learning data science on Kaggle.
# 
# # Overview
# Want to get started with Machine Learning? In this series, you will quickly get up to speed building your first machine learning model. You will then progress through a series of improvements, until you have everything you need to build great models.
# 
# - ** Pre-Requisites: ** Basic Python programming expertise <br>
# - ** Getting Started: ** Go through the tutorials listed below, starting at the top. After the first tutorial, you will be start coding. Your code runs online, so you won't need to download any software or do any set-up on your local computer. 
# 
# *Later tutorials build on code you write in the earlier tutorials. So most users are better off starting from the beginning.*
# 
# ---
# 
# # Intro to Machine Learning
# | Name  | Description
# |:----- |:-----|
# | [How Models Work](https://www.kaggle.com/dansbecker/how-models-work)  |  The first step if you are new to machine learning
# | [Starting Your ML Project](https://www.kaggle.com/dansbecker/starting-your-ml-project) | Loading data, and setting up your computing environment for your hands-on project
# | [Selecting and Filtering Data in Pandas](https://www.kaggle.com/dansbecker/selecting-and-filtering-in-pandas) | Getting your data ready for modeling
# | [Running Your First Model](https://www.kaggle.com/dansbecker/your-first-scikit-learn-model) | Building your first model. Hurray!
# | [Model Validation](https://www.kaggle.com/dansbecker/model-validation) | Measuring the performance of your model. This opens up the possibilities for trying and comparing alternative models
# | [Underfitting, Overfitting and Model Optimization](https://www.kaggle.com/dansbecker/underfitting-overfitting-and-model-optimization) | Fine-tune your model for better performance.
# | [Random Forests](https://www.kaggle.com/dansbecker/random-forests) | Using a more sophisticated machine learning algorithm.
# | [Submitting To A Competition](https://www.kaggle.com/dansbecker/submitting-from-a-kernel) | Take pride in what you've built, and start tracking your ongoing progress through a Kaggle Competition.
# 
# 
# # Intermediate Machine Learning
# 
# | Name  | Description
# |:----- |:-----|
# | [Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values)  |  Learn multiple approaches for dealing with missing data fields
# | [Using Categorical Data](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding) | Handle this important but challenging data type
# | [Gradient Boosting with XGBoost](https://www.kaggle.com/dansbecker/learning-to-use-xgboost/) | The most important technique for building high-performance models on conventional data (the type that fits in tables or data frames.)
# | [Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-dependence-plots/) | Extract insights from your models. Insights many didn't even realize were possible.
# | [Scikit-Learn Pipelines](https://www.kaggle.com/dansbecker/pipelines/) | Make your machine learning code cleaner and more professional
# | [Cross-Validation](https://www.kaggle.com/dansbecker/cross-validation) |Improve how you compare and choose models and data preprocessing
# | [Data Leakage](https://www.kaggle.com/dansbecker/data-leakage/) | Identify and avoid one of the most common and costly mistakes in machine learning.
