{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing Libraries\n\nimport csv\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom joblib import dump, load\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing variables\n\nsplit = 0.7\nSTD = 0.01","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing train data. Using cleaned data obtaind from this link: https://www.kaggle.com/cdeotte/data-without-drift\n\ndir = '../input/data-without-drift/'\ndata = pd.read_csv(dir + 'train_clean.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Establishing rolling features function with variable window sizes per feature. These were chosen post-model fitting based on a trial basis and comparing with feature importances obtained below\n\ndef add_rolling_features(data):\n    data['r_mean_3000'] = data['signal'].rolling(3000).mean()\n    data['r_stdev_5'] = data['signal'].rolling(5).std()\n    data['r_ema_20'] = data['signal'].ewm(span=20, adjust=False).mean()\n    data['r_ema_5'] = data['signal'].ewm(span=5, adjust=False).mean()\n    data['signal'] = data['signal'] + np.random.normal(0,STD,size=len(data['signal'])) \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding rolling features to dataset\n\ndata = add_rolling_features(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting signal vs. time to get a visual representation of the data\n\nfig = plt.figure(figsize = (25, 10), dpi = 50, facecolor ='w', edgecolor ='k')\nplt.plot(data['time'], data['signal'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating data into features and labels based on headers and converting into an np.array\n\nlabels = np.array(data['open_channels'])\nfeature_cols = ['signal', \n                'r_mean_3000',\n                'r_stdev_5',\n                'r_ema_20',\n                'r_ema_5',\n               ]\n\nfeatures= data[feature_cols]\nfeature_list = list(data.columns)\nfeatures = np.array(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using test_train_split to using an 80:20 split between train and test respectively\n\ntrain_features, test_features, train_labels, test_labels = \\\ntrain_test_split(features, labels, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing shape to verify dimensions before fitting model\n\nprint('Training Features Shape:', train_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Features Shape:', test_features.shape)\nprint('Testing Labels Shape:', test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling data to remove any potential bias when fitting\n\nsc = StandardScaler()\ntrain_features = sc.fit_transform(train_features)\ntest_features = sc.transform(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Light Gradient Boosting Model classification with a maximum tree depth of 4\n\nmodel = LGBMClassifier(max_depth = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the model\n\nmodel.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract feature importances\n\nfi = pd.DataFrame({'feature': list(feature_cols),\n                   'importance': model.feature_importances_}).\\\n                    sort_values('importance', ascending = False)\n\nfi.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\n\npredictions = model.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the Confusion Matrix\n\npd.crosstab(test_labels, predictions, rownames = ['Actual'], colnames = ['Predicted'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy Score\n\naccuracy_score(test_labels, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# F1-score, a good indicator of leaderboard score with submission data\n\nf1_score(test_labels, predictions, average='macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing submission data\n\nsub_data = pd.read_csv(dir + 'test_clean.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting signal vs. time to get a visual representation of the data\n\nfig = plt.figure(figsize = (25, 10), dpi = 50, facecolor ='w', edgecolor ='k')\nplt.plot(sub_data['time'], sub_data['signal'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding rolling features to submission data to align it to the data used to fit the model\n\nsub_data = add_rolling_features(sub_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting and transforming features to submission data to align it to the data used to fit the model\n\nsub_features = sub_data[feature_cols]\nsub_features = np.array(sub_features)\nsub_features = sc.transform(sub_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gathering predictions of the submission data\n\nsub_predictions = model.predict(sub_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenating it to the submission data\n\nsub_data['open_channels'] = sub_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Isolating the columns of data required for submission\n\nout_cols = ['time', 'open_channels']\nout_data = sub_data[out_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output to csv\n\nout_data.to_csv('submission.csv', index=False, float_format='%.4f')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}