{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Let's begin\n"},{"metadata":{},"cell_type":"markdown","source":"Loading the libraries is done"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    \n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train data is viewed using .head() in pandas"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To check the length of datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x=train_data['Survived'], y=train_data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing values\nyou would have obsereved that certain values were either null or NaN so now let's see what proportion of them are there in training and test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing values\nmissing_data=train_data.isnull().sum()\nmissing_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(a=missing_data['Age'], label='Age',kde=False)\nsns.distplot(a=missing_data['Cabin'], label= 'Cabin',kde=False)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Name, Sex, Cabin & Embarked are categorical. Remove Name & Ticket as they are irrelavant. Remove cabin as too many null values. You can also use pipelines or SimpleImputer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Name, Sex, Cabin & Embarked are categorical. Remove Name & Ticket as they are irrelavant. Remove cabin as too many null values.\ntrain_data.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)\ntest_data.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filling the train and test data with mean taken of all the entries"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())\n\ntest_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For embarked, there are 2 missing values, drop them.\ntrain_data.dropna(subset = [\"Embarked\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dummy Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dummy encoding of 2 remaining categorical variables.\ntrain_data = pd.get_dummies(train_data, columns=[\"Sex\"], drop_first=True)\ntrain_data = pd.get_dummies(train_data, columns=[\"Embarked\"],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.get_dummies(test_data, columns=[\"Sex\"], drop_first=True)\ntest_data = pd.get_dummies(test_data, columns=[\"Embarked\"],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data[\"Survived\"]\n\nX = train_data.drop(['Survived'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Certain algorithms to work we must normalize the data so I have normalized using StandardScaler method"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc=StandardScaler()\nsc.fit(train_data.drop(['Survived', 'PassengerId'], axis = 1))\nX_train = sc.transform(train_data.drop(['Survived', 'PassengerId'], axis = 1))\nX_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training & Scoring**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.23, random_state = 5)\n\nmodel_LR = LogisticRegression(max_iter=5000)\nmodel_LR.fit(X_train, y_train)\nLR_predict = model_LR.predict(X_test)\nLR_score = model_LR.score(X_test,y_test)\n\nmodel_X = XGBClassifier(eta=0.1, n_estimators=50,\n                        max_depth=5, subsample=0.6, colsample_bytree=0.7,objective= 'binary:logistic',\n                        scale_pos_weight=1, seed=27)\nmodel_X.fit(X_train, y_train)\nX_predict = model_X.predict(X_test)\nX_score = model_X.score(X_test,y_test)\n\nrfc = RandomForestClassifier(n_estimators=6)\nrfc.fit(X_train, y_train)\nRFC_predict = rfc.predict(X_test)\nRFC_score = rfc.score(X_test,y_test)\n\nmodel_DTC = DecisionTreeClassifier(max_depth=7, min_samples_leaf=6, min_samples_split=2)\nmodel_DTC.fit(X_train, y_train)\nDTC_predict = model_DTC.predict(X_test)\nDTC_score = model_DTC.score(X_test,y_test)\n\nmodel_GB = GradientBoostingClassifier(random_state=10, n_estimators=1500,min_samples_split=100, max_depth=6)\nmodel_GB.fit(X, y)\nGB_predict = model_GB.predict(X_test)\nGB_score = model_GB.score(X_test,y_test)\n\nx1=LR_score, X_score, RFC_score, DTC_score, GB_score\nprint(x1)\n\nsns.distplot(a=x1, kde=True)\nplt.legend()\nplt.title('Accuracy estimates of Logistic regression, XGB, decision trees, Random Forest, and Gradient Boosting')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us use another algorithm called Naive bayes and now i have used cross validation scoring parameter"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score\n\ngnb= GaussianNB()\ngnb.fit(X_train, y_train)\nprediction = gnb.predict(X_test)\ncross_scores = cross_val_score(gnb,X_train,y_train,cv=8)\nprint(cross_scores)\n\nsns.distplot(a=cross_scores, kde=True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNeighbors in imported from sklearn library"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nneigh= KNeighborsClassifier(n_neighbors=5, leaf_size=30)\nneigh.fit(X_train, y_train)\nKN_predict = neigh.predict(X_test)\ncross_scores = cross_val_score(neigh,X_train,y_train,cv=8)\nprint(cross_scores)\nprint(accuracy_score(KN_predict, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model_X.predict(test_data)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do comment on if any improvement could be done on this\nI would be looking for more possible approaches like neural nets etc.\ninstead of mean i would look for pipelines and simpleimputer in future "},{"metadata":{},"cell_type":"markdown","source":"# References\n1. https://www.kaggle.com/kshivi99/predcting-the-titanic-survivors-minimal-kernal\n2. https://www.kaggle.com/mdmahmudferdous/titanic-survivor-prediction-0-804-top-8"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}