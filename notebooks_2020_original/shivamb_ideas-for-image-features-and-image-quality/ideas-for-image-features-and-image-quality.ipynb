{"cells":[{"metadata":{"_uuid":"fe1ee0c221546a5e4757bdfe512c1c39ee157654","_cell_guid":"37c92f91-7569-4b03-a82a-236dff6fef9a","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":37,"hidden":false,"width":12,"row":0}},"version":1}}},"cell_type":"markdown","source":"\n# Ideas for Generating Image Features and Measuring Image Quality\n\n<br>\n\n![](https://i.imgur.com/84TEdoa.png)\n\n<br>\n\n[Avito](https://www.kaggle.com/c/avito-demand-prediction) is Russia's largest Advertisment firm. The quality of the advertisement image significantly affects the demand volume on an item. For both advertisers and Avito, it is important to use authentic high quality images. In this kernel, I have implemented some ideas which can be used to create new features related to images. These features are an indicatory factors about the Image Quality. Following is the list of feature ideas:  \n\n\n### 1. Dullness : Is the Image Very Dull ?   \n    \n   1.1 Image Dullness Score\n\n### 2. Whiteness : Is the Image Very White ?  \n   2.1 Image Whiteness Score  \n    \n### 3. Uniformity : Is the Image too Uniform ?\n   3.1 Average Pixel Width\n\n### 4. Colors : What are the top colors used in the Image ? \n   4.1 Dominant Color of the Image   \n   4.2 Average Color of the Image\n\n### 5. Dimensions : Is the Image too Large or too Small ?  \n   5.1 Width of the Image    \n   5.2 Height of the Image   \n   5.3 Size of the Image    \n\n### 6. Blurrness : Is the Image Too Blurry ?   \n   6.1 Width of the Image      \n\n<br>\n"},{"metadata":{"_uuid":"5768a3c8f6f633403efdcce8398ac3eaa74ebde1","_cell_guid":"ccdc873b-d98f-40c8-939c-9725a74f262c","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"hidden":true}},"version":1}},"collapsed":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom scipy.stats import itemfreq\nfrom scipy import ndimage as ndi\nimport matplotlib.pyplot as plt\nfrom skimage import feature\nfrom PIL import Image as IMG\nimport numpy as np\nimport pandas as pd \nimport operator\nimport cv2\nimport os \n\nfrom IPython.core.display import HTML \nfrom IPython.display import Image\n\nimages_path = '../input/sampleavitoimages/sample_avito_images/'\nimgs = os.listdir(images_path)\n\nfeatures = pd.DataFrame()\nfeatures['image'] = imgs","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"1d372df765926103668eeaa3e1b35e6cc9f0debf","_cell_guid":"ca91d69c-1652-4565-a167-7d8f0e6cb678","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":6,"hidden":false,"width":12,"row":37}},"version":1}}},"cell_type":"markdown","source":"## 1. Is the image Very Dull \n\n### Feature 1 : Dullness\n\nDull Images may not be good for the advirtisment purposes. The analysis of prominent colors present in the images can indicate a lot about if the image is dull or not. In the following cell, I have added a code to measure the dullness score of the image which can be used as one of the feature in the model. \n\n"},{"metadata":{"_cell_guid":"459760ce-8324-48a3-ba03-a2a38d20fea7","_uuid":"e20c9c69fd613f94e3b4b94a290d59776603f5a1","collapsed":true,"extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"hidden":true}},"version":1}},"trusted":true},"cell_type":"code","source":"def color_analysis(img):\n    # obtain the color palatte of the image \n    palatte = defaultdict(int)\n    for pixel in img.getdata():\n        palatte[pixel] += 1\n    \n    # sort the colors present in the image \n    sorted_x = sorted(palatte.items(), key=operator.itemgetter(1), reverse = True)\n    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 25\n    for i, x in enumerate(sorted_x[:pixel_limit]):\n        if all(xx <= 20 for xx in x[0][:3]): ## dull : too much darkness \n            dark_shade += x[1]\n        if all(xx >= 240 for xx in x[0][:3]): ## bright : too much whiteness \n            light_shade += x[1]\n        shade_count += x[1]\n        \n    light_percent = round((float(light_shade)/shade_count)*100, 2)\n    dark_percent = round((float(dark_shade)/shade_count)*100, 2)\n    return light_percent, dark_percent","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d9b6724b5fdb52cf9a7504012337017d49c49344","_cell_guid":"48e163bf-c867-43b9-b61f-22aece750aaa","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":4,"hidden":false,"width":4,"row":43}},"version":1}}},"cell_type":"markdown","source":"Lets compute the dull score for the sample images from Avito's dataset "},{"metadata":{"_cell_guid":"2b547611-5247-4424-b05d-02c87750c669","_uuid":"f3cec207d871a5188fe4f78dc049af477b873981","collapsed":true,"extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":4,"height":7,"hidden":false,"width":4,"row":43}},"version":1}},"trusted":true},"cell_type":"code","source":"def perform_color_analysis(img, flag):\n    path = images_path + img \n    im = IMG.open(path) #.convert(\"RGB\")\n    \n    # cut the images into two halves as complete average may give bias results\n    size = im.size\n    halves = (size[0]/2, size[1]/2)\n    im1 = im.crop((0, 0, size[0], halves[1]))\n    im2 = im.crop((0, halves[1], size[0], size[1]))\n\n    try:\n        light_percent1, dark_percent1 = color_analysis(im1)\n        light_percent2, dark_percent2 = color_analysis(im2)\n    except Exception as e:\n        return None\n\n    light_percent = (light_percent1 + light_percent2)/2 \n    dark_percent = (dark_percent1 + dark_percent2)/2 \n    \n    if flag == 'black':\n        return dark_percent\n    elif flag == 'white':\n        return light_percent\n    else:\n        return None","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"e36b0c53-d99b-41b7-a9b5-b3133e77f73f","_kg_hide-input":true,"_uuid":"c4685c6501071e90cbd70f2476e97cd9d8cdd596","trusted":true},"cell_type":"code","source":"features['dullness'] = features['image'].apply(lambda x : perform_color_analysis(x, 'black'))\ntopdull = features.sort_values('dullness', ascending = False)\ntopdull.head(5)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"b392a3958d5fab56539a0ae1350fd23d8afb7de7","_cell_guid":"0e009ae9-f83f-4a42-8bf7-eeeadd6ef331","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":8,"height":4,"hidden":false,"width":4,"row":43}},"version":1}}},"cell_type":"markdown","source":"Lets plot some of the images with very high dullness"},{"metadata":{"_cell_guid":"ceac13b7-f269-477c-9598-db0948aba06a","_kg_hide-input":true,"_uuid":"88f5ca1819a615a208489c1c29c04090b3fbe449","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":24,"hidden":false,"width":4,"row":47}},"version":1}},"trusted":true},"cell_type":"code","source":"for j,x in topdull.head(2).iterrows():\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Dullness : \" + str(x['dullness']) +\")</h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"6ac2621912480b3ac85ac298f5199de725d3519d","_cell_guid":"cc5a68d1-be44-4cbb-9da7-a4f6446ad2d0","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":6,"hidden":false,"width":12,"row":71}},"version":1}}},"cell_type":"markdown","source":"## 2. Is the Image too bright or white \n\n### Feature 2 : Image Whiteness\n\nSome images can be too white or too bright which might not be good for the advertisement purposes. Using the samy type of color analysis, we can check if the images are too white. "},{"metadata":{"_cell_guid":"359b7df1-fd85-4ca6-ab7b-33ee28c1e9f3","_uuid":"41320793876b85cdde8cd7184d21fda98268b5f0","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":8,"height":7,"hidden":false,"width":4,"row":47}},"version":1}},"trusted":true},"cell_type":"code","source":"features['whiteness'] = features['image'].apply(lambda x : perform_color_analysis(x, 'white'))\ntopdull = features.sort_values('whiteness', ascending = False)\ntopdull.head(5)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"b95ef5abf56433113bf1a0e99882cbdc9f0bcbad","_cell_guid":"1b6cae3a-5d7f-40e3-8833-bdd697a8ea22","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":4,"height":4,"hidden":false,"width":4,"row":50}},"version":1}}},"cell_type":"markdown","source":"Lets plot some of the images having high whiteness score"},{"metadata":{"_cell_guid":"b23796d6-f646-4dab-adef-eb432b27a5f0","_kg_hide-input":true,"_uuid":"725452854350e7cb163a6cd50ff8b033ca0221c1","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":24,"hidden":false,"width":4,"row":77}},"version":1}},"trusted":true},"cell_type":"code","source":"for j,x in topdull.head(2).iterrows():\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Whiteness : \" + str(x['whiteness']) +\")</h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"2a521a22a76e75937aff2476579f1fd473ce7a68","_cell_guid":"d2150622-7eea-462c-b6b2-3bc21e51c1f6","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":7,"hidden":false,"width":12,"row":101}},"version":1}}},"cell_type":"markdown","source":"## 3. Uniform Images (with no pixel variations)\n\n### Feature 3 - Average Pixel Width (using edge detection)\n\nSome images may contain no pixel variation and are entirely uniform. Average Pixel Width is a measure which indicates the amount of edges present in the image. If this number comes out to be very low, then the image is most likely a uniform image and may not represent right content. \n\nTo compute this measure, I am using skimage's Canny Detection"},{"metadata":{"_cell_guid":"616df65d-8954-4361-ad24-1ce5c6252ead","_kg_hide-input":true,"_uuid":"ad37cc1d00a1ca112be728f1002fd1bb399c6543","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":4,"height":5,"hidden":false,"width":4,"row":54}},"version":1}},"trusted":true},"cell_type":"code","source":"im1 = IMG.open(images_path+'59.png')\nim2 = im1.convert(mode='L')\nim = np.asarray(im2)\n\nedges1 = feature.canny(im, sigma=1)\nedges2 = feature.canny(im, sigma=3)\n\n# display results\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3), sharex=True, sharey=True)\n\nax1.imshow(im, cmap=plt.cm.gray)\nax1.axis('off')\nax1.set_title('noisy image', fontsize=20)\n\nax2.imshow(edges1, cmap=plt.cm.gray)\nax2.axis('off')\nax2.set_title('Canny filter, $\\sigma=1$', fontsize=20)\n\nax3.imshow(edges2, cmap=plt.cm.gray)\nax3.axis('off')\nax3.set_title('Canny filter, $\\sigma=3$', fontsize=20)\n\nfig.tight_layout()\n\nplt.show()","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"10461e41-46ce-409f-835f-eb654000656d","_uuid":"110a8eea49567c004c98ae6e936bf0c2a91c09c1","collapsed":true,"extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":8,"height":7,"hidden":false,"width":4,"row":54}},"version":1}},"trusted":true},"cell_type":"code","source":"def average_pixel_width(img):\n    path = images_path + img \n    im = IMG.open(path)    \n    im_array = np.asarray(im.convert(mode='L'))\n    edges_sigma1 = feature.canny(im_array, sigma=3)\n    apw = (float(np.sum(edges_sigma1)) / (im.size[0]*im.size[1]))\n    return apw*100","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"10c37cfd-3e67-4fc1-bfa7-38e46753c2ae","_kg_hide-input":true,"_uuid":"0408abec0f3556514f5a1919e8562c89e0a55dde","trusted":true},"cell_type":"code","source":"features['average_pixel_width'] = features['image'].apply(average_pixel_width)\ntempdf = features.sort_values('average_pixel_width').head()\ntempdf ","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"4d246893ad53122ecd36dd263046142e9003ab8a","_cell_guid":"d2f12b86-5c88-4a6a-87cc-f741f5033957"},"cell_type":"markdown","source":"Lets plot some images having very low average pixel width"},{"metadata":{"_cell_guid":"1448292a-2fb5-4837-8120-5e2f7a944fea","_kg_hide-input":true,"_uuid":"255c2cdcf648df5511327e498433d95ebfce5748","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":62,"hidden":false,"width":4,"row":108}},"version":1}},"trusted":true},"cell_type":"code","source":"for j,x in tempdf.head(6).iterrows():\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Average Pixel Width : \" + str(x['average_pixel_width']) +\")</h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"b49cb2ad57ec1ae349ba8c44a0d95e79b8176cf0","_cell_guid":"10fdbda1-c082-47cd-89bd-74349e720da1","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":5,"hidden":false,"width":12,"row":170}},"version":1}}},"cell_type":"markdown","source":"Above images are most likely nosie and have low average pixel width values.\n\n## 4. What are the key colors used in the image ?\n\nColors used in the images play a significant role in garnering the attraction from users. Additional features related to colors such as Dominant and Average colors can be created. \n\n### Feature 4.1 - Dominant Color"},{"metadata":{"_cell_guid":"60580391-e3f4-4a07-bb32-4b54586692f3","_uuid":"7eff644388288eadb616c67550383e584726084a","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":4,"height":11,"hidden":false,"width":5,"row":77}},"version":1}},"trusted":true},"cell_type":"code","source":"def get_dominant_color(img):\n    path = images_path + img \n    img = cv2.imread(path)\n    arr = np.float32(img)\n    pixels = arr.reshape((-1, 3))\n\n    n_colors = 5\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n    flags = cv2.KMEANS_RANDOM_CENTERS\n    _, labels, centroids = cv2.kmeans(pixels, n_colors, None, criteria, 10, flags)\n\n    palette = np.uint8(centroids)\n    quantized = palette[labels.flatten()]\n    quantized = quantized.reshape(img.shape)\n\n    dominant_color = palette[np.argmax(itemfreq(labels)[:, -1])]\n    return dominant_color\n\nfeatures['dominant_color'] = features['image'].apply(get_dominant_color)\nfeatures.head(10)","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"5674845fa267cd9be5512323ea2a2656dd5a67f2","_cell_guid":"d6f04d44-3232-4c1a-9eec-204c663ba769","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":5,"hidden":false,"width":12,"row":175}},"version":1}}},"cell_type":"markdown","source":"Lets split the dominant color's RGB values to separate features \n\n- Feature 4.1.1 dominant_red value\n- Feature 4.1.2 dominant_green value\n- Feature 4.1.3 dominant_blue value"},{"metadata":{"_cell_guid":"ebe2559c-1b9f-4aee-9be4-5401e3ad5106","_uuid":"4b1a36b983440352d38415805775ecea36107273","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":4,"height":7,"hidden":false,"width":4,"row":59}},"version":1}},"trusted":true},"cell_type":"code","source":"features['dominant_red'] = features['dominant_color'].apply(lambda x: x[0]) / 255\nfeatures['dominant_green'] = features['dominant_color'].apply(lambda x: x[1]) / 255\nfeatures['dominant_blue'] = features['dominant_color'].apply(lambda x: x[2]) / 255\nfeatures[['dominant_red', 'dominant_green', 'dominant_blue']].head(5)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"f7592cadd7cfed432db20aa1635a7ad5c51eea96","_cell_guid":"714eba9e-f82d-470e-9587-44af5e56a0ca","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":8,"height":4,"hidden":false,"width":4,"row":61}},"version":1}}},"cell_type":"markdown","source":"### Feature 4.2 Average Color"},{"metadata":{"_cell_guid":"c198f9fe-9f28-4304-a121-d11af52ee5d7","_uuid":"5a20ae6b7face06ba53f506aad059062d0ce7f6e","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":11,"hidden":false,"width":9,"row":180}},"version":1}},"trusted":true},"cell_type":"code","source":"def get_average_color(img):\n    path = images_path + img \n    img = cv2.imread(path)\n    average_color = [img[:, :, i].mean() for i in range(img.shape[-1])]\n    return average_color\n\nfeatures['average_color'] = features['image'].apply(get_average_color)\nfeatures.head(10)","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"14bfd944-f2cc-4472-8fd8-1a155b8cf975","_uuid":"a4d855fea8aa0649ef5478908b99d6d63699967b","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":4,"height":7,"hidden":false,"width":4,"row":88}},"version":1}},"trusted":true},"cell_type":"code","source":"features['average_red'] = features['average_color'].apply(lambda x: x[0]) / 255\nfeatures['average_green'] = features['average_color'].apply(lambda x: x[1]) / 255\nfeatures['average_blue'] = features['average_color'].apply(lambda x: x[2]) / 255\nfeatures[['average_red', 'average_green', 'average_blue']].head(5)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"ad345e6c8c9b502e26c6038bdc17e621b5981774","_cell_guid":"52ee862a-5932-4e33-9cc2-c821e8f60471","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":5,"hidden":false,"width":12,"row":191}},"version":1}}},"cell_type":"markdown","source":"## 5. Dimensions of the Image \n\nToo Big Images or Too Small Images might not be very good for generating good attraction. Users may skip viewing a very large or very small sized image. Hence for advertisers it is important to set precise dimensions and size of the image. Hence we can create additional features. \n\n- Image width\n- Image height\n- Image size"},{"metadata":{"_cell_guid":"6f0917eb-cadf-460f-9996-55071a1808a8","_uuid":"023cb77036bff2cf1dd613814779b60ff7b0f507","collapsed":true,"extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"hidden":true}},"version":1}},"trusted":true},"cell_type":"code","source":"def getSize(filename):\n    filename = images_path + filename\n    st = os.stat(filename)\n    return st.st_size\n\ndef getDimensions(filename):\n    filename = images_path + filename\n    img_size = IMG.open(filename).size\n    return img_size ","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"efafe14e-52fb-409e-9588-92b62643edfa","_uuid":"1eab34994a899bec9a35c40505d77105e7524b8d","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"hidden":true}},"version":1}},"trusted":true},"cell_type":"code","source":"features['image_size'] = features['image'].apply(getSize)\nfeatures['temp_size'] = features['image'].apply(getDimensions)\nfeatures['width'] = features['temp_size'].apply(lambda x : x[0])\nfeatures['height'] = features['temp_size'].apply(lambda x : x[1])\nfeatures = features.drop(['temp_size', 'average_color', 'dominant_color'], axis=1)\nfeatures.head()","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"8d6e3013322b525cca9b5c394037063d69264a1c","_cell_guid":"5957b9c9-f56d-4dca-8191-494010c95122"},"cell_type":"markdown","source":"## 6. Is the image too Blurry \n\n### Feature 6 - Image Blurrness\n\nTo measure the image blurrness, I refered to the following paper: \"Diatom Autofocusing in Brightfield Microscopy: A Comparative Study\". \n\nIn this paper the author Pech-Pacheco et al. has provided variance of the Laplacian Filter which can be used to measure if the image blurryness score.\n\nIn this technique, the single channel of an image is convolved  with the the laplacian filter. If the specified value is less than a threshold value, then image is blurry otherwise not.  \n\n![](https://www.pyimagesearch.com/wp-content/uploads/2015/09/detecting_blur_laplacian.png)\n\n-  Paper Link : http://optica.csic.es/papers/icpr2k.pdf  \n-  Reference : https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n\n\n\n\n"},{"metadata":{"_cell_guid":"35dd5e89-2cee-465d-b130-65d585b2085b","collapsed":true,"_uuid":"1e8b1d93a2fd13b4596ee438de577648f106fcaa","trusted":true},"cell_type":"code","source":"def get_blurrness_score(image):\n    path =  images_path + image \n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    fm = cv2.Laplacian(image, cv2.CV_64F).var()\n    return fm","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"0ce0b212-9286-4a05-bf91-d983af10ff88","_uuid":"fd9726fd33bfcce9be4c5c5ee1e19c471df8b3e6","trusted":true},"cell_type":"code","source":"features['blurrness'] = features['image'].apply(get_blurrness_score)\nfeatures[['image','blurrness']].head(5)","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"0a4edead-46c7-4a80-b8ec-57d7b53d29d4","_uuid":"4b5142c9c3c79fa53d0848d3f8001392c888230b","trusted":true},"cell_type":"code","source":"tempdf = features.sort_values('blurrness')\nfor y,x in tempdf.head(5).iterrows():\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Blurrness : \" + str(x['blurrness']) +\")</h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"6f4673f3661aece639244f52620598d3a284d83f","_cell_guid":"17ab42cb-dbe5-412e-849c-dc591b86e040","extensions":{"jupyter_dashboards":{"views":{"report_default":{},"grid_default":{"col":0,"height":9,"hidden":false,"width":12,"row":203}},"version":1}}},"cell_type":"markdown","source":"### Other Ideas about features from Image\n\n- No of objects detected \n- Total Number of Color Present \n- No. of shapes detected \n- Amount of Text Present in the image \n\nOther great kernels on Image Feature Extraction:\n\n1. https://www.kaggle.com/wesamelshamy/ad-image-recognition-and-quality-scoring by wesamelshamy  \n2. https://www.kaggle.com/peterhurford/image-feature-engineering by peterhurford  "}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"extensions":{"jupyter_dashboards":{"views":{"report_default":{"type":"report","name":"report"},"grid_default":{"type":"grid","defaultCellHeight":20,"maxColumns":12,"name":"grid","cellMargin":10}},"version":1,"activeView":"grid_default"}}},"nbformat":4,"nbformat_minor":1}