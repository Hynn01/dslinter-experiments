{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom keras import backend as K\nfrom tensorflow.keras.optimizers import SGD , RMSprop\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\nprint(tf.__version__)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Augmentation\n\nbase_dir=os.path.join(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/\")\ntrain_dir=os.path.join(base_dir,\"train\")\nval_dir=os.path.join(base_dir,\"val\")\nprint(train_dir, val_dir, sep='\\n')\n\nIMG_SHAPE=150\nbatch_size=64\n\nimage_gen_train = ImageDataGenerator(\n                    rescale=1./255,\n                    rotation_range=15,\n                    horizontal_flip=True\n                    )\n\n\ntrain_data_gen = image_gen_train.flow_from_directory(\n                                                batch_size=batch_size,\n                                                directory=train_dir,\n                                                shuffle=True,\n                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n                                                )\n\nimage_gen_val = ImageDataGenerator(rescale=1./255,\n                   rotation_range=15,\n                   horizontal_flip=True)\n\nval_data_gen = image_gen_val.flow_from_directory(batch_size=16,\n                                                 directory=val_dir,\n                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n                                                 )\nprint(train_data_gen.class_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model copied from https://github.com/deadskull7/Pneumonia-Diagnosis-using-XRays-96-percent-Recall\n\ndef swish_activation(x):\n    return (K.sigmoid(x) * x)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(16, (3, 3), activation='relu', padding=\"same\", input_shape=(150,150,3)))\nmodel.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=(150,150,3)))\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\nmodel.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\nmodel.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation=swish_activation))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(2 , activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n                  optimizer=RMSprop(lr=0.00005),\n                  metrics=['accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=6\nhistory = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=int(np.ceil(train_data_gen.n / float(batch_size))),\n    epochs=epochs,\n    validation_data=val_data_gen,\n    validation_steps=int(np.ceil(val_data_gen.n / float(16)))\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.models import load_model\nmodel.save('/kaggle/working/m.h5')\n# history=load_model('/kaggle/working/m.h5')\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generating test data set with labels\n\nfrom keras.utils import to_categorical\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\ntest_list_pne=os.listdir(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/PNEUMONIA/\")\ntest_dir_pne=os.path.join(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/PNEUMONIA/\")\ntest_list_nor=os.listdir(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/NORMAL/\")\ntest_dir_nor=os.path.join(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/NORMAL/\")\ntest_x=[]\ntest_y=[]\nfor name in tqdm(test_list_pne):\n    # predicting images\n    path = test_dir_pne + name\n    img = image.load_img(path, target_size=(150, 150))\n    x = image.img_to_array(img)\n    test_x.append(x)\n    test_y.append(1)\n    \nfor name in tqdm(test_list_nor):\n    # predicting images\n    path = test_dir_nor + name\n    img = image.load_img(path, target_size=(150, 150))\n    x = image.img_to_array(img)\n    test_x.append(x)\n    test_y.append(0)\n\ntest_x=np.array(test_x)\ntest_y=np.array(test_y)\ntest_y= to_categorical(test_y, 2)\n\nprint(\"Total number of test examples: \", test_x.shape)\nprint(\"Total number of labels:\", test_y.shape)\n# print(test_y)\ntest_loss, test_score = model.evaluate(test_x, test_y)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)\n\n# prediction on test data\n\npreds = model.predict(test_x)\npreds = np.argmax(preds, axis=-1)\ntest_y= np.argmax(test_y,axis=-1) \nprint(\"test_y= \", test_y.shape)\nprint(\"Pred= \", preds.shape)\n# print(preds)\n# pred=[]\n# for p in preds:\n#     if p == 1:\n#         pred.append(1)\n#     else:\n#         pred.append(0)\n# pred=np.array(pred)\n# print(\"pred shape= \", pred.shape)\n# # print(pred)\n        \n\n\n# CM = confusion_matrix(test_y, pred)\n# fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n# plt.show()\n\ncm  = confusion_matrix(test_y, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.show()\n\ntn, fp, fn, tp = cm.ravel()\n\nprecision = tp/(tp+fp)\nrecall = tp/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ignore these cells they are just for testing\n\ntest_list=os.listdir(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/PNEUMONIA/\")\ntest_dir=os.path.join(\"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/PNEUMONIA/\")\n# print(test_dir)\nfrom keras.preprocessing import image\nimport skimage\nfrom skimage.transform import resize\nimport cv2 \nfrom tqdm import tqdm_notebook as tqdm\nX=[]\nT=0\nF=0\nimmg=[]\n\nfor name in tqdm(test_list):\n    # predicting images\n    path = test_dir + name\n    img = image.load_img(path, target_size=(150, 150))\n    x = image.img_to_array(img)\n#     x = np.expand_dims(x, axis=0)\n#     images = np.vstack([x])\n    immg.append(x)\n#     classes = model.predict(images)\n#     if classes[0]>0.5:\n#         F=F+1\n#     else:\n#         T=T+1\n\nimmge=np.array(immg)        \nclasses = model.predict_classes(np.squeeze(immge))\nprint(np.squeeze(immge).shape)\nprint(classes.shape)\nfor i in classes:\n    if i>0.5:\n        F=F+1\n    else:\n        T=T+1\nprint(\"T={} , F={}\".format(T,F) )\nT=0\nF=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Ignore these cells they are just for testing\n\nfor name in tqdm(test_list):\n    # predicting images\n    path = test_dir + name\n    img = cv2.imread(path)\n    if img is not None:\n        img = skimage.transform.resize(img, (150, 150, 3))\n        #img_file = scipy.misc.imresize(arr=img_file, size=(150, 150, 3))\n        img = np.asarray(img)\n        X.append(img)\nX = np.asarray(X)\nprint(X.shape)\nclasses = model.predict(X)\nprint(classes.shape)\nfor i in classes:\n    if i>0.5:\n        F=F+1\n    else:\n        T=T+1\nprint(\"T={} , F={}\".format(T,F) )\nT=0\nF=0\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}