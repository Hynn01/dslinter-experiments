{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"_is_fork":false,"_change_revision":0,"language_info":{"mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","version":"3.6.1","codemirror_mode":{"name":"ipython","version":3}}},"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"5e5ac084a529bb752da187faef256f0d348dbfd7","_cell_guid":"54b3f5d0-9c46-a82c-86bf-3b24c8c6d7a3"},"source":"Analyzing Soccer Player Faces\n--------------------------------\n\nIn this script we will explore a dataset of faces of approximately 450 top male soccer players and approximately 150 top female soccer players.\nWe will examine the main modes of variation in the appearance of player faces (the face images of the players are conveniently almost perfectly aligned so the images turn out particularly nice).\n\nWe then try to find correlations between face features and real life attributes of those players such as \"Age\", \"Height\", \"Weight\" and \"Sex\".\n\nNote that the first part of this script is essentially the same code that I used in [Visualizing PCA][1], but the data here is more interesting since it contains human faces. I welcome everyone to go visit also the [Visualizing PCA][1] script and look at the difference when applying the same piece of code to a different dataset.\n\n  [1]: https://www.kaggle.com/selfishgene/leaf-classification/visualizing-pca-with-leaf-dataset"},{"cell_type":"code","metadata":{"_uuid":"9dd3e2e39060dcb8f75b81e71ed7e68ac6deb708","collapsed":true,"_cell_guid":"c7a5a770-ab02-efc2-f440-07590e028d0f"},"execution_count":null,"outputs":[],"source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport glob\n\nfrom sklearn import decomposition\nfrom sklearn.neighbors import KernelDensity\nfrom sklearn.manifold import TSNE\n\nmatplotlib.style.use('fivethirtyeight')"},{"cell_type":"markdown","metadata":{"_uuid":"7a9f0af75d63e831da35b351dbe02d0832ce5d98","_cell_guid":"0bd85e09-9399-4024-a5f6-32019d426c5a"},"source":"## Load the data "},{"cell_type":"code","metadata":{"_uuid":"8110c6a621d200d3e5ab32f1e96da41b7f556dfe","collapsed":true,"_cell_guid":"e8598ac8-aa4c-aeb6-9d5a-5bfec83bcaa5"},"execution_count":null,"outputs":[],"source":"#%% load the data, go over training images and store them in a list\nmaleFaceFiles   = glob.glob('../input/Pictures/*.png')\nfemaleFaceFiles = glob.glob('../input/Pictures_f/*.png')\nfaceFiles = maleFaceFiles + femaleFaceFiles\n\nlistOfPlayerNames = []\nlistOfImages = []\nfor imageFilename in faceFiles:\n    currName = imageFilename.split(\"/\")[-1].split('.')[0]\n        \n    try:\n        currImage = mpimg.imread(imageFilename)\n        if len(np.unique(currImage[:,:,0].ravel())) <= 40:\n            print(\"no image for '\" + currName + \"'\")\n        else:\n            listOfPlayerNames.append(currName)\n            listOfImages.append(currImage)\n    except:\n        print(\"didn't load '\" + currName + \"'\")\n        \nfemaleNames = [x.split(\"/\")[-1].split('.')[0] for x in femaleFaceFiles]\nisFemale    = [x in femaleNames for x in listOfPlayerNames]\n\nprint('Total number of loaded face images is %d' %(len(listOfImages)))"},{"cell_type":"markdown","metadata":{"_uuid":"4a1499064a52d9e7c7cff1e02e24c4cd70073abb","_cell_guid":"4df8d857-d9f3-7eaf-0a2a-468f74e60529"},"source":"## Show a random sample of players in the dataset"},{"cell_type":"code","metadata":{"_uuid":"cad75cd7354902918eac32d2bf7445a4cea4f778","collapsed":true,"_cell_guid":"7549c323-98c8-aee1-17b7-b354e2abbccc"},"execution_count":null,"outputs":[],"source":"#%% show some images\nmatplotlib.rcParams['font.size'] = 9\nmatplotlib.rcParams['figure.figsize'] = (12,19)\n\nnumRows = 9; numCols = 5\n\nplt.figure()\nfor k in range(numRows*numCols):\n    randInd = np.random.randint(len(listOfImages))\n    plt.subplot(numRows,numCols,k+1); \n    plt.imshow(listOfImages[randInd])\n    plt.title(listOfPlayerNames[randInd]); plt.axis('off')"},{"cell_type":"markdown","metadata":{"_uuid":"cf03f00a0fac69967663e33ae6e24d0b425291a5","_cell_guid":"03684245-77c0-4586-be23-6797a7303bed"},"source":"## Reorganize the Data for later"},{"cell_type":"code","metadata":{"_uuid":"6dd20bfd34d4ef20379539dda766eaed886105a5","collapsed":true,"_cell_guid":"c8e577be-7f00-46c1-aaac-69a86c81726a"},"execution_count":null,"outputs":[],"source":"#%% gather everything into a large matrix\nfullImageMatrix4D = np.zeros((128,128,3,len(listOfImages)))\n\nbackGroundImage = np.zeros((128,128,3))\nbackGroundImage[:,:,0] = 0.3\nbackGroundImage[:,:,1] = 0.4\nbackGroundImage[:,:,2] = 0.5\n\nfor k, currImage in enumerate(listOfImages):\n    alphaChannel = currImage[:,:,3]\n    rgbImage = currImage[:,:,:3]\n    tiledAlpha = np.tile(alphaChannel[:,:,np.newaxis],(1,1,3))\n    \n    fullImageMatrix4D[:,:,:,k] = rgbImage*tiledAlpha + (tiledAlpha < 0.15)*backGroundImage"},{"cell_type":"markdown","metadata":{"_uuid":"28b0e52d218b529fb1836c0ac21dc50ee3fa4f13","_cell_guid":"8e2f5b71-7dc0-2b33-867c-c1f8d9db6430"},"source":"## Show the Mean Face Image and pixel-wise Standard Deviation Image"},{"cell_type":"code","metadata":{"collapsed":true,"_kg_hide-output":false,"_uuid":"4946cb900b4b853e0e2b1789e48227abba0ad41b","_kg_hide-input":false,"_cell_guid":"5e8b4b84-654b-eb8c-c49f-54171c6c8dad"},"execution_count":null,"outputs":[],"source":"# show mean face image and stdev image\nmatplotlib.rcParams['font.size'] = 10\nmatplotlib.rcParams['figure.figsize'] = (12,12)\n\nplt.figure(); \nplt.subplot(1,2,1); plt.imshow(fullImageMatrix4D.mean(axis=3)); \nplt.title('mean face Image'); plt.axis('off')\nplt.subplot(1,2,2); plt.imshow(fullImageMatrix4D.std(axis=3)); \nplt.title('standard deviation Image'); plt.axis('off')"},{"cell_type":"markdown","metadata":{"_uuid":"d599ab580e9edfc3ea380bb343cfa79631c158df","_cell_guid":"f385c902-181d-c787-e5ec-4346dc91cdba"},"source":"## Define a Gaussian Model class that will later help us visualize things:\n\n(this is long, just skip this to get to the analysis)"},{"cell_type":"code","metadata":{"collapsed":true,"_kg_hide-output":true,"_uuid":"766211fd32536ec7759acc294d61ad4a1599edb8","_kg_hide-input":true,"_cell_guid":"b52a3d4a-e439-3925-4885-d073faa1ad35"},"execution_count":null,"outputs":[],"source":"#%% define GaussianModel class and some additional helper functions\n\nclass GaussianModel:\n\n    def __init__(self, X, numBasisFunctions=10, objectPixels=None):\n        '''\n        inputs: \n            X                    - numSamples x numDimentions matrix\n            numBasisFunctions       - number of basis function to use\n            objectPixels (optional) - an binnary mask image used for presentation\n                                      will be used as Im[objectPixels] = dataSample\n                                      must satisfy objectPixels.ravel().sum() = X.shape[1]\n        '''\n        \n        self.numBasisFunctions = numBasisFunctions\n        if objectPixels is None:\n            self.objectPixels = np.ones((1,X.shape[1]),dtype=np.bool)\n        else:\n            self.objectPixels = objectPixels\n        assert(self.objectPixels.ravel().sum() == X.shape[1])\n\n        PCAModel = decomposition.PCA(n_components=numBasisFunctions, whiten=True)\n        #PCAModel = decomposition.IncrementalPCA(n_components=numBasisFunctions, whiten=True, batch_size=400)\n        self.dataRepresentation = PCAModel.fit_transform(X)\n        self.PCAModel = PCAModel\n\n        \n    def RepresentUsingModel(self, X):\n        return self.PCAModel.transform(X)\n\n    def ReconstructUsingModel(self, X_transformed):\n        return self.PCAModel.inverse_transform(X_transformed)\n\n    def InterpretUsingModel(self, X):\n        return self.PCAModel.inverse_transform(self.PCAModel.transform(X))\n\n        \n    # shows the eigenvectors of the gaussian covariance matrix\n    def ShowVarianceDirections(self, numDirectionsToShow=16):\n        #matplotlib.rcParams['font.size'] = 14\n        numDirectionsToShow = min(numDirectionsToShow, self.numBasisFunctions)\n        \n        numFigRows = 4; numFigCols = 4;\n        numDirectionsPerFigure = numFigRows*numFigCols\n        numFigures = int(np.ceil(float(numDirectionsToShow)/numDirectionsPerFigure))\n        \n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotInd in range(numDirectionsPerFigure):\n                eigVecInd = numDirectionsPerFigure*figureInd + plotInd\n                if eigVecInd >= self.numBasisFunctions:\n                    break\n                deltaImage = np.zeros(np.shape(self.objectPixels))\n                deltaImage[self.objectPixels] = self.PCAModel.components_[eigVecInd,:].ravel()\n\n                plt.subplot(numFigRows,numFigCols,plotInd+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(deltaImage)\n                elif np.shape(self.objectPixels)[2] == 3:\n                    deltaImage = 0.1/deltaImage.std()*deltaImage+0.5\n                    deltaImage[deltaImage>1] = 1.0\n                    deltaImage[deltaImage<0] = 0.0\n                    plt.imshow(deltaImage); plt.axis('off')\n                else:\n                    plt.imshow(deltaImage); plt.axis('off')\n                plt.title('%.3f%s explained' %(100*self.PCAModel.explained_variance_ratio_[eigVecInd], '%'))\n            plt.tight_layout()\n\n    \n    # shows several random model reconstructions\n    def ShowReconstructions(self, X, numReconstructions=6):\n        #matplotlib.rcParams['font.size'] = 14\n        assert(np.shape(X)[1] == self.objectPixels.ravel().sum())\n        numSamples = np.shape(X)[0]\n        numReconstructions = min(numReconstructions, numSamples)\n        \n        originalImage      = np.zeros(np.shape(self.objectPixels))\n        reconstructedImage = np.zeros(np.shape(self.objectPixels))\n        \n        numReconstructionsPerFigure = min(6, numReconstructions)\n        numFigures = int(np.ceil(float(numReconstructions)/numReconstructionsPerFigure))\n        \n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotCol in range(numReconstructionsPerFigure):\n                dataSampleInd = np.random.randint(numSamples)\n                originalImage[self.objectPixels] = X[dataSampleInd,:].ravel()\n                reconstructedImage[self.objectPixels] = self.InterpretUsingModel(np.reshape(X[dataSampleInd,:],[1,-1])).ravel()\n                diffImage = abs(originalImage - reconstructedImage)\n                \n                # original image\n                plt.subplot(3,numReconstructionsPerFigure,0*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(originalImage); plt.title('original signal')\n                else:\n                    plt.imshow(originalImage, cmap='gray'); plt.title('original image'); plt.axis('off')\n                    \n                # reconstred image\n                plt.subplot(3,numReconstructionsPerFigure,1*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(reconstructedImage); plt.title('reconstructed signal')\n                elif np.shape(self.objectPixels)[2] == 3:\n                    reconstructedImage[reconstructedImage>1] = 1.0\n                    reconstructedImage[reconstructedImage<0] = 0.0\n                    plt.imshow(reconstructedImage); plt.title('reconstructed image'); plt.axis('off')\n                else:\n                    plt.imshow(reconstructedImage, cmap='gray'); plt.title('reconstructed image'); plt.axis('off')\n\n                # diff image\n                plt.subplot(3,numReconstructionsPerFigure,2*numReconstructionsPerFigure+plotCol+1)\n                if np.shape(self.objectPixels)[0] == 1:\n                    plt.plot(diffImage); plt.title('abs difference signal')\n                else:\n                    plt.imshow(diffImage, cmap='gray'); plt.title('abs difference image'); plt.axis('off')\n            plt.tight_layout()\n\n            \n    # shows distrbution along the variance directions and several images along that variance direction\n    def ShowModelVariations(self, numVariations=6):\n        #matplotlib.rcParams['font.size'] = 14\n\n        showAsTraces = (np.shape(self.objectPixels)[0] == 1)\n        numVariations = min(numVariations, self.numBasisFunctions)\n                \n        numVarsPerFigure = min(6,numVariations)\n        numFigures = int(np.ceil(float(numVariations)/numVarsPerFigure))\n        \n        lowRepVec     = np.percentile(self.dataRepresentation, 2, axis=0)\n        medianRepVec  = np.percentile(self.dataRepresentation, 50, axis=0)\n        highRepVec    = np.percentile(self.dataRepresentation, 98, axis=0)\n\n        for figureInd in range(numFigures):\n            plt.figure()\n            for plotCol in range(numVarsPerFigure):\n                eigVecInd = numVarsPerFigure*figureInd+plotCol\n                if eigVecInd >= self.numBasisFunctions:\n                    break\n\n                # create the low and high precentile representation activation vectors\n                currLowPrecentileRepVec             = medianRepVec.copy()\n                currLowPrecentileRepVec[eigVecInd]  = lowRepVec[eigVecInd]\n                currHighPrecentileRepVec            = medianRepVec.copy()\n                currHighPrecentileRepVec[eigVecInd] = highRepVec[eigVecInd]\n\n                # create blank images\n                deltaImage          = np.zeros(np.shape(self.objectPixels))\n                medianImage         = np.zeros(np.shape(self.objectPixels))\n                lowPrecentileImage  = np.zeros(np.shape(self.objectPixels))\n                highPrecentileImage = np.zeros(np.shape(self.objectPixels))\n\n                # fill the object pixels with the relevant data\n                deltaImage[self.objectPixels]          = self.PCAModel.components_[eigVecInd,:].ravel()\n                lowPrecentileImage[self.objectPixels]  = self.ReconstructUsingModel(currLowPrecentileRepVec).ravel()\n                medianImage[self.objectPixels]         = self.ReconstructUsingModel(medianRepVec).ravel()\n                highPrecentileImage[self.objectPixels] = self.ReconstructUsingModel(currHighPrecentileRepVec).ravel()\n\n                # calculate the Gaussian smoothed distribution of values along the eignevector direction\n                sigmaOfKDE = 0.12\n                pdfStart   = min(self.dataRepresentation[:,eigVecInd]) - 3*sigmaOfKDE\n                pdfStop    = max(self.dataRepresentation[:,eigVecInd]) + 3*sigmaOfKDE\n                xAxis = np.linspace(pdfStart,pdfStop,200)\n                PDF_Model = KernelDensity(kernel='gaussian', bandwidth=sigmaOfKDE).fit(self.dataRepresentation[:,eigVecInd].reshape(-1,1))\n                logPDF = PDF_Model.score_samples(xAxis.reshape(-1,1))\n\n                # show distribution of current component \n                plt.subplot(5,numVarsPerFigure,0*numVarsPerFigure+plotCol+1)\n                plt.fill(xAxis, np.exp(logPDF), fc='b', alpha=0.9);\n                plt.title('%.3f%s explained' %(100*self.PCAModel.explained_variance_ratio_[eigVecInd], '%'))\n                \n                # show variance direction (eigenvector)\n                plt.subplot(5,numVarsPerFigure,1*numVarsPerFigure+plotCol+1);\n                if showAsTraces:\n                    plt.plot(deltaImage); plt.title('eigenvector ' + str(eigVecInd))\n                elif np.shape(self.objectPixels)[2] == 3:\n                    deltaImage = 0.1/deltaImage.std()*deltaImage+0.5\n                    deltaImage[deltaImage>1] = 1.0\n                    deltaImage[deltaImage<0] = 0.0\n                    plt.imshow(deltaImage); plt.title('eigenvector ' + str(eigVecInd)); plt.axis('off')\n                else:\n                    plt.imshow(deltaImage); plt.title('eigenvector ' + str(eigVecInd)); plt.axis('off')\n\n                # show 2nd precentile image\n                plt.subplot(5,numVarsPerFigure,2*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(lowPrecentileImage); plt.title('2nd precentile')\n                elif np.shape(self.objectPixels)[2] == 3:\n                    lowPrecentileImage[lowPrecentileImage>1] = 1.0\n                    lowPrecentileImage[lowPrecentileImage<0] = 0.0\n                    plt.imshow(lowPrecentileImage); plt.title('2nd precentile'); plt.axis('off')\n                else:\n                    plt.imshow(lowPrecentileImage, cmap='gray'); plt.title('2nd precentile'); plt.axis('off')\n\n                # show median image\n                plt.subplot(5,numVarsPerFigure,3*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(medianImage); plt.title('median')\n                else:\n                    plt.imshow(medianImage, cmap='gray'); plt.title('median'); plt.axis('off')\n\n                # show 98th precentile image\n                plt.subplot(5,numVarsPerFigure,4*numVarsPerFigure+plotCol+1)\n                if showAsTraces:\n                    plt.plot(highPrecentileImage); plt.title('98th precentile')\n                elif np.shape(self.objectPixels)[2] == 3:\n                    highPrecentileImage[highPrecentileImage>1] = 1.0\n                    highPrecentileImage[highPrecentileImage<0] = 0.0\n                    plt.imshow(highPrecentileImage); plt.title('98th precentile'); plt.axis('off')\n                else:\n                    plt.imshow(highPrecentileImage, cmap='gray'); plt.title('98th precentile'); plt.axis('off')\n            plt.tight_layout()\n        \n            \n    # shows distrbution along the variance directions and several images along that variance direction\n    def ShowSingleComponentVariation(self, X, listOfComponents=[0,1]):\n        #matplotlib.rcParams['font.size'] = 14\n\n        showAsTraces = (np.shape(self.objectPixels)[0] == 1)\n        assert(all([(x in range(self.numBasisFunctions)) for x in listOfComponents]))\n                \n        X_rep = self.RepresentUsingModel(X)\n        \n        percentilesToShow = [1,10,30,70,90,99]\n        numReadDataSamplePerPercentile = 4\n        representationPercentiles = []\n        for percentile in percentilesToShow:\n            representationPercentiles.append(np.percentile(self.dataRepresentation, percentile, axis=0))\n        medianRepVec =  np.percentile(self.dataRepresentation, 50, axis=0)\n\n        for eigVecInd in listOfComponents:\n            plt.figure(); gs = gridspec.GridSpec(numReadDataSamplePerPercentile+2,len(percentilesToShow))\n\n            # calculate the Gaussian smoothed distribution of values along the eignevector direction\n            sigmaOfKDE = 0.12\n            pdfStart   = min(self.dataRepresentation[:,eigVecInd]) - 3*sigmaOfKDE\n            pdfStop    = max(self.dataRepresentation[:,eigVecInd]) + 3*sigmaOfKDE\n            xAxis = np.linspace(pdfStart,pdfStop,200)\n            PDF_Model = KernelDensity(kernel='gaussian', bandwidth=sigmaOfKDE).fit(self.dataRepresentation[:,eigVecInd].reshape(-1,1))\n            logPDF = PDF_Model.score_samples(xAxis.reshape(-1,1))\n            percentileValuesToShow = [representationPercentiles[x][eigVecInd] for x in range(len(representationPercentiles))]\n            percentilesToShowLogPDF = PDF_Model.score_samples(np.array(percentileValuesToShow).reshape(-1,1))\n\n            # show distribution of current component and red dots at the list of precentiles to show \n            plt.subplot(gs[0,:])\n            plt.fill(xAxis, np.exp(logPDF), fc='b', alpha=0.9);\n            plt.scatter(percentileValuesToShow, np.exp(percentilesToShowLogPDF), c='r',s=300);\n            plt.title('%.3f%s explained' %(100*self.PCAModel.explained_variance_ratio_[eigVecInd], '%'))\n            \n            for plotCol, currPrecentile in enumerate(percentilesToShow):                \n                currPrecentileRepVec             = medianRepVec.copy()\n                currPrecentileRepVec[eigVecInd]  = representationPercentiles[plotCol][eigVecInd]\n                \n                currPrecentileImage = np.zeros(np.shape(self.objectPixels))\n                currPrecentileImage[self.objectPixels]  = self.ReconstructUsingModel(currPrecentileRepVec).ravel()\n                \n                # show the median image with current precentile as activation of the curr image\n                plt.subplot(gs[1,plotCol]);\n                if showAsTraces:\n                    plt.plot(currPrecentileImage); plt.title('precentile: ' + str(percentilesToShow[plotCol]) + '%')\n                elif np.shape(self.objectPixels)[2] == 3:\n                    currPrecentileImage[currPrecentileImage>1] = 1.0\n                    currPrecentileImage[currPrecentileImage<0] = 0.0\n                    plt.imshow(currPrecentileImage); plt.title('precentile: ' + str(percentilesToShow[plotCol]) + '%'); plt.axis('off')\n                else:\n                    plt.imshow(currPrecentileImage, cmap='gray'); plt.title('precentile: ' + str(percentilesToShow[plotCol]) + '%'); plt.axis('off')\n\n                # find the most suitible candidates in X for current precentile\n                distFromPercentile = abs(X_rep[:,eigVecInd] - representationPercentiles[plotCol][eigVecInd])\n                X_inds = np.argpartition(distFromPercentile, numReadDataSamplePerPercentile)[:numReadDataSamplePerPercentile]\n                for k, X_ind in enumerate(X_inds):\n                    currNearestPrecentileImage = np.zeros(np.shape(self.objectPixels))\n                    currNearestPrecentileImage[self.objectPixels]  = X[X_ind,:].ravel()\n                    \n                    plt.subplot(gs[2+k,plotCol]);\n                    if showAsTraces:\n                        plt.plot(currNearestPrecentileImage); plt.title('Close Neighbor');\n                    else:\n                        plt.imshow(currNearestPrecentileImage, cmap='gray'); plt.title('Close Neighbor'); plt.axis('off')\n            plt.tight_layout()\n\n            \n    # show the scatter plot of the first 2 PC components and and approximation of all PC compents scatter using t-SNE \n    def ShowDataScatterPlotsWithTSNE(self, X=None, y=None, colorMap='Paired', pointSize=120, pointAlpha=0.9):\n        \n        if X is None:\n            X_rep = self.dataRepresentation\n        else:\n            X_rep = self.RepresentUsingModel(X)\n            \n        if y is None:\n            y = np.ones(X_rep.shape[0])\n            \n        tSNE_PCAModel = TSNE(n_components=2, random_state=0)\n        X_rep_tSNE = tSNE_PCAModel.fit_transform(X_rep) \n        \n        plt.figure()\n        plt.subplot(1,2,1); plt.scatter(X_rep[:,0],X_rep[:,1],c=y,cmap=colorMap,s=pointSize,alpha=pointAlpha)\n        plt.title('PCA representation'); plt.xlabel('PC1 coeff'); plt.ylabel('PC2 coeff')\n        plt.subplot(1,2,2); plt.scatter(X_rep_tSNE[:,0],X_rep_tSNE[:,1],c=y,cmap=colorMap,s=pointSize,alpha=pointAlpha)\n        plt.title('t-SNE representation'); plt.xlabel('t-SNE axis1'); plt.ylabel('t-SNE axis2')\n        \n        self.tSNE_embedding = tSNE_PCAModel.embedding_"},{"cell_type":"markdown","metadata":{"_uuid":"8510f5b842662c6e394a9e52d1b57a74c15d1aeb","_cell_guid":"a1a6af7a-cc6c-5412-d46d-cb149d190543"},"source":"## Build The Gaussian Model\n\na Multivariate Gaussian model essentially models the mean data sample and the co-variance matrix of the data distribution. This can be reformulated as several variance \"directions\" along which the mean data sample can vary in an independent fashion."},{"cell_type":"code","metadata":{"_uuid":"faf19c20cab415c5338da48c08a3ff4c40f0e3a3","collapsed":true,"_cell_guid":"a4d226a7-ca0f-d9e8-183d-9214363f4c95"},"execution_count":null,"outputs":[],"source":"objectPixels = np.ones((np.shape(fullImageMatrix4D)[0],np.shape(fullImageMatrix4D)[1],np.shape(fullImageMatrix4D)[2]))\nsampleDim = objectPixels.size\nX = fullImageMatrix4D.reshape(sampleDim,-1).T\n\nface_PCAModel = GaussianModel(X, numBasisFunctions=120, objectPixels=(objectPixels==1))"},{"cell_type":"markdown","metadata":{"_uuid":"ce1339f7d2bf124bae573e5cd91df918c3987203","_cell_guid":"1d340609-ee80-1654-43ac-22194c733666"},"source":"----------\n\n***NOTE FOR POTENTIAL FORKERS***: if you change \"numBasisFunctions=120\" to be for example \"numBasisFunctions=40\" (or any other number), you will get different quality reconstructions. Generally, one should play around with this value and see what is happening. you can fork and play around.\n\n----------\n\n## Now lets look at the main variance \"directions\" of the Gaussian Model (PCA)\n\nEach image is a different \"direction\" in the high dimensional image space, and we should think of it as adding or subtracting a little bit of that image to the mean face image"},{"cell_type":"code","metadata":{"_uuid":"df8d05e1a34630b61210bc490658c1e532102a3e","collapsed":true,"_cell_guid":"2824e9af-1fc6-9ee4-fc5f-93f213cfc0e3"},"execution_count":null,"outputs":[],"source":"matplotlib.rcParams['font.size'] = 8\nmatplotlib.rcParams['figure.figsize'] = (12,12)\n\nface_PCAModel.ShowVarianceDirections(numDirectionsToShow=16)"},{"cell_type":"markdown","metadata":{"_uuid":"c0cc139b33ea90333a2fa3adb7df0d82dbea6e73","_cell_guid":"0a88e26b-e122-6a71-13a0-7faf2b8f160b"},"source":"----------\n\n***NOTE FOR POTENTIAL FORKERS***: if you change \"numDirectionsToShow=16\" to be for example \"numBasisFunctions=32\" you will get more eigenvectors. you can fork and play around.\n\n----------\n\n\n## Lets see how well can a 120 component PCA model reconstruct the original images"},{"cell_type":"code","metadata":{"_uuid":"870ed9716d5baa77c79ff1026f02f1639020868d","collapsed":true,"_cell_guid":"e4941559-91a3-991b-c2cc-c6b0d77e0f62"},"execution_count":null,"outputs":[],"source":"matplotlib.rcParams['font.size'] = 8\nmatplotlib.rcParams['figure.figsize'] = (14,8)\n\nface_PCAModel.ShowReconstructions(X, numReconstructions=12)"},{"cell_type":"markdown","metadata":{"_uuid":"6e06063f7277cb97831b03dd8231154a500c0a05","_cell_guid":"28840212-f5c8-758c-9c42-c590b2f27bf7"},"source":"we can see that by trying to reconstruct original image using a linear combination of only 120 images we are able to get a fairly good reconstruction of players. Usually, the better reconstruction one can get with a fewer number of components implies that there are a lot of dependencies in the data (i.e. a lot of correlated pixels)\n\n----------\n\n## Let's look at how the the face images vary around the mean face image:"},{"cell_type":"code","metadata":{"_uuid":"8fd75511fee7a44e431b7ddf1e8e660c5d0d5384","collapsed":true,"_cell_guid":"6a3aefdf-90f9-0900-f6cd-9623f48bd942"},"execution_count":null,"outputs":[],"source":"matplotlib.rcParams['font.size'] = 7\nmatplotlib.rcParams['figure.figsize'] = (12,9)\n\nface_PCAModel.ShowModelVariations(numVariations=6)"},{"cell_type":"markdown","metadata":{"_uuid":"a593948651cfaef0f2047cb771afde579909bee6","_cell_guid":"72bf52ec-15a6-94f2-23ec-3e5e9650a2a9"},"source":"**For those of us unfamiliar with this kind of a plot and since this is quite a busy plot, let me explain what we see:**\n------------------------------------------------------------------------\n  \n\n\n----------\n\n\n - The upper most row contains the data distributions of each eigenvector (i.e. the histogram along that \"direction\")\n - The second row contains what we already saw in a previous plot, what we called the variance directions.\n - The forth row contains the median image of leafs. notice that this row is identical for all eigenvectors\n - The third row holds the 2nd percentile images of each eigenvector. it's easier to think of this as the median image minus the eigenvector image multiplied by some constant. i.e the image we see is the forth row image, minus the second row image, when the second row image is multiplied by a constant. The constant is chosen to show the varying degree of influence of this specific eigenvector on the \"average\" image, so we can visualize what type of variation this particular eigenvector tends to capture. 2nd percentile will subtract a relatively large absolute value from the median image, showing us what images look like when this coefficient is highly negative. 98th percentile would be just the opposite, showing us what images look like when this coefficient is at the upper end of the range. 50th percentile would give us a \"middle of the road\" effect of this coefficient.\n\n\n----------\n\n\nThis plot helps us visualize what a direction in this high dimensional image space means. For example:\n\n - **The first eigenvector** (leftmost column), we can see\n   that it **controls the difference between dark skinned players and light skinned players**. i.e we can say that some of the variance along the change of skin color is explained by this component.\n\n - **The second eigenvector** (second from the left), we can see\n   that it **controls the difference between male and female players**. i.e we can say that some of the variance along the change of player sex is explained by this component.\n\n----------\n\nWe can now deep deeper into some interesting looking eigenvectors"},{"cell_type":"markdown","metadata":{"_uuid":"ea3e8316bdd65fb38ff419b2aa259e7a5e53774d","_cell_guid":"d89a0495-c25b-f8fa-fefe-693196d92323"},"source":"**Eigenvector 1: dark skinned or light skinned?**\n-------------------------------------------------"},{"cell_type":"code","metadata":{"_uuid":"d413846316211466c52588265f5ba4d4f21bfd91","collapsed":true,"_cell_guid":"ae134d2a-20df-5049-a891-751fa0017dce"},"execution_count":null,"outputs":[],"source":"matplotlib.rcParams['font.size'] = 7\nmatplotlib.rcParams['figure.figsize'] = (12,10)\n\nface_PCAModel.ShowSingleComponentVariation(X, listOfComponents=[0])"},{"cell_type":"markdown","metadata":{"_uuid":"5d9010c3c098f88d4d865f36eb2fa8d467f2f572","_cell_guid":"486178de-8ea9-9004-4f50-a70aa27050a6"},"source":"**Let me explain this plot:**\n\n - at the top row we can see the distribution of the coefficient along\n   this particular variance direction.\n - at the second row we can see percentile images that correspond to\n   different red dots in the distribution.\n - the four bottom rows contain nearest neighbor images from the data\n   itself that are closest to the percentile images above (4 nearest\n   neighbors for each percentile image)\n\n----------\n\n**Eigenvector 2: male or female?**\n-------------------------------------------"},{"cell_type":"code","metadata":{"_uuid":"e4f564216f8f317fe723fd3c81037244c3df1964","collapsed":true,"_cell_guid":"c3a06427-63ad-4bb5-e6cf-b4f72df5334c"},"execution_count":null,"outputs":[],"source":"matplotlib.rcParams['font.size'] = 7\nmatplotlib.rcParams['figure.figsize'] = (12,10)\n\nface_PCAModel.ShowSingleComponentVariation(X, listOfComponents=[1])"},{"cell_type":"markdown","metadata":{"_uuid":"1c640675b9415ac07535885bf5c39828c3f4b0f9","_cell_guid":"13811983-3e6b-9d61-391f-b23eb423c69d"},"source":"**Eigenvector 11: dim or bright lighting? (perhaps indoor vs outdoor)**\n------------------------------------------"},{"cell_type":"code","metadata":{"_uuid":"01720f00890dc56bb7c129336f9c8a7336c3c7b2","collapsed":true,"_cell_guid":"ed0d3906-e4c7-c376-e00c-71796a415d32"},"execution_count":null,"outputs":[],"source":"matplotlib.rcParams['font.size'] = 7\nmatplotlib.rcParams['figure.figsize'] = (12,10)\n\nface_PCAModel.ShowSingleComponentVariation(X, listOfComponents=[10])"},{"cell_type":"markdown","metadata":{"_uuid":"d2bfe4aaba5ba8f8180f4963d0be547865e9d734","_cell_guid":"50f04a3a-82d1-f50d-bfde-3e94c2e78d98"},"source":"----------\n\n***NOTE FOR POTENTIAL FORKERS***: if you change \"listOfComponents=[10]\" to be for example \"listOfComponents=[10,11,12]\" you will get to see these plots for eigenvectors 11,12 and 13. You can fork and play around if you find any interesting components.\n\n----------"},{"cell_type":"markdown","metadata":{"_uuid":"f1f9004d8d7cd7860f8fadd00f7a69ff870ff294","_cell_guid":"7ccb4223-cb0c-e3e6-33f4-8946490c9dbb"},"source":"Now lets collect some attributes from 'FullData.csv' for the players we have also face images for"},{"cell_type":"code","metadata":{"_uuid":"46d465472c9e49f2a136a8bce1e1c477ebd2e844","collapsed":true,"_cell_guid":"5277dac4-d79f-ae9a-a7a9-323e6757847e"},"execution_count":null,"outputs":[],"source":"#%% for every player that we have a picture for, get his data from \"FullData.csv\" (if present)\nplayerData = pd.read_csv('../input/FullData.csv').drop_duplicates(subset='Name', keep='last').reset_index(drop=True)\n\nlistOfAllPlayerNames = playerData['Name'].tolist()\nrecordRowInds = [listOfAllPlayerNames.index(x) if x in listOfAllPlayerNames else 'False' for x in listOfPlayerNames]\n\ndesiredColumns = ['Name', 'Nationality', 'Sex', 'Age [years]', 'Height [cm]', 'Weight [kg]']\nplayerWithPicsData = pd.DataFrame(index=range(len(listOfPlayerNames)),columns=desiredColumns)\nplayerWithPicsData.loc[:,'Name'] = [x for x in listOfPlayerNames]\nplayerWithPicsData.loc[:,'Sex']  = ['Female' if x else 'Male' for x in isFemale]\n\nfor k, currRowInd in enumerate(recordRowInds):\n    if currRowInd != 'False':\n        playerWithPicsData.loc[k,'Age [years]'] = float(playerData.loc[currRowInd, 'Age'])\n        playerWithPicsData.loc[k,'Height [cm]'] = float(playerData.loc[currRowInd, 'Height'].split(' ')[0])\n        playerWithPicsData.loc[k,'Weight [kg]'] = float(playerData.loc[currRowInd, 'Weight'].split(' ')[0])\n        playerWithPicsData.loc[k,'Nationality'] = playerData.loc[currRowInd, 'Nationality']\n    \n# extract face features\nfaceFeatures = face_PCAModel.RepresentUsingModel(X)\n\nplayerWithPicsData.head(10)"},{"cell_type":"code","metadata":{"_uuid":"958a5ba6bf957eac4bb4ee7b53549af7dcad1d25","collapsed":true,"_cell_guid":"3676550d-12a4-3ff0-4357-956375c6f681"},"execution_count":null,"outputs":[],"source":"playerWithPicsData.tail()"},{"cell_type":"markdown","metadata":{"_uuid":"9df4486216a9bb0acf70299d196b9d95442ffa96","_cell_guid":"47271ead-4101-20f9-b924-b2f30fb51c12"},"source":"## Plot the correlation between different attributes and the different PCA components"},{"cell_type":"code","metadata":{"_uuid":"63c038aaed028a381a05354921e6c42a99e2e337","collapsed":true,"_cell_guid":"a45264f0-68b4-9502-d5ef-4e37a3e0243b"},"execution_count":null,"outputs":[],"source":"# find the PCA component that most correlates with 'Sex'\nreleventCols = np.array(playerWithPicsData.loc[:,'Sex'].notnull())\ntargetFeature = np.array(playerWithPicsData.loc[releventCols,'Sex'] == 'Male')[:,np.newaxis]\ncorrWithSexVec = np.corrcoef(np.hstack((targetFeature,faceFeatures[releventCols,:])).T)[0,1:]\nmostCorrelatedWithSex = np.argmax(abs(corrWithSexVec))\n\n# find the PCA component that most correlates with 'Age'\nreleventCols = np.array(playerWithPicsData.loc[:,'Age [years]'].notnull())\ntargetFeature = np.array(playerWithPicsData.loc[releventCols,'Age [years]'].tolist())[:,np.newaxis]\ncorrWithAgeVec = np.corrcoef(np.hstack((targetFeature,faceFeatures[releventCols,:])).T)[0,1:]\nmostCorrelatedWithAge = np.argmax(abs(corrWithAgeVec))\n\n# find the PCA component that most correlates with 'Height'\nreleventCols = np.array(playerWithPicsData.loc[:,'Height [cm]'].notnull())\ntargetFeature = np.array(playerWithPicsData.loc[releventCols,'Height [cm]'].tolist())[:,np.newaxis]\ncorrWithHeightVec = np.corrcoef(np.hstack((targetFeature,faceFeatures[releventCols,:])).T)[0,1:]\nmostCorrelatedWithHeight = np.argmax(abs(corrWithHeightVec))\n\n# find the PCA component that most correlates with 'Weight'\nreleventCols = np.array(playerWithPicsData.loc[:,'Weight [kg]'].notnull())\ntargetFeature = np.array(playerWithPicsData.loc[releventCols,'Weight [kg]'].tolist())[:,np.newaxis]\ncorrWithWeightVec = np.corrcoef(np.hstack((targetFeature,faceFeatures[releventCols,:])).T)[0,1:]\nmostCorrelatedWithWeight = np.argmax(abs(corrWithWeightVec))\n\nmatplotlib.rcParams['font.size'] = 8\nmatplotlib.rcParams['figure.figsize'] = (12,12)\n\nplt.figure()\nplt.subplot(4,1,1); plt.plot(np.abs(corrWithSexVec)); \nplt.ylim(-0.02,1); plt.ylabel('with Sex')\nplt.subplot(4,1,2); plt.plot(np.abs(corrWithAgeVec)); \nplt.ylim(-0.02,1); plt.ylabel('with Age')\nplt.subplot(4,1,3); plt.plot(np.abs(corrWithHeightVec)); \nplt.ylim(-0.02,1); plt.ylabel('with Height')\nplt.subplot(4,1,4); plt.plot(np.abs(corrWithWeightVec)); \nplt.ylim(-0.02,1); plt.ylabel('with Weight')\nplt.xlabel('PCA coefficient index')\nplt.suptitle('How different PCA Components correlate with real life attributes?')"},{"cell_type":"markdown","metadata":{"_uuid":"f9efc86c10f0ef42c30cca7fe21cdba1e0ce8e11","_cell_guid":"46690aca-f697-4dd8-5d81-94dbe61d2de7"},"source":"We can see that there are **no clear high correlations** except for those that we already previously saw between male and females. **too bad**. \nI suspect we will see some correlations with the Nationality field if we further divide it into continents, but I leave it to you to investigate this if you wish.\n\n----------\n\n\nTo conclude, I hope that the fact that we can use **almost exactly the same code and analysis tools** as in [Visualizing PCA][1] script and get quick a feel for how players look like as well as how leaves look like demonstrates **the incredible power of basic visualization techniques** such as we presented here. I hope everyone reading this will use some of these techniques in the future :-)\n\n\n  [1]: https://www.kaggle.com/selfishgene/leaf-classification/visualizing-pca-with-leaf-dataset"}]}