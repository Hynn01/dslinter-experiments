{"cells":[{"metadata":{"_uuid":"32c4540d5c17dd49f01fda65a0123429d4766185"},"cell_type":"markdown","source":"# CareerCon 2019 - Help Navigate Robots\n## Robots are smart… by design !!\n\n![](https://www.lextronic.fr/imageslib/4D/0J7589.320.gif)\n\n---\n\nRobots are smart… by design. To fully understand and properly navigate a task, however, they need input about their environment.\n\nIn this competition, you’ll help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors).\n\nWe’ve collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises. The task is to predict which one of the nine floor types (carpet, tiles, concrete) the robot is on using sensor data such as acceleration and velocity. Succeed and you'll help improve the navigation of robots without assistance across many different surfaces, so they won’t fall down on the job.\n\n###  Its a golden chance to help humanity, by helping Robots !\n\n<br>\n<img src=\"https://media2.giphy.com/media/EizPK3InQbrNK/giphy.gif\" border=\"1\" width=\"400\" height=\"300\">"},{"metadata":{"_uuid":"de888bce663ba641995d030d0dcdd95360cb6a28"},"cell_type":"markdown","source":"<br>\n# DATA"},{"metadata":{"_uuid":"e9b0d04e4f2b6a9d5a0d1055419050a7655a7ca8"},"cell_type":"markdown","source":"**X_[train/test].csv** - the input data, covering 10 sensor channels and 128 measurements per time series plus three ID columns:\n\n- ```row_id```: The ID for this row.\n\n- ```series_id: ID``` number for the measurement series. Foreign key to y_train/sample_submission.\n\n- ```measurement_number```: Measurement number within the series.\n\nThe orientation channels encode the current angles how the robot is oriented as a quaternion (see Wikipedia). Angular velocity describes the angle and speed of motion, and linear acceleration components describe how the speed is changing at different times. The 10 sensor channels are:\n\n```\norientation_X\n\norientation_Y\n\norientation_Z\n\norientation_W\n\nangular_velocity_X\n\nangular_velocity_Y\n\nangular_velocity_Z\n\nlinear_acceleration_X\n\nlinear_acceleration_Y\n\nlinear_acceleration_Z\n```\n\n**y_train.csv** - the surfaces for training set.\n\n- ```series_id```: ID number for the measurement series.\n\n- ```group_id```: ID number for all of the measurements taken in a recording session. Provided for the training set only, to enable more cross validation strategies.\n\n- ```surface```: the target for this competition.\n\n**sample_submission.csv** - a sample submission file in the correct format."},{"metadata":{"_uuid":"88fc88965190e2cd530b27eed932a64ededa4d24"},"cell_type":"markdown","source":"### Load packages"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom time import time\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib import rcParams\n%matplotlib inline\nle = preprocessing.LabelEncoder()\nfrom numba import jit\nimport itertools\nfrom seaborn import countplot,lineplot, barplot\nfrom numba import jit\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn import preprocessing\nfrom scipy.stats import randint as sp_randint\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import LeaveOneGroupOut\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport matplotlib.style as style \nstyle.use('ggplot')\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport gc\ngc.enable()\n\n!ls ../input/\n!ls ../input/robots-best-submission\nprint (\"Ready !\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d76cf110d2434d03688b2cc6170d0f75b340cf43"},"cell_type":"markdown","source":"### Load data"},{"metadata":{"trusted":true,"_uuid":"f5fdc987f79035336b408413b3b3111d1b48fd2a","_kg_hide-input":true},"cell_type":"code","source":"data = pd.read_csv('../input/career-con-2019/X_train.csv')\ntr = pd.read_csv('../input/career-con-2019/X_train.csv')\nsub = pd.read_csv('../input/career-con-2019/sample_submission.csv')\ntest = pd.read_csv('../input/career-con-2019/X_test.csv')\ntarget = pd.read_csv('../input/career-con-2019/y_train.csv')\nprint (\"Data is ready !!\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_uuid":"c49cf65c83506e6f1cdbf049770740c224b2f710"},"cell_type":"markdown","source":"# Data exploration"},{"metadata":{"_uuid":"b09576a89afcccb0ace8841e1b4a14142054ed1b","trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9c0b9ad768f90783be27d56afc9aa1f115a3d85e"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c13bbb57f94f994192d098fe06ff1bddb0a97e5e","trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbc403dd007803ef8f1d4bf22f310e75d2fe6410"},"cell_type":"code","source":"len(data.measurement_number.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ad813b0402fd2456e39da99c394db358a725b3c"},"cell_type":"markdown","source":"Each series has 128 measurements. \n\n**1 serie = 128 measurements**. \n\nFor example, serie with series_id=0 has a surface = *fin_concrete* and 128 measurements."},{"metadata":{"_uuid":"5d08e46ff34ccc728b50ffb6361dc0dd756f66d6"},"cell_type":"markdown","source":"### describe (basic stats)"},{"metadata":{"_uuid":"a82a4fcfd7b086e5dfd2dabf56bf631c176a6eb1","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c3a4a4564428f8c470983f5dbb6cf3d70135aad","trusted":false},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae7e4ecb648eb745fe29ced1f41e63c682fefeef"},"cell_type":"code","source":"target.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"415e07220d00de24101ff63203ede09344cb7654"},"cell_type":"markdown","source":"### There is missing data in test and train data"},{"metadata":{"_uuid":"bfc230e8283491c2cfe124b6c5c2a08f7560a14a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"totalt = data.isnull().sum().sort_values(ascending=False)\npercent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([totalt, percent], axis=1, keys=['Total', 'Percent'])\nprint (\"Missing Data at Training\")\nmissing_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4bdd12a7223d80e2d4c6c9be217935a5b80d526","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"totalt = test.isnull().sum().sort_values(ascending=False)\npercent = (test.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([totalt, percent], axis=1, keys=['Total', 'Percent'])\nprint (\"Missing Data at Test\")\nmissing_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5df358d1c6e20ef11dceeae075d2baf43637e493","_kg_hide-input":true},"cell_type":"code","source":"print (\"Test has \", (test.shape[0]-data.shape[0])/128, \"series more than Train (later I will prove it) = 768 registers\")\ndif = test.shape[0]-data.shape[0]\nprint (\"Let's check this extra 6 series\")\ntest.tail(768).describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"292032ddce3cd9a1e13bb293f54a8e13110a172d"},"cell_type":"markdown","source":"If we look at the features: orientation, angular velocity and linear acceleration, we can see big differences between **max** and **min** from entire test vs 6 extra test's series (see **linear_acceleration_Z**).\n\nObviously we are comparing 3810 series vs 6 series so this is not a big deal."},{"metadata":{"_uuid":"bf7a6fae6a923c8dfcc5109c3046ae0df69acf7e"},"cell_type":"markdown","source":"### goup_id will be important !!"},{"metadata":{"trusted":true,"_uuid":"201702606eafc959122328907ef5bc4ef79cce4c"},"cell_type":"code","source":"target.groupby('group_id').surface.nunique().max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69b96a79cf5e50e271fa806ecd9bf740aaecf7b5"},"cell_type":"code","source":"target['group_id'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82a6003aa08750f8a54bbe198138eb93391f8c07"},"cell_type":"markdown","source":"**73 groups**\n**Each group_id is a unique recording session and has only one surface type **"},{"metadata":{"trusted":true,"_uuid":"a269f0dee43e08548387036415ccd35e8eff0fbf","_kg_hide-input":true},"cell_type":"code","source":"sns.set(style='darkgrid')\nsns.countplot(y = 'surface',\n              data = target,\n              order = target['surface'].value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"### Target feature - surface and group_id distribution\nLet's show now the distribution of target feature - surface and group_id.\nby @gpreda."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(26,8))\ntmp = pd.DataFrame(target.groupby(['group_id', 'surface'])['series_id'].count().reset_index())\nm = tmp.pivot(index='surface', columns='group_id', values='series_id')\ns = sns.heatmap(m, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ns.set_title('Number of surface category per group_id', size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7d6a731deca66f053bcd2ce8b967f75d3c7cb55"},"cell_type":"markdown","source":"We need to classify on which surface our robot is standing.\n\nMulti-class Multi-output\n\n9 classes (suface)"},{"metadata":{"trusted":true,"_uuid":"e7f84ce27858bf7ca2124c387c6b57622e62d268","_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(23,5)) \nsns.set(style=\"darkgrid\")\ncountplot(x=\"group_id\", data=target, order = target['group_id'].value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22cbfad75b65c3d1325bc212e458517fb48271a9"},"cell_type":"markdown","source":"**So, we have 3810 train series, and 3816 test series.\nLet's engineer some features!**\n\n## Example: Series 1\n\nLet's have a look at the values of features in a single time-series, for example series 1  ```series_id=0```\n\nClick to see all measurements of the **first series** "},{"metadata":{"trusted":true,"_uuid":"522f9517178318b63b1a04d60b89ff0255c340b9","_kg_hide-output":true,"_kg_hide-input":false},"cell_type":"code","source":"serie1 = tr.head(128)\nserie1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5747f4f7685cfc8508146c8766d653d017e5d3ff","_kg_hide-input":true},"cell_type":"code","source":"serie1.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9789905b315de7f991a2556d42555301b824ec0","_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(26, 16))\nfor i, col in enumerate(serie1.columns[3:]):\n    plt.subplot(3, 4, i + 1)\n    plt.plot(serie1[col])\n    plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this example, we can see a quite interesting performance:\n1. Orientation X increases\n2. Orientation Y decreases\n3. We don't see any kind of pattern except for linear_acceleration_Y\n\nAnd we know that in this series, the robot moved throuh \"fine_concrete\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head(1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"6e9b98b9eaf71df046376bd73828213334e44228"},"cell_type":"code","source":"del serie1\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing Series\n\nBefore, I showed you as an example the series 1.\n\n**This code allows you to visualize any series.**\n\nFrom: *Code Snippet For Visualizing Series Id by @shaz13*"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"series_dict = {}\nfor series in (data['series_id'].unique()):\n    series_dict[series] = data[data['series_id'] == series]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plotSeries(series_id):\n    style.use('ggplot')\n    plt.figure(figsize=(28, 16))\n    print(target[target['series_id'] == series_id]['surface'].values[0].title())\n    for i, col in enumerate(series_dict[series_id].columns[3:]):\n        if col.startswith(\"o\"):\n            color = 'red'\n        elif col.startswith(\"a\"):\n            color = 'green'\n        else:\n            color = 'blue'\n        if i >= 7:\n            i+=1\n        plt.subplot(3, 4, i + 1)\n        plt.plot(series_dict[series_id][col], color=color, linewidth=3)\n        plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, Let's see code for series 15 ( is an example, try what you want)**"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"id_series = 15\nplotSeries(id_series)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"del series_dict\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"963cf57a97a9fb7d2d8de783ab6b5b5534528a62"},"cell_type":"markdown","source":"<br>\n### Correlations (Part I)"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"350fad123d6f263143b755e87907466125d0873a"},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(tr.iloc[:,3:].corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5fcebd7ab6c85869f78f9b2cc879245a4678c15"},"cell_type":"markdown","source":"**Correlations test (click \"code\")** "},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true,"scrolled":true,"_uuid":"4a6390d7c94e53c7d91130de89b4150ff4db1858"},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(test.iloc[:,3:].corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cef8898b944df80a038dfd557eb543ece43c59b"},"cell_type":"markdown","source":"Well, this is immportant, there is a **strong correlation** between:\n- angular_velocity_Z and angular_velocity_Y\n- orientation_X and orientation_Y\n- orientation_Y and orientation_Z\n\nMoreover, test has different correlations than training, for example:\n\n- angular_velocity_Z and orientation_X: -0.1(training) and 0.1(test). Anyway, is too small in both cases, it should not be a problem."},{"metadata":{},"cell_type":"markdown","source":"## Fourier Analysis\n\nMy hope was, that different surface types yield (visible) differences in the frequency spectrum of the sensor measurements.\n\nMachine learning techniques might learn frequency filters on their own, but why don't give the machine a little head start? So I computed the the cyclic FFT for the angular velocity and linear acceleration sensors and plotted mean and standard deviation of the absolute values of the frequency components per training surface category (leaving out the frequency 0 (i.e. constants like sensor bias, earth gravity, ...).\n\nThe sensors show some different frequency characterists (see plots below), but unfortunately the surface categories have all similar (to the human eye) shapes, varying mostly in total power, and the standard deviations are high (compared to differences in the means). So there are no nice strong characteristic peaks for surface types. But that does not mean, that there is nothing detectable by more sophisticated statistical methods.\n\nThis article http://www.kaggle.com/christoffer/establishing-sampling-frequency makes a convincing case, that the sampling frequency is around 400Hz, so according to that you would see the frequency range to 3-200 Hz in the diagrams (and aliased higher frequencies).\n\nby [@trohwer64](https://www.kaggle.com/trohwer64)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_x = pd.read_csv('../input/career-con-2019/X_train.csv')\ntrain_y = pd.read_csv('../input/career-con-2019/y_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import math\n\ndef prepare_data(t):\n    def f(d):\n        d=d.sort_values(by=['measurement_number'])\n        return pd.DataFrame({\n         'lx':[ d['linear_acceleration_X'].values ],\n         'ly':[ d['linear_acceleration_Y'].values ],\n         'lz':[ d['linear_acceleration_Z'].values ],\n         'ax':[ d['angular_velocity_X'].values ],\n         'ay':[ d['angular_velocity_Y'].values ],\n         'az':[ d['angular_velocity_Z'].values ],\n        })\n\n    t= t.groupby('series_id').apply(f)\n\n    def mfft(x):\n        return [ x/math.sqrt(128.0) for x in np.absolute(np.fft.fft(x)) ][1:65]\n\n    t['lx_f']=[ mfft(x) for x in t['lx'].values ]\n    t['ly_f']=[ mfft(x) for x in t['ly'].values ]\n    t['lz_f']=[ mfft(x) for x in t['lz'].values ]\n    t['ax_f']=[ mfft(x) for x in t['ax'].values ]\n    t['ay_f']=[ mfft(x) for x in t['ay'].values ]\n    t['az_f']=[ mfft(x) for x in t['az'].values ]\n    return t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=prepare_data(train_x)\nt=pd.merge(t,train_y[['series_id','surface','group_id']],on='series_id')\nt=t.rename(columns={\"surface\": \"y\"})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def aggf(d, feature):\n    va= np.array(d[feature].tolist())\n    mean= sum(va)/va.shape[0]\n    var= sum([ (va[i,:]-mean)**2 for i in range(va.shape[0]) ])/va.shape[0]\n    dev= [ math.sqrt(x) for x in var ]\n    return pd.DataFrame({\n        'mean': [ mean ],\n        'dev' : [ dev ],\n    })\n\ndisplay={\n'hard_tiles_large_space':'r-.',\n'concrete':'g-.',\n'tiled':'b-.',\n\n'fine_concrete':'r-',\n'wood':'g-',\n'carpet':'b-',\n'soft_pvc':'y-',\n\n'hard_tiles':'r--',\n'soft_tiles':'g--',\n}","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(14, 8*7))\n#plt.margins(x=0.0, y=0.0)\n#plt.tight_layout()\n# plt.figure()\n\nfeatures=['lx_f','ly_f','lz_f','ax_f','ay_f','az_f']\ncount=0\n\nfor feature in features:\n    stat= t.groupby('y').apply(aggf,feature)\n    stat.index= stat.index.droplevel(-1)\n    b=[*range(len(stat.at['carpet','mean']))]\n\n    count+=1\n    plt.subplot(len(features)+1,1,count)\n    for i,(k,v) in enumerate(display.items()):\n        plt.plot(b, stat.at[k,'mean'], v, label=k)\n        # plt.errorbar(b, stat.at[k,'mean'], yerr=stat.at[k,'dev'], fmt=v)\n   \n    leg = plt.legend(loc='best', ncol=3, mode=\"expand\", shadow=True, fancybox=True)\n    plt.title(\"sensor: \" + feature)\n    plt.xlabel(\"frequency component\")\n    plt.ylabel(\"amplitude\")\n\ncount+=1\nplt.subplot(len(features)+1,1,count)\nk='concrete'\nv=display[k]\nfeature='lz_f'\nstat= t.groupby('y').apply(aggf,feature)\nstat.index= stat.index.droplevel(-1)\nb=[*range(len(stat.at['carpet','mean']))]\n\nplt.errorbar(b, stat.at[k,'mean'], yerr=stat.at[k,'dev'], fmt=v)\nplt.title(\"sample for error bars (lz_f, surface concrete)\")\nplt.xlabel(\"frequency component\")\nplt.ylabel(\"amplitude\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"del train_x, train_y\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Is it an Humanoid Robot instead of a car?\n\n![](https://media1.giphy.com/media/on7ipUR0rFjRS/giphy.gif)\n\n**Acceleration**\n- X (mean at 0)\n- Y axis is centered at a value wich shows us the movement (straight ).\n- Z axis is centered at 10 (+- 9.8) wich is the gravity !! , you can see how the robot bounds.\n\nAngular velocity (X,Y,Z) has mean (0,0,0) so there is no lineal movement on those axis (measured with an encoder or potentiometer)\n\n**Fourier**\n\nWe can see: with a frequency 3 Hz we can see an acceleration, I think that acceleration represents one step.\nMaybe ee can suppose that every step is caused by many different movements, that's why there are different accelerations at different frequencies.\n\nAngular velocity represents spins. \nEvery time the engine/servo spins, the robot does an step - relation between acc y vel."},{"metadata":{"_uuid":"39d1a130f33eab27902537c5420009a79c3d5b5e"},"cell_type":"markdown","source":"---\n\n# Feature Engineering"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0a71fa5de75fe5999a5a29c133729ce98ce742ec"},"cell_type":"code","source":"def plot_feature_distribution(df1, df2, label1, label2, features,a=2,b=5):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(a,b,figsize=(17,9))\n\n    for feature in features:\n        i += 1\n        plt.subplot(a,b,i)\n        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59f47deb4bb7068e8f10cd452d7bb129147a9703","_kg_hide-input":true},"cell_type":"code","source":"features = data.columns.values[3:]\nplot_feature_distribution(data, test, 'train', 'test', features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e78ffb1cdc96434bdf09664e542d90282c2f27b"},"cell_type":"markdown","source":"Godd news, our basic features have the **same distribution (Normal) on test and training**. There are some differences between *orientation_X* , *orientation_Y* and *linear_acceleration_Y*.\n\nI willl try **StandardScaler** to fix this, and remember: orientation , angular velocity and linear acceleration are measured with different units, scaling might be a good choice."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"38e97acf34aee3ebf86e21ac47721235f5e97b0d"},"cell_type":"code","source":"def plot_feature_class_distribution(classes,tt, features,a=5,b=2):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(a,b,figsize=(16,24))\n\n    for feature in features:\n        i += 1\n        plt.subplot(a,b,i)\n        for clas in classes:\n            ttc = tt[tt['surface']==clas]\n            sns.kdeplot(ttc[feature], bw=0.5,label=clas)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c210ee38641ed22cb69d1dc667e7a49a6202158","_kg_hide-input":true},"cell_type":"code","source":"classes = (target['surface'].value_counts()).index\naux = data.merge(target, on='series_id', how='inner')\nplot_feature_class_distribution(classes, aux, features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c924937a209d671131f93d6b3b504e373a507f3"},"cell_type":"markdown","source":"**Normal distribution**\n\nThere are obviously differences between *surfaces* and that's good, we will focus on that in order to classify them better.\n\nKnowing this differences and that variables follow a normal distribution (in most of the cases) we need to add new features like: ```mean, std, median, range ...``` (for each variable).\n\nHowever, I will try to fix *orientation_X* and *orientation_Y* as I explained before, scaling and normalizing data.\n\n---\n\n### Now with a new scale (more more precision)"},{"metadata":{"trusted":true,"_uuid":"5648ba909b6e14e23ac7bcdf67c4ef394e41616a","_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(26, 16))\nfor i,col in enumerate(aux.columns[3:13]):\n    ax = plt.subplot(3,4,i+1)\n    ax = plt.title(col)\n    for surface in classes:\n        surface_feature = aux[aux['surface'] == surface]\n        sns.kdeplot(surface_feature[col], label = surface)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Histogram for main features"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(26, 16))\nfor i, col in enumerate(data.columns[3:]):\n    ax = plt.subplot(3, 4, i + 1)\n    sns.distplot(data[col], bins=100, label='train')\n    sns.distplot(test[col], bins=100, label='test')\n    ax.legend()   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94886bd81fcce921c227b1bea2b3bcbf1000af64"},"cell_type":"markdown","source":"## Step 0 : quaternions"},{"metadata":{"_uuid":"8e6b5a603fb6ab4a55aff3f0b9c78b91b1aafa94"},"cell_type":"markdown","source":"Orientation - quaternion coordinates\nYou could notice that there are 4 coordinates: X, Y, Z, W.\n\nUsually we have X, Y, Z - Euler Angles. But Euler Angles are limited by a phenomenon called \"gimbal lock,\" which prevents them from measuring orientation when the pitch angle approaches +/- 90 degrees. Quaternions provide an alternative measurement technique that does not suffer from gimbal lock. Quaternions are less intuitive than Euler Angles and the math can be a little more complicated.\n\nHere are some articles about it:\n\nhttp://www.chrobotics.com/library/understanding-quaternions\n\nhttp://www.tobynorris.com/work/prog/csharp/quatview/help/orientations_and_quaternions.htm\n\nBasically 3D coordinates are converted to 4D vectors."},{"metadata":{"trusted":true,"_uuid":"380379e7555eec39b2e1c0ce52e0d4f44e4d9cee"},"cell_type":"code","source":"# https://stackoverflow.com/questions/53033620/how-to-convert-euler-angles-to-quaternions-and-get-the-same-euler-angles-back-fr?rq=1\ndef quaternion_to_euler(x, y, z, w):\n    import math\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98e19f9744a025cad5c293ac4805973147763a59"},"cell_type":"code","source":"def fe_step0 (actual):\n    \n    # https://www.mathworks.com/help/aeroblks/quaternionnorm.html\n    # https://www.mathworks.com/help/aeroblks/quaternionmodulus.html\n    # https://www.mathworks.com/help/aeroblks/quaternionnormalize.html\n    \n    # Spoiler: you don't need this ;)\n    \n    actual['norm_quat'] = (actual['orientation_X']**2 + actual['orientation_Y']**2 + actual['orientation_Z']**2 + actual['orientation_W']**2)\n    actual['mod_quat'] = (actual['norm_quat'])**0.5\n    actual['norm_X'] = actual['orientation_X'] / actual['mod_quat']\n    actual['norm_Y'] = actual['orientation_Y'] / actual['mod_quat']\n    actual['norm_Z'] = actual['orientation_Z'] / actual['mod_quat']\n    actual['norm_W'] = actual['orientation_W'] / actual['mod_quat']\n    \n    return actual","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1144686aa67b816664135aa06c535abae0680b49"},"cell_type":"markdown","source":"\n> *Are there any reasons to not automatically normalize a quaternion? And if there are, what quaternion operations do result in non-normalized quaternions?*\n\nAny operation that produces a quaternion will need to be normalized because floating-point precession errors will cause it to not be unit length.\nI would advise against standard routines performing normalization automatically for performance reasons. \nAny competent programmer should be aware of the precision issues and be able to normalize the quantities when necessary - and it is not always necessary to have a unit length quaternion.\nThe same is true for vector operations.\n\nsource: https://stackoverflow.com/questions/11667783/quaternion-and-normalization"},{"metadata":{"trusted":true,"_uuid":"3e0487602f32048e3e4ef8d78872fd3a5c5ab212"},"cell_type":"code","source":"data = fe_step0(data)\ntest = fe_step0(test)\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"86af351b44a48c44d4c144a426c086808cebb6f2"},"cell_type":"code","source":"fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols=4, figsize=(18, 5))\n\nax1.set_title('quaternion X')\nsns.kdeplot(data['norm_X'], ax=ax1, label=\"train\")\nsns.kdeplot(test['norm_X'], ax=ax1, label=\"test\")\n\nax2.set_title('quaternion Y')\nsns.kdeplot(data['norm_Y'], ax=ax2, label=\"train\")\nsns.kdeplot(test['norm_Y'], ax=ax2, label=\"test\")\n\nax3.set_title('quaternion Z')\nsns.kdeplot(data['norm_Z'], ax=ax3, label=\"train\")\nsns.kdeplot(test['norm_Z'], ax=ax3, label=\"test\")\n\nax4.set_title('quaternion W')\nsns.kdeplot(data['norm_W'], ax=ax4, label=\"train\")\nsns.kdeplot(test['norm_W'], ax=ax4, label=\"test\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0555bc57a2e21e1c02d7e283b12b1a93e592e3e"},"cell_type":"markdown","source":"## Step 1: (x, y, z, w) -> (x,y,z)   quaternions to euler angles"},{"metadata":{"trusted":true,"_uuid":"ea2742c44f2dde37dbbc6ec771fe72edb7adcace"},"cell_type":"code","source":"def fe_step1 (actual):\n    \"\"\"Quaternions to Euler Angles\"\"\"\n    \n    x, y, z, w = actual['norm_X'].tolist(), actual['norm_Y'].tolist(), actual['norm_Z'].tolist(), actual['norm_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    actual['euler_x'] = nx\n    actual['euler_y'] = ny\n    actual['euler_z'] = nz\n    return actual","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"964d3636206b760b03d406c8a2eb36345b97f339"},"cell_type":"code","source":"data = fe_step1(data)\ntest = fe_step1(test)\nprint (data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_uuid":"f0576bce229f1e43af62ddd6652fecac09ad2088"},"cell_type":"markdown","source":"![](https://d2gne97vdumgn3.cloudfront.net/api/file/UMYT4v0TyIgtyGm8ZXDQ)"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"fa6856f6c043e0cdb6624153aa7b9a38ad861ea4"},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15, 5))\n\nax1.set_title('Roll')\nsns.kdeplot(data['euler_x'], ax=ax1, label=\"train\")\nsns.kdeplot(test['euler_x'], ax=ax1, label=\"test\")\n\nax2.set_title('Pitch')\nsns.kdeplot(data['euler_y'], ax=ax2, label=\"train\")\nsns.kdeplot(test['euler_y'], ax=ax2, label=\"test\")\n\nax3.set_title('Yaw')\nsns.kdeplot(data['euler_z'], ax=ax3, label=\"train\")\nsns.kdeplot(test['euler_z'], ax=ax3, label=\"test\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f157e747b3499c5aaa10b7a26535c6738571511e"},"cell_type":"markdown","source":"**Euler angles** are really important, and we have a problem with Z.\n\n### Why Orientation_Z (euler angle Z) is so important?\n\nWe have a robot moving around, imagine a robot moving straight through different surfaces (each with different features), for example concrete and hard tile floor. Our robot can can **bounce** or **balance** itself a little bit on if the surface is not flat and smooth, that's why we need to work with quaternions and take care of orientation_Z.\n\n![](https://lifeboat.com/blog.images/robot-car-find-share-on-giphy.gif.gif)"},{"metadata":{"trusted":true,"_uuid":"2c6336ba69afee3fe38103cdcf23d280a2144c51"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e990575053b4c20d976e99e9879aabd04b68a3af"},"cell_type":"markdown","source":"## Step 2: + Basic features"},{"metadata":{"_uuid":"839cfc267c2ca5a8aab619cfd7e265da8c5f3388","trusted":true},"cell_type":"code","source":"def feat_eng(data):\n    \n    df = pd.DataFrame()\n    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 + data['angular_velocity_Z']**2)** 0.5\n    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 + data['linear_acceleration_Z']**2)**0.5\n    data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 + data['orientation_Z']**2)**0.5\n    data['acc_vs_vel'] = data['totl_linr_acc'] / data['totl_anglr_vel']\n    \n    def mean_change_of_abs_change(x):\n        return np.mean(np.diff(np.abs(np.diff(x))))\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number']:\n            continue\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        df[col + '_mean_change_of_abs_change'] = data.groupby('series_id')[col].apply(mean_change_of_abs_change)\n        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n    return df\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da872f84dbe19df5250f319ec34750279798b4bf","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\ndata = feat_eng(data)\ntest = feat_eng(test)\nprint (\"New features: \",data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"99a53e21a7cb54d3f73e8f8c12c5d17b0c7b7590"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## New advanced features"},{"metadata":{},"cell_type":"markdown","source":"**Useful functions**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from scipy.stats import kurtosis\nfrom scipy.stats import skew\n\ndef _kurtosis(x):\n    return kurtosis(x)\n\ndef CPT5(x):\n    den = len(x)*np.exp(np.std(x))\n    return sum(np.exp(x))/den\n\ndef skewness(x):\n    return skew(x)\n\ndef SSC(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    # xn+1 \n    xn_i1 = x[0:len(x)-2]  # xn-1\n    ans = np.heaviside((xn-xn_i1)*(xn-xn_i2),0)\n    return sum(ans[1:]) \n\ndef wave_length(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    # xn+1 \n    return sum(abs(xn_i2-xn))\n    \ndef norm_entropy(x):\n    tresh = 3\n    return sum(np.power(abs(x),tresh))\n\ndef SRAV(x):    \n    SRA = sum(np.sqrt(abs(x)))\n    return np.power(SRA/len(x),2)\n\ndef mean_abs(x):\n    return sum(abs(x))/len(x)\n\ndef zero_crossing(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    # xn+1\n    return sum(np.heaviside(-xn*xn_i2,0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This advanced features based on robust statistics."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fe_advanced_stats(data):\n    \n    df = pd.DataFrame()\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number']:\n            continue\n        if 'orientation' in col:\n            continue\n            \n        print (\"FE on column \", col, \"...\")\n        \n        df[col + '_skew'] = data.groupby(['series_id'])[col].skew()\n        df[col + '_mad'] = data.groupby(['series_id'])[col].mad()\n        df[col + '_q25'] = data.groupby(['series_id'])[col].quantile(0.25)\n        df[col + '_q75'] = data.groupby(['series_id'])[col].quantile(0.75)\n        df[col + '_q95'] = data.groupby(['series_id'])[col].quantile(0.95)\n        df[col + '_iqr'] = df[col + '_q75'] - df[col + '_q25']\n        df[col + '_CPT5'] = data.groupby(['series_id'])[col].apply(CPT5) \n        df[col + '_SSC'] = data.groupby(['series_id'])[col].apply(SSC) \n        df[col + '_skewness'] = data.groupby(['series_id'])[col].apply(skewness)\n        df[col + '_wave_lenght'] = data.groupby(['series_id'])[col].apply(wave_length)\n        df[col + '_norm_entropy'] = data.groupby(['series_id'])[col].apply(norm_entropy)\n        df[col + '_SRAV'] = data.groupby(['series_id'])[col].apply(SRAV)\n        df[col + '_kurtosis'] = data.groupby(['series_id'])[col].apply(_kurtosis) \n        df[col + '_zero_crossing'] = data.groupby(['series_id'])[col].apply(zero_crossing) \n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Frequency of the max value\n- Frequency of the min value\n- Count Positive values\n- Count Negative values\n- Count zeros"},{"metadata":{"trusted":true},"cell_type":"code","source":"basic_fe = ['linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z',\n           'angular_velocity_X','angular_velocity_Y','angular_velocity_Z']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fe_plus (data):\n    \n    aux = pd.DataFrame()\n    \n    for serie in data.index:\n        #if serie%500 == 0: print (\"> Serie = \",serie)\n        \n        aux = X_train[X_train['series_id']==serie]\n        \n        for col in basic_fe:\n            data.loc[serie,col + '_unq'] = aux[col].round(3).nunique()\n            data.loc[serie,col + 'ratio_unq'] = aux[col].round(3).nunique()/18\n            try:\n                data.loc[serie,col + '_freq'] = aux[col].value_counts().idxmax()\n            except:\n                data.loc[serie,col + '_freq'] = 0\n            \n            data.loc[serie,col + '_max_freq'] = aux[aux[col] == aux[col].max()].shape[0]\n            data.loc[serie,col + '_min_freq'] = aux[aux[col] == aux[col].min()].shape[0]\n            data.loc[serie,col + '_pos_freq'] = aux[aux[col] >= 0].shape[0]\n            data.loc[serie,col + '_neg_freq'] = aux[aux[col] < 0].shape[0]\n            data.loc[serie,col + '_nzeros'] = (aux[col]==0).sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Important !\nAs you can see in this kernel https://www.kaggle.com/anjum48/leakage-within-the-train-dataset\n\nAs discussed in the discussion forums (https://www.kaggle.com/c/career-con-2019/discussion/87239#latest-508136) it looks as if each series is part of longer aquisition periods that have been cut up into chunks with 128 samples.\n\nThis means that each series is not truely independent and there is leakage between them via the orientation data. Therefore if you have any features that use orientation, you will get a very high CV score due to this leakage in the train set.\n\n[This kernel](https://www.kaggle.com/anjum48/leakage-within-the-train-dataset) will show you how it is possible to get a CV score of 0.992 using only the **orientation data**.\n\n---\n\n**So I recommend not to use orientation information**"},{"metadata":{"_uuid":"dbcefc404120fbe2fe258e55dba360ae4abebe28"},"cell_type":"markdown","source":"## Correlations (Part II)"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2a4d42345597eb73ae9eeee15d01e8cf00fcde15"},"cell_type":"code","source":"#https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas\ncorr_matrix = data.corr().abs()\nraw_corr = data.corr()\n\nsol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n                 .stack()\n                 .sort_values(ascending=False))\ntop_corr = pd.DataFrame(sol).reset_index()\ntop_corr.columns = [\"var1\", \"var2\", \"abs corr\"]\n# with .abs() we lost the sign, and it's very important.\nfor x in range(len(top_corr)):\n    var1 = top_corr.iloc[x][\"var1\"]\n    var2 = top_corr.iloc[x][\"var2\"]\n    corr = raw_corr[var1][var2]\n    top_corr.at[x, \"raw corr\"] = corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ba7c1e4842e51e43e1477a560737996dd44e714"},"cell_type":"code","source":"top_corr.head(15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c662ddae92c05c04c5c8da3c6dbcbf8e4463026"},"cell_type":"markdown","source":"### Filling missing NAs and infinite data ∞  by zeroes 0"},{"metadata":{"_uuid":"d860de8e308eb3f290ec8b117138a29b7297c67a","trusted":false},"cell_type":"code","source":"data.fillna(0,inplace=True)\ntest.fillna(0,inplace=True)\ndata.replace(-np.inf,0,inplace=True)\ndata.replace(np.inf,0,inplace=True)\ntest.replace(-np.inf,0,inplace=True)\ntest.replace(np.inf,0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f181b816f73cc9432d9c06691b0056d42aa1ba2a"},"cell_type":"markdown","source":"## Label encoding"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c941d97295dadf25cfc644d34739ecae714cb034"},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47a5ac7c0189bd91b8ddda57557f18e78ef0cd9c","trusted":true},"cell_type":"code","source":"target['surface'] = le.fit_transform(target['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cddb6bdd77a79e7bbe9cb685d26ed0b08396f153","_kg_hide-input":true},"cell_type":"code","source":"target['surface'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"367ef510be72f1e3747319b58c7b440cdf63b24d","_kg_hide-input":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f3f7f48b328a8e33d538e6ab4a527e83d758ad2"},"cell_type":"markdown","source":"# Run Model"},{"metadata":{"_uuid":"3ce1af90458d3f2d791ccd33396ecd2a04772ef6"},"cell_type":"markdown","source":"**use random_state at Random Forest**\n\nif you don't use random_state you will get a different solution everytime, sometimes you will be lucky, but other times you will lose your time comparing."},{"metadata":{},"cell_type":"markdown","source":"**Validation Strategy: Stratified KFold**"},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=59)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89f5ce542394410d66ae7b65abc2410a2b8a64ee"},"cell_type":"code","source":"predicted = np.zeros((test.shape[0],9))\nmeasured= np.zeros((data.shape[0]))\nscore = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bde524f57f7e5b8c6250c3178147445adb6682e","_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"for times, (trn_idx, val_idx) in enumerate(folds.split(data.values,target['surface'].values)):\n    model = RandomForestClassifier(n_estimators=500, n_jobs = -1)\n    #model = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=5, n_jobs=-1)\n    model.fit(data.iloc[trn_idx],target['surface'][trn_idx])\n    measured[val_idx] = model.predict(data.iloc[val_idx])\n    predicted += model.predict_proba(test)/folds.n_splits\n    score += model.score(data.iloc[val_idx],target['surface'][val_idx])\n    print(\"Fold: {} score: {}\".format(times,model.score(data.iloc[val_idx],target['surface'][val_idx])))\n\n    importances = model.feature_importances_\n    indices = np.argsort(importances)\n    features = data.columns\n    \n    if model.score(data.iloc[val_idx],target['surface'][val_idx]) > 0.92000:\n        hm = 30\n        plt.figure(figsize=(7, 10))\n        plt.title('Feature Importances')\n        plt.barh(range(len(indices[:hm])), importances[indices][:hm], color='b', align='center')\n        plt.yticks(range(len(indices[:hm])), [features[i] for i in indices])\n        plt.xlabel('Relative Importance')\n        plt.show()\n\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"577027dedc815f3017b45b083ed369af716a8c67"},"cell_type":"code","source":"print('Avg Accuracy RF', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"656aaea32483d0e084b2f770e83c82432b09e884"},"cell_type":"code","source":"confusion_matrix(measured,target['surface'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffa41a80aae336ad8603555ce4fac99a72bb3da6"},"cell_type":"markdown","source":"### Confusion Matrix Plot"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"a57b94fbaf78297c2ce0f75930c9cc818b62dfe9"},"cell_type":"code","source":"# https://www.kaggle.com/artgor/where-do-the-robots-drive\n\ndef plot_confusion_matrix(truth, pred, classes, normalize=False, title=''):\n    cm = confusion_matrix(truth, pred)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    plt.figure(figsize=(10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion matrix', size=15)\n    plt.colorbar(fraction=0.046, pad=0.04)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.grid(False)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1325eb6df3969555a7c0fa55c204b5af296916ef","_kg_hide-input":false},"cell_type":"code","source":"plot_confusion_matrix(target['surface'], measured, le.classes_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"581bcda8f5d0d1a0c4afced8ca94f2143433e1d2"},"cell_type":"markdown","source":"### Submission (Part I)"},{"metadata":{"_uuid":"a7b987ad134006f8e162eacac0ca4aaab64c88df","trusted":false},"cell_type":"code","source":"sub['surface'] = le.inverse_transform(predicted.argmax(axis=1))\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1139e9efbe8d5907b4ab7d8647f2a21f195d424"},"cell_type":"markdown","source":"### Best Submission"},{"metadata":{"trusted":true,"_uuid":"026e7ea1f7a5e6776f9608735bf3c95edaba9f0d","_kg_hide-input":true},"cell_type":"code","source":"best_sub = pd.read_csv('../input/robots-best-submission/final_submission.csv')\nbest_sub.to_csv('best_submission.csv', index=False)\nbest_sub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d841fea3dd79acebad5694911a8cc8b96bd02306"},"cell_type":"markdown","source":"## References\n\n[1] https://www.kaggle.com/vanshjatana/help-humanity-by-helping-robots-4e306b\n\n[2] https://www.kaggle.com/artgor/where-do-the-robots-drive\n\n[3] https://www.kaggle.com/gpreda/robots-need-help\n\n[4] https://www.kaggle.com/vanshjatana/help-humanity-by-helping-robots-4e306b by [@vanshjatana](https://www.kaggle.com/vanshjatana)"},{"metadata":{"_uuid":"1c3402791f26a2292cb6d38cd2653fa02414d121"},"cell_type":"markdown","source":"# ABOUT Submissions & Leaderboard"},{"metadata":{"_uuid":"4aec8a7f9e7344b2206c013ae3fac9c3a3d721a3"},"cell_type":"markdown","source":"This kernel [distribution hack](https://www.kaggle.com/donkeys/distribution-hack) by [@donkeys](https://www.kaggle.com/donkeys) simply produces 9 output files, one for each target category. \nI submitted each of these to the competition to see how much of each target type exists in the test set distribution. Results:\n\n- carpet 0.06\n- concrete 0.16\n- fine concrete 0.09\n- hard tiles 0.06\n- hard tiles large space 0.10\n- soft pvc 0.17\n- soft tiles 0.23\n- tiled 0.03\n- wood 0.06\n\nAlso posted a discussion [thread](https://www.kaggle.com/c/career-con-2019/discussion/85204)\n\n"},{"metadata":{"_uuid":"35c196f89b7028efc325f7a8d7a729d272b1c24f"},"cell_type":"markdown","source":"**by [@ninoko](https://www.kaggle.com/ninoko)**\n\nI've probed the public leaderboard and this is what I got\nThere are much less surfaces like wood or tiled, and much more soft and hard tiles in public leaderboard. This can be issue, why CV and LB results differ strangely.\n\n![graph](https://i.imgur.com/DoFc3mW.png)"},{"metadata":{"_uuid":"d70684d8b0317f25c64ed4cb2e0b072fb26db118"},"cell_type":"markdown","source":"**I will analyze my best submissions in order to find something interesting.**\n\nPlease, feel free to optimize this code."},{"metadata":{"trusted":true,"_uuid":"3893445099eea5cf72000c3bc7a83db744341c79","_kg_hide-input":true},"cell_type":"code","source":"sub073 = pd.read_csv('../input/robots-best-submission/mybest0.73.csv')\nsub072 = pd.read_csv('../input/robots-best-submission/sub_0.72.csv')\nsub072_2 = pd.read_csv('../input/robots-best-submission/sub_0.72_2.csv')\nsub071 = pd.read_csv('../input/robots-best-submission/sub_0.71.csv')\nsub06 = pd.read_csv('../input/robots-best-submission/sub_0.6.csv')\n\nsub073 = sub073.rename(columns = {'surface':'surface073'})\nsub072 = sub072.rename(columns = {'surface':'surface072'})\nsub072_2 = sub072_2.rename(columns = {'surface':'surface072_2'})\nsub071 = sub071.rename(columns = {'surface':'surface071'})\nsub06 = sub06.rename(columns = {'surface':'surface06'})\nprint (\"Submission data is ready\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8aa2e8afb5d56292593111e876d755d604a4e3d8"},"cell_type":"code","source":"sub073.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"276a4b7571cce9a17a57b0810381fe03da842d04"},"cell_type":"code","source":"subtest = pd.concat([sub073['series_id'], sub073['surface073'], sub072['surface072'], sub071['surface071'], sub06['surface06']], axis=1)\nsubtest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30c68a9fd3389a9c6b888f91058f030ae4fbb681","_kg_hide-input":false},"cell_type":"code","source":"differents = []\nfor i in range (0,subtest.shape[0]): \n    labels = list(subtest.iloc[i,1:])\n    result = len(set(labels))>1\n    if result:\n        differents.append((i, str(labels)))\n        \ndifferents = pd.DataFrame(differents, columns=['idx','group']) \ndifferents.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e22e5bf8069eafa2770a66e71af8e574b37768a"},"cell_type":"markdown","source":"For example the serie with **series_id = 2** has the following predicition:\n\n```\n['tiled', 'tiled', 'tiled', 'fine_concrete']\n```\n\nThis means that my best submissions (*0.73, 0.72 and  0.71 LB* ) predicted the same: **tiled**, but a worst submission (*0.6 LB*) would have predicted **fine_concrete**.\n\n---\n\n### So... Why is this interesting?\n\nIn order to improve our classification, LB is indicating us wich kind of surfaces are confused with others.\nIn that example, ```tiled``` and ```fine_concrete``` are being **confused** (maybe because the two surfaces are **alike**)\n\n---\n\nAs you can see bellow, we have **177 cases of confusion**\nI'm going to plot the tp 10% and see what happens."},{"metadata":{"trusted":true,"_uuid":"effe29d90ec4c2c076f6c0b704c27d5ad06e22a6"},"cell_type":"code","source":"differents['group'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cd802f9436ebc6d48219200724d4bf07e25429af"},"cell_type":"code","source":"differents['count'] = differents.groupby('group')['group'].transform('count')\ndifferents = differents.sort_values(by=['count'], ascending=False)\ndifferents = differents.drop(['idx'],axis=1)\ndifferents = differents.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d69858fa7ac6868ea2aaf2d92ddbf529914bf5d2"},"cell_type":"code","source":"differents.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20736e592364db07889c8054448a34f5b05cb522"},"cell_type":"markdown","source":"We can see that **wood** and **fine_concrete** are really hard to guess."},{"metadata":{"_uuid":"4854db3e2c47b39c6fa2b86e1fac362ababff416"},"cell_type":"markdown","source":"### Maybe this is the most interesting part, the difference between a 0.73 and 0.72 submission."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ef21ea63a8abe571357cd40e81a2eb86cee59291"},"cell_type":"code","source":"differents.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35cdc507b25c7609015ed5898f14cbaf8c907a5a"},"cell_type":"markdown","source":"Remember the order at the array is [0.73LB, 0.72LB, 0.71LB, 06LB].\nSeries with ```series_id```= 575, 1024, 911, 723, 148, 338 are really interesting because they show important differences between surfaces that often are being confused."},{"metadata":{"_uuid":"82b84bde1ed3d6e5ffe42531cedf1298609fce2e"},"cell_type":"markdown","source":"## Next Step ??\n\n- I will create a test dataset with those special cases and then I will ad a new CV stage where I will try to classify those surfaces correctly.\n- I will look for surfaces distinctive features."},{"metadata":{},"cell_type":"markdown","source":"## Generate a new train and test: Fast Fourier Transform Denoising"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from numpy.fft import *\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style \nstyle.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X_train = pd.read_csv('../input/career-con-2019/X_train.csv')\nX_test = pd.read_csv('../input/career-con-2019/X_test.csv')\ntarget = pd.read_csv('../input/career-con-2019/y_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series_dict = {}\nfor series in (X_train['series_id'].unique()):\n    series_dict[series] = X_train[X_train['series_id'] == series] ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# From: Code Snippet For Visualizing Series Id by @shaz13\ndef plotSeries(series_id):\n    style.use('ggplot')\n    plt.figure(figsize=(28, 16))\n    print(target[target['series_id'] == series_id]['surface'].values[0].title())\n    for i, col in enumerate(series_dict[series_id].columns[3:]):\n        if col.startswith(\"o\"):\n            color = 'red'\n        elif col.startswith(\"a\"):\n            color = 'green'\n        else:\n            color = 'blue'\n        if i >= 7:\n            i+=1\n        plt.subplot(3, 4, i + 1)\n        plt.plot(series_dict[series_id][col], color=color, linewidth=3)\n        plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotSeries(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from @theoviel at https://www.kaggle.com/theoviel/fast-fourier-transform-denoising\ndef filter_signal(signal, threshold=1e3):\n    fourier = rfft(signal)\n    frequencies = rfftfreq(signal.size, d=20e-3/signal.size)\n    fourier[frequencies > threshold] = 0\n    return irfft(fourier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's denoise train and test angular_velocity and linear_acceleration data"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X_train_denoised = X_train.copy()\nX_test_denoised = X_test.copy()\n\n# train\nfor col in X_train.columns:\n    if col[0:3] == 'ang' or col[0:3] == 'lin':\n        # Apply filter_signal function to the data in each series\n        denoised_data = X_train.groupby(['series_id'])[col].apply(lambda x: filter_signal(x))\n        \n        # Assign the denoised data back to X_train\n        list_denoised_data = []\n        for arr in denoised_data:\n            for val in arr:\n                list_denoised_data.append(val)\n                \n        X_train_denoised[col] = list_denoised_data\n        \n# test\nfor col in X_test.columns:\n    if col[0:3] == 'ang' or col[0:3] == 'lin':\n        # Apply filter_signal function to the data in each series\n        denoised_data = X_test.groupby(['series_id'])[col].apply(lambda x: filter_signal(x))\n        \n        # Assign the denoised data back to X_train\n        list_denoised_data = []\n        for arr in denoised_data:\n            for val in arr:\n                list_denoised_data.append(val)\n                \n        X_test_denoised[col] = list_denoised_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series_dict = {}\nfor series in (X_train_denoised['series_id'].unique()):\n    series_dict[series] = X_train_denoised[X_train_denoised['series_id'] == series] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotSeries(1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24, 8))\nplt.title('linear_acceleration_X')\nplt.plot(X_train.angular_velocity_Z[128:256], label=\"original\");\nplt.plot(X_train_denoised.angular_velocity_Z[128:256], label=\"denoised\");\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Generate new denoised train and test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_denoised.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_denoised.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_denoised.to_csv('test_denoised.csv', index=False)\nX_test_denoised.to_csv('train_denoised.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}