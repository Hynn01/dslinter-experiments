{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"###### Importing necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport re\n#NLTK\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet\n\n#Scikit-Learn\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n\n#Spell Correction\n!pip install autocorrect\nfrom autocorrect import Speller\n\n#Tokenization\n!pip install wordninja\nimport wordninja\n\n#Necessary Libraries for plotting charts\nimport matplotlib.pyplot as plt\n#plotly\n!pip install plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\n\n!pip install contractions\n# contractions is a library for converting words like \"I'm\" to \"I am\"\nimport contractions\n\n# Necessary Libraries to find similarity\nimport gensim ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\ndf=pd.read_csv('../input/preprocessed-review-file/Review_text_preprocessed_file.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scikit-Learn\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n#Necessary Libraries for plotting charts\nimport matplotlib.pyplot as plt\n#plotly\n!pip install plotly\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace null values with empty string\ndef remove_null(text):\n    text = ''\n    return text\n\n#  repalcing null values in pros and cons columns\nfor i in df[df['Pros_Modified_Text'].isnull()]['Pros_Modified_Text'].index:\n    df.loc[i,'Pros_Modified_Text'] = remove_null(df.loc[i,'Pros_Modified_Text'])\n\nfor i in df[df['Cons_Modified_Text'].isnull()]['Cons_Modified_Text'].index:\n    df.loc[i,'Cons_Modified_Text'] = remove_null(df.loc[i,'Cons_Modified_Text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Function to calculate trigrams from a corpus using count vectorizer\ndef get_trigrams(corpus):\n    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Function to calculate bigrams from a corpus using count vectorizer\ndef get_bigrams(corpus):\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Function to plot a bar graph of top bigrams and trigrams"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_plot_top_n_trigrams(CompanyName,ReviewType,n):\n    common_words = get_trigrams(df[df['CompanyName']==CompanyName][ReviewType])[:n]\n    df1 = pd.DataFrame(common_words, columns = ['word', 'count'])\n    fig = px.bar(df1, x='word', y='count')\n    fig.update_layout(title_text='Top 20 trigrams by count in '+ReviewType[0:4]+' Review for '+CompanyName, template=\"plotly_white\")\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot_top_n_trigrams('Amazon','Pros_Modified_Text',20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot_top_n_trigrams('Amazon','Cons_Modified_Text',20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_plot_top_n_bigrams(CompanyName,ReviewType,n):\n    common_words = get_bigrams(df[df['CompanyName']==CompanyName][ReviewType])[:n]\n    df1 = pd.DataFrame(common_words, columns = ['word', 'count'])\n    fig = px.bar(df1, x='word', y='count')\n    fig.update_layout(title_text='Top 20 bigrams by count in '+ReviewType[0:4]+' Review for '+CompanyName, template=\"plotly_white\")\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot_top_n_bigrams('Amazon','Pros_Modified_Text',20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_plot_top_n_bigrams('Amazon','Cons_Modified_Text',20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####Creating a dataframe of bigrams by company and Review Type\ndef bigramdataframe(df,companyname,reviewtype):\n    data=get_bigrams(df[df['CompanyName']==companyname][reviewtype])\n    temp = pd.DataFrame(data, columns =['Bigram', 'Frequency']) \n    temp['CompanyName']=companyname\n    temp['ReviewType']=reviewtype[0:4]\n    return temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a dataframe of bigrams with frequency for all the companies and by review type\ncompany_list=list(df['CompanyName'].unique())\nReview_Type=['Pros_Modified_Text','Cons_Modified_Text']\nbigrams= pd.DataFrame(columns =['Bigram', 'Frequency','CompanyName','ReviewType'])\nfor i in company_list:\n    for j in Review_Type:\n        bigrams=pd.concat([bigrams,bigramdataframe(df,i,j)])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bigrams.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####Creating a dataframe of trigrams by company and Review Type\ndef trigramdataframe(df,companyname,reviewtype):\n    data=get_trigrams(df[df['CompanyName']==companyname][reviewtype])\n    temp = pd.DataFrame(data, columns =['Trigram', 'Frequency']) \n    temp['CompanyName']=companyname\n    temp['ReviewType']=reviewtype[0:4]\n    return temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trigrams= pd.DataFrame(columns =['Trigram', 'Frequency','CompanyName','ReviewType'])\nfor i in company_list:\n    for j in Review_Type:\n        trigrams=pd.concat([trigrams,trigramdataframe(df,i,j)])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trigrams.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to calculate overall average rating based on keyword i.e.,bigram or trigram\nimport re\ndef avgsentiscorebasedonkeyword(Companyname,keyword,ReviewColumnName):\n    avg=df[(df[ReviewColumnName].str.contains(keyword,flags=re.IGNORECASE, regex=True)) & (df['CompanyName']==Companyname)]['Review_polarity'].mean()\n    return avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def avg_rating_column(df,ngramtype):\n    ratings_list=[]\n    for index, row in df.iterrows():\n        Companyname=row['CompanyName']\n        keyword=row[ngramtype]\n        if str(row['ReviewType'])=='Pros':\n            ReviewColumnName='Pros_Modified_Text'\n        elif str(row['ReviewType'])=='Cons':\n            ReviewColumnName='Cons_Modified_Text'\n        else:\n            pass\n        ratings_list.append(avgsentiscorebasedonkeyword(Companyname,keyword,ReviewColumnName))\n    return(ratings_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Group dataframe by company name,review type and take top 100 rows based on frequency in each category\nbigrams = bigrams.groupby([\"CompanyName\",\"ReviewType\"]).apply(lambda x: x.sort_values([\"Frequency\"], ascending = False)).reset_index(drop=True)\ntrigrams= trigrams.groupby([\"CompanyName\",\"ReviewType\"]).apply(lambda x: x.sort_values([\"Frequency\"], ascending = False)).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Pros_Modified_Text'] = df['Pros_Modified_Text'].map(str)\ndf['Cons_Modified_Text'] = df['Cons_Modified_Text'].map(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select top N rows within each category\nbigrams_top100=bigrams.groupby([\"CompanyName\",\"ReviewType\"]).head(100)\ntrigrams_top100=trigrams.groupby([\"CompanyName\",\"ReviewType\"]).head(100)\n#Reindexing\nbigrams_top100.index = range(len(bigrams_top100.index))\ntrigrams_top100.index = range(len(trigrams_top100.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bigrams_top100['AverageRating']=avg_rating_column(bigrams_top100,'Bigram')\ntrigrams_top100['AverageRating']=avg_rating_column(trigrams_top100,'Trigram')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bigrams_top100.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bigrams_top100 = bigrams_top100[pd.notnull(bigrams_top100['ReviewType'])]\ntrigrams_top100=trigrams_top100[pd.notnull(trigrams_top100['ReviewType'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bigrams_top100_pros=bigrams_top100[bigrams_top100['ReviewType']=='Pros']\nbigrams_top100_cons=bigrams_top100[bigrams_top100['ReviewType']=='Cons']\ntrigrams_top100_pros=trigrams_top100[trigrams_top100['ReviewType']=='Pros']\ntrigrams_top100_cons=trigrams_top100[trigrams_top100['ReviewType']=='Cons']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to calculate cosine similarity\ndef get_phrase_similarity(p1,p2,model): \n    tokens_1=[t for t in p1.split() if t in model.wv.vocab]\n    tokens_2=[t for t in p2.split() if t in model.wv.vocab]\n    #compute cosine similarity using word embedings \n    cosine=0\n    if (len(tokens_1) > 0 and len(tokens_2)>0):\n        cosine=model.wv.n_similarity(tokens_1,tokens_2)\n    return cosine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Pros review text using CBOW,char n-gram and skipgram\npros_document_list=[]\nfor i in range(len(df['Pros_Modified_Text'])):\n    pros_document_list.append(df['Pros_Modified_Text'][i].lower().split())\n    #Train a CBOW Model\nmodel_cbow = gensim.models.Word2Vec (pros_document_list, size=150, window=10, min_count=0, workers=10)\nmodel_cbow.train(pros_document_list,total_examples=len(pros_document_list),epochs=10)\n#Train a char n-gram model (subword information) with fastText\nfrom gensim.models.fasttext import FastText\nmodel_subword = FastText(pros_document_list, size=150, window=10, min_count=0, workers=10, min_n=3, max_n=6)  # instantiate\nmodel_subword.train(pros_document_list,total_examples=len(pros_document_list),epochs=10)\n#Train a SkipGram model\nmodel_skipgram = gensim.models.Word2Vec (pros_document_list, size=150, window=10, min_count=0, workers=10, sg=1)\nmodel_skipgram.train(pros_document_list,total_examples=len(pros_document_list),epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(model_cbow.wv.vocab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to compute rating after taking similarities into consideration\ndef function4(df,list1,companyname,ngramType):\n    rating_list=[]\n    for i in list1:\n        numerator=0\n        denominator=0\n        for j in i:\n            numerator=numerator+float((df[(df['CompanyName']==companyname)&(df[ngramType]==j)]['AverageRating'])*(df[(df['CompanyName']==companyname)&(df[ngramType]==j)]['Frequency']))\n            denominator=denominator+float((df[(df['CompanyName']==companyname)&(df[ngramType]==j)]['Frequency']))\n        rating_list.append(float(numerator/denominator))\n    return rating_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def function3(df,companyname,ngramtype):\n    model_cbow_list=[]\n    model_skipgram_list=[]\n    model_subword_list=[]\n    for idx1, row1 in df[df['CompanyName']==companyname].iterrows():\n        cbow_list=[]\n        skipgram_list=[]\n        subword_list=[]\n        for idx2, row2 in df[df['CompanyName']==companyname].iterrows():\n            cos_m1_score=get_phrase_similarity(row1[ngramtype],row2[ngramtype],model_cbow)\n            cos_m2_score=get_phrase_similarity(row1[ngramtype],row2[ngramtype],model_skipgram)\n            cos_m3_score=get_phrase_similarity(row1[ngramtype],row2[ngramtype],model_subword)\n            cbow_list.append((row2[ngramtype],cos_m1_score))\n            skipgram_list.append((row2[ngramtype],cos_m2_score))\n            subword_list.append((row2[ngramtype],cos_m3_score))\n        cbow_list=sorted(cbow_list, key = lambda x: x[1],reverse=True)\n        skipgram_list=sorted(skipgram_list, key = lambda x: x[1],reverse=True)\n        subword_list=sorted(subword_list, key = lambda x: x[1],reverse=True)\n        model_cbow_list.append([word for word,idx in cbow_list][0:5])\n        model_skipgram_list.append([word for word,idx in skipgram_list][0:5])\n        model_subword_list.append([word for word,idx in subword_list][0:5])\n    result=df[df['CompanyName']==companyname]\n    result['cbow']=model_cbow_list\n    result['skipgram']=model_skipgram_list\n    result['subword']=model_subword_list\n    result['cbow_rating']=function4(result,model_cbow_list,companyname,ngramtype)\n    result['skipgram_rating']=function4(result,model_skipgram_list,companyname,ngramtype)\n    result['subword_rating']=function4(result,model_subword_list,companyname,ngramtype)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"Final_result_Bigrams=pd.concat([function3(bigrams_top100_pros,'Amazon','Bigram'),function3(bigrams_top100_cons,'Amazon','Bigram'),\n                               function3(bigrams_top100_pros,'IBM','Bigram'),function3(bigrams_top100_cons,'IBM','Bigram'),\n                               function3(bigrams_top100_pros,'Google','Bigram'),function3(bigrams_top100_cons,'Google','Bigram'),\n                               function3(bigrams_top100_pros,'Microsoft','Bigram'),function3(bigrams_top100_cons,'Microsoft','Bigram')],ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_result_Bigrams.to_csv('Final_result_Bigrams.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_result_Trigrams=pd.concat([function3(trigrams_top100_pros,'Amazon','Trigram'),function3(trigrams_top100_cons,'Amazon','Trigram'),\n                               function3(trigrams_top100_pros,'IBM','Trigram'),function3(trigrams_top100_cons,'IBM','Trigram'),\n                               function3(trigrams_top100_pros,'Google','Trigram'),function3(trigrams_top100_cons,'Google','Trigram'),\n                               function3(trigrams_top100_pros,'Microsoft','Trigram'),function3(trigrams_top100_cons,'Microsoft','Trigram')],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_result_Trigrams.to_csv('Final_result_Trigrams.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}