{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# General imports\nimport numpy as np\nimport pandas as pd\nimport os, sys, gc, warnings, random, datetime\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm import tqdm\n\nimport math\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"########################### Helpers\n#################################################################################\n## Seeder\n# :seed to make all processes deterministic     # type: int\ndef seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \n## Memory Reducer\n# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n# :verbose                                        # type: bool\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Model\nimport lightgbm as lgb\n\ndef make_predictions(tr_df, tt_df, features_columns, target, lgb_params, NFOLDS=2):\n    \n    folds = GroupKFold(n_splits=NFOLDS)\n\n    X,y = tr_df[features_columns], tr_df[target]    \n    P,P_y = tt_df[features_columns], tt_df[target]  \n    split_groups = tr_df['DT_M']\n\n    tt_df = tt_df[['TransactionID',target]]    \n    predictions = np.zeros(len(tt_df))\n    oof = np.zeros(len(tr_df))\n    \n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=split_groups)):\n        print('Fold:',fold_)\n        tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n        vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n            \n        print(len(tr_x),len(vl_x))\n        tr_data = lgb.Dataset(tr_x, label=tr_y)\n        vl_data = lgb.Dataset(vl_x, label=vl_y)  \n\n        estimator = lgb.train(\n            lgb_params,\n            tr_data,\n            valid_sets = [tr_data, vl_data],\n            verbose_eval = 200,\n        )   \n        \n        pp_p = estimator.predict(P)\n        predictions += pp_p/NFOLDS\n        \n        oof_preds = estimator.predict(vl_x)\n        oof[val_idx] = (oof_preds - oof_preds.min())/(oof_preds.max() - oof_preds.min())\n\n        if LOCAL_TEST:\n            feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n            print(feature_imp)\n        \n        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n        gc.collect()\n        \n    tt_df['prediction'] = predictions\n    print('OOF AUC:', metrics.roc_auc_score(y, oof))\n    if LOCAL_TEST:\n        print('Holdout AUC:', metrics.roc_auc_score(tt_df[TARGET], tt_df['prediction']))\n    \n    return tt_df\n## -------------------","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Vars\n#################################################################################\nSEED = 42\nseed_everything(SEED)\nLOCAL_TEST = False\nTARGET = 'isFraud'\nSTART_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Model params\nlgb_params = {\n                    'objective':'binary',\n                    'boosting_type':'gbdt',\n                    'metric':'auc',\n                    'n_jobs':-1,\n                    'learning_rate':0.01,\n                    'num_leaves': 2**8,\n                    'max_depth':-1,\n                    'tree_learner':'serial',\n                    'colsample_bytree': 0.5,\n                    'subsample_freq':1,\n                    'subsample':0.7,\n                    'n_estimators':800,\n                    'max_bin':255,\n                    'verbose':-1,\n                    'seed': SEED,\n                    'early_stopping_rounds':100, \n                } ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### DATA LOAD\n#################################################################################\nprint('Load Data')\n\nif LOCAL_TEST:\n    train_df = pd.read_pickle('../input/ieee-fe-for-local-test/train_df.pkl')\n    test_df = pd.read_pickle('../input/ieee-fe-for-local-test/test_df.pkl') \nelse:\n    train_df = pd.read_pickle('../input/ieee-fe-with-some-eda/train_df.pkl')\n    test_df = pd.read_pickle('../input/ieee-fe-with-some-eda/test_df.pkl')\n    \nremove_features = pd.read_pickle('../input/ieee-fe-with-some-eda/remove_features.pkl')\nremove_features = list(remove_features['features_to_remove'].values)\nprint('Shape control:', train_df.shape, test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Final features list\nfeatures_columns = [col for col in list(train_df) if col not in remove_features]\n\n########################### Final Minification\n## I don't like this part as it changes float numbers\n## small change but change.\n## To be able to train lgbm without \n## minification we need to do some changes on model\n## we will do it later.\nif not LOCAL_TEST:\n    train_df = reduce_mem_usage(train_df)\n    test_df  = reduce_mem_usage(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Model Train\nif LOCAL_TEST:\n    lgb_params['learning_rate'] = 0.01\n    lgb_params['n_estimators'] = 10000\n    lgb_params['early_stopping_rounds'] = 100\n    test_predictions = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params, NFOLDS=4)\nelse:\n    lgb_params['learning_rate'] = 0.007\n    lgb_params['n_estimators'] = 10000\n    lgb_params['early_stopping_rounds'] = 100    \n    test_predictions = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params, NFOLDS=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Export\nif not LOCAL_TEST:\n    test_predictions['isFraud'] = test_predictions['prediction']\n    test_predictions[['TransactionID','isFraud']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}