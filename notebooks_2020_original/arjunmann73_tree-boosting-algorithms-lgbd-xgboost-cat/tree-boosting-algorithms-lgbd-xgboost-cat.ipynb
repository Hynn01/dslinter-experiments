{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Competition Objective\n## Data\nIn this competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\nThe data is broken into two files identity and transaction, which are joined by TransactionID.\nNote: Not all transactions have corresponding identity information.\n\n### Categorical Features - Transaction\n* ProductCD\n* emaildomain\n* card1 - card6\n* addr1, addr2\n* P_emaildomain\n* R_emaildomain\n* M1 - M9\n\n### Categorical Features - Identity\n* DeviceType\n* DeviceInfo\n* id_12 - id_38\nThe TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp)."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Data preperation \nData is separated into two datasets: information about the identity of the customer and transaction information. Not all transactions belong to identities which are available. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\nimport datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn import metrics\nfrom sklearn import linear_model\nimport gc\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR, SVR\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn import metrics\nfrom sklearn import linear_model\nimport gc\nimport seaborn as sns\nimport warnings\n\nimport eli5\nimport shap\nfrom IPython.display import HTML\nimport json\nimport altair as alt\n\nimport networkx as nx\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = '../input/ieee-fraud-detection/'\ntrain_identity = pd.read_csv(f'{folder_path}train_identity.csv')\ntrain_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\ntest_identity = pd.read_csv(f'{folder_path}test_identity.csv')\ntest_transaction = pd.read_csv(f'{folder_path}test_transaction.csv')\nsub = pd.read_csv(f'{folder_path}sample_submission.csv')\n# Merging the 2 datasets based on the condition stated above!\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')\nprint(type(train), type(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train dataset has\", train.shape[0],\"rows and\", train.shape[1], \"columns.\")\nprint(\"Test dataset has\", test.shape[0],\"rows and\", test.shape[1], \"columns.\")\ndel train_identity, train_transaction, test_identity, test_transaction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will drop columns with more than 90% of the data missing or Nans and columns with only 1 unique value."},{"metadata":{"trusted":true},"cell_type":"code","source":"many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\nmany_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]\nbig_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\nbig_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\none_value_cols = [col for col in train.columns if train[col].nunique() <= 1]\none_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols+ one_value_cols_test))\ncols_to_drop.remove('isFraud') # We don't want to remove the Target variable haha\n\ntest_errors = ['id_24', 'id_26', 'id_21', 'id_23', 'id_07', 'id_18', 'id_27', 'id_25', 'id_22', 'id_08']\ntrain_errors = ['id-25', 'id-22', 'id-26', 'id-24', 'id-08', 'id-21', 'id-23', 'id-07', 'id-27']\ntest_cols_to_drop = [cols for cols in cols_to_drop if cols not in test_errors]\ntest_cols_to_drop += ['id-24', 'id-26', 'id-21', 'id-23', 'id-07', 'id-18', 'id-27', 'id-25', 'id-22', 'id-08']\n\ntrain_cols_to_drop = [cols for cols in cols_to_drop if cols not in train_errors]\ntrain_cols_to_drop += ['id_25', 'id_22', 'id_26', 'id_24', 'id_08', 'id_21', 'id_23', 'id_07', 'id_27']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(train_cols_to_drop, axis=1)\ntest = test.drop(test_cols_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.rename(columns={'id-01': 'id_01',\n                     'id-02': 'id_02',\n                     'id-03': 'id_03',\n                     'id-04': 'id_04',\n                     'id-05': 'id_05',\n                     'id-06': 'id_06',\n                     'id-09': 'id_09',\n                     'id-10': 'id_10',\n                     'id-11': 'id_11',\n                     'id-12': 'id_12',\n                     'id-13': 'id_13',\n                     'id-14': 'id_14',\n                     'id-15': 'id_15',\n                     'id-16': 'id_16',\n                     'id-17': 'id_17',\n                     'id-19': 'id_19',\n                     'id-20': 'id_20',\n                     'id-28': 'id_28',\n                     'id-29': 'id_29',\n                     'id-30': 'id_30',\n                     'id-31': 'id_31',\n                     'id-32': 'id_32',\n                     'id-33': 'id_33',\n                     'id-34': 'id_34',\n                     'id-35': 'id_35',\n                     'id-36': 'id_36',\n                     'id-37': 'id_37',\n                     'id-38': 'id_38'\n                    \n}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to convert the categorical variables to numerical values, we use the LabelEncoder from sklearn."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_19', 'id_20',  'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9',\n            'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']\n'''\nfor col in cat_cols:\n    if col in train.columns:\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))  \n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\ny = train.sort_values('TransactionDT')['isFraud']\n#X_test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)\nX_test = test.drop(['TransactionDT', 'TransactionID'], axis=1)\ndel train\ntest = test[[\"TransactionDT\", 'TransactionID']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before modeling, let us clean the infinite values to nan."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.replace([np.inf, -np.inf], np.nan)\nX_test = X_test.replace([np.inf, -np.inf], np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numba import jit\n@jit\ndef fast_auc(y_true, y_prob):\n    \"\"\"\n    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    nfalse = 0\n    auc = 0\n    n = len(y_true)\n    for i in range(n):\n        y_i = y_true[i]\n        nfalse += (1 - y_i)\n        auc += y_i * nfalse\n    auc /= (nfalse * (n - nfalse))\n    return auc\n\n\ndef eval_auc(y_true, y_pred):\n    \"\"\"\n    Fast auc eval function for lgb.\n    \"\"\"\n    return 'auc', fast_auc(y_true, y_pred), True\n\n\ndef group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n    \"\"\"\n    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n    \"\"\"\n    maes = (y_true-y_pred).abs().groupby(types).mean()\n    return np.log(maes.map(lambda x: max(x, floor))).mean()\n\n    \ndef train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, plot_feature_importance=False, \n                               model=None, verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3, averaging='usual',\n                               n_jobs=-1):\n\n    columns = X.columns if columns is None else columns\n    n_splits = folds.n_splits if splits is None else n_folds\n    X_test = X_test[columns]\n    \n    # to set up scoring parameters\n    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n                        'catboost_metric_name': 'AUC',\n                        'sklearn_scoring_function': metrics.roc_auc_score},\n                    }\n    \n    result_dict = {}\n    if averaging == 'usual':\n        # out-of-fold predictions on train data\n        oof = np.zeros((len(X), 1))\n\n        # averaged predictions on train data\n        prediction = np.zeros((len(X_test), 1))\n        \n    elif averaging == 'rank':\n        # out-of-fold predictions on train data\n        oof = np.zeros((len(X), 1))\n\n        # averaged predictions on train data\n        prediction = np.zeros((len(X_test), 1))\n\n    \n    # list of scores on folds\n    scores = []\n    feature_importance = pd.DataFrame()\n    \n    # split and train on folds\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n        if type(X) == np.ndarray:\n            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n            y_train, y_valid = y[train_index], y[valid_index]\n        else:\n            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n            \n        if model_type == 'lgb':\n            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = n_jobs)\n            model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n            \n            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n            \n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n        \n        if model_type == 'sklearn':\n            model = model\n            model.fit(X_train, y_train)\n            \n            y_pred_valid = model.predict(X_valid).reshape(-1,)\n            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n            print('')\n            \n            y_pred = model.predict_proba(X_test)\n        \n        if model_type == 'cat':\n            model = CatBoostClassifier(iterations=n_estimators, eval_metric='AUC')\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid),cat_features=cat_cols, use_best_model=True, verbose=False)\n\n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test)\n        \n        if averaging == 'usual':\n            \n            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n            \n            prediction += y_pred.reshape(-1, 1)\n\n        elif averaging == 'rank':\n                                  \n            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n                                  \n            prediction += pd.Series(y_pred).rank().values.reshape(-1, 1)        \n        \n        if model_type == 'lgb' and plot_feature_importance:\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = columns\n            fold_importance[\"importance\"] = model.feature_importances_\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction /= n_splits\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    result_dict['oof'] = oof\n    result_dict['prediction'] = prediction\n    result_dict['scores'] = scores\n    \n    if model_type == 'lgb':\n        if plot_feature_importance:\n            feature_importance[\"importance\"] /= n_splits\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n            \n            result_dict['feature_importance'] = feature_importance\n            result_dict['top_columns'] = cols\n        \n    return result_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fold = 5\nfolds = TimeSeriesSplit(n_splits=n_fold)\nfolds = KFold(n_splits=5)\nparams = {'num_leaves': 256,\n          'min_child_samples': 79,\n          'objective': 'binary',\n          'max_depth': 13,\n          'learning_rate': 0.03,\n          \"boosting_type\": \"gbdt\",\n          \"subsample_freq\": 3,\n          \"subsample\": 0.9,\n          \"bagging_seed\": 11,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.3,\n          'reg_lambda': 0.3,\n          'colsample_bytree': 0.9,\n         }\nresult_dict_lgb = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgbd', \n                                             eval_metric='auc', plot_feature_importance=True,\n                                             verbose=500, early_stopping_rounds=200, n_estimators=5000, \n                                             averaging='usual', n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['isFraud'] = result_dict_lgb['prediction']\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CAT"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier, Pool, cv\nfrom sklearn.metrics import auc\nimport shap\n\nthresh = 0.80\nX_less_nas = X.dropna(thresh=X.shape[0]*(1-thresh), axis='columns')\ncols_dropped  = list(set(X.columns)-set(X_less_nas.columns))\nX_test.drop(cols_dropped, axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Catfeats = ['ProductCD'] + \\\n           [\"card\"+f\"{i+1}\" for i in range(6)] + \\\n           [\"addr\"+f\"{i+1}\" for i in range(2)] + \\\n           [\"P_emaildomain\", \"R_emaildomain\"] + \\\n           [\"M\"+f\"{i+1}\" for i in range(9)] + \\\n           [\"DeviceType\", \"DeviceInfo\"] + \\\n           [\"id_\"+f\"{i}\" for i in range(12, 39)]\n\n# removing columns dropped earlier when we weeded out the empty columns\n\nCatfeats = list(set(Catfeats)- set(cols_dropped))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_less_nas.fillna(-10000, inplace=True)\nX_test.fillna(-10000, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Cat_Cols:', cat_cols)\nprint('CAT_FEATS:', Catfeats)\nCatfeats.remove('id_26')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_params = {\n    'loss_function': 'Logloss',\n    'custom_loss':['AUC'],\n    'logging_level':'Silent',\n    'task_type' : 'CPU',\n    'early_stopping_rounds' : 100\n}\nsimple_model = CatBoostClassifier(**cat_params)\nsimple_model.fit(\n    X_less_nas, y,\n    cat_features=Catfeats,logging_level = 'Silent'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['isFraud'] = simple_model.predict_proba(X_test)[:,1]\nsub.to_csv('catboost.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nclf = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=9,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    missing=-999,\n    random_state=2019,\n    tree_method='hist'  # THE MAGICAL PARAMETER\n)\nclf.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['isFraud'] = clf.predict_proba(X_test)[:,1]\nsub.to_csv('simple_xgboost.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Weighted class XGBoost\n"},{"metadata":{},"cell_type":"markdown","source":"To handle class imbalance, we use a weighted model, where scale_pos_weight is the ratio of positive to negative cases. In our case, it is a 96.5% to 3.5% split, so we set it to the value 1/28."},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nclf = xgb.XGBClassifier(\n    scale_pos_weight=69,\n    n_estimators=500,\n    max_depth=9,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    missing=-999,\n    random_state=2019,\n    tree_method='hist'  # THE MAGICAL PARAMETER\n)\nclf.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['isFraud'] = clf.predict_proba(X_test)[:,1]\nsub.to_csv('weighted_xgboost.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}