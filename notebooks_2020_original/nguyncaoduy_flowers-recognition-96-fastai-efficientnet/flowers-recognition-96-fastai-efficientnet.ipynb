{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Normally, we can use a common model such as **ResNet** for this task!\n* However, I want to test out **EfficientNet** with fastai this time! :))"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Download EfficientNet from LukeMK\n! pip install efficientnet-pytorch","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing the libraries\nfrom fastai.vision import *\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the path\npath = Path('/kaggle/input/flowers-recognition/flowers')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the data using fastai's Datablock API\nsrc = (ImageList.from_folder(path)\n                .split_by_rand_pct(0.2, seed=42)\n                .label_from_folder()\n                .transform(get_transforms(), size=300))\n\ndata = src.databunch(bs=8).normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see some training examples\ndata.show_batch(rows=2, figsize=(9, 6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* EfficientNet comes with a variety of sub-models **from b0 to b7**\n* The larger the model, the higher the amount of **width, depth, resolution, and dropout**\n* We start out with image size of **224x224**, so let's use **b0** first as a baseline\n* We can use bigger images later with larger models"},{"metadata":{},"cell_type":"markdown","source":"| Coefficient | Width | Depth | Resolution | Dropout | Last layer |\n|:-----------:|:-----:|:-----:|:----------:|:-------:|:----------:|\n|      b0     |  1.0  |  1.0  |     224    |   0.2   |1280|\n|      b1     |  1.0  |  1.1  |     240    |   0.2   |1280|\n|      b2     |  1.1  |  1.2  |     260    |   0.3   |1408|\n|      b3     |  1.2  |  1.4  |     300    |   0.3   |1536|\n|      b4     |  1.4  |  1.8  |     380    |   0.4   |1792|\n|      b5     |  1.6  |  2.2  |     456    |   0.4   |2048|\n|      b6     |  1.8  |  2.6  |     528    |   0.5   |2304|\n|      b7     |  2.0  |  3.1  |     600    |   0.5   |2560|"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Replace the fully connected layer at the end to fit our task\n# Pre-trained model based on adversarial training\narch = EfficientNet.from_pretrained(\"efficientnet-b3\", advprop=True)\narch._fc = nn.Linear(1536, data.c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define custom loss function\nloss_func = LabelSmoothingCrossEntropy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the model\nlearn = Learner(data, arch, loss_func=loss_func, metrics=accuracy, model_dir='/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model using 1 Cycle policy\nlearn.fit_one_cycle(3, slice(1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unfreeze the model and retrain\nlearn.unfreeze()\nlearn.fit_one_cycle(2, slice(1e-5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the result\nlearn.show_results(rows=2, figsize=(9, 6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* In conclusion, our model was able to reach **96-97% accuracy** using b3 with 300x300 images!\n* However, it seemed that the model **consumed a lot of memory and training time!** \n* I was not able to train with b7 using 600x600 images. \n* I'm pretty sure that the result **will be even better** if I could use that!\n* Hope that I will be able to find out the issue next time. :((\n* The good thing is that the model **converges very fast after just 1-2 epochs**! :))"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}