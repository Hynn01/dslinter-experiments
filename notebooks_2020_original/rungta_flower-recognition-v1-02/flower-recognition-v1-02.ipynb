{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom os import listdir\nfrom os.path import join\nimport cv2\nimport pandas\nimport os\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = \"../input/flowers-recognition/flowers/\"\nfolders = os.listdir(data)\nprint(folders)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_names = []\ntrain_labels = []\ntrain_images = []\n\nsize = 64,64\n\nfor folder in folders:\n    for file in os.listdir(os.path.join(data,folder)):\n        if file.endswith(\"jpg\"):\n            image_names.append(os.path.join(data,folder,file))\n            train_labels.append(folder)\n            img = cv2.imread(os.path.join(data,folder,file))\n            im = cv2.resize(img,size)\n            train_images.append(im)\n        else:\n            continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = np.array(train_images)\n\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.astype('float32') / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_dummies = pandas.get_dummies(train_labels)\n\nlabels =  label_dummies.values.argmax(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pandas.unique(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pandas.unique(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"union_list = list(zip(train, labels))\nrandom.shuffle(union_list)\ntrain,labels = zip(*union_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = np.array(train)\nlabels = np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n\nmodel = keras.Sequential()\nmodel.add(Conv2D(64, kernel_size = (3,3), activation = 'relu', input_shape = (64,64,3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\nmodel.add(Conv2D(128, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\nmodel.add(Conv2D(128, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\nmodel.add(Conv2D(128, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(5, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.fit(train, labels,\n          epochs=5, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}