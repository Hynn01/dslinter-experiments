{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Summary\nI was confused as to what is it that we are trying to forecast in this competition. Apparently, if you group your test set by `installation_id` you will get a long list of the activities of a user. It contains games, clips, activities, Assessments, etc. We should use this history to predict the very last row of each `installation_id`. Below is an example for the first user in test set `00abaee7`. This data shows, he/she started the app, watched the welcome to app clip, then magma peak - level 1 clip and then two other clips. Then he/she played the \"Chow Time\" game. As you scroll down you can see all of his/her acitivies. At the very end of the activities list you can see that he/she started to play \"Cauldron Filler\" Assessment task which only has 1 row. The test set is truncated there to indicate that we should predict this user's Assessment on this task."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\ntrain_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\nspecs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\ntest = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\nsubmission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('max_rows', None)\ntest.query('installation_id==\"00abaee7\"').head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.query('installation_id==\"00abaee7\"').tail(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline model\nNow to get started with a very basic baseline and make everything more clear, I have used the mode value of each Assessment task in the train_labels set and used them as predictions. As you see it gives us LB 0.395"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_map = dict(train_labels.groupby('title')['accuracy_group'].agg(lambda x:x.value_counts().index[0])) # get the mode\nlabels_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['accuracy_group'] = test.groupby('installation_id').last()['title'].map(labels_map).reset_index(drop=True)\nsubmission.to_csv('submission.csv', index=None)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['accuracy_group'].plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels['accuracy_group'].plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hope this gets you started. Kudos to yasufuminakama for clarifying it for me. \n\nHappy kaggling!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}