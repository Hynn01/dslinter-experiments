{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os, sys, glob\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Listing of tick data files"},{"metadata":{"trusted":true},"cell_type":"code","source":"tickdata = dict()\nfor root, dirs, filenames in os.walk('/kaggle/input'):\n    for dirname in dirs:\n        files_csv_zg = glob.glob(os.path.join(root, dirname,'*.csv.zg'))\n        tickdata[str(dirname)] = files_csv_zg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Created tensorflow CsvDataset for time series data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the gzipped csv, extension set to .csv.zg to disable decompression in kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = dict()\nfor ccy, files in tickdata.items():\n    datasets[ccy]=tf.data.experimental.CsvDataset(files, [tf.string,tf.float32,tf.float32],header=True, compression_type=\"GZIP\",select_cols=[0,1,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_ds = next(iter(datasets.values()))\ninput_ds.element_spec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in input_ds.take(5):\n    print(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conversion function\n\n```(datetime: string, bid: float32, ask: float32) -> (dateime: string, timestamp: float64,  bid: float32, ask: float32, mid: float32, spread:float32)```"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime, timedelta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_func(dt, bid, ask):\n    txt = lambda t : t.numpy().decode('ascii')\n    conv = lambda z : pd.Timestamp(datetime.strptime(z.numpy().decode('ascii'), '%Y-%m-%d %H:%M:%S.%f')).to_datetime64()\n    return tf.py_function(txt,[dt], tf.string), tf.py_function(conv, [dt], tf.float64), bid, ask,(bid+ask)/2, ask-bid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_data = dict()\nfor key, ds in datasets.items():\n    ts_data[key] = ds.map(conv_func)\n    ts_data[key].cache(key)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = next(iter(ts_data.values()))\ntest_ds.element_spec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in test_ds.take(5):\n    print(f)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}