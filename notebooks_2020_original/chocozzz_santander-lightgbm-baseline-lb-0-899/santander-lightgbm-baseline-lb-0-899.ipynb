{"cells":[{"metadata":{"_uuid":"2252270d7f435df3804fddd8d467a873e434a1d5"},"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-organizations/141/thumbnail.jpg?r=890)\n# Santander Customer Transaction Prediction\nCan you identify who will make a transaction?\n\nVersion6\n- Ensemble : LB 0.899\n- LightGBM : LB 0.898\n- Catboost : LB 0.898 "},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true,"_uuid":"7cdca812b176d9cc19bec30b12c700178571341d"},"cell_type":"code","source":"### 패키지 설치 \nimport pandas as pd #Analysis \nimport matplotlib.pyplot as plt #Visulization\nimport seaborn as sns #Visulization\nimport numpy as np #Analysis \nfrom scipy.stats import norm #Analysis \nfrom sklearn.preprocessing import StandardScaler #Analysis \nfrom scipy import stats #Analysis \nimport warnings \nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport gc\n\nimport os\nimport string\ncolor = sns.color_palette()\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\n\nimport plotly.graph_objs as go\n\nimport time\nimport random","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nimport gc\nimport time\nimport sys\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')\nfrom sklearn import metrics\n\nplt.style.use('seaborn')\nsns.set(font_scale=1)\npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7a2000100605301248b40c0e875048a34d79c32"},"cell_type":"code","source":"# Taking a look at how many rows and columns the train dataset contains\nrows1 = train_df.shape[0]; rows2 = test_df.shape[0]; \ncolumns1 = train_df.shape[1]; columns2 = test_df.shape[1]\nprint(\"The train dataset contains {0} rows and {1} columns\".format(rows1, columns1))\nprint(\"The test dataset contains {0} rows and {1} columns\".format(rows2, columns2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dac02272370589dee903587ee04d5d4ee45dffbf"},"cell_type":"markdown","source":"There are some check point. \n- 1. The train and test row are similar.  \n- 2. The column size so many.  "},{"metadata":{"trusted":true,"_uuid":"aac1a10d58f9e4063d40a62098e0f058f8ae250c"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d8f7f0446ff253e5e30a94c841c8a07a4a95c80"},"cell_type":"markdown","source":"Wow. All variable name is var_. it means that the variable is identifier !!!. https://www.kaggle.com/c/porto-seguro-safe-driver-prediction porto competition also has identifier variable. This link will help."},{"metadata":{"trusted":true,"_uuid":"ed0c0153ea8907385b705d9a549fd628d25e487f"},"cell_type":"code","source":"data = [go.Bar(\n            x = train_df[\"target\"].value_counts().index.values,\n            y = train_df[\"target\"].value_counts().values,\n            text='Distribution of target variable'\n    )]\n\nlayout = go.Layout(\n    title='Target variable distribution'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8558b2bcaad208aed499860883a68d1544a8abe7"},"cell_type":"markdown","source":"Target is unbalanced. i'll try upsampling...!"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c8cfb9140c90478679ca84396afb8fb0d2ac14e1"},"cell_type":"code","source":"#https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-nn-approach\ndef mis_value_graph(data):  \n    data = [\n    go.Bar(\n        x = data.columns,\n        y = data.isnull().sum(),\n        name = 'Counts of Missing value',\n        textfont=dict(size=20),\n        marker=dict(\n        line=dict(\n            color= generate_color(),\n            #width= 2,\n        ), opacity = 0.45\n    )\n    ),\n    ]\n    layout= go.Layout(\n        title= '\"Total Missing Value By Column\"',\n        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n        yaxis= dict(title='Value Count', ticklen=5, gridwidth=2),\n        showlegend=True\n    )\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig, filename='skin')\n    \ndef generate_color():\n    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: random.randint(0, 255), range(3)))\n    return color\n\nmis_value_graph(train_df)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"59dbde482ec71ee6baf4c06ea7ecfbea41f55d05"},"cell_type":"code","source":"#https://www.kaggle.com/ashishpatel26/bird-eye-view-of-two-sigma-nn-approach\ndef mis_value_graph(data):  \n    data = [\n    go.Bar(\n        x = data.columns,\n        y = data.isnull().sum(),\n        name = 'Counts of Missing value',\n        textfont=dict(size=20),\n        marker=dict(\n        line=dict(\n            color= generate_color(),\n            #width= 2,\n        ), opacity = 0.45\n    )\n    ),\n    ]\n    layout= go.Layout(\n        title= '\"Total Missing Value By Column\"',\n        xaxis= dict(title='Columns', ticklen=5, zeroline=False, gridwidth=2),\n        yaxis= dict(title='Value Count', ticklen=5, gridwidth=2),\n        showlegend=True\n    )\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig, filename='skin')\n    \ndef generate_color():\n    color = '#{:02x}{:02x}{:02x}'.format(*map(lambda x: random.randint(0, 255), range(3)))\n    return color\n\nmis_value_graph(test_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4078fa3c26fa649dd203e32bc1981b59d9501d2"},"cell_type":"markdown","source":"Train and Test has no missing value. Very Nice !!!. "},{"metadata":{"trusted":true,"_uuid":"096aed71c764065e41e0aa2e4c7170f44837af50"},"cell_type":"code","source":"train_int = train_df.copy()\ndel train_int['ID_code']\ndata = [\n    go.Heatmap(\n        z= train_int.corr().values,\n        x= train_int.columns.values,\n        y= train_int.columns.values,\n        colorscale='Viridis',\n        reversescale = False,\n        #text = True ,\n        opacity = 1.0 )\n]\n\nlayout = go.Layout(\n    title='Pearson Correlation of Integer-type features',\n    xaxis = dict(ticks='', nticks=36),\n    yaxis = dict(ticks='' ),\n    width = 900, height = 700)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='labelled-heatmap')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff0b13df257ae9ee849d47f7cab29e299ea4c75b"},"cell_type":"markdown","source":"## LightGBM BaseLine"},{"metadata":{"trusted":true,"_uuid":"6d620e0dd22e27e639fee2bf056c0fe6528e237b","_kg_hide-input":true},"cell_type":"code","source":"# https://www.kaggle.com/fayzur/customer-transaction-prediction-strong-baseline\n# Thanks fayzur. Nice Parameter \nparam = {\n        'num_leaves': 10,\n        'max_bin': 119,\n        'min_data_in_leaf': 11,\n        'learning_rate': 0.02,\n        'min_sum_hessian_in_leaf': 0.00245,\n        'bagging_fraction': 1.0, \n        'bagging_freq': 5, \n        'feature_fraction': 0.05,\n        'lambda_l1': 4.972,\n        'lambda_l2': 2.276,\n        'min_gain_to_split': 0.65,\n        'max_depth': 14,\n        'save_binary': True,\n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'binary',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'auc',\n        'is_unbalance': True,\n        'boost_from_average': False,\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0775a59bf014dbbb7a8e879dd9cd3c008b56ee6"},"cell_type":"code","source":"features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\ntarget = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7c1952aecdc81cf4afdda7f9fdc9342e0484442"},"cell_type":"code","source":"%%time\nfrom sklearn.metrics import roc_auc_score, roc_curve\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\nfeature_importance_df = pd.DataFrame()\n\nstart = time.time()\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(skf.split(train_df.values, target.values)):\n    print(\"fold n°{}\".format(fold_))\n    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    num_round = 10000\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 100)\n    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / 5\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10ffee346217f2ff29f8aafaa99ed31490e1e9a2"},"cell_type":"code","source":"cols = (feature_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(14,26))\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (averaged over folds)')\nplt.tight_layout()\nplt.savefig('lgbm_importances.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d53f531c423fc9b9695555f1eef12771b6d88e1"},"cell_type":"code","source":"##submission\nsub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\nsub_df[\"target\"] = predictions\nsub_df.to_csv(\"lgb_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fc313aeff29c13b83db3abfcbe51ed08f7e9b1b"},"cell_type":"code","source":"## Catboost : https://www.kaggle.com/wakamezake/starter-code-catboost-baseline\nfrom catboost import Pool, CatBoostClassifier\nmodel = CatBoostClassifier(loss_function=\"Logloss\", eval_metric=\"AUC\")\nkf = KFold(n_splits=5, random_state=42, shuffle=True)\n\ny_valid_pred = 0 * target\ny_test_pred = 0\n\nfor idx, (train_index, valid_index) in enumerate(kf.split(train_df)):\n    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n    X_train, X_valid = train_df[features].iloc[train_index,:], train_df[features].iloc[valid_index,:]\n    _train = Pool(X_train, label=y_train)\n    _valid = Pool(X_valid, label=y_valid)\n    print( \"\\nFold \", idx)\n    fit_model = model.fit(_train,\n                          eval_set=_valid,\n                          use_best_model=True,\n                          verbose=200\n                         )\n    pred = fit_model.predict_proba(X_valid)[:,1]\n    print( \"  auc = \", roc_auc_score(y_valid, pred) )\n    y_valid_pred.iloc[valid_index] = pred\n    y_test_pred += fit_model.predict_proba(test_df[features])[:,1]\ny_test_pred /= 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da02204a130a43e5efb0967350ec84fbb0d38156"},"cell_type":"code","source":"##submission\nsub_df1 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\nsub_df1[\"target\"] = y_test_pred\nsub_df1.to_csv(\"cat_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b37bf176b65d0fab959625832c05bd22e1b0501f"},"cell_type":"code","source":"corr_df = pd.merge(sub_df,sub_df1,how='left',on='ID_code')\ncorr_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06da1c6f92bb4f6ad9c725569c511b084d18d1e6"},"cell_type":"code","source":"##submission\nsub_df2 = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\nsub_df2[\"target\"] = 0.5*sub_df[\"target\"] + 0.5*sub_df1[\"target\"]\nsub_df2.to_csv(\"lgb_cat_submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}