{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nimport csv\nimport pandas as pd\nimport matplotlib as plt\nimport matplotlib.cm as cm\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\nimport chardet\nfrom skimage.feature import local_binary_pattern\nimport copy\ndemoindex = 1\ndef downsample(img):\n    row = img.shape[0]\n    col = img.shape[1]\n    newimg = np.zeros((int(row / 2), int(col / 2)))\n    for i in range(0, row - 1, 2):\n        for j in range(0, col - 1, 2):\n            s = 0\n            s = s + img[i,j] + img[i+1,j] + img[i,j+1] + img[i+1,j+1]\n            s = int(s/4)\n            r = int(i / 2)\n            c = int(j / 2)\n            newimg[r][c] = s\n    return newimg","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"info = pd.read_csv(\"/kaggle/input/ultrasound-nerve-segmentation/train_masks.csv\") \nimage_path = \"/kaggle/input/ultrasound-nerve-segmentation/train/{}_{}.tif\"\nmask_path = \"/kaggle/input/ultrasound-nerve-segmentation/train/{}_{}_mask.tif\"\nrows = 420\ncols = 580\nwindow_height = 60\nwindow_width = 70\nstep_size = [window_height, window_width]\nnums = 120\nli = []\ni = 0\nwhile len(li) < nums:  #note the index of images that have nerve\n    mask = cv2.imread(mask_path.format(info['subject'][i], info['img'][i]), 2)\n    if (np.sum(mask) > 0):\n        li.append(i)\n    i = i + 1    \nimgs = np.zeros((nums, int(rows / 2), int(cols / 2)))\nmasks = np.zeros((nums, int(rows / 2), int(cols / 2)))\ncontours = np.zeros((nums, int(rows/2), int(cols/2)))\nimgwithoutline = np.zeros((nums, int(rows/2), int(cols/2)))\ncor = np.zeros((nums, 2))\ncenteredoutline = np.zeros((nums, int(window_height), int(window_width)))\nmaps = np.zeros((nums, 5, int(window_height), int(window_width)))\nmap1 = np.zeros((nums, int(rows/2), int(cols/2)))\nmap2 = np.zeros((nums, int(rows/2), int(cols/2)))\nmap3 = np.zeros((nums, int(rows/2), int(cols/2)))\nmap4 = np.zeros((nums, int(rows/2), int(cols/2)))\nmap5 = np.zeros((nums, int(rows/2), int(cols/2)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L5 = np.array((1,4,6,4,1))\nL5 = L5.reshape(1,5)\nE5 = np.array((-1,-2,0,2,1))\nE5 = E5.reshape(1,5)\nS5 = np.array((-1,0,2,0,-1))\nS5 = S5.reshape(1,5)\nR5 = np.array((1,-4,6,-4,1))\nR5 = R5.reshape(1,5)\nW5 = np.array((-1,2,0,-2,1))\nW5 = W5.reshape(1,5)\nkernel1 = np.kron(L5.T, L5)\nkernel2 = np.kron(E5.T, E5)\nkernel3 = np.kron(S5.T,S5)\nkernel4 = np.kron(W5.T,W5)\nkernel5 = np.kron(R5.T,R5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Center the nerve, generate positive window"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import signal\nfor n in range(0,nums):\n    img = cv2.imread(image_path.format(info['subject'][n], info['img'][n]), 2)\n    mask = cv2.imread(mask_path.format(info['subject'][n], info['img'][n]), 2)\n    imgm=cv2.medianBlur(img,5)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    equ = clahe.apply(imgm)\n    equ = downsample(equ)\n    mask = downsample(mask)\n    imgs[n,:,:] = equ\n    map1[n] = signal.convolve2d(equ, kernel1, mode = 'same')\n    map2[n] = signal.convolve2d(equ, kernel2, mode = 'same')\n    map3[n] = signal.convolve2d(equ, kernel3, mode = 'same')\n    map4[n] = signal.convolve2d(equ, kernel4, mode = 'same')\n    map5[n] = signal.convolve2d(equ, kernel5, mode = 'same')\n    masks[n,:,:] = mask.astype(np.bool)\n    imgwithoutline[n,:,:] = copy.deepcopy(equ)\n    mask_outline = cv2.blur(mask, (3,3))\n    mask_outline = mask_outline * ((mask_outline < 255) & (mask_outline > 0))\n    contours[n,:,:] = mask_outline > 0\n    temp = np.where(mask.astype(np.bool))\n    if temp[0].size != 0:         # center of the nerve\n        xs = temp[0]\n        ys = temp[1]\n        x = int((min(xs) + max(xs)) / 2)\n        y = int((min(ys) + max(ys)) / 2)\n        cor[n,0] = x\n        cor[n,1] = y\n        contour = contours[n,x - int(window_height / 2) : x + int(window_height / 2),y - int(window_width / 2):y + int(window_width / 2)]\n        centeredoutline[n,:,:] = contour\n        maps[n,0] = map1[n,x - int(window_height / 2) : x + int(window_height / 2),y - int(window_width / 2):y + int(window_width / 2)]\n        maps[n,1] = map2[n,x - int(window_height / 2) : x + int(window_height / 2),y - int(window_width / 2):y + int(window_width / 2)]\n        maps[n,2] = map3[n,x - int(window_height / 2) : x + int(window_height / 2),y - int(window_width / 2):y + int(window_width / 2)]\n        maps[n,3] = map4[n,x - int(window_height / 2) : x + int(window_height / 2),y - int(window_width / 2):y + int(window_width / 2)]\n        maps[n,4] = map5[n,x - int(window_height / 2) : x + int(window_height / 2),y - int(window_width / 2):y + int(window_width / 2)]\nimgwithmask = imgs * masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(imgs[demoindex],cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,axarr = plt.subplots(5,1, figsize = (6, 5 * 6))\naxarr[0].imshow(maps[demoindex,0],cmap = 'gray')\naxarr[0].imshow(centeredoutline[demoindex],alpha = 0.2)\naxarr[0].set_title('detect average intensity')\naxarr[1].imshow(maps[demoindex,1],cmap = 'gray')\naxarr[1].imshow(centeredoutline[demoindex],alpha = 0.2)\naxarr[1].set_title('detect edges')\naxarr[2].imshow(maps[demoindex,2],cmap = 'gray')\naxarr[2].imshow(centeredoutline[demoindex],alpha = 0.2)\naxarr[2].set_title('detect spots')\naxarr[3].imshow(maps[demoindex,3],cmap = 'gray')\naxarr[3].imshow(centeredoutline[demoindex],alpha = 0.2)\naxarr[3].set_title('detect wave texture')\naxarr[4].imshow(maps[demoindex,4],cmap = 'gray')\naxarr[4].imshow(centeredoutline[demoindex],alpha = 0.2)\naxarr[4].set_title('detect ripple texture')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generate negative windows"},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_patch = []\nallpatch = []\npatcheswithoutline = []\nlabels = []\nstep_size = [window_height, window_width]\nfeatures = []\n\nfor n in range(0, nums):\n    curneg = []\n    img = imgs[n]\n    mask = masks[n]\n    for i in range(0, int(rows/2) - window_height + 1, step_size[0]):\n        for j in range(0, int(cols/2) - window_width + 1, step_size[1]):\n            curpatch = np.zeros((5, window_height, window_width))\n            m = mask[i:i+window_height, j:j+window_width]\n            m1 = map1[n, i:i+window_height, j: j + window_width]\n            m2 = map2[n, i:i+window_height, j: j + window_width]\n            m3 = map3[n, i:i+window_height, j: j + window_width]\n            m4 = map4[n, i:i+window_height, j: j + window_width]\n            m5 = map5[n, i:i+window_height, j: j + window_width]\n            curpatch[0,:,:]=m1\n            curpatch[1,:,:]=m2\n            curpatch[2,:,:]=m3\n            curpatch[3,:,:]=m4\n            curpatch[4,:,:]=m5\n            curimage.append(curpatch)\n            if (np.sum(m) == 0):    \n                curneg.append(curpatch)\n    curneg = np.array(curneg)\n    neg_patch.append(curneg)\n    allpatch.append(curimage)\nneg_patch = np.array(neg_patch)\n#             temp = withline[i:i + window_height, j:j + window_width]\n#             curoutline.append(temp)\n#     curneg = np.stack(curneg)\n#     curpatch = np.stack(curpatch)\n#     curoutline = np.stack(curoutline)\n#     neg.append(curneg)\n#             allpatch.append(curpatch)\n#     patcheswithoutline.append(curoutline)\n# neg = np.array(neg)\n# allpatch = np.array(allpatch)\n# labels = np.array(labels, dtype = np.bool)\n# patcheswithoutline = np.array(patcheswithoutline)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nnegpatch = np.zeros((5 * nums, 5, window_height, window_width))\ncur = 0\nfor i in range(0, nums):\n    curneg = neg_patch[i]\n    randomindex = random.sample(range(0,curneg.shape[0]),5)\n    negpatch[5 * i] = curneg[randomindex[0]]\n    negpatch[5 * i + 1] = curneg[randomindex[1]]\n    negpatch[5 * i + 2] = curneg[randomindex[2]]\n    negpatch[5 * i + 3] = curneg[randomindex[3]]\n    negpatch[5 * i + 4] = curneg[randomindex[4]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,axarr = plt.subplots(5,1, figsize = (6, 5 * 6))\naxarr[0].imshow(negpatch[demoindex,0],cmap = 'gray')\naxarr[0].set_title('detect average intensity')\naxarr[1].imshow(negpatch[demoindex,1],cmap = 'gray')\naxarr[1].set_title('detect edges')\naxarr[2].imshow(negpatch[demoindex,2],cmap = 'gray')\naxarr[2].set_title('detect spots')\naxarr[3].imshow(negpatch[demoindex,3],cmap = 'gray')\naxarr[3].set_title('detect wave texture')\naxarr[4].imshow(negpatch[demoindex,4],cmap = 'gray')\naxarr[4].set_title('detect ripple texture')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maps.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"al = np.concatenate((maps, negpatch), axis = 0)\nlabels = np.zeros(al.shape[0], dtype = np.bool)\nlabels[: maps.shape[0]] = 1\nfeatures = al.reshape(al.shape[0], -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = np.zeros(features.shape[1])\nfor i in range(features.shape[1]):\n    f = features[:, i]\n    fa = f[labels == 1]\n    fb = f[labels == 0]\n    mi = np.mean(f)\n    mia = np.mean(fa)\n    mib = np.mean(fb)\n    na = fa.shape[0]\n    nb = fb.shape[0]\n    va = np.var(fa)\n    vb = np.var(fb)\n    scores[i] = (na * np.square((mia - mi))+nb * np.square((mib-mi)))/(na*va+nb*vb)\nindexes = np.argsort(scores) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.where(scores > 0.1)[0].size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testnums = 50\ntestpatches = []\ntestlabels = []\ntestout = []\ntest_step_size = [window_height, window_width]\ntestmaps = np.zeros((testnums, 5, window_height, window_width))\ncorordinate = set()\nfor n in range(li[nums - 1] + 1, li[nums - 1] + testnums ):\n    img = cv2.imread(image_path.format(info['subject'][n], info['img'][n]), 2)\n    mask = cv2.imread(mask_path.format(info['subject'][n], info['img'][n]), 2)\n    imgm=cv2.medianBlur(img,5)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    equ = clahe.apply(imgm)\n    equ = downsample(equ)\n    mask = downsample(mask)\n    for i in range(0, int(rows/2 - window_height + 1), test_step_size[0]):\n        for j in range(0, int(cols/2 - window_width + 1), test_step_size[1]):\n            map1 = signal.convolve2d(equ[i:i+window_height, j: j + window_width], kernel1, mode = 'same')\n            map2 = signal.convolve2d(equ[i:i+window_height, j: j + window_width], kernel2, mode = 'same')\n            map3 = signal.convolve2d(equ[i:i+window_height, j: j + window_width], kernel3, mode = 'same')\n            map4 = signal.convolve2d(equ[i:i+window_height, j: j + window_width], kernel4, mode = 'same')\n            map5 = signal.convolve2d(equ[i:i+window_height, j: j + window_width], kernel5, mode = 'same')\n            m = mask[i:i+window_height, j:j+window_width]\n            testmaps[n,0] = map1\n            testmaps[n,1] = map2\n            testmaps[n,2] = map3\n            testmaps[n,3] = map4\n            testmaps[n,4] = map5\n            corordinate.add((i, j))\n            if (np.sum(m) > 0):\n                testlabels.append(1)\n            else:\n                testlabels.append(0)\ntestlabels = np.array(testlabels, dtype = np.bool)\ntestfeatures = testmaps.reshape(testmaps.shape[0], -1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\noutput = clf.predict(testfeatures)\nconfusion = confusion_matrix(testlabels, output)\np = clf.predict_proba(testfeatures)\nconfusion","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}