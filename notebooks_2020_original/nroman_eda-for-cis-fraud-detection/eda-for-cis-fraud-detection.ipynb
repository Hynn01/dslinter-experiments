{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel I will do my EDA on the dataset, make some visualizations, try to find any insights and create some new features.\n\nJoin me, it promises to be a thrilling adventure.\n\nSome tricks being used:\n* [card1 count encoding](#1)\n* [Covariate Shift](#2)\n* [features interaction](#3)\n* [data relaxation](#4)\n\nNew engineered features:\n* [Number of NaNs](#5)\n* [TransactionAmt and it's decimal part](#6)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport multiprocessing\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport gc\nfrom time import time\nimport datetime\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nimport graphviz\nwarnings.simplefilter('ignore')\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading all datasets using multiprocessing. This speads up a process a bit."},{"metadata":{"trusted":true},"cell_type":"code","source":"files = ['../input/test_identity.csv', \n         '../input/test_transaction.csv',\n         '../input/train_identity.csv',\n         '../input/train_transaction.csv',\n         '../input/sample_submission.csv']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\ndef load_data(file):\n    return pd.read_csv(file)\n\nwith multiprocessing.Pool() as pool:\n    test_id, test_tr, train_id, train_tr, sub = pool.map(load_data, files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train = pd.merge(train_tr, train_id, on='TransactionID', how='left')\ntest = pd.merge(test_tr, test_id, on='TransactionID', how='left')\n\ndel test_id, test_tr, train_id, train_tr\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_numerical(feature):\n    \"\"\"\n    Plot some information about a numerical feature for both train and test set.\n    Args:\n        feature (str): name of the column in DataFrame\n    \"\"\"\n    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16, 18))\n    sns.kdeplot(train[feature], ax=axes[0][0], label='Train');\n    sns.kdeplot(test[feature], ax=axes[0][0], label='Test');\n\n    sns.kdeplot(train[train['isFraud']==0][feature], ax=axes[0][1], label='isFraud 0')\n    sns.kdeplot(train[train['isFraud']==1][feature], ax=axes[0][1], label='isFraud 1')\n\n    test[feature].index += len(train)\n    axes[1][0].plot(train[feature], '.', label='Train');\n    axes[1][0].plot(test[feature], '.', label='Test');\n    axes[1][0].set_xlabel('row index');\n    axes[1][0].legend()\n    test[feature].index -= len(train)\n\n    axes[1][1].plot(train[train['isFraud']==0][feature], '.', label='isFraud 0');\n    axes[1][1].plot(train[train['isFraud']==1][feature], '.', label='isFraud 1');\n    axes[1][1].set_xlabel('row index');\n    axes[1][1].legend()\n\n    pd.DataFrame({'train': [train[feature].isnull().sum()], 'test': [test[feature].isnull().sum()]}).plot(kind='bar', rot=0, ax=axes[2][0]);\n    pd.DataFrame({'isFraud 0': [train[(train['isFraud']==0) & (train[feature].isnull())][feature].shape[0]],\n                  'isFraud 1': [train[(train['isFraud']==1) & (train[feature].isnull())][feature].shape[0]]}).plot(kind='bar', rot=0, ax=axes[2][1]);\n\n    fig.suptitle(feature, fontsize=18);\n    axes[0][0].set_title('Train/Test KDE distribution');\n    axes[0][1].set_title('Target value KDE distribution');\n    axes[1][0].set_title('Index versus value: Train/Test distribution');\n    axes[1][1].set_title('Index versus value: Target distribution');\n    axes[2][0].set_title('Number of NaNs');\n    axes[2][1].set_title('Target value distribution among NaN values');\n    \n# This code is stolen from Chris Deotte. \ndef relax_data(df_train, df_test, col):\n    cv1 = pd.DataFrame(df_train[col].value_counts().reset_index().rename({col:'train'},axis=1))\n    cv2 = pd.DataFrame(df_test[col].value_counts().reset_index().rename({col:'test'},axis=1))\n    cv3 = pd.merge(cv1,cv2,on='index',how='outer')\n    factor = len(df_test)/len(df_train)\n    cv3['train'].fillna(0,inplace=True)\n    cv3['test'].fillna(0,inplace=True)\n    cv3['remove'] = False\n    cv3['remove'] = cv3['remove'] | (cv3['train'] < len(df_train)/10000)\n    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] < cv3['test']/3)\n    cv3['remove'] = cv3['remove'] | (factor*cv3['train'] > 3*cv3['test'])\n    cv3['new'] = cv3.apply(lambda x: x['index'] if x['remove']==False else 0,axis=1)\n    cv3['new'],_ = cv3['new'].factorize(sort=True)\n    cv3.set_index('index',inplace=True)\n    cc = cv3['new'].to_dict()\n    df_train[col] = df_train[col].map(cc)\n    df_test[col] = df_test[col].map(cc)\n    return df_train, df_test\n\ndef plot_categorical(train: pd.DataFrame, test: pd.DataFrame, feature: str, target: str, values: int=5):\n    \"\"\"\n    Plotting distribution for the selected amount of most frequent values between train and test\n    along with distibution of target\n    Args:\n        train (pandas.DataFrame): training set\n        test (pandas.DataFrame): testing set\n        feature (str): name of the feature\n        target (str): name of the target feature\n        values (int): amount of most frequest values to look at\n    \"\"\"\n    df_train = pd.DataFrame(data={feature: train[feature], 'isTest': 0})\n    df_test = pd.DataFrame(data={feature: test[feature], 'isTest': 1})\n    df = pd.concat([df_train, df_test], ignore_index=True)\n    df = df[df[feature].isin(df[feature].value_counts(dropna=False).head(values).index)]\n    train = train[train[feature].isin(train[feature].value_counts(dropna=False).head(values).index)]\n    fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n    sns.countplot(data=df.fillna('NaN'), x=feature, hue='isTest', ax=axes[0]);\n    sns.countplot(data=train[[feature, target]].fillna('NaN'), x=feature, hue=target, ax=axes[1]);\n    axes[0].set_title('Train / Test distibution of {} most frequent values'.format(values));\n    axes[1].set_title('Train distibution by {} of {} most frequent values'.format(target, values));\n    axes[0].legend(['Train', 'Test']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transaction DT\nAccording to the official description 'TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp).' I see people in some kernels assume that a start date is a 1 of December 2017, but to be honest the exact start date is not that important. \n\nSo lets transform TransactionDT into a datetime."},{"metadata":{"trusted":true},"cell_type":"code","source":"startdate = datetime.datetime.strptime('2017-12-01', '%Y-%m-%d')\ntrain['TransactionDT'] = train['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\ntest['TransactionDT'] = test['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(16, 6))\ntrain.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=axes).set_ylabel('isFraud mean', fontsize=14);\naxes.set_title('Mean of isFraud by day', fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(16, 6))\ntrain['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=axes).set_xlabel('Date', fontsize=14);\ntest['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=axes).set_ylabel('Number of training examples', fontsize=14);\naxes.set_title('Number of training examples by day', fontsize=16);\naxes.legend(['Train', 'Test']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now combining both mean of isFraud by day and number of training examples by day into a single plot."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(16, 6))\ntrain.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=ax1, color='blue')\nax1.tick_params(axis='y', labelcolor='blue')\nax1.set_ylabel('isFraud mean', color='blue', fontsize=14)\nax2 = ax1.twinx()\ntrain['TransactionDT'].dt.floor('d').value_counts().sort_index().plot(ax=ax2, color='tab:orange');\nax2.tick_params(axis='y', labelcolor='tab:orange');\nax2.set_ylabel('Number of training examples', color='tab:orange', fontsize=14);\nax2.grid(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n# card1\nI have decided to start from one of the most important features of this dataset according to LightGBM feature_importance. And **card1** is one of those features.\n\nWhat I did is I've created a separate dataset with only this feature in it and also I added one more feature to this new dataset, which is an original feature's frequency (count) encoding. Why I did this? Well, you can reference [Santander Customer Transaction Prediction](https://www.kaggle.com/c/santander-customer-transaction-prediction) competition, where this kind of encoding really boosted a score up. \n\nI'll make some visualizations (shoutout to [Chris Deotte](https://www.kaggle.com/cdeotte)) to show you why that works and might work in this case as well."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"y = train['isFraud']\nX = pd.DataFrame()\nX['card1'] = train['card1']\nX['card1_count'] = train['card1'].map(pd.concat([train['card1'], test['card1']], ignore_index=True).value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\nclf = DecisionTreeClassifier(max_leaf_nodes=4)\nclf.fit(X_train, y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So if we train a simple decision tree, using this two features we have an AUC slightly higher that 0.5. Let's see why by plotting this tree as a graph"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tree_graph = tree.export_graphviz(clf, out_file=None, max_depth = 10,\n    impurity = False, feature_names = X.columns, class_names = ['0', '1'],\n    rounded = True, filled= True )\ngraphviz.Source(tree_graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first split is by the values less than or equal to 10881.5 (black line) and the second one is 8750.0 (red line) and a tree does not use a count feature at all."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(14, 6))\nsns.kdeplot(X[y==1]['card1'], label='isFraud 1');\nsns.kdeplot(X[y==0]['card1'], label='isFraud 0');\nplt.plot([10881.5, 10881.5], [0.0000, 0.0001], sns.xkcd_rgb[\"black\"], lw=2);\nplt.plot([8750.0, 8750.0], [0.0000, 0.0001], sns.xkcd_rgb[\"red\"], lw=2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But lets take a little step back and train a boosting model on only one original feature card1"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"params = {'objective': 'binary', \"boosting_type\": \"gbdt\", \"subsample\": 1, \"bagging_seed\": 11, \"metric\": 'auc', 'random_state': 47}\nX_train, X_test, y_train, y_test = train_test_split(X['card1'], y, test_size=0.33, random_state=47, stratify=y)\nclf = lgb.LGBMClassifier(**params)\nclf.fit(X_train.values.reshape(-1, 1), y_train)\nprint('ROC AUC score', roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a heatmap with a probability of isFraud=1 for every unique value in the **card1** feature.\n\nThis picture reminds me an opening from a Total Recall movie. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nx = clf.predict_proba(X['card1'].sort_values().unique().reshape(-1, 1))[:, 1]\nx = pd.Series(x, index=X['card1'].sort_values().unique())\nsns.heatmap(x.to_frame(), cmap='RdBu_r', center=0.0);\nplt.xticks([]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets add a second feature - count encoded **card1** values."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\nclf = lgb.LGBMClassifier(**params)\nclf.fit(X_train, y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Holdout score has significantly increased. Lets create another heatmap and see why. \n\nThere are some darker spots in some intersections of the variable **card1** values and it's count encoded values. This is the reason of the holdout score improvement.\n\n*The image is pre-rendered since rendering takes some significant amount of time*"},{"metadata":{},"cell_type":"markdown","source":"![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1696976%2F7153f1242daa586d6849c83242c3fe40%2F35267aee89a7552caf082b6bb0039aa5-full.png?generation=1564585074348507&alt=media)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('card1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting this variable gives us such information as:\n* distribution in train and test set is almost equal.\n* distribution between target values differs, which make this feature so valuable\n* this feature doesn't have any NaNs"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\nLets check a Covariate Shift of the feature. This means that we will try to distinguish whether a values correspond to a training set or to a testing set."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def covariate_shift(feature):\n    df_card1_train = pd.DataFrame(data={feature: train[feature], 'isTest': 0})\n    df_card1_test = pd.DataFrame(data={feature: test[feature], 'isTest': 1})\n\n    # Creating a single dataframe\n    df = pd.concat([df_card1_train, df_card1_test], ignore_index=True)\n    \n    # Encoding if feature is categorical\n    if str(df[feature].dtype) in ['object', 'category']:\n        df[feature] = LabelEncoder().fit_transform(df[feature].astype(str))\n    \n    # Splitting it to a training and testing set\n    X_train, X_test, y_train, y_test = train_test_split(df[feature], df['isTest'], test_size=0.33, random_state=47, stratify=df['isTest'])\n\n    clf = lgb.LGBMClassifier(**params, num_boost_round=500)\n    clf.fit(X_train.values.reshape(-1, 1), y_train)\n    roc_auc =  roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1])\n\n    del df, X_train, y_train, X_test, y_test\n    gc.collect();\n    \n    return roc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate Shift ROC AUC score:', covariate_shift('card1'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ROC AUC score is close to 0.5, this means that this feature almost does not have any shift between train and test and is definitely worth keeping it."},{"metadata":{},"cell_type":"markdown","source":"# ProductCD"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'ProductCD', 'isFraud')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift ROC AUC:', covariate_shift('ProductCD'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# card2"},{"metadata":{},"cell_type":"markdown","source":"Making a count feature for card2 to perform the same experiment as with card1. First the heatmap for all possible interactions of card2 feature and it's count."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"y = train['isFraud']\nX = pd.DataFrame()\nX['card2'] = train['card2']\nX['card2_count'] = train['card2'].map(pd.concat([train['card2'], test['card2']], ignore_index=True).value_counts(dropna=False))\n\nresult_df = pd.DataFrame()\n\nfor i in X['card2'].sort_values().unique():\n    x = pd.DataFrame()\n    x['card2'] = [i] * X['card2_count'].nunique()\n    x['card2_count'] = X['card2_count'].sort_values().unique()\n    \n    result_df = pd.concat([result_df, x], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\nclf = lgb.LGBMClassifier(**params)\nclf.fit(X_train, y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))\n\npreds = clf.predict_proba(result_df)[:, 1]\npreds = preds.reshape(X['card2'].nunique(dropna=False), X['card2_count'].nunique(dropna=False))\npreds = pd.DataFrame(preds, index=X['card2'].sort_values().unique(), columns=X['card2_count'].sort_values().unique())\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 6))\nsns.heatmap(preds, cmap='RdBu_r', center=0.0);\nax.set_ylabel('card2');\nax.set_xlabel('card2_count');\nax.set_title('card2 / card2_count interaction');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And a scatter plot with a \"decision boundary\" of the model. White 'X' marks represents a test set examples."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test_X = pd.DataFrame()\ntest_X['card2'] = test['card2']\ntest_X['card2_count'] = test['card2'].map(pd.concat([train['card2'], test['card2']], ignore_index=True).value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nax = plt.axes()\nsc = plt.scatter(y=result_df['card2'], x=result_df['card2_count'], c=clf.predict_proba(result_df)[:, 1], cmap='RdBu_r');\nax.set_ylabel('card2');\nax.set_xlabel('card2_count');\nax.set_title('card2 / card2_count interaction');\nplt.colorbar(sc);\nplt.scatter(y=test_X['card2'], x=test_X['card2_count'], marker='x', c='white', alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('card2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift ROC AUC:', covariate_shift('card2'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# card3"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('card3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift ROC AUC:', covariate_shift('card3'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# card4"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_train = pd.DataFrame(data={'card4': train['card4'], 'isTest': 0})\ndf_test = pd.DataFrame(data={'card4': test['card4'], 'isTest': 1})\ndf = pd.concat([df_train, df_test], ignore_index=True)\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nsns.countplot(data=df.fillna('NaN'), x='card4', hue='isTest', ax=axes[0]);\nsns.countplot(data=train[['card4', 'isFraud']].fillna('NaN'), x='card4', hue='isFraud', ax=axes[1]);\naxes[0].set_title('Train / Test distibution');\naxes[1].set_title('Train distibution by isFraud');\naxes[0].legend(['Train', 'Test']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift ROC AUC:', covariate_shift('card4'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# card5"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('card5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift ROC AUC:', covariate_shift('card5'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# card6"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_train = pd.DataFrame(data={'card6': train['card6'], 'isTest': 0})\ndf_test = pd.DataFrame(data={'card6': test['card6'], 'isTest': 1})\ndf = pd.concat([df_train, df_test], ignore_index=True)\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nsns.countplot(data=df.fillna('NaN'), x='card6', hue='isTest', ax=axes[0]);\nsns.countplot(data=train[['card6', 'isFraud']].fillna('NaN'), x='card6', hue='isFraud', ax=axes[1]);\naxes[0].set_title('Train / Test distibution');\naxes[1].set_title('Train distibution by isFraud');\naxes[0].legend(['Train', 'Test']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift ROC AUC:', covariate_shift('card6'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# addr1 "},{"metadata":{},"cell_type":"markdown","source":"Another feature with a relatively high importance is **addr1**. According to the name of the feature we can assume that it contains some kind of users address, but in an encoded way. Also this time a feature have some missing values. We are going to fill them with 0."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"y = train['isFraud']\nX = pd.DataFrame()\nX['addr1'] = train['addr1']\nX['addr1_count'] = train['addr1'].map(pd.concat([train['addr1'], test['addr1']], ignore_index=True).value_counts(dropna=False))\nX['addr1'].fillna(0, inplace=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X['addr1'], y, test_size=0.33, random_state=47)\nclf = DecisionTreeClassifier(max_leaf_nodes=4)\nclf.fit(X_train.values.reshape(-1, 1), y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tree_graph = tree.export_graphviz(clf, out_file=None, max_depth = 10,\n    impurity = False, feature_names = ['addr1'], class_names = ['0', '1'],\n    rounded = True, filled= True )\ngraphviz.Source(tree_graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(14, 6))\nsns.kdeplot(X[y==1]['addr1'], label='isFraud 1');\nsns.kdeplot(X[y==0]['addr1'], label='isFraud 0');\nplt.plot([50.0, 50.0], [0.0000, 0.008], sns.xkcd_rgb[\"black\"], lw=2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again training a gradient boosting model with only one feature."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"params = {'objective': 'binary', \"boosting_type\": \"gbdt\", \"subsample\": 1, \"bagging_seed\": 11, \"metric\": 'auc', 'random_state': 47}\nX_train, X_test, y_train, y_test = train_test_split(X['addr1'], y, test_size=0.33, random_state=47, stratify=y)\nclf = lgb.LGBMClassifier(**params)\nclf.fit(X_train.values.reshape(-1, 1), y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test.values.reshape(-1, 1))[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predictions heatmap."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nx = clf.predict_proba(X['addr1'].sort_values().unique().reshape(-1, 1))[:, 1]\nx = pd.Series(x, index=X['addr1'].sort_values().unique())\nsns.heatmap(x.to_frame(), cmap='RdBu_r', center=0.0);\nplt.xticks([]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far we are doing exactly the same thing that we have been doing for the previous variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\nclf = lgb.LGBMClassifier(**params)\nclf.fit(X_train, y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"result_df = pd.DataFrame()\n\nfor i in X['addr1'].sort_values().unique():\n    x = pd.DataFrame()\n    x['addr1'] = [i] * X['addr1_count'].nunique()\n    x['addr1_count'] = X['addr1_count'].sort_values().unique()\n    \n    result_df = pd.concat([result_df, x], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"preds = clf.predict_proba(result_df)[:, 1]\npreds = preds.reshape(X['addr1'].nunique(), X['addr1_count'].nunique())\npreds = pd.DataFrame(preds, index=X['addr1'].sort_values().unique(), columns=X['addr1_count'].sort_values().unique())\n\nplt.figure(figsize=(12, 6))\nsns.heatmap(preds, cmap='RdBu_r', center=0.0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('addr1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution is the same, amount of NaN's is the same. Some difference in target value distribution. \n\nNext checking Covariate Shift for addr1."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift ROC AUC score:', covariate_shift('addr1'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ROC AUC score is close to 0.5\n\nThis feature also does not have any shift between train and test set."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n# card1 to addr1 interaction\n\nNext I am going to create a new feature out of this two features interaction and train on the result."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"X = pd.DataFrame()\nX['addr1'] = train['addr1']\nX['card1'] = train['card1']\ny = train['isFraud']\nX['addr1'].fillna(0, inplace=True)\n\nX['addr1_card1'] = X['addr1'].astype(str) + '_' + X['card1'].astype(str)\nX['addr1_card1'] = LabelEncoder().fit_transform(X['addr1_card1'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First training a model only using this two features, without their interaction."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X[['addr1', 'card1']], y, test_size=0.33, random_state=47, stratify=y)\nclf = lgb.LGBMClassifier(**params)\nclf.fit(X_train, y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now WITH interaction"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X[['addr1', 'card1', 'addr1_card1']], y, test_size=0.33, random_state=47, stratify=y)\nclf1 = lgb.LGBMClassifier(**params)\nclf1.fit(X_train, y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf1.predict_proba(X_test)[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"result_df = pd.DataFrame()\n\nfor i in tqdm_notebook(X['addr1'].sort_values().unique()):\n    x = pd.DataFrame()\n    x['addr1'] = [i] * X['card1'].nunique()\n    x['card1'] = X['card1'].sort_values().unique()\n    \n    result_df = pd.concat([result_df, x], axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predictions heatmap of the two features interaction."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"preds = clf.predict_proba(result_df)[:, 1]\npreds = preds.reshape(X['addr1'].nunique(), X['card1'].nunique())\npreds = pd.DataFrame(preds, index=X['addr1'].sort_values().unique(), columns=X['card1'].sort_values().unique())\nplt.figure(figsize=(12, 6))\nsns.heatmap(preds, cmap='RdBu_r', center=0.0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally adding count features, so all in all we have 5 features"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X['card1_count'] = train['card1'].map(pd.concat([train['card1'], test['card1']], ignore_index=True).value_counts(dropna=False))\nX['addr1_count'] = train['addr1'].map(pd.concat([train['addr1'], test['addr1']], ignore_index=True).value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=47, stratify=y)\nclf = lgb.LGBMClassifier(**params)\nclf.fit(X_train, y_train)\nprint('ROC AUC score:', roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n# New feature: number of NaN's\nWe have plenty of NaN's in this dataset and they can have a significant effect so why don't we use them?\nI am adding a new column to the dateset, which will contain a number of NaN for each row. So if a row (a single training example) contain, say, 10 NaNs, a new feature's value for this row will be 10."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['nulls'] = train.isnull().sum(axis=1)\ntest['nulls'] = test.isnull().sum(axis=1)\nplot_numerical('nulls')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariant shift ROC AUC:', covariate_shift('nulls'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that this feature might be useful, but also keep in mind that covatiate shift is almost 0.7, which tells us that the distribution between train and test set has some difference."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n# TransactionAmt and it's decimal part\n\nFirst let's take a look at TransactionAmt feature and them I will create a new one - it's decimal part, which is a very popular way of creating a new features."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('TransactionAmt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Moving average for TransactionAmt over time."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,1,figsize=(16, 6))\naxes.set_title('Moving average of TransactionAmt', fontsize=16);\ntrain[['TransactionDT', 'TransactionAmt']].set_index('TransactionDT').rolling(10000).mean().plot(ax=axes);\ntest[['TransactionDT', 'TransactionAmt']].set_index('TransactionDT').rolling(10000).mean().plot(ax=axes);\naxes.legend(['Train', 'Test']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(16, 6))\ntrain.set_index('TransactionDT').resample('D').mean()['TransactionAmt'].plot(ax=axes).set_ylabel('TransactionAmt mean', fontsize=14);\ntest.set_index('TransactionDT').resample('D').mean()['TransactionAmt'].plot(ax=axes).set_ylabel('TransactionAmt mean', fontsize=14);\naxes.set_title('Mean of TransactionAmt by day', fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A relationship between mean of TransactionAmt by day and a mean of isFraud by day."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(16, 6))\ntrain.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=ax1, color='blue')\nax1.tick_params(axis='y', labelcolor='blue')\nax1.set_ylabel('isFraud mean by day', color='blue', fontsize=14)\nax2 = ax1.twinx()\ntrain.set_index('TransactionDT').resample('D').mean()['TransactionAmt'].plot(ax=ax2, color='tab:orange')\nax2.tick_params(axis='y', labelcolor='tab:orange');\nax2.set_ylabel('TransactionAmt mean by day', color='tab:orange', fontsize=14);\nax2.grid(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decimal part of transaction amount."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\ntest['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)\nplot_numerical('TransactionAmt_decimal')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(16, 6))\ntrain.set_index('TransactionDT').resample('D').mean()['TransactionAmt_decimal'].plot(ax=axes).set_ylabel('TransactionAmt_decimal mean', fontsize=14);\ntest.set_index('TransactionDT').resample('D').mean()['TransactionAmt_decimal'].plot(ax=axes).set_ylabel('TransactionAmt_decimal mean', fontsize=14);\naxes.set_title('Mean of TransactionAmt_decimal by day', fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A relationship between mean of TransactionAmt_decimal by day and a mean of isFraud by day."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(16, 6))\ntrain.set_index('TransactionDT').resample('D').mean()['isFraud'].plot(ax=ax1, color='blue')\nax1.tick_params(axis='y', labelcolor='blue')\nax1.set_ylabel('isFraud mean by day', color='blue', fontsize=14)\nax2 = ax1.twinx()\ntrain.set_index('TransactionDT').resample('D').mean()['TransactionAmt_decimal'].plot(ax=ax2, color='tab:orange')\nax2.tick_params(axis='y', labelcolor='tab:orange');\nax2.set_ylabel('TransactionAmt_decimal mean by day', color='tab:orange', fontsize=14);\nax2.grid(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lenght of the decimal part of transaction amount. What does it mean? Well, if lenght is 1 or 2 signs it is totaly understandable - it might be cents. But what is wrong with a decimal part's lenght being 3 and more sings? Maybe it is due to a currency convertion?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['TransactionAmt_decimal_lenght'] = train['TransactionAmt'].astype(str).str.split('.', expand=True)[1].str.len()\ntest['TransactionAmt_decimal_lenght'] = test['TransactionAmt'].astype(str).str.split('.', expand=True)[1].str.len()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_train = pd.DataFrame(data={'TransactionAmt_decimal_lenght': train['TransactionAmt_decimal_lenght'], 'isTest': 0})\ndf_test = pd.DataFrame(data={'TransactionAmt_decimal_lenght': test['TransactionAmt_decimal_lenght'], 'isTest': 1})\ndf = pd.concat([df_train, df_test], ignore_index=True)\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nsns.countplot(data=df.fillna('NaN'), x='TransactionAmt_decimal_lenght', hue='isTest', ax=axes[0]);\nsns.countplot(data=train[['TransactionAmt_decimal_lenght', 'isFraud']].fillna('NaN'), x='TransactionAmt_decimal_lenght', hue='isFraud', ax=axes[1]);\naxes[0].set_title('Train / Test distibution');\naxes[1].set_title('Train distibution by isFraud');\naxes[0].legend(['Train', 'Test']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Covariate shift for all 3 features."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariant shift ROC AUC:', covariate_shift('TransactionAmt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariant shift ROC AUC:', covariate_shift('TransactionAmt_decimal'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariant shift ROC AUC:', covariate_shift('TransactionAmt_decimal_lenght'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V1"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V1')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V1'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V2"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V2')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V2'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V3"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V3')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V3'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V4"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V4')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V4'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V5"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V5')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V5'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V6"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V6')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V6'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V7"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V7')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V7'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V258"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V258')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V258'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\nThis is where I want to introduce a little trick to you, called data relaxation. So what is it? In order to understand it take a look at the plot above. See the distibution difference between train and test set at a certain point? Gradient boosting algorithm doesn't know what to do with a data it has never seen so it will not approximate it well. And what we do by relaxing data is we are removing all the values from the train set that appears in it 3 times more often than in a test set and vice versa, also cleaning all the data that appears in train and test set only couple of times.\n\n## V258 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'V258')\nplot_numerical('V258')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V294"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('V294')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('V294'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## V294 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'V294')\nplot_numerical('V294')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C1"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('C1')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C1'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C1 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C1')\nplot_numerical('C1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C2"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('C2')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C2'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C2 after data relaxation."},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C2')\nplot_numerical('C2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C2'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C3"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_numerical('C3')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C3'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C3 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C3')\nplot_numerical('C3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C3'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C4"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C4'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C4 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C4')\nplot_numerical('C4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C4'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C5"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C5'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C5 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C5')\nplot_numerical('C5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C5'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C6"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C6')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C6'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C6 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C6')\nplot_numerical('C6')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C6'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C7"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C7')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C7'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C7 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C7')\nplot_numerical('C7')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C7'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C8"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C8'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C8 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C8')\nplot_numerical('C8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C8'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C9"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C9')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C9'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C9 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C9')\nplot_numerical('C9')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C9'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C10"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C10'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C10 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C10')\nplot_numerical('C10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C10'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C11"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C11')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C11'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C11 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C11')\nplot_numerical('C11')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C11'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C12"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C12')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C12'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C12 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C12')\nplot_numerical('C12')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C12'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C13"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C13')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C13'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C13 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C13')\nplot_numerical('C13')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C13'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C14"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('C14')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('C14'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C14 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'C14')\nplot_numerical('C14')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('C14'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D1"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D1'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D2"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D2'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D3"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D3'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D4"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D4'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D5"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D5'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D6"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D6')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D6'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D7"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D7')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D7'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D8"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D8'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D9"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D9')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D9'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D10"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D10'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D11"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D11')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D11'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D12"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D12')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D12'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D13"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D13')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D13'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D14"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D14')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D14'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D15"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('D15')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('D15'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_01"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('id_01')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_01', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_02"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('id_02')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_03"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_03', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_04"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_04', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_05"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_05', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_06"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_06', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_07"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_07', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_08"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('id_08')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_08', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_09"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_09', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_10"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('id_10')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_10', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_11"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('id_11')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_12"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_12', 'isFraud', 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_13"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_13', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_14"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_14', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_15"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_15', 'isFraud', 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_16"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_16', 'isFraud', 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_17"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('id_17')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_17', 'isFraud', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# id_31"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(train, test, 'id_31', 'isFraud', 6)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Covariate shift:', covariate_shift('id_31'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id_31 after data relaxation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = relax_data(train, test, 'id_31')\nplot_categorical(train, test, 'id_31', 'isFraud', 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_numerical('id_31')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Covariate shift after data relaxation:', covariate_shift('id_31'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}