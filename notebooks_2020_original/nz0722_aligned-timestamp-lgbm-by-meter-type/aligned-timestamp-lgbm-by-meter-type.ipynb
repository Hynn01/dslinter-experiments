{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The idea is to **align the timestamp by peak air temperature**, based on an assumption that the highest air temperature should appear at around 14:00.\n\nAfter aligning the timestamp of weather data, LB jumped from 1.12 to 1.11.","metadata":{"_kg_hide-input":false}},{"cell_type":"markdown","source":"**First, why do we do this timestamp alignment?**","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\nfrom os.path import join as pjoin\n\nfrom tqdm import tqdm_notebook as tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RAW_DATA_DIR = '/kaggle/input/ashrae-energy-prediction/'\n\nweather_dtypes = {\n    'site_id': np.uint8,\n    'air_temperature': np.float32,\n    'cloud_coverage': np.float32,\n    'dew_temperature': np.float32,\n    'precip_depth_1_hr': np.float32,\n    'sea_level_pressure': np.float32,\n    'wind_direction': np.float32,\n    'wind_speed': np.float32,\n}\n\nweather_train = pd.read_csv(pjoin(RAW_DATA_DIR, 'weather_train.csv'),dtype=weather_dtypes,\n    parse_dates=['timestamp'])\nweather_test = pd.read_csv(pjoin(RAW_DATA_DIR, 'weather_test.csv'),dtype=weather_dtypes,\n    parse_dates=['timestamp'])\n\nweather = pd.concat([weather_train,weather_test],ignore_index=True)\ndel weather_train, weather_test\nweather_key = ['site_id', 'timestamp']\ntemp_skeleton = weather[weather_key + ['air_temperature']].drop_duplicates(subset=weather_key).sort_values(by=weather_key).copy()\ndel weather","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_to_plot = temp_skeleton.copy()\ndata_to_plot[\"hour\"] = data_to_plot[\"timestamp\"].dt.hour\ncount = 1\nplt.figure(figsize=(25, 15))\nfor site_id, data_by_site in data_to_plot.groupby('site_id'):\n    by_site_by_hour = data_by_site.groupby('hour').mean()\n    ax = plt.subplot(4, 4, count)\n    plt.plot(by_site_by_hour.index,by_site_by_hour['air_temperature'],'xb-')\n    ax.set_title('site: '+str(site_id))\n    count += 1\nplt.tight_layout()\nplt.show()\ndel data_to_plot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see in the previous graph, the **peak temperature appears at different time** in different sites. Quite some **even during the nights**, which doesn't make any sense. It means, the timestamp data here are not in their local time. As energy consumptions are related to the local time, an alighment is nescessary before using timestamp. We would calculate the differences between peak temperature times and 14:00, assume these results are the offsets, and align the timestamp of every site with them.\n\nThis following cell made LB jumped from 1.12 to 1.11. ","metadata":{}},{"cell_type":"code","source":"# calculate ranks of hourly temperatures within date/site_id chunks\ntemp_skeleton['temp_rank'] = temp_skeleton.groupby(['site_id', temp_skeleton.timestamp.dt.date])['air_temperature'].rank('average')\n\n# create a dataframe of site_ids (0-16) x mean hour rank of temperature within day (0-23)\ndf_2d = temp_skeleton.groupby(['site_id', temp_skeleton.timestamp.dt.hour])['temp_rank'].mean().unstack(level=1)\n\n# Subtract the columnID of temperature peak by 14, getting the timestamp alignment gap.\nsite_ids_offsets = pd.Series(df_2d.values.argmax(axis=1) - 14)\nsite_ids_offsets.index.name = 'site_id'\n\ndef timestamp_align(df):\n    df['offset'] = df.site_id.map(site_ids_offsets)\n    df['timestamp_aligned'] = (df.timestamp - pd.to_timedelta(df.offset, unit='H'))\n    df['timestamp'] = df['timestamp_aligned']\n    del df['timestamp_aligned']\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n# Modified to support timestamp type, categorical type\n# Modified to add option to use float16 or not. feather format does not support float16.\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            # skip datetime type or categorical type\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nroot = Path('../input/ashrae-feather-format-for-fast-loading')\n\ntrain_df = pd.read_feather(root/'train.feather')\nweather_train_df = pd.read_feather(root/'weather_train.feather')\nbuilding_meta_df = pd.read_feather(root/'building_metadata.feather')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"building_site_dict = dict(zip(building_meta_df['building_id'], building_meta_df['site_id']))\nsite_meter_raw = train_df[['building_id', 'meter', 'timestamp', 'meter_reading']].copy()\nsite_meter_raw['site_id'] = site_meter_raw.building_id.map(building_site_dict)\ndel site_meter_raw['building_id']\nsite_meter_to_plot = site_meter_raw.copy()\nsite_meter_to_plot[\"hour\"] = site_meter_to_plot[\"timestamp\"].dt.hour\nelec_to_plot = site_meter_to_plot[site_meter_to_plot.meter == 0]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do we also need to align the train data? Below is the electric consumptions & site graph, where timestamp are more aligned. Only site 14 is different, where the consumptions start from 10:00 am, while it's consumption ratio is also different with others. In Site 14 Education ranks first, which might be a reason of the expection. My guess is weather and train data come from different source, that's maybe also why they are in two seperete datasets.","metadata":{}},{"cell_type":"code","source":"count = 1\nplt.figure(figsize=(25, 50))\nfor site_id, data_by_site in elec_to_plot.groupby('site_id'):\n    by_site_by_hour = data_by_site.groupby('hour').mean()\n    ax = plt.subplot(15, 4, count)\n    plt.plot(by_site_by_hour.index,by_site_by_hour['meter_reading'],'xb-')\n    ax.set_title('site: '+str(site_id))\n    count += 1\nplt.tight_layout()\nplt.show()\ndel elec_to_plot, site_meter_to_plot, building_site_dict, site_meter_raw","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df):\n    df[\"hour\"] = df[\"timestamp\"].dt.hour\n    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n    df[\"month\"] = df[\"timestamp\"].dt.month\n    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n    \ndef add_lag_feature(weather_df, window=3):\n    group_df = weather_df.groupby('site_id')\n    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n    rolled = group_df[cols].rolling(window=window, min_periods=0)\n    lag_mean = rolled.mean().reset_index().astype(np.float16)\n    lag_max = rolled.max().reset_index().astype(np.float16)\n    lag_min = rolled.min().reset_index().astype(np.float16)\n    lag_std = rolled.std().reset_index().astype(np.float16)\n    for col in cols:\n        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n        weather_df[f'{col}_std_lag{window}'] = lag_std[col]\n        \ntrain_df['date'] = train_df['timestamp'].dt.date\ntrain_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])\nbuilding_meta_df[building_meta_df.site_id == 0]\ntrain_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\ndebug = False    \npreprocess(train_df)\n\n# https://www.kaggle.com/ryches/simple-lgbm-solution\ndf_group = train_df.groupby('building_id')['meter_reading_log1p']\nbuilding_mean = df_group.mean().astype(np.float16)\nbuilding_median = df_group.median().astype(np.float16)\nbuilding_min = df_group.min().astype(np.float16)\nbuilding_max = df_group.max().astype(np.float16)\nbuilding_std = df_group.std().astype(np.float16)\n\ntrain_df['building_mean'] = train_df['building_id'].map(building_mean)\ntrain_df['building_median'] = train_df['building_id'].map(building_median)\ntrain_df['building_min'] = train_df['building_id'].map(building_min)\ntrain_df['building_max'] = train_df['building_id'].map(building_max)\ntrain_df['building_std'] = train_df['building_id'].map(building_std)\n\nweather_train_df = timestamp_align(weather_train_df)\nweather_train_df = weather_train_df.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n\nadd_lag_feature(weather_train_df, window=3)\nadd_lag_feature(weather_train_df, window=72)\n\nprimary_use_list = building_meta_df['primary_use'].unique()\nprimary_use_dict = {key: value for value, key in enumerate(primary_use_list)} \nprint('primary_use_dict: ', primary_use_dict)\nbuilding_meta_df['primary_use'] = building_meta_df['primary_use'].map(primary_use_dict)\n\ngc.collect()\n\nreduce_mem_usage(train_df, use_float16=True)\nreduce_mem_usage(building_meta_df, use_float16=True)\nreduce_mem_usage(weather_train_df, use_float16=True)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_cols = ['building_id', 'site_id', 'primary_use']  # , 'meter'\nfeature_cols = ['square_feet', 'year_built'] + [\n    'hour', 'weekend', # 'month' , 'dayofweek'\n    'building_median'] + [\n    'air_temperature', 'cloud_coverage',\n    'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure',\n    'wind_direction', 'wind_speed', 'air_temperature_mean_lag72',\n    'air_temperature_max_lag72', 'air_temperature_min_lag72',\n    'air_temperature_std_lag72', 'cloud_coverage_mean_lag72',\n    'dew_temperature_mean_lag72', 'precip_depth_1_hr_mean_lag72',\n    'sea_level_pressure_mean_lag72', 'wind_direction_mean_lag72',\n    'wind_speed_mean_lag72', 'air_temperature_mean_lag3',\n    'air_temperature_max_lag3',\n    'air_temperature_min_lag3', 'cloud_coverage_mean_lag3',\n    'dew_temperature_mean_lag3',\n    'precip_depth_1_hr_mean_lag3', 'sea_level_pressure_mean_lag3',\n    'wind_direction_mean_lag3', 'wind_speed_mean_lag3']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_X_y(train_df, target_meter):\n    target_train_df = train_df[train_df['meter'] == target_meter]\n    target_train_df = target_train_df.merge(building_meta_df, on='building_id', how='left')\n    target_train_df = target_train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\n    X_train = target_train_df[feature_cols + category_cols]\n    y_train = target_train_df['meter_reading_log1p'].values\n\n    del target_train_df\n    return X_train, y_train\n\ndef fit_lgbm(train, val, devices=(-1,), seed=None, cat_features=None, num_rounds=1500, lr=0.1, bf=0.1):\n    \"\"\"Train Light GBM model\"\"\"\n    X_train, y_train = train\n    X_valid, y_valid = val\n    metric = 'l2'\n    params = {'num_leaves': 31,\n              'objective': 'regression',\n#               'max_depth': -1,\n              'learning_rate': lr,\n              \"boosting\": \"gbdt\",\n              \"bagging_freq\": 5,\n              \"bagging_fraction\": bf,\n              \"feature_fraction\": 0.9,\n              \"metric\": metric,\n#               \"verbosity\": -1,\n#               'reg_alpha': 0.1,\n#               'reg_lambda': 0.3\n              }\n    device = devices[0]\n    if device == -1:\n        # use cpu\n        pass\n    else:\n        # use gpu\n        print(f'using gpu device_id {device}...')\n        params.update({'device': 'gpu', 'gpu_device_id': device})\n\n    params['seed'] = seed\n\n    early_stop = 20\n    verbose_eval = 20\n\n    d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n    d_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_features)\n    watchlist = [d_train, d_valid]\n\n    print('training LGB:')\n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n\n    # predictions\n    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n    \n    print('best_score', model.best_score)\n    log = {'train/mae': model.best_score['training']['l2'],\n           'valid/mae': model.best_score['valid_1']['l2']}\n    return model, y_pred_valid, log\n\nfolds = 5\nseed = 666\nshuffle = False\nkf = KFold(n_splits=folds, shuffle=shuffle, random_state=seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_meter = 0\nX_train, y_train = create_X_y(train_df, target_meter=target_meter)\ny_valid_pred_total = np.zeros(X_train.shape[0])\ngc.collect()\nprint('target_meter', target_meter, X_train.shape)\n\ncat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\nprint('cat_features', cat_features)\n\nmodels0 = []\nfor train_idx, valid_idx in kf.split(X_train, y_train):\n    train_data = X_train.iloc[train_idx,:], y_train[train_idx]\n    valid_data = X_train.iloc[valid_idx,:], y_train[valid_idx]\n\n    print('train', len(train_idx), 'valid', len(valid_idx))\n#     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n    model, y_pred_valid, log = fit_lgbm(train_data, valid_data, cat_features=category_cols,\n                                        num_rounds=1000, lr=0.05, bf=0.7)\n    y_valid_pred_total[valid_idx] = y_pred_valid\n    models0.append(model)\n    gc.collect()\n    if debug:\n        break\n\nsns.distplot(y_train)\ndel X_train, y_train\ngc.collect()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_meter = 1\nX_train, y_train = create_X_y(train_df, target_meter=target_meter)\ny_valid_pred_total = np.zeros(X_train.shape[0])\ngc.collect()\nprint('target_meter', target_meter, X_train.shape)\n\ncat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\nprint('cat_features', cat_features)\n\nmodels1 = []\nfor train_idx, valid_idx in kf.split(X_train, y_train):\n    train_data = X_train.iloc[train_idx,:], y_train[train_idx]\n    valid_data = X_train.iloc[valid_idx,:], y_train[valid_idx]\n\n    print('train', len(train_idx), 'valid', len(valid_idx))\n#     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n    model, y_pred_valid, log = fit_lgbm(train_data, valid_data, cat_features=category_cols, num_rounds=1000,\n                                       lr=0.05, bf=0.5)\n    y_valid_pred_total[valid_idx] = y_pred_valid\n    models1.append(model)\n    gc.collect()\n    if debug:\n        break\n\nsns.distplot(y_train)\ndel X_train, y_train\ngc.collect()","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_meter = 2\nX_train, y_train = create_X_y(train_df, target_meter=target_meter)\ny_valid_pred_total = np.zeros(X_train.shape[0])\n\ngc.collect()\nprint('target_meter', target_meter, X_train.shape)\n\ncat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\nprint('cat_features', cat_features)\n\nmodels2 = []\nfor train_idx, valid_idx in kf.split(X_train, y_train):\n    train_data = X_train.iloc[train_idx,:], y_train[train_idx]\n    valid_data = X_train.iloc[valid_idx,:], y_train[valid_idx]\n\n    print('train', len(train_idx), 'valid', len(valid_idx))\n#     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n    model, y_pred_valid, log = fit_lgbm(train_data, valid_data, cat_features=category_cols,\n                                        num_rounds=1000, lr=0.05, bf=0.8)\n    y_valid_pred_total[valid_idx] = y_pred_valid\n    models2.append(model)\n    gc.collect()\n    if debug:\n        break\n\nsns.distplot(y_train)\ndel X_train, y_train\ngc.collect()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_meter = 3\nX_train, y_train = create_X_y(train_df, target_meter=target_meter)\ny_valid_pred_total = np.zeros(X_train.shape[0])\n\ngc.collect()\nprint('target_meter', target_meter, X_train.shape)\n\ncat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\nprint('cat_features', cat_features)\n\nmodels3 = []\nfor train_idx, valid_idx in kf.split(X_train, y_train):\n    train_data = X_train.iloc[train_idx,:], y_train[train_idx]\n    valid_data = X_train.iloc[valid_idx,:], y_train[valid_idx]\n\n    print('train', len(train_idx), 'valid', len(valid_idx))\n#     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n    model, y_pred_valid, log = fit_lgbm(train_data, valid_data, cat_features=category_cols, num_rounds=1000,\n                                       lr=0.03, bf=0.9)\n    y_valid_pred_total[valid_idx] = y_pred_valid\n    models3.append(model)\n    gc.collect()\n    if debug:\n        break\n\nsns.distplot(y_train)\ndel X_train, y_train\ngc.collect()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('loading...')\ntest_df = pd.read_feather(root/'test.feather')\nweather_test_df = pd.read_feather(root/'weather_test.feather')\n\nprint('preprocessing building...')\ntest_df['date'] = test_df['timestamp'].dt.date\npreprocess(test_df)\ntest_df['building_mean'] = test_df['building_id'].map(building_mean)\ntest_df['building_median'] = test_df['building_id'].map(building_median)\ntest_df['building_min'] = test_df['building_id'].map(building_min)\ntest_df['building_max'] = test_df['building_id'].map(building_max)\ntest_df['building_std'] = test_df['building_id'].map(building_std)\n\nprint('preprocessing weather...')\nweather_test_df = timestamp_align(weather_test_df)\nweather_test_df = weather_test_df.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\nweather_test_df.groupby('site_id').apply(lambda group: group.isna().sum())\n\nadd_lag_feature(weather_test_df, window=3)\nadd_lag_feature(weather_test_df, window=72)\n\nprint('reduce mem usage...')\nreduce_mem_usage(test_df, use_float16=True)\nreduce_mem_usage(weather_test_df, use_float16=True)\n\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_feather(os.path.join(root, 'sample_submission.feather'))\nreduce_mem_usage(sample_submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_X(test_df, target_meter):\n    target_test_df = test_df[test_df['meter'] == target_meter]\n    target_test_df = target_test_df.merge(building_meta_df, on='building_id', how='left')\n    target_test_df = target_test_df.merge(weather_test_df, on=['site_id', 'timestamp'], how='left')\n    X_test = target_test_df[feature_cols + category_cols]\n    return X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred(X_test, models, batch_size=1000000):\n    iterations = (X_test.shape[0] + batch_size -1) // batch_size\n    print('iterations', iterations)\n\n    y_test_pred_total = np.zeros(X_test.shape[0])\n    for i, model in enumerate(models):\n        print(f'predicting {i}-th model')\n        for k in tqdm(range(iterations)):\n            y_pred_test = model.predict(X_test[k*batch_size:(k+1)*batch_size], num_iteration=model.best_iteration)\n            y_test_pred_total[k*batch_size:(k+1)*batch_size] += y_pred_test\n\n    y_test_pred_total /= len(models)\n    return y_test_pred_total","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_test = create_X(test_df, target_meter=0)\ngc.collect()\n\ny_test0 = pred(X_test, models0)\n\nsns.distplot(y_test0)\n\ndel X_test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_test = create_X(test_df, target_meter=1)\ngc.collect()\n\ny_test1 = pred(X_test, models1)\nsns.distplot(y_test1)\n\ndel X_test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_test = create_X(test_df, target_meter=2)\ngc.collect()\n\ny_test2 = pred(X_test, models2)\nsns.distplot(y_test2)\n\ndel X_test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = create_X(test_df, target_meter=3)\ngc.collect()\n\ny_test3 = pred(X_test, models3)\nsns.distplot(y_test3)\n\ndel X_test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.loc[test_df['meter'] == 0, 'meter_reading'] = np.expm1(y_test0)\nsample_submission.loc[test_df['meter'] == 1, 'meter_reading'] = np.expm1(y_test1)\nsample_submission.loc[test_df['meter'] == 2, 'meter_reading'] = np.expm1(y_test2)\nsample_submission.loc[test_df['meter'] == 3, 'meter_reading'] = np.expm1(y_test3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')\nsample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.log1p(sample_submission['meter_reading']).hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_feature_importance(model):\n    importance_df = pd.DataFrame(model.feature_importance(),\n                                 index=feature_cols + category_cols,\n                                 columns=['importance']).sort_values('importance')\n    fig, ax = plt.subplots(figsize=(8, 8))\n    importance_df.plot.barh(ax=ax)\n    fig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(models0[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(models1[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(models2[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(models3[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}