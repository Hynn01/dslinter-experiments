{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ðŸ‡§ðŸ‡· Este projeto foi descontinuado em 08/06/2020\n# ðŸ‡ºðŸ‡¸ This project has been discontinued in June 8th, 2020\n\n---\n\n# ðŸ‡§ðŸ‡· Panorama do COVID-19 no Brasil/ ðŸ‡ºðŸ‡¸ COVID-19 in Brazil: An Overview\n\nðŸ‡§ðŸ‡· O objetivo deste notebook Ã© analisar os dados disponÃ­veis na base de dados brasileira sobre o COVID-19 [disponÃ­vel aqui](https://www.kaggle.com/unanimad/corona-virus-brazil/kernels) e, por meio de perguntas e respostas de alto-nÃ­vel, colaborar para a anÃ¡lise da situaÃ§Ã£o. O cÃ³digo produzido Ã© uma maneira de atestar como as respostas foram obtidas, estando livre para consultas, revisÃ£o e sugestÃµes de melhorias ou outras investigaÃ§Ãµes por meio do painel de discussÃ£o.\n\n**Disclaimer/Aviso Legal**: Essas informaÃ§Ãµes devem servir aos interessados como uma primeira orientaÃ§Ã£o. As informaÃ§Ãµes gerais aqui contidas, no entanto, nÃ£o fornecem qualquer garantia. Desse modo, estÃ¡ excluÃ­da a garantia ou responsabilidade de qualquer tipo, por exemplo, de precisÃ£o, confiabilidade, completude e atualidade das informaÃ§Ãµes. \n\n---\n\nðŸ‡ºðŸ‡¸ The objective of this notebook is to analyze the data available in the Brazilian COVID-19 database [available here](https://www.kaggle.com/unanimad/corona-virus-brazil/kernels) and, through questions and high-level answers, collaborate in the analysis of the situation. The code produced attests how the answers were obtained, open for queries, reviews, suggestions for improvements, or new investigations through the discussions panel.\n\n**Disclaimer/Legal warning**: The information here contained should serve as first guidance. The general information here contained does not provide any guarantees, however. Therefore, it is excluded the guarantee or responsibility of any kind, such as precision, reliability, completeness, and currentness of the information.\n\n\n**ElloÃ¡ B. Guedes**  \nebgcosta@uea.edu.br  \nwww.elloaguedes.com  \n\n**JÃºlio B. Guedes**  \njulio.costa@ccc.ufcg.edu.br  \n[COVID-19 Timeline](https://juliobguedes.codes/covid)\n\n---\n\n## ðŸ‡§ðŸ‡· Confira nosso outro projeto de anÃ¡lise do COVID-19 em Ã¢mbito global\n\nSiga o link: https://juliobguedes.codes/covid\n\n## ðŸ‡ºðŸ‡¸ Check out our project on COVID-19 worldwide timeline\n\nClick here: https://juliobguedes.codes/covid","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# ðŸ‡§ðŸ‡· Confira minha participaÃ§Ã£o no PyData Manaus\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VXDU3nzFTTw?controls=0&amp;start=334\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ãšltima execuÃ§Ã£o\nimport datetime\nprint(datetime.datetime.now())\ntoday = datetime.datetime.now().strftime('%d/%m/%Y')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# imports\nimport numpy as np\nimport pandas as pd\nimport os\nimport numpy as np\n\n# bokeh packages\nfrom bokeh.io import output_file,show,output_notebook,push_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource,HoverTool,CategoricalColorMapper\nfrom bokeh.layouts import row,column,gridplot\nfrom bokeh.models.widgets import Tabs,Panel\nfrom bokeh.models import GeoJSONDataSource\noutput_notebook()\n\n# plotly packages\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.graph_objs import *\n\nimport json\nimport geopandas as gpd\nimport plotly.graph_objects as go\nimport unidecode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/corona-virus-brazil/brazil_covid19.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analytics\n\n- ðŸ‡§ðŸ‡· AnÃ¡lise de dados sobre os casos, Ã³bitos, proporÃ§Ãµes, distribuiÃ§Ã£o geogrÃ¡fica, etc.\n- Base de dados atualizada diariamente e oriunda daqui: https://www.kaggle.com/unanimad/corona-virus-brazil\n\n---\n\n- ðŸ‡ºðŸ‡¸ Data analysis over the confirmed cases, deaths, proportions, geographic distribuition, etc\n- Database daily updated acquired here: https://www.kaggle.com/unanimad/corona-virus-brazil","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: A qual perÃ­odo de tempo os dados se referem?\n\n**Resposta**:  \n\n### ðŸ‡ºðŸ‡¸ To which period of time the data refers to?\n\n**Answer**:  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(min(data['date']))\nprint(max(data['date']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Qual a incidÃªncia diÃ¡ria de casos suspeitos, confirmados e mortes no perÃ­odo?\n\n**Resposta**: Os grÃ¡ficos a seguir mostram esta informaÃ§Ã£o para casos suspeitos, confirmados e Ã³bitos. Note que a escala de cada grÃ¡fico Ã© diferente, mas que a ordem de crescimento em todos segue de maneira ascendente.\n\nEm 20/03/2020, o MinistÃ©rio da SaÃºde passa a declarar estado de transmissÃ£o comunitÃ¡ria do COVID-19 no PaÃ­s e, com isso, casos suspeitos deixam de ser contabilizados. Vide: [EstadÃ£o, 20/03/2020, 19h27min](https://saude.estadao.com.br/noticias/geral,ministerio-da-saude-declara-estado-de-transmissao-comunitaria-de-coronavirus-em-todo-o-pais,70003242077)\n\n### ðŸ‡ºðŸ‡¸ Question: What is the daily incidence of suspected, confirmed and death cases in this period?\n\n**Asnwer**: The plots below show this information for suspected, confirmed and death cases. Note that the scale of each plot is different, but the growth rate is ascending in all of them.\n\nIn March 20th, 2020 the Brazilian Health Ministry declared the state of comunitary transmission of COVID-19 and suspected cases stop being accounted for. If you want to know more, please see the news at [Estadao, March 20th, 2020, 7:27PM](https://saude.estadao.com.br/noticias/geral,ministerio-da-saude-declara-estado-de-transmissao-comunitaria-de-coronavirus-em-todo-o-pais,70003242077).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## SÃ­ntese diÃ¡ria\ndf2 = data.groupby(['date'])['cases','deaths'].agg('sum')\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Atualizando com antiga versÃ£o do dataset\nold = pd.read_csv('/kaggle/input/corona-virus-brazil/brazil_covid19_old.csv')\nold = old.groupby(['date'])['suspects'].agg('sum')\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    xaxis = dict(\n        tickmode = 'array',\n        tickvals = old.index,\n        ticktext = old.index\n    ),\n    xaxis_title=\"Data\",\n    yaxis_title = \"Quantidade\"\n)\nsuspeitos = old.loc[:'2020-03-21']\nfig = px.bar(title='Casos suspeitos -- Descontinuado a partir de 21/03/2020', x=suspeitos.index, y=suspeitos)\nfig['layout'].update(layout)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.graph_objs import *\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n)\n\nfig = make_subplots(rows=2, cols=1,subplot_titles=('Casos Confirmados atÃ© ' + today, 'Ã“bitos atÃ© '+ today))\nfig.append_trace(go.Bar(name='Confirmados', x=df2.index, y=df2['cases']), row=1, col=1)\nfig.append_trace(go.Bar(name='Ã“bitos', x=df2.index, y=df2['deaths']), row=2, col=1)\n\nfig.update_xaxes(title_text=\"Data\", row=1, col=1)\nfig.update_yaxes(title_text=\"Quantidade\", row=1, col=1)\nfig.update_xaxes(title_text=\"Data\", row=2, col=1)\nfig.update_yaxes(title_text=\"Quantidade\", row=2, col=1)\n\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title=\"VisualizaÃ§Ã£o Conjunta de Casos e Ã“bitos atÃ© \" + today,\n)\n\nfig = go.Figure(data=[\n    go.Bar(name='Confirmados', x=df2.index, y=df2['cases']),\n    go.Bar(name='Ã“bitos', x=df2.index, y=df2['deaths'])\n])\nfig.update_xaxes(title_text='Data')\nfig.update_yaxes(title_text='Quantidade')\nfig.update_layout(barmode='stack')\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Qual a distribuiÃ§Ã£o geogrÃ¡fica dos casos confirmados?\n### ðŸ‡ºðŸ‡¸ Question: What is the confirmed cases geographic distribution?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# utils\ndef remove_accents(a):\n    unaccented_string = unidecode.unidecode(a)\n    return unaccented_string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data.drop('hour',axis= 1, inplace=True)\natual = max(data['date'])\ndf3 = data.loc[data['date'] == max(data['date'])].groupby(['state'])['cases','deaths'].agg('sum')\ndf4 = pd.DataFrame({\"name\": df3.index, 'cases': df3['cases'], 'deaths':df3['deaths']})\ndf4.index = range(0,27)\n\nbrazil = gpd.read_file('/kaggle/input/brazil-states-geojson/brazil.geojson')\n\ndf4['name'] = df4['name'].apply(remove_accents)\ndf4 = df4.sort_values('name')\nbrazil['name'] = brazil['name'].apply(remove_accents)\nbrazil = brazil.sort_values('name')\n\npop_states = brazil.merge(df4, left_on = 'name', right_on = 'name')\ngeosource = GeoJSONDataSource(geojson = pop_states.to_json())\nmerged_json = json.loads(pop_states.to_json())\njson_data = json.dumps(merged_json)\ngeosource = GeoJSONDataSource(geojson = json_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.io import output_notebook, show, output_file\nfrom bokeh.plotting import figure\nfrom bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar\nfrom bokeh.palettes import brewer\nfrom bokeh.palettes import magma,viridis,cividis\nfrom bokeh.layouts import row\n\ndef myplot3(geosource,tema, complemento = '',jump = 1,high = 100):\n    \n    tipo = 'Ã“bitos'\n    palette = magma(256)\n    if tema.startswith('case'):\n        tipo = 'Casos'\n        palette = viridis(256)[:248]\n    elif tema.startswith('letalidade'):\n        tipo = 'Letalidade'\n        palette = cividis(256)[:248]\n    elif tema.startswith('leitospor100mil'):\n        tipo = 'Leitos de UTI por 100 mil habitantes'\n        palette = magma(256)\n    elif tema.startswith('leitos'):\n        tipo = 'Leitos de UTI'\n        palette = viridis(256)[:248]\n    elif tema.startswith('testesRapidos'):\n        tipo = 'Testes RÃ¡pidos'\n        palette = viridis(256)[:248]\n    elif tema.startswith('testesRTPCR'):\n        tipo = 'Testes RT-PCR'\n        palette = magma(256)\n        \n        \n    palette = palette[::-1]\n    color_mapper = LinearColorMapper(palette = palette, low = 0, high = high)\n\n    #Define custom tick labels for color bar.\n    if (not tema.startswith('letalidade')):\n        d = {}\n        for i in range(0,int(high),jump):\n            d[str(i)] = str(i)\n\n            \n        d[str(int(high) + 1)] = '>' + str(int(high) + 1)\n                \n        hover = HoverTool(tooltips = [ ('Estado','@name'),('Quantidade', '@{'+tema+'}{%d}')], formatters={'@{'+ tema +'}' : 'printf'})\n    elif (tema.startswith('leitos') or tema.startswith('teste')):\n        d = {}\n        for i in np.arange(0, high+1, jump):\n            d[str(round(i,2))] = str(round(i,2))\n        d[str(high + 1)] = '>'+ str(high + 1)\n        hover = HoverTool(tooltips = [ ('Estado','@name'),('Quantidade', '@{'+tema+'}{%d}')], formatters={'@{'+ tema +'}' : 'printf'})\n    else:\n        d = {}\n        for i in np.arange(0, high+0.5, jump):\n            d[str(round(i,2))] = str(round(i,2))\n        d[str(round(high + 0.5,2))] = '>'+ str(round(high + 0.5,2))\n        hover = HoverTool(tooltips = [ ('Estado','@name'),('Taxa', '@{'+tema+'}{%.2f%%}')], formatters={'@{'+ tema +'}' : 'printf'})\n    \n    \n    tick_labels = d\n    #Create color bar. \n    color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8,width = 300, height = 20,\n    border_line_color=None,location = (0,0), orientation = 'horizontal', major_label_overrides = tick_labels)\n\n\n\n    #Create figure object.\n    p = figure(title = tipo + complemento + ' em {0}'.format((datetime.datetime.now()).strftime('%d/%m/%Y')), plot_height = 430 , plot_width = 330, toolbar_location = None, tools =[hover])\n    p.xgrid.grid_line_color = None\n    p.ygrid.grid_line_color = None\n    p.xaxis.visible = False\n    p.yaxis.visible = False\n\n\n    p.patches('xs','ys', source = geosource,fill_color = {'field' :str(tema), 'transform' : color_mapper},\n              line_color = 'black', line_width = 0.25, fill_alpha = 1)\n\n    p.add_layout(color_bar, 'below')\n    return p\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show(row(myplot3(geosource = geosource,tema = 'cases',jump = 2000, high = max(df4['cases'])),\n         myplot3(geosource = geosource,tema = 'deaths', jump = 1000, high = max(df4['deaths']))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Qual a incidÃªncia de casos e Ã³bitos por Estado, a cada 100 mil habitantes?\n### ðŸ‡ºðŸ‡¸ Question: What is the incidence of confirmed cases and deaths by State, every 100 thousand habitants?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"populacao = pd.read_csv('/kaggle/input/dadosbrasil/populacao.csv',sep=\";\")\npopulacao['name'] = populacao['name'].apply(remove_accents)\npopulacao = populacao.sort_values('name')\npopulacao = populacao.merge(df4, left_on = 'name', right_on = 'name')\npopulacao['casespor100mil'] = (populacao['cases']/populacao['populacao'])*100000\npopulacao['deathspor100mil'] = (populacao['deaths']/populacao['populacao'])*100000\npopulacao['leitospor100mil'] = (populacao['leitos']/populacao['populacao'])*100000\npopulacao['letalidade'] = round(populacao['deaths']/populacao['cases'],3)*100\n\n# Abertura do mapa\nbrazil = gpd.read_file('/kaggle/input/brazil-states-geojson/brazil.geojson')\n## mesclagem das bases\nbrazil['name'] = brazil['name'].apply(remove_accents)\nbrazil = brazil.sort_values('name')\npop_states = brazil.merge(populacao, left_on = 'name', right_on = 'name')\n# Input GeoJSON source that contains features for plotting\ngeosource = GeoJSONDataSource(geojson = pop_states.to_json())\n\nimport json\n\n#Read data to json.\nmerged_json = json.loads(pop_states.to_json())\njson_data = json.dumps(merged_json)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show(row(myplot3(geosource = geosource,tema = 'casespor100mil',jump = 10, high = max(populacao['casespor100mil']), complemento = ' por 100 mil habitantes '),\n         myplot3(geosource = geosource,tema = 'deathspor100mil', jump = 2, high = max(populacao['deathspor100mil']), complemento = ' por 100 mil habitantes ')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ðŸ‡§ðŸ‡· AnÃ¡lise da Letalidade/ ðŸ‡ºðŸ‡¸ Lethality Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Qual a taxa de letalidade do CoronavÃ­rus no Brasil?\n\n**Resposta**:\n\n- Qual a taxa de letalidade no Brasil, obtida com os dados mais recentes disponÃ­veis?\n- O cÃ¡lculo da taxa de letalidade Ã© dado por:\n\n$$\n\\textrm{Taxa de letalidade} =  \\frac{\\sum \\textrm{Ã³bitos}}{\\sum \\textrm{casos}}\n$$\n\n### ðŸ‡ºðŸ‡¸ Question: What is the lethality rate of Coronavirus in Brazil?\n\n**Answer**:  \n- What is the lethality rate in Brazil, calculated with the most recent data?\n- The lethality rate is calculated by:\n\n$$\n\\textrm{Lethality rate} = \\frac{\\sum \\textrm{deaths}}{\\sum \\textrm{cases}}\n$$\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"letalidade = sum(df4['deaths'])/sum(df4['cases'])\nprint(\"Taxa de Letalidade em \" + today + \": {0:6.3f}%\".format(letalidade*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Como foi a modificaÃ§Ã£o da letalidade ao longo do tempo em Ã¢mbito nacional?\n\n**MÃ©todo**: Calcular a taxa de letalidade dia a dia  \n**ConsideraÃ§Ãµes**: Observa-se que a taxa de letalidade vem crescendo vertiginosamente!\n\n### ðŸ‡ºðŸ‡¸ Question: How the lethality changed with time, in national scope?\n\n**Method**: Calculate the lethality rate each day.  \n**Considerations**: Its observed that the lethality rate grows vertiginously!  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['letalidade'] = df2['deaths']/df2['cases']\ndf2.fillna(0,inplace=True)\ndf2 = df2.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Letalidade ao Longo do Tempo\",\n    xaxis_title=\"Data\",\n    yaxis_title=\"Taxa de Letalidade\",\n    yaxis_tickformat = '.2%')\n\nfig = go.Figure(data=[\n    go.Scatter(x=df2['date'], y=df2['letalidade'])])\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Qual a taxa de letalidade por Estado?\n### ðŸ‡ºðŸ‡¸ Question: What is the lethality rate by State?\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show(myplot3(geosource = geosource,tema = 'letalidade', jump = 0.5, high = max(populacao['letalidade']), complemento = ''))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ðŸ‡§ðŸ‡· RelaÃ§Ã£o com Indicadores SÃ³cio-Economicos / ðŸ‡ºðŸ‡¸ Relation with Socio-Economic Indicators\n\n- ðŸ‡§ðŸ‡· As anÃ¡lises a seguir contemplam aspectos de indicadores sÃ³cio-econÃ´micos e recursos disponÃ­veis para o combate ao COVID-19 em cada estado\n\n- ðŸ‡ºðŸ‡¸  The following analisis contemplate socio-economic indicators and resources available to fight COVID-19 in each state\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Quantos leitos de UTI do SUS hÃ¡ por Estado?\n\n- Os dados obtidos neste sentido sÃ£o de 2018 e nÃ£o contemplam atualizaÃ§Ãµes recentes, decorrente dos hospitais de campanha que estÃ£o sendo construÃ­dos, por exemplo.\n- Este dado auxilia a estimar os recursos para enfrentamento dos casos mais graves.\n- Dados de UTI de 2018 extraÃ­dos do site do Conselho Federal de Medicina. Conferir nos links Ãºteis.  \n- Os leitos de UTI somam todos os tipos, desde adulto nos graus I a III, infantil I a III, neonatal I a III, queimados, coronariana e outros.\n\n### ðŸ‡ºðŸ‡¸ Question: How many ICU beds each state have?\n\n- The data obtained in this matter are from 2018 and have no recent updates, from field hospitals being built, for instance.\n- This data helps estimating the resources to face the most serious cases.\n- The ICU data of 2018 were extracted from the Federal Council of Medicine. Check the useful links.\n- The ICU beds number is the sum of every type of ICU: Adult I to III, Infant I to III, neonatal I to III, burns, coronary, and others.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show(row(myplot3(geosource = geosource,tema = 'leitos', jump = 1, high = max(populacao['leitos']), complemento = ''),myplot3(geosource = geosource,tema = 'leitospor100mil', jump = 1, high = max(populacao['leitospor100mil']), complemento = '')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Os Estados com maior PIB tambÃ©m mais investem mais em leitos de UTI no SUS?\n\nVamos analisar esta pergunta por meio da correlaÃ§Ã£o do PIB com o nÃºmero de leitos existentes. Se a correlaÃ§Ã£o for positiva e forte, hÃ¡ uma boa evidÃªncia de que isto, de fato, ocorra, pois viria a demonstrar um retorno para populaÃ§Ã£o por meio de um bom serviÃ§o de saÃºde.\n\nA correlaÃ§Ã£o resultou em 0.97, indicando fortes evidÃªncias a favor desta hipÃ³tese.\n\n### ðŸ‡ºðŸ‡¸ Question: The States with the highest GDP also invest more in ICU beds in Public Health?\n\n**Clarification**: SUS is an abbreviation of Sistema Ãšnico de SaÃºde, which stands for Unique Health System. SUS is the primary public health care in Brazil.\n\nLet us analyze this question through the correlation between GDP and the number of ICU beds. If it is a positive strong correlation, there is good evidence that this, in fact, occurs, since it demonstrates a return to the population by a good health system.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"populacao['pib'] = [int(x.replace('.','')) for x in populacao['pib']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"populacao['pib'].corr(populacao['leitos'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"populacao['populacao'].corr(populacao['leitos'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: O nÃºmero de leitos de UTI tem relaÃ§Ã£o com o PIB per capita?\n\n- Seguindo a mesma estratÃ©gia anterior, apenas checando os fatores de desigualdade social.\n- Essa questÃ£o foi brilhantemente sugerida por [Claudio de Pizzo](http://https://www.kaggle.com/claudiodipizzo)  \n- **ConclusÃ£o**: Tal correlaÃ§Ã£o parece mesmo fraca. Intrigante!\n\n### ðŸ‡ºðŸ‡¸ Question: Is the number of UCI units related to PIB per capita?\n\n- Following the same strategy as before, just checking the factors of social inequality.\n- This question was  brilliantly suggested by [Claudio de Pizzo](http://https://www.kaggle.com/claudiodipizzo)\n- **Conclusion**: Such correlation seems to be weak. Intriguing!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"newData = pd.read_csv('/kaggle/input/testdata/testData.csv')\nnewData['name'] = newData['name'].apply(remove_accents)\nnewData = newData.merge(populacao, left_on = 'name', right_on = 'name')\nnewData['pibpercapita'].corr(newData['leitos'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"PIB per capita versus Leitos de UTI\",\n    xaxis_title=\"PIB per capita\",\n    yaxis_title=\"Leitos de UTI\")\n\nfig = go.Figure(data=[\n    go.Scatter(x=newData['pibpercapita'], y=newData['leitos'],mode='markers')])\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: E quanto ao IDH-M?\n\nO IDH-M data de 2017.\n\nA correlaÃ§Ã£o encontra-se na categoria moderada (de 0,5 a 0,7), mas prÃ³ximo ao limiar inferior, sugindo fraqueza.  \nAssim, vÃª-se que a prepoderÃ¢ncia de outros aspectos da qualidade de vida aferidos no IDH-M sejam mais relevantes que os leitos de UTI. De fato, quando examina-se a composiÃ§Ã£o do IDH-M, esta hipÃ³tese Ã© corroborada. Ver links Ãºteis no final.\n\n### ðŸ‡ºðŸ‡¸ Question: How about the cities' GDP?\n\nThe data for this analysis is from 2017.\n\nThe correlation is moderate (from 0.5 to 0.7), but closer to the lowest boundary, suggesting a week correlation.  \nTherefore, it is possible to see the dominance of other aspects of life quality that are more relevant in the cities' GDP than the number of ICU beds. In fact, when analyzing the composing of the cities' GDP, this hypothesis is corroborated. Check the useful links at the end.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"populacao['idhm'] = [float(x.replace(',','.')) for x in populacao['idhm']]\npopulacao['idhm'].corr(populacao['leitos'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· A taxa de letalidade pelo COVID-19 em cada Estado Ã© correlacionada com o PIB per capita?\n\n- Se o PIB total Ã© alto, mas o PIB per capita Ã© baixo, hÃ¡ grande desigualdade na populaÃ§Ã£o\n- Nesses casos, ao examinar o PIB per capita, temos uma visÃ£o melhor das condiÃ§Ãµes de vida da populaÃ§Ã£o e como isso impacta na saÃºde e qualidade de vida\n- SerÃ¡ que este indicador socio-econÃ´mico se correlaciona com a letalidade que estamos vendo agora em cada Estado?\n- Essa questÃ£o foi brilhantemente sugerida por [Claudio de Pizzo](http://https://www.kaggle.com/claudiodipizzo)\n- **ConclusÃ£o**: Existe uma fraca correlaÃ§Ã£o negativa, isto Ã©, quanto maior o PIB per capita, menor Ã© a letalidade, mas nÃ£o hÃ¡ tanta forÃ§a nessa relaÃ§Ã£o\n\n### ðŸ‡ºðŸ‡¸ Does the letality rate due to COVID-19 is correlated with GDP per capita among states?\n\n- If the total GDP is high, but the GDP per capita is low, there is great inequality in the population\n- In these cases, when examining the GDP per capita, we have a better view of the living conditions of the population and how it impacts on health and quality of life.\n- Does this socio-economic indicator correlate with the lethality that we are seeing now in each state?\n- This question was  brilliantly suggested by [Claudio de Pizzo](http://https://www.kaggle.com/claudiodipizzo)\n- **Conclusion**: There is a weak negative correlation, i.e, as higher the GDP per capita, the lower the letality, but there is very few strenght in this relation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"newData = pd.read_csv('/kaggle/input/testdata/testData.csv')\nnewData['name'] = newData['name'].apply(remove_accents)\nnewData = newData.merge(populacao, left_on = 'name', right_on = 'name')\nnewData['pibpercapita'].corr(newData['letalidade'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· A taxa de letalidade pelo COVID-19 em cada Estado Ã© correlacionada com o nÃºmero de leitos de UTI disponÃ­veis?\n\n- Se hÃ¡ um bom nÃºmero de leitos, Ã© provÃ¡vel que a populaÃ§Ã£o seja bem amparada, diminuindo a perda de vidas.\n- **ConclusÃ£o**: Existe uma fraca correlaÃ§Ã£o positiva, o que Ã© um pouco contraditÃ³rio. Provavelmente, na prÃ¡tica, estas duas variÃ¡veis nÃ£o estÃ£o correlacionadas.\n\n### ðŸ‡ºðŸ‡¸ Does the letality rate due to COVID-19 is correlated with the number of ICU beds among states?\n\n- If there is plenty ICU beds, it is likely that the population is having good health support, which might decrease deaths\n- **Conclusion**: There is a weak positive correlation, which is somewhat contradictory. In practice, these two variables may not be correlated at all.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['letalidade'].corr(newData['leitos'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· O nÃºmero de casos de COVID-19 em cada Estado Ã© correlacionado com o PIB per capita?\n\n- SerÃ¡ que o PIB per capita alto favorece a diminuiÃ§Ã£o da contaminaÃ§Ã£o? Pode haver uma indicaÃ§Ã£o de que acesso a recursos materiais favoreÃ§a acesso Ã  saneamento, educaÃ§Ã£o e outros elementos que podem ser estratÃ©gicos para uma menor exposiÃ§Ã£o ao vÃ­rus?\n- Essa questÃ£o foi brilhantemente sugerida por [Claudio de Pizzo](http://https://www.kaggle.com/claudiodipizzo)\n- **ConclusÃ£o**: Existe uma fraca correlaÃ§Ã£o positiva, nÃ£o Ã© possÃ­vel supor tal hipÃ³tese.\n\n### ðŸ‡ºðŸ‡¸ Is the number of COVID-19 cases per State is correlated with GDP per capita?\n\n- Does the high GDP per capita favor the reduction of contamination? Could there be an indication that access to material resources favors access to sanitation, education and other elements that may be strategic for less exposure to the virus?\n- This question was  brilliantly suggested by [Claudio de Pizzo](http://https://www.kaggle.com/claudiodipizzo)\n- **Conclusion**: There is a weak positive correlation, therefore it is not possible to suppose such hypothesis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"newData = pd.read_csv('/kaggle/input/testdata/testData.csv')\nnewData['name'] = newData['name'].apply(remove_accents)\nnewData = newData.merge(df4, left_on = 'name', right_on = 'name')\nnewData['cases'].corr(newData['pibpercapita'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ðŸ‡§ðŸ‡· EstratÃ©gia de distribuiÃ§Ã£o de testes / ðŸ‡ºðŸ‡¸ Test distribution strategy\n\n- ðŸ‡§ðŸ‡· [De acordo com o MinistÃ©rio da SaÃºde](http://https://saude.gov.br/noticias/agencia-saude/46632-comeca-hoje-a-distribuicao-de-500-mil-testes-rapidos-para-todo-o-pais), em 01/04/2020 houve a distribuiÃ§Ã£o de 500 mil testes para a populaÃ§Ã£o, em todos os estados\n- Os testes foram de dois tipos:  \n    1. *Testes rÃ¡pidos*: Com resultados obtidos em cerca de 20min, sÃ£o indicados apenas para os profissionais dos serviÃ§os de saÃºde e da seguranÃ§a. Devem ser feitos apÃ³s o sÃ©timo dia do inÃ­cio dos sintomas e detectam a presenÃ§a de anticorpos contra o vÃ­rus SARS-CoV-2;\n    2. *TESTES RT-PCR*: Baseados em Biologia Molecular, eles identificam o COVID-19 em seus estÃ¡gios iniciais. Tais testes sÃ£o usados para casos graves internados.\n- De acordo com o governo, hÃ¡ mais testes a caminho.  \n  \n\n- ðŸ‡ºðŸ‡¸ [According to the Ministry of Health](http://https://saude.gov.br/noticias/agencia-saude/46632-comeca-hoje-a-distribuicao-de-500-mil-testes-rapidos-para-todo-o-pais), on April 1st,2020, 500 thousand tests were distributed to the population, in all states\n- The tests were of two types:\nÂ Â Â Â  1. *Rapid tests*: With results obtained in about 20 minutes, they are indicated only for health and safety professionals. They must be done after the seventh day of the onset of symptoms and detect the presence of antibodies against the SARS-CoV-2 virus;\nÂ Â Â Â  2. *RT-PCR TESTS*: Based on Molecular Biology, they identify COVID-19 in its early stages. Such tests are used for severe hospitalized cases.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Os testes foram distribuÃ­dos para os Estados com maior nÃºmero de casos? \n\n- Vamos considerar o nÃºmero de casos por estado em 31/03/2020\n- **ConclusÃ£o**: No caso dos testes rÃ¡pidos, hÃ¡ fortes evidÃªncias que o nÃºmero de casos foi determinante para a estratÃ©gia de distribuiÃ§Ã£o dos mesmos. No caso dos testes RT-PRC, nÃ£o hÃ¡ igual forÃ§a de evidÃªncia na afirmaÃ§Ã£o.\n\n### ðŸ‡ºðŸ‡¸ Have the tests been distributed to the states with the highest number of cases?\n\n- Let's consider the number of cases per state in 03/31/2020\n- **Conclusion**: In the case of rapid tests, there is strong evidence that the number of cases was decisive in  distribution strategy. In the case of RT-PRC tests, there is no equal strength of evidence in the statement.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Cases on March 31/2020 per state\ndata = pd.read_csv('/kaggle/input/corona-virus-brazil/brazil_covid19.csv')\ndf3 = data.loc[data['date'] == '2020-03-31'].groupby(['state'])['cases','deaths'].agg('sum')\ndf3 = df3.reset_index()\ndf3['name'] = df3['state'].apply(remove_accents)\ndf3.drop(['state'],axis=1,inplace=True)\nnewData = pd.read_csv('/kaggle/input/testdata/testData.csv')\nnewData['name'] = newData['name'].apply(remove_accents)\nnewData = newData.merge(df3, left_on = 'name', right_on = 'name')\nnewData['cases'].corr(newData['testesRapidos'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['cases'].corr(newData['testesRTPCR'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Os testes foram distribuÃ­dos para os Estados com maior nÃºmero de Ã³bitos? \n\n- Considerando dados por estado coletados em 31/03/2020\n- **ConclusÃ£o**: As mesmas conclusÃµes anteriores se aplicam.\n\n### ðŸ‡ºðŸ‡¸ Have the tests been distributed to the states with the highest number of deaths?\n\n- Considering data from state available in 03/31/2020\n- **Conclusion**: The same conclusions as above apply.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['deaths'].corr(newData['testesRapidos'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['deaths'].corr(newData['testesRTPCR'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Os testes foram distribuÃ­dos para os Estados com maior PIB? \n\n- Considerando dados por estado coletados em 31/03/2020\n\n### ðŸ‡ºðŸ‡¸ Have the tests been distributed to the states with the highest GDP?\n\n- Considering data from state available in 03/31/2020\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"subset = populacao[['name','pib']]\nnewData = newData.merge(subset, left_on = 'name', right_on = 'name')\nnewData['testesRapidos'].corr(newData['pib'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['testesRTPCR'].corr(newData['pib'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ðŸ‡§ðŸ‡· Antes de concluir, resta a pergunta: os estados com maior PIB tem maior nÃºmero de casos e Ã³bitos?\n- ðŸ‡ºðŸ‡¸ Before concluding, the question remains: do the states with the highest GDP have a higher number of cases and deaths?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['pib'].corr(newData['cases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['pib'].corr(newData['deaths'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ðŸ‡§ðŸ‡· **ConclusÃ£o**: Estados com maior PIB receberam maior quantidade de testes porque tambÃ©m registraram maior nÃºmero de casos e Ã³bitos. A distribuiÃ§Ã£o de testes na ocasiÃ£o parece ter considerado o panorama disponÃ­vel de maneira consistente e estratÃ©gica.\n- ðŸ‡ºðŸ‡¸ **Conclusion**: Higher GDP states received more tests because they also recorded a higher number of cases and deaths. The distribution of tests at the time seems to have considered the panorama available in a consistent and strategic way.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Os testes foram distribuÃ­dos para os Estados com nÃºmero de casos e Ã³bitos per capita?\n\n- Considerando dados por estado coletados em 31/03/2020\n\n### ðŸ‡ºðŸ‡¸ Have the tests been distributed to the states with higher cases and deaths per capita?\n\n- Considering data from state available in 03/31/2020\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"populacao = pd.read_csv('/kaggle/input/dadosbrasil/populacao.csv',sep=\";\")\npopulacao['name'] = populacao['name'].apply(remove_accents)\npopulacao = populacao.sort_values('name')\nnewData = newData.merge(populacao,left_on='name', right_on='name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['casescapita'] = (newData['cases']/newData['populacao'])\nnewData['deathscapita'] = (newData['deaths']/newData['populacao'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['testesRapidos'].corr(newData['casescapita'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['testesRapidos'].corr(newData['deathscapita'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['testesRTPCR'].corr(newData['casescapita'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData['testesRTPCR'].corr(newData['deathscapita'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- ðŸ‡§ðŸ‡· **ConclusÃ£o**: Na minha opiniÃ£o, a distribuiÃ§Ã£o de testes poderia ter sido ainda melhor, considerando a proporÃ§Ã£o de doentes e Ã³bitos nos estados, nÃ£o o quantitativo geral.\n- ðŸ‡ºðŸ‡¸ **Conclusion**: In my opinion, the distribution of tests could have been even better, considering the proportion of patients and deaths in the states, not the general number.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Como foi a distribuiÃ§Ã£o geogrÃ¡fica dos testes disponibilizados em 01/04/2020?\n### ðŸ‡ºðŸ‡¸ How was the geographic distribution of the tests made available on April 1st, 2020?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Abertura do mapa\nbrazil = gpd.read_file('/kaggle/input/brazil-states-geojson/brazil.geojson')\nbrazil['name'] = brazil['name'].apply(remove_accents)\nbrazil = brazil.sort_values('name')\n## mesclagem das bases\npop_states = brazil.merge(newData, left_on = 'name', right_on = 'name')\n# Input GeoJSON source that contains features for plotting\ngeosource = GeoJSONDataSource(geojson = pop_states.to_json())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Dados de 31/03/2020, ignorar cabeÃ§alho -- Data from 03/31/2020, ignore header\")\nshow(row(myplot3(geosource = geosource,tema = 'testesRapidos', jump = 100, high = max(newData['testesRapidos']), complemento = ''),myplot3(geosource = geosource,tema = 'testesRTPCR', jump = 100, high = max(newData['testesRTPCR']), complemento = '')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ðŸ‡§ðŸ‡· Examinando a SÃ©rie Temporal de Casos e Prevendo o NÃºmero de Casos / ðŸ‡ºðŸ‡¸ Examinating the Time Series of Cases and Predicting the Number of Cases\n\nðŸ‡§ðŸ‡· Vamos ignorar agora a distribuiÃ§Ã£o geogrÃ¡fica e considerar apenas o quantitativo de casos.\n\nðŸ‡ºðŸ‡¸ Let's ignore for now the geographic distribution and consider only the quantitative aspect of cases.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\ndf2 = data.groupby(['date'])['cases','deaths'].agg('sum')\ndf2 = df2.reset_index()\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"SÃ©rie temporal de Casos\",\n    xaxis_title=\"Data\",\n    yaxis_title=\"Quantidade\",\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=df2['date'], y=df2['cases'])\n    \n])\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Em que ordem o nÃºmero de casos estÃ¡ crescendo a cada dois dias?\n\n- Vamos comeÃ§ar a anÃ¡lise pelo primeiro dia em que houve casos confirmados\n- Iremos representar as linhas que denotam diferentes ordens crescimento de casos\n- ComeÃ§aremos a anÃ¡lise a partir do 27o. dia, que Ã© onde foi registrado o primeiro caso\n\n### ðŸ‡ºðŸ‡¸ Question: How much is the number of cases rising every two days?\n\n- Let's start our analysis from the day where the first case happened\n- We will denote lines that illustrate distinct growth orders\n- Our analysis will start from day 27, where the first case was reported","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfy = df2.copy()\ndfy.drop(['date','deaths'],axis=1,inplace = True)\ndfy = dfy.reset_index()\ndfy['dias'] = dfy['index']\n\n# Cases double by rate every 2 days\ndef casesDouble(rate, doubleDays):\n    supposedCases = [1]\n    for i in range(len(doubleDays)-1):\n        supposedCases.append(rate*supposedCases[-1])\n    return supposedCases\n\ndoubleDays = list(range(0,max(dfy['dias']),2))\ndfSupposed = pd.DataFrame({'dias':doubleDays,'2x':casesDouble(2,doubleDays),'3x':casesDouble(3,doubleDays),'1.5x':casesDouble(1.5,doubleDays)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"SuposiÃ§Ã£o do crescimento de casos a cada 2 dias (Escala logarÃ­tmica)\",\n    xaxis_title=\"Dias desde o primeiro caso\",\n    yaxis_title=\"Quantidade (escala log)\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    ),\n    yaxis_type=\"log\"\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dfy['dias'], y=dfy['cases'], name='Casos Reais',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['2x'], name = '2x',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['3x'], name = '3x',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['1.5x'], name = '1.5x',mode=\"lines+markers\")\n])\n\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ðŸ‡§ðŸ‡· **ConclusÃ£o**: O nÃºmero de casos parecem crescer 1,5 vezes a cada dois dias por muito tempo dentre o perÃ­odo observado.\nðŸ‡ºðŸ‡¸ **Conclusion**: The number of cases seems to grow 1.5 times every two days during the most part of days observed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· E a cada 3 dias?\n### ðŸ‡ºðŸ‡¸ And every 3 days?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dfy = df2.copy()\ndfy.drop(['date','deaths'],axis=1,inplace = True)\ndfy = dfy.reset_index()\ndfy['dias'] = dfy['index']\n\n# Cases double by rate every 3 days\ndef casesDouble(rate, doubleDays):\n    supposedCases = [1]\n    for i in range(len(doubleDays)-1):\n        supposedCases.append(rate*supposedCases[-1])\n    return supposedCases\n\ndoubleDays = list(range(0,max(dfy['dias']),3))\ndfSupposed = pd.DataFrame({'dias':doubleDays,'2x':casesDouble(2,doubleDays),'3x':casesDouble(3,doubleDays),'1.5x':casesDouble(1.5,doubleDays)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"SuposiÃ§Ã£o do crescimento de casos a cada 3 dias (Escala logarÃ­tmica)\",\n    xaxis_title=\"Dias desde o primeiro caso\",\n    yaxis_title=\"Quantidade (escala log)\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    ),\n    yaxis_type=\"log\"\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dfy['dias'], y=dfy['cases'], name='Casos Reais',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['2x'], name = '2x',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['3x'], name = '3x',mode=\"lines+markers\"),\n    go.Scatter(x=dfSupposed['dias'], y=dfSupposed['1.5x'], name = '1.5x',mode=\"lines+markers\")\n])\n\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ðŸ‡§ðŸ‡· **ConclusÃ£o**: Por muito tempo, o nÃºmero de casos pareceu mais que dobrar a cada trÃªs dias!  \nðŸ‡ºðŸ‡¸ **Conclusion**: For a long time the number of cases seemed to more than double every three days!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Como se comporta um estimador bastante simples, baseado em regressÃ£o linear, para prever o nÃºmero de casos?\n\n\n* **Holdout**: Treinar com 90% dos dados (90% dos primeiros dias) e testar nos 10% restantes\n* **AvaliaÃ§Ã£o de performance**: Raiz do erro mÃ©dio quadrÃ¡tico e $R^2$ Score\n* **PrecauÃ§Ãµes**: NÃ£o hÃ¡ 'lookahead'\n* **ConclusÃ£o**: Como esperado, nÃ£o hÃ¡ como uma regressÃ£o linear capturar bem o formato da tendÃªncia de crescimento. Portanto, o regressor subestima o nÃºmero de casos em relaÃ§Ã£o ao cenÃ¡rio real.\n\n### ðŸ‡ºðŸ‡¸ Question: How a simple estimator, based on linear regression, performs when predicting the number of cases?\n\n* **Holdout**: Training with 90% of the data (90% first days) and test with the last 10%.\n* **Performance Evaluation**: RMSE (Root Mean Squared Error) and $R^2$ Score.\n* **Precautions**: There is no lookahead.\n* **Conclusion**: As expected, it is not possible for a linear regression to capture the format and tendency of growth. Therefore, the regressor underestimates the number of cases when compared to the real scenario.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nimport datetime\nimport numpy as np\n\ndf2['date'] = pd.to_datetime(df2['date'])\ndf2 = df2.loc[df2['date'] >= '02-26-2020']\ndf2['dias'] = range(1,len(df2) + 1,1)\n\n## Treino\ndias_train = df2['dias'][:int(0.9*len(df2))]\ncases_train = df2['cases'][:int(0.9*len(df2))]\n\n## Teste\ndias_test = df2['dias'][int(0.9*len(df2)):]\ncases_test =  df2['cases'][int(0.9*len(df2)):]\n\nprevisao = len(df2) - len(dias_test)\n\nprint(\"Holdout: Dados Totais: %d, Treino: %d dias, Teste: %d dias\" % (len(df2),len(dias_train),len(dias_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nreg = LinearRegression().fit(dias_train.values.reshape(-1,1), cases_train)\ny_previsto = reg.predict(dias_test.values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Estimador linear para o nÃºmero de casos\",\n    xaxis_title=\"Dias desde a primeira notificaÃ§Ã£o\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dias_train, y=df2['cases'][:int(0.9*len(df2))], name='Dados de Treinamento',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=y_previsto, name = 'Casos Estimados',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=df2['cases'][int(0.9*len(df2)):], name = 'Casos Reais',mode=\"lines+markers\")\n])\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0= previsao + 0.5,\n            y0=120,\n            x1=previsao + 0.5,\n            y1=max(df2['cases']),\n            line=dict(\n                width=1.5,\n                dash= \"dash\"\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[previsao + 0.5],\n    y=[2],\n    text=[\"InÃ­cio da previsÃ£o\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\nprint(\"Erro mÃ©dio quadrÃ¡tico: \",mean_squared_error(cases_test,y_previsto))\nprint(\"R^2 Score: \", r2_score(cases_test,y_previsto))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: A tendÃªncia de crescimento dos casos Ã© de ordem exponencial?\n\n* ModificaÃ§Ã£o: Quantidade de dias desde o primeiro caso versus casos no dia\n* Vamos fazer um scatterplot do logaritmo dos casos versus o nÃºmero de dias.\n* Caso tenda a uma reta, hÃ¡ fortes evidÃªncias positivas para a pergunta em questÃ£o\n* **ConclusÃ£o**: Considerando os dados atuais, nÃ£o estamos fortemente em ordem exponencial, embora a tendÃªncia ainda seja crescente. HÃ¡ que se salientar que esta conclusÃ£o baseia-se apenas nos dados disponÃ­veis no dataset e pode estar havendo subnotificaÃ§Ã£o de casos em razÃ£o de dificuldades na ampla testagem.\n\n### ðŸ‡ºðŸ‡¸ Question: The cases growth tendency is exponencial?\n\n* Modification: Number of days since the first case vs. Number of cases in the day.\n* Let's make a scatter plot of the logarithm of cases versus the number of days.\n* If it tends to a straight line, there are strong positive evidences to the standing question.\n* **Conclusion**: Considering the current version of the data, there is no strength in the exponential tendency, even that the tendency is growing. We need to point out that this conclusion is based only on the data available in the dataset, and sub notification might be occurring due to difficulties in extensive wide testing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nimport datetime\nimport numpy as np\n\ndf2['date'] = pd.to_datetime(df2['date'])\ndf2 = df2.loc[df2['date'] >= '02-26-2020']\ndf2['dias'] = range(1,len(df2) + 1,1)\nlog_y_data = np.log(df2['cases'])\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title=\"Log Casos versus Dias\"\n)\n\nfig = go.Figure(data=[go.Scatter(name='log Casos',x=df2['dias'], y=log_y_data, mode='markers'),\n                     go.Scatter(name='ReferÃªncia',x=df2['dias'], y=df2['dias'], line=dict(color='firebrick', width=0.5,\n                              dash='dash'))])\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Como se comporta uma estimador baseado em regressÃ£o exponencial para o nÃºmero de casos?\n\n* **Holdout**: Treinar com 90% dos dados (90% dos primeiros dias) e testar nos 10% restantes\n* **AvaliaÃ§Ã£o de performance**: Raiz do erro mÃ©dio quadrÃ¡tico e R^2 Score\n* **PrecauÃ§Ãµes**: NÃ£o hÃ¡ 'lookahead'\n* **ConclusÃ£o**: NÃ£o Ã© um bom estimador para o problema. O valor de R^2 negativo e alto revela que este estimador Ã© pior que uma reta horizontal para o cenÃ¡rio\n\n### ðŸ‡ºðŸ‡¸ Question: How a exponencial estimator performs when predicting the number of cases?\n\n* **Holdout**: Training with 90% of the data (90% first days) and test with the last 10%.\n* **Performance Evaluation**: RMSE (Root Mean Squared Error) and $R^2$ Score.\n* **Precautions**: There is no lookahead.\n* **Conclusion**: It is not a good estimator for the problem. The highly negative R^2 Score reveals that the estimator is worst than a horizontal line for the scenario. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nimport datetime\nimport numpy as np\n\nlog_y_data = np.log(df2['cases'])\n\ncases_train_log = log_y_data[:int(0.9*len(df2))]\ncases_test_log = log_y_data[int(0.9*len(df2)):]\n\nprint(\"Holdout: Dados Totais: %d, Treino: %d dias, Teste: %d dias\" % (len(df2),len(dias_train),len(dias_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treino do modelo (interpolaÃ§Ã£o da curva)\ncurve_fit = np.polyfit(dias_train, cases_train_log, 1)\ny_train = (np.exp(curve_fit[1]) * np.exp(curve_fit[0]*dias_train)).astype(int)\ny_estimado = (np.exp(curve_fit[1]) * np.exp(curve_fit[0]*dias_test)).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Estimador exponencial para o nÃºmero de casos\",\n    xaxis_title=\"Dias desde a primeira notificaÃ§Ã£o\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dias_train, y=df2['cases'][:int(0.9*len(df2))], name='Dados de Treinamento',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=y_estimado, name = 'Casos Estimados',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=df2['cases'][int(0.9*len(df2)):], name = 'Casos Reais',mode=\"lines+markers\")\n])\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0= previsao + 0.5,\n            y0=120,\n            x1=previsao + 0.5,\n            y1=max(y_estimado),\n            line=dict(\n                width=1.5,\n                dash= \"dash\"\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[previsao + 0.5],\n    y=[2],\n    text=[\"InÃ­cio da previsÃ£o\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nprint(\"Erro mÃ©dio quadrÃ¡tico: \",mean_squared_error(cases_test_log,y_estimado))\nprint(\"R^2 Score: \", r2_score(cases_test,y_estimado))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Como se comporta uma estimador baseado em Rede Neural Artificial Multi-Layer Perceptron para um dia Ã  frente?\n\n* **HipÃ³tese**: RNAs MLPs sÃ£o aproximadoras universais de qualquer funÃ§Ã£o  \n* **Metodologia**: Treinar com n-1 dias para prever o dia seguinte\n* **AvaliaÃ§Ã£o de performance**: \n    1. Erro mÃ©dio absoluto que, para uma Ãºnica amostra, se reduz a: $\\left| x_i - \\hat{x}_i \\right|$\n* **Busca de parÃ¢metros**: Foi feita de maneira ad-hoc em relaÃ§Ã£o ao nÃºmero de neurÃ´nios nas camadas ocultas e Ã  funÃ§Ã£o de ativaÃ§Ã£o. VÃ¡rios testes foram realizados. O otimizador escolhido leva em conta que hÃ¡ poucos dados disponÃ­veis sobre o problema. O nÃºmero de iteraÃ§Ãµes atÃ© a convergÃªncia foi continuamente aumentado atÃ© atingir valores satisfatÃ³rios.\n* **PrecauÃ§Ãµes**: NÃ£o hÃ¡ 'lookahead'\n* **ConclusÃ£o**: Ã‰ um estimador excelente para o problema!!\n\n### ðŸ‡ºðŸ‡¸ Question: How an estimator based in an Artificial Neural Network Multi-Layer Perceptron performs predicting a day ahead?\n\n* **Hypothesis**: Artificial Neural Networks (ANNs) Multi-layer Perceptrons (MLPs) can approximate any function.  \n* **Methodology**: Train with n-1 days and predict the last day.\n* **Performance Evaluation**: \n    1. Mean Absolute Error that, for a single sample, reduces to $\\left| x_i - \\hat{x}_i \\right|$\n* **Parameter Search**: It was done in an ad-hoc manner in relation to the number of neurons in each hidden layer and the activation function. Many tests have been carried out. The optimizer was chosen considering that there is little data available. The number of epochs until the convergence increases until reaching satisfactory values.\n* **Precautions**: There is no lookahead.\n* **Conclusion**: It is an excelent estimator for the problem!!\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Treino\ndias_train = df2['dias'][:-1]\ncases_train = df2['cases'][:-1]\n\n## Teste\ndias_test = df2['dias'][-1:]\ncases_test =  df2['cases'][-1:]\n\nprevisao = len(df2) - len(dias_test)\n\nprint(\"Novo Holdout: Dados Totais: %d, Treino: %d dias, Teste: %d dia\" % (len(df2),len(dias_train),len(dias_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n# Treino da rede neural\nmlp = MLPRegressor(hidden_layer_sizes=(200,200),activation='relu',solver='lbfgs',max_iter=1000, shuffle=True)\nmlp.fit(X=dias_train.values.reshape(-1,1),y=cases_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_previsto = mlp.predict(dias_test.values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Estimador baseado em RNA MLP para o nÃºmero de casos\",\n    xaxis_title=\"Dias desde a primeira notificaÃ§Ã£o\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dias_train, y=df2['cases'][:-1], name='Dados de Treinamento',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=y_previsto, name = 'Casos Estimados',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test, y=df2['cases'][-1:], name = 'Casos Reais',mode=\"lines+markers\")\n])\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0= previsao + 0.5,\n            y0=120,\n            x1=previsao + 0.5,\n            y1=max(df2['cases']) + 100,\n            line=dict(\n                width=1.5,\n                dash= \"dash\"\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[previsao - 0.5],\n    y=[2],\n    text=[\"InÃ­cio da previsÃ£o\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Erro MÃ©dio Absoluto: {0:6.3f} casos\".format(mean_absolute_error(cases_test,y_previsto)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Pergunta: Como se comporta uma estimador baseado em Rede Neural Artificial Multi-Layer Perceptron para um dia Ã  frente + ACF da sÃ©rie temporal?\n\n* **HipÃ³teses**:\n    1. RNAs MLPs sÃ£o aproximadoras universais de qualquer funÃ§Ã£o  \n    2. Algumas sÃ©ries temporais sÃ£o auto-correlacionadas\n* **Metodologia**: \n    1. Calcular o ACF da SÃ©rie Temporal\n    2. Defasar a sÃ©rie temporal conforme o resultado anterior\n    3. Treinar a mesma arquitetura de RNA MLP anterior com n-1 dias para prever o dia seguinte\n* **AvaliaÃ§Ã£o de performance**: \n    1. Erro mÃ©dio absoluto que, para uma Ãºnica amostra, se reduz a: $\\left| x_i - \\hat{x}_i \\right|$\n* **PrecauÃ§Ãµes**: NÃ£o hÃ¡ 'lookahead'\n* **ConclusÃ£o**:\n\n### ðŸ‡ºðŸ‡¸ Question: How an ANN MLP estimator performs in the task of predicting a day ahead + Time Series ACF?\n\n* **Hypothesis**:\n    1. ANN MLPs can approximate any function.\n    2. Some Time Series are autocorrelated.\n* **Methodology**: \n    1. Calculate the autocorrelation function of the Time Series.\n    2. Lag the Time Series based on the previous result.\n    3. Train an MLP with the same architecture that we used in the last example using $n-1$ days and predict the $n-th$ day.\n* **Performance Evaluation**: \n    1. Mean Absolute Error that, for a single sample, reduces to $\\left| x_i - \\hat{x}_i \\right|$\n* **PrecauÃ§Ãµes**: There is no lookahead.\n* **Conclusion**:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### ðŸ‡§ðŸ‡· Parte 1: Organizando os dados\n#### ðŸ‡ºðŸ‡¸ Step 1: Tidying the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\ndf3 = None\ndf3 = df2.copy()\ndf3.head()\ndf3.set_index('dias',inplace=True)\ndf3.drop(['date','deaths'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ðŸ‡§ðŸ‡· Parte 2: Obtendo o ACF\n\nObserve: a sÃ©rie Ã© muito bem autocorrelacionada com janela (lag) = 1\n\n#### ðŸ‡ºðŸ‡¸ Step 2: Obtaining the autocorrelation function\n\nObserve: The time series is very well autocorrelated with lag = 1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.graphics.tsa.plot_acf(df3.values.squeeze(), lags=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ðŸ‡§ðŸ‡· Parte 3: Obtendo tambÃ©m o PACF\n\nTambÃ©m nota-se que a sÃ©rie Ã© muito bem parcialmente auto-correlacionada com lag = 1\n\n#### ðŸ‡ºðŸ‡¸ Step 3: Obtaining the partial autocorrelation function\n\nIt is also noticeable that the series is very well partially autocorrelated with lag = 1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.graphics.tsa.plot_pacf(df3.values.squeeze(), lags=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ðŸ‡§ðŸ‡· Parte 4: Preparando os dados\n\nCom vistas a obter a seguinte preparaÃ§Ã£o dos dados\n* Atributos preditores: \n    1. Dia $t$\n    2. NÃºmero de casos no dia $t$\n    3. NÃºmero de casos no dia $t - 1$\n* Atributo alvo: nÃºmero de casos no dia $t + 1$\n\n#### ðŸ‡ºðŸ‡¸ Step 4: Preparing the data\n\nLooking forward to obtaining the following preparation of data:\n* Features:\n    1. Day $t$\n    2. Number of cases in $t$\n    3. Number of cases in $t - 1$\n* Target variable: number of cases in $t + 1$","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df3['yesterday'] = df3['cases'].shift(1,fill_value=0)\ndf3.reset_index(level=0, inplace=True)\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ðŸ‡§ðŸ‡· Parte 5: PreparaÃ§Ã£o do Holdout\n\n#### ðŸ‡ºðŸ‡¸ Step 5: Holdout preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Treino\ndias_train = df3[['dias','yesterday']][:-1]\ncases_train = df3['cases'][:-1]\n\n## Teste\ndias_test = df3[['dias','yesterday']][-1:]\ncases_test =  df3['cases'][-1:]\n\nprevisao = len(df3) - len(dias_test)\n\nprint(\"Novo Holdout: Dados Totais: %d, Treino: %d dias, Teste: %d dia\" % (len(df2),len(dias_train),len(dias_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ðŸ‡§ðŸ‡· Parte 6: Treino da mesma MLP com nova estratÃ©gia\n#### ðŸ‡ºðŸ‡¸ Step 6: Training the same MLP architecture using this new strategy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n# Treino da rede neural\nmlp = MLPRegressor(hidden_layer_sizes=(200,200),activation='relu',solver='lbfgs',max_iter=1000, shuffle=True)\nmlp.fit(X=dias_train.values,y=cases_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_previsto = mlp.predict(dias_test.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"RNA MLP para previsÃ£o um dia Ã  frente com dia anterior nos atributos\",\n    xaxis_title=\"Dias desde a primeira notificaÃ§Ã£o\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 4\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=dias_train['dias'], y=df3['cases'][:-1], name='Dados de Treinamento',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test['dias'], y=y_previsto, name = 'Casos Estimados',mode=\"lines+markers\"),\n    go.Scatter(x=dias_test['dias'], y=df3['cases'][-1:], name = 'Casos Reais',mode=\"lines+markers\")\n])\nfig.add_shape(\n        # Line Vertical\n        dict(\n            type=\"line\",\n            x0= previsao + 0.5,\n            y0=120,\n            x1=previsao + 0.5,\n            y1=max(df2['cases']) + 100,\n            line=dict(\n                width=1.5,\n                dash= \"dash\"\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[previsao - 0.5],\n    y=[2],\n    text=[\"InÃ­cio da previsÃ£o\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Erro MÃ©dio Absoluto: {0:6.3f} casos\".format(mean_absolute_error(cases_test,y_previsto)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ðŸ‡§ðŸ‡· ConsideraÃ§Ãµes Finais / ðŸ‡ºðŸ‡¸ Final Remarks\n\n- ðŸ‡§ðŸ‡· A utilizaÃ§Ã£o de conhecimentos sobre a auto-correlaÃ§Ã£o total e parcial da sÃ©rie foi a melhor estratÃ©gia para previsÃ£o um dia Ã  frente\n- Utilizou-se dados dos casos do dia anterior para auxiliar no aprendizado dos padrÃµes implÃ­citos no crescimento da sÃ©rie\n- O melhor modelo obtido foi uma Rede Neural Multi Layer Perceptron com duas camadas ocultas e 200 neurÃ´nios em cada camada, funÃ§Ã£o de ativaÃ§Ã£o 'relu'e otimizador LBFGS em virtude da pequena quantidade de dados\n- A RNA se mostrou bastante tolerante aos ruÃ­dos e capturou adequadamente flutuaÃ§Ãµes que nÃ£o estÃ£o nos dados em si, tais como: \n   - Chegada de mais kits de testes\n   - SubnotificaÃ§Ã£o\n   - NotificaÃ§Ã£o tardia\n   \n\n- ðŸ‡ºðŸ‡¸ The use of knowledge about autocorrelation and partial autocorrelation was the best strategy to predict a day ahead.\n- The number of cases in the previous day was used to help the models to learn implicit patterns in the series growth.\n- The best model obtained was an ANN MLP with two hidden layers and 200 neurons each, using `relu` as the activation function and `LBFGS` as the optimizer, in virtue of the small amount of data.\n- The ANN has shown tolerance to noise and appropriately captured fluctuations that are not in the data itself, such as:\n    * The arrival of more testing kits\n    * Subnotification\n    * Late notification","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# ðŸ‡§ðŸ‡· Palpite para o futuro: NÃºmero de casos amanhÃ£/ ðŸ‡ºðŸ‡¸ Guessing the future: Number of cases tomorrow\n\n - ðŸ‡§ðŸ‡· Obtido automaticamente a partir do mesmo modelo retreinado com todos os dados\n - SerÃ£o realizadas 20 execuÃ§Ãµes, para minimizar o viÃ©s estocÃ¡stico da inicializaÃ§Ã£o aleatÃ³ria dos pesos\n - SerÃ¡ considerada a previsÃ£o mais otimista, com o menor nÃºmero de casos\n \n \n - ðŸ‡ºðŸ‡¸ Automatically obtained using the same model retrained with all the data\n - Will be run 20 times, to minimize the stochastic bias of the random weight initialization\n - The most optimistic prediction will be considered, with the lowest amount of cases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\n# Para uso nos dias que fiz previsÃ£o Ã  posteriori\n#df3.drop(df3.tail(1).index,inplace=True) \n\ntomorrow = max(df3['dias']) + 1\ntoday_cases = df3.loc[df3['dias'] == max(df3['dias'])]['cases']\n\nresults = []\nfor i in range(20):\n\n    # Treino da rede neural\n    mlp = MLPRegressor(hidden_layer_sizes=(200,200),activation='relu',solver='lbfgs',max_iter=3000, shuffle=True)\n    mlp.fit(X=df3[['dias','yesterday']].values,y=df3['cases'].values.ravel())\n    \n\n    x = pd.Series([tomorrow,int(today_cases)]).values.reshape(1,-1)\n    tomorrow_cases = mlp.predict(x)\n    results.append(tomorrow_cases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tomorrow_data = (datetime.datetime.now()).strftime('%d/%m/%Y')\nprint(\"PrevisÃ£o de casos para {0} no Brasil, a conferir na coletiva diÃ¡ria das 17h30min: {1}\".format(tomorrow_data,int(min(results))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"| **Data da PrevisÃ£o** | **NÃºmero de Casos Previstos** | **NÃºmero de Casos Real** | **ObservaÃ§Ã£o**|\n| --- | --- | ---| --- |  \n| 03/04/2020 | 9152 | 9056 |  |\n| 04/04/2020 | 10432 | 10278 |   | \n| 05/04/2020 | 11766 | 11130|    |\n| 06/04/2020 |  12521     |12056 |  |\n| 07/04/2020 |  13379     |  14347   |  |\n| 08/04/2020 | 15316     | 15927    |   |\n| 09/04/2020 | 17943 | 17857 | A posteriori em 10/04  |\n| 10/04/2020 | 20071 | 19638 |  |\n| 11/04/2020 | 21923      |20727      |  |\n| 12/04/2020 |  21919     | 22169       |  |\n| 13/04/2020 | 24097   |   23430   |  |\n| 14/04/2020 | 25353     | 25262   |  |\n| 15/04/2020 | 27010      | 28320 |      |\n| 16/04/2020 | 30788   | 30425    | A posteriori em 17/04  |\n| 17/04/2020 | 32730   | 33682    |  |\n| 18/04/2020 |36598       | 36599      | A posteriori em 20/04 - Erro por um caso! |\n| 19/04/2020| 39721         |   38654      | A posteriori em 20/04  | \n| 20/04/2020| 41664     |40581     | A posteriori em 22/04 |\n| 21/04/2020|  43517       |    43079     | A posteriori em 22/04    | \n| 22/04/2020|  45985       |  45757  |    | \n| 23/04/2020|   48708         |   49492    | (Buffer de testes divulgado de uma vez sÃ³?)   |\n| 24/04/2020| 52806 |   52995 |   |\n| 25/04/2020| 56585 | 58509  |   |\n| 26/04/2020| 62838      | 63584    |    |\n| 27/04/2020| 66246   |  66501  |    | \n| 28/04/2020| 71186 | 71886 | |\n| 29/04/2020| 77052      | 78162   |.  |\n| 30/04/2020| 83951       | 85380   |.  |\n|01/05/2020 | 91967  | 91589   |   | \n| 02/05/2020 | 98552 | 96396 | | \n| 03/05/2020 | 103467 | 101147 | A posteriori em 04/05|\n| 04/05/2020 | 107909 | 107780  | | \n| 05/05/2020|  111746   | 114715  | (Erro no preenchimento do dataset? -- Corrigido!)|\n| 06/05/2020|  122221  | 125218    |.    | \n| 07/05/2020 | 133920     | 135106   |.  |\n| 08/05/2020 | 144682 |145328  |. |\n| 09/05/2020 | 155719 |155939  |. |\n| 10/05/2020 |167089   | 162699  |  | \n| 11/05/2020 | 173487   |168331  |  .| \n| 12/05/2020| 178559    |177589   |. |\n| 13/05/2020|  188156 | 188974 | . |\n| 14/05/2020| 200292 | 202918 | .|\n| 15/05/2020| 215428 | 218223 | .|\n| 16/05/2020|  232085   | 233142   |.   |\n| 17/05/2020|248059      | 241080    | (A posteriori em 18/05/2020) |\n| 18/05/2020|255226    |254220  |. |\n| 19/05/2020| 268995  |271628   |.  |\n| 20/05/2020|287681    |291579    |.    |  \n| 21/05/2020| 309425 | 310087 | | \n| 22/05/2020| 329081 | 330890 | |\n| 23/05/2020| 351431 | 347398 | (A posteriori em 24/05/2020) | \n| 24/05/2020| 368255 | 363211 | | \n| 25/05/2020| 384151| 374898| |\n| 26/05/2020| 394788| 391222 |(A posteriori em 27/05/2020) |\n| 27/05/2020| 411194| 411821 | |\n| 28/05/2020|431782      |438238     |.  |\n| 29/05/2020| 461557     |  465166    |.  |\n|30/05/2020|  490163    |  498440    |.  |\n| 31/05/2020| 526460     |  514849    |.  |\n| 01/06/2020| 542052    | 526447   |. | \n| 02/06/2020| 551830 | 555383 | .|\n| 03/06/2020|582685  | 584016  | (A posteriori em 04/06/2020) |\n| 04/06/2020|612518  | 614941  | (MudanÃ§a no horÃ¡rio de divulgaÃ§Ã£o dos resultados)  |\n| 05/06/2020 |645351  |.   |.  |\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = [9056, 10278, 11130, 12056,14347, 15927, 17857, 19638, 20727, 22169, 23430, 25262, 28320, 30425, 33682, 36599, 38654, 40581, 43079, 45757, 52995, 58509, 63584, 66501, 71886, 78162, 85380, 91589, 96396,101147,107780, 114715,125218, 135106, 145328, 155939, 162699, 168331, 177589, 188974, 202918, 218223, 233142, 241080, 254220, 271628, 291579, 310087, 330890, 347398, 363211, 374898, 391222, 411821, 438238, 465166, 498440, 514849, 526447, 555393,584016, 614941]\ny_previsto = [9152, 10432, 11766, 12521, 13379, 15316, 17943, 20071, 21923, 21919, 24097, 25353, 27010, 30788, 32730, 36598, 39721, 41664, 43517, 45985, 52806, 56585, 62838, 66246, 71186, 77052,83951, 91967,98552, 103467, 107909,111746,122221, 133920, 144682, 155719, 167089, 173487, 178559, 188156, 200292, 215428, 232085, 248059, 255226, 268995, 287681, 309425, 329081, 351431, 368255, 384151, 394788, 411194, 431782, 461557, 490163, 526460, 542052,551830,582685, 612518] \n\nprint(\"Raiz do Erro MÃ©dio QuadrÃ¡tico (RMSE): {0:6.4f}\".format(mean_squared_error(y_true,y_previsto)**0.5))\nprint(\"R2-Score: {0:6.4f}\".format(r2_score(y_true,y_previsto)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Visualizando real versus previsÃ£o a partir de 03/04/2020\n\n### ðŸ‡ºðŸ‡¸ Visualizing ground truth versus prediction starting in April 3rd, 2020","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# CriaÃ§Ã£o dos rÃ³tulos para o eixo x com datas\nlabels = []\nstart_date = datetime.date(2020, 4, 3)\nend_date = datetime.date.today()\ndelta = datetime.timedelta(days=1)\nwhile start_date < end_date:\n    labels.append(start_date.strftime('%d/%m/%Y'))\n    start_date += delta\n\nlayout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"Visualizando previsÃµes one-day-ahead realizadas com o modelo proposto\",\n    xaxis_title=\"Datas\",\n    yaxis_title=\"Quantidade de casos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3,\n        tickangle = 295\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=labels, y=y_true, name='Casos Reais',mode=\"lines+markers\"),\n    go.Scatter(x=labels, y=y_previsto, name = 'Casos Estimados',mode=\"lines+markers\"),\n])\n\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Visualizando os ResÃ­duos\n\n- Os resÃ­duos na previsÃ£o sÃ£o a diferenÃ§a entre os valores previstos e observados ao quadrado\n- Resultam em pontos que sÃ£o comparados com a reta-0\n- A reta-0 representa o modelo perfeito, em que a distÃ¢ncia entre o valor previsto e observado Ã© zero\n- Visualizar os resÃ­duos ajuda a interpretar visualmente a qualidade do modelo\n\n### ðŸ‡ºðŸ‡¸ Visualizing the residuals\n\n- The residual in the prediction are the square of the difference between the predicted ($x'$) and the real ($x$) values: $(x' - x)^2$\n- The result is a set of points that are compared with the line-0\n- The line-0 represents the perfect model, in which the distance between every predicted and real value is zero.\n- Visualizing the residual values helps to visually understand the quality of the model\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"residuos = []\ndatas = []\ninicio = datetime.datetime.now() - datetime.timedelta(days=len(y_true))\nfor (x,y) in zip(y_true,y_previsto):\n    r = (x-y)\n    residuos.append(r)\n    datas.append(inicio.strftime('%d/%m/%Y'))\n    inicio += datetime.timedelta(days=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = Layout(\n    paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n    title= \"VisualizaÃ§Ã£o dos ResÃ­duos\",\n    xaxis_title=\"Dia da PrevisÃ£o\",\n    yaxis_title=\"ResÃ­duos\",\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 1,\n        dtick = 3,\n        tickangle = 295\n    )\n)\n\nfig = go.Figure(data=[\n    go.Scatter(x=datas, y=residuos, name='Residuos',mode=\"markers\")\n])\nfig.add_shape(\n        # Horizontal Line\n        dict(\n            type=\"line\",\n            x0= 0,\n            y0= 0,\n            x1= len(y_true),\n            y1=0,\n            name = \"Reta Zero\",\n            line=dict(\n                width=3,\n                dash= \"dash\"\n            ),\n            \n))\n\nfig.add_trace(go.Scatter(\n    x=[len(y_true)],\n    y=[300],\n    text=[\"Reta Zero\"],\n    mode=\"text\",\n))\nfig['layout'].update(layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ðŸ‡§ðŸ‡· Links Ãšteis / ðŸ‡ºðŸ‡¸ Useful links\n\n* https://docs.bokeh.org/en/latest/docs/user_guide/geo.html  \n* https://towardsdatascience.com/walkthrough-mapping-basics-with-bokeh-and-geopandas-in-python-43f40aa5b7e9  \n* https://pt.wikipedia.org/wiki/Lista_de_unidades_federativas_do_Brasil_por_popula%C3%A7%C3%A3o\n* http://www.atlasbrasil.org.br/2013/data/rawData/publicacao_atlas_municipal_pt.pdf\n* http://portal.cfm.org.br/images/PDF/leitosdeutiestados2018.pdf\n* https://www.ssp.sp.gov.br/fale/estatisticas/answers.aspx?t=6\n* https://github.com/codeforamerica/click_that_hood/blob/master/public/data/brazil-states.geojson\n* https://docs.python.org/3/library/datetime.html","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Agradecimento\n\nA autora ElloÃ¡ B. Guedes agradece o apoio financeiro provido pela FAPEAM no Ã¢mbito do Projeto PPP 04/2017.\n\n![](http://www.fapeam.am.gov.br/downloads/57415/)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}