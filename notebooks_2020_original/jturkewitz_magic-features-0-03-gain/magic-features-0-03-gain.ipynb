{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ab872372-3724-e09b-f6f2-25ef67d1e02d"},"source":"Adding the following meta features allowed my model to go from 0,252 to 0.217. I suspect that more gain can be squeezed from similar features as well, I just found this last night. The magic features are based on question frequency. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d67033b-e87c-645c-1239-9159cb4d2453"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport timeit"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74c072c2-89d0-9b2d-b6fa-74ddfef3acab"},"outputs":[],"source":"train_orig =  pd.read_csv('../input/train.csv', header=0)\ntest_orig =  pd.read_csv('../input/test.csv', header=0)\n\ntic0=timeit.default_timer()\ndf1 = train_orig[['question1']].copy()\ndf2 = train_orig[['question2']].copy()\ndf1_test = test_orig[['question1']].copy()\ndf2_test = test_orig[['question2']].copy()\n\ndf2.rename(columns = {'question2':'question1'},inplace=True)\ndf2_test.rename(columns = {'question2':'question1'},inplace=True)\n\ntrain_questions = df1.append(df2)\ntrain_questions = train_questions.append(df1_test)\ntrain_questions = train_questions.append(df2_test)\n#train_questions.drop_duplicates(subset = ['qid1'],inplace=True)\ntrain_questions.drop_duplicates(subset = ['question1'],inplace=True)\n\ntrain_questions.reset_index(inplace=True,drop=True)\nquestions_dict = pd.Series(train_questions.index.values,index=train_questions.question1.values).to_dict()\ntrain_cp = train_orig.copy()\ntest_cp = test_orig.copy()\ntrain_cp.drop(['qid1','qid2'],axis=1,inplace=True)\n\ntest_cp['is_duplicate'] = -1\ntest_cp.rename(columns={'test_id':'id'},inplace=True)\ncomb = pd.concat([train_cp,test_cp])\n\ncomb['q1_hash'] = comb['question1'].map(questions_dict)\ncomb['q2_hash'] = comb['question2'].map(questions_dict)\n\nq1_vc = comb.q1_hash.value_counts().to_dict()\nq2_vc = comb.q2_hash.value_counts().to_dict()\n\ndef try_apply_dict(x,dict_to_apply):\n    try:\n        return dict_to_apply[x]\n    except KeyError:\n        return 0\n#map to frequency space\ncomb['q1_freq'] = comb['q1_hash'].map(lambda x: try_apply_dict(x,q1_vc) + try_apply_dict(x,q2_vc))\ncomb['q2_freq'] = comb['q2_hash'].map(lambda x: try_apply_dict(x,q1_vc) + try_apply_dict(x,q2_vc))\n\ntrain_comb = comb[comb['is_duplicate'] >= 0][['id','q1_hash','q2_hash','q1_freq','q2_freq','is_duplicate']]\ntest_comb = comb[comb['is_duplicate'] < 0][['id','q1_hash','q2_hash','q1_freq','q2_freq']]\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45730778-80b2-778f-4e2f-6e84abf49d04"},"outputs":[],"source":"corr_mat = train_comb.corr()\ncorr_mat.head()\n#more frequenct questions are more likely to be duplicates"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}