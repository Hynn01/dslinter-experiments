{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U nvidia-ml-py3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport os\nimport random\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm.notebook import tqdm\n\ntorch.cuda.empty_cache()\ntorch.cuda.set_device(\"cuda:0\")\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.enabled = True\n\nfrom pynvml import *\nnvmlInit()\ndeviceCount = nvmlDeviceGetCount()\nfor i in range(deviceCount):\n    handle = nvmlDeviceGetHandleByIndex(i)\n    print(f\"Device {i} {nvmlDeviceGetName(handle).decode()}\")\ninfo = nvmlDeviceGetMemoryInfo(handle)    \ndef gpu_stats(message=''):\n    message = f\"{message}\\n\" or ''\n    tqdm.write(\n        f\"{message}\"\n        f\"Free GPU memory - {info.free // (1024 * 1024)} MB\\n\"\n        f\"Used GPU memory - {info.used // (1024 * 1024)} MB\\n\"\n    )\ngpu_stats()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%time\ntorch.manual_seed(70)\nbatch_size = 64\nimage_size = 64\n\nrandom_transforms = [transforms.ColorJitter(), transforms.RandomRotation(degrees=20)]\ntransform = transforms.Compose([transforms.Resize(image_size),\n                                transforms.CenterCrop(image_size),\n                                transforms.RandomHorizontalFlip(p=0.5),\n                                transforms.RandomApply(random_transforms, p=0.2),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntrain_data = datasets.ImageFolder('../input/', transform=transform)\ndataloader = torch.utils.data.DataLoader(\n    train_data, shuffle=True,\n    batch_size=batch_size,\n    pin_memory=True\n)\nimgs, label = next(iter(dataloader))\nimgs = imgs.numpy().transpose(0, 2, 3, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5):\n    plt.imshow(imgs[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init(m):\n    \"\"\"\n    Takes as input a neural network m that will initialize all its weights.\n    \"\"\"\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nLR_G = 0.0005\nLR_D = 0.001\n\nbeta1 = 0.5\nepochs = 20\n\nreal_label = 0.9\nfake_label = 0\nnz = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, channels=3, features_d=64):\n        super(Discriminator, self).__init__()\n        \n        self.channels = channels\n\n        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):\n            block = [\n                nn.Conv2d(\n                    n_input,\n                    n_output,\n                    kernel_size=k_size,\n                    stride=stride,\n                    padding=padding,\n                    bias=False\n                )\n            ]\n            if bn:\n                block.append(nn.BatchNorm2d(n_output))\n            block.append(nn.LeakyReLU(0.2, inplace=True))\n            return block\n\n        self.model = nn.Sequential(\n            *convlayer(self.channels, features_d, 4, 2, 1),\n            *convlayer(features_d, features_d * 2, 4, 2, 1),\n            *convlayer(features_d * 2, features_d * 4, 4, 2, 1, bn=True),\n            *convlayer(features_d * 4, features_d * 8, 4, 2, 1, bn=True),\n            nn.Conv2d(features_d * 8, 1, 4, 1, 0, bias=False),  # FC with Conv.\n        )\n\n    def forward(self, imgs):\n        logits = self.model(imgs)\n        out = torch.sigmoid(logits)\n    \n        return out.view(-1, 1)\n    \n\nclass Generator(nn.Module):\n    def __init__(self, nz=256, channels=3):\n        super(Generator, self).__init__()\n        \n        self.nz = nz\n        self.channels = channels\n        \n        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0):\n            block = [\n                nn.ConvTranspose2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),\n                nn.BatchNorm2d(n_output),\n                nn.ReLU(inplace=True),\n            ]\n            return block\n\n        self.model = nn.Sequential(\n            *convlayer(self.nz, 1024, 4, 1, 0), # Fully connected layer via convolution.\n            *convlayer(1024, 512, 4, 2, 1),\n            *convlayer(512, 256, 4, 2, 1),\n            *convlayer(256, 128, 4, 2, 1),\n            *convlayer(128, 64, 4, 2, 1),\n            nn.ConvTranspose2d(64, self.channels, 3, 1, 1),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        z = z.view(-1, self.nz, 1, 1)\n        img = self.model(z)\n        return img\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnetD = Discriminator().to(device)\nnetG = Generator(nz).to(device)\n\ncriterion = nn.BCELoss()\n\noptimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(beta1, 0.999))\n\nif os.path.exists('../working/discriminator.pth'):\n    tqdm.write(\"Found checkpoint, preloading the data...\")\n    #Disc\n    checkpoint = torch.load('../working/discriminator.pth')\n    netD.load_state_dict(checkpoint['model_state_dict'])\n    optimizerD.load_state_dict(checkpoint['optimizer_state_dict'])\n    epochs = epochs - checkpoint['epoch']\n    errD = checkpoint['loss']\n    # Gen\n    checkpoint = torch.load('../working/generator.pth')\n    netG.load_state_dict(checkpoint['model_state_dict'])\n    optimizerG.load_state_dict(checkpoint['optimizer_state_dict'])\n    epochs = epochs - checkpoint['epoch']\n    errG = checkpoint['loss']\n\nG_losses = []\nD_losses = []\nepoch_time = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_loss (G_losses, D_losses, epoch):\n    plt.figure(figsize=(10,5))\n    plt.title(\"Generator and Discriminator Loss - EPOCH \"+ str(epoch))\n    plt.plot(G_losses,label=\"G\")\n    plt.plot(D_losses,label=\"D\")\n    plt.xlabel(\"iterations\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n    \ndef show_generated_img(n_images=5):\n    sample = []\n    for _ in range(n_images):\n        noise = torch.randn(1, nz, 1, 1, device=device)\n        gen_image = netG(noise).to(\"cpu\").clone().detach().squeeze(0)\n        gen_image = gen_image.numpy().transpose(1, 2, 0)\n        sample.append(gen_image)\n\n    figure, axes = plt.subplots(1, len(sample), figsize = (64,64))\n    for index, axis in enumerate(axes):\n        axis.axis('off')\n        image_array = sample[index]\n        axis.imshow(image_array)\n\n    plt.show()\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor epoch in tqdm(range(epochs), position=1):\n    start = time.time()\n    for ii, (real_images, train_labels) in tqdm(\n        enumerate(dataloader),\n        total=len(dataloader),\n        position=0,\n        leave=False\n    ):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        netD.zero_grad()\n        real_images = real_images.to(device)\n        train_labels = train_labels.to(device)\n        batch_size = real_images.size(0)\n        labels = torch.full((batch_size, 1), real_label, device=device)\n        labels = labels.to(device)\n        \n        output = netD(real_images)\n        output = output.to(device)\n        errD_real = criterion(output, labels)\n        errD_real.to(device)\n        errD_real.backward()\n        D_x = output.mean().item()\n        \n        # train with fake\n        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n        noise = noise.to(device)\n        fake = netG(noise)\n        fake = fake.to(device)\n        labels.fill_(fake_label)\n        output = netD(fake.detach())\n        output.to(device)\n        errD_fake = criterion(output, labels)\n        errD_fake = errD_fake.to(device)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n        \n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        labels.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake)\n        output = output.to(device)\n        errG = criterion(output, labels)\n        errG.to(device)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n        \n        # Save Losses for plotting later\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n        \n        if (ii+1) % (len(dataloader)//2) == 0:\n            tqdm.write(\n                f'[{epoch + 1}/{epochs}][{ii+1}/{len(dataloader)}] '\n                f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n                f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}'\n            )\n            gpu_stats(message=f\"Stats for iteration {ii+1}:\\n\")\n    plot_loss (G_losses, D_losses, epoch)\n    G_losses = []\n    D_losses = []\n    show_generated_img()\n    torch.save(\n        {\n            'epoch': epoch,\n            'model_state_dict': netD.state_dict(),\n            'optimizer_state_dict': optimizerD.state_dict(),\n            'loss': errD\n        },\n        '../working/discriminator.pth'\n    )\n    torch.save(\n        {\n            'epoch': epoch,\n            'model_state_dict': netG.state_dict(),\n            'optimizer_state_dict': optimizerG.state_dict(),\n            'loss': errG\n        },\n        '../working/generator.pth'\n    )\n    epoch_time.append(time.time()- start)\n\n#fixed_noise = torch.randn(25, nz, 1, 1, device=device)    \n#valid_image = netG(fixed_noise)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print (\">> average EPOCH duration = \", np.mean(epoch_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('../output_images'):\n    os.mkdir('../output_images')\n    \nim_batch_size = 50\nn_images=10000\n\nfor i_batch in tqdm(range(0, n_images, im_batch_size)):\n    gen_z = torch.randn(im_batch_size, nz, 1, 1, device=device)\n    gen_images = netG(gen_z)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)):\n        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25, 16))\n# display 10 images from each class\nfor i, j in enumerate(images[:32]):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    plt.imshow(j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nshutil.make_archive('images', 'zip', '../output_images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}