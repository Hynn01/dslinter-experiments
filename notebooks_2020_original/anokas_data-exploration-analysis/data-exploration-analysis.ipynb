{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d5edcd32-1cbb-dace-9c27-968e6b3b39e1","_active":false,"collapsed":false},"source":"## Classifying the Amazon Rainforest\n\nWelcome back to another satellite imagery competition - these seem to be in fashion lately :) This time, unlike other recent satellite imagery competitions, we have to add tags to each image (which are segments of a larger image of the Amazon Rainforest). However, since each image can have multiple labels, that makes this a **multi-label** classification challenge as opposed to standard multi-class problem.\n\n**And as always, if this helped you, some upvotes would be very much appreciated - that's where I get my motivation! :D**\n\nTime to get straight into the data:","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14b58767-2c57-fd00-a82b-31f91b230112","_active":false},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npal = sns.color_palette()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nprint('# File sizes')\nfor f in os.listdir('../input'):\n    if not os.path.isdir('../input/' + f):\n        print(f.ljust(30) + str(round(os.path.getsize('../input/' + f) / 1000000, 2)) + 'MB')\n    else:\n        sizes = [os.path.getsize('../input/'+f+'/'+x)/1000000 for x in os.listdir('../input/' + f)]\n        print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + ' ({} files)'.format(len(sizes)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c23e9d2f-281d-633d-c392-1dd3375d716c","_active":false},"source":"Wow, so Kaggle Kernels has the full data! (Thanks Kaggle Team! :))\n\nLooks like we have 40k images for training, and 40k images for testing.\nThe jpegs are on average **15KB**, and the tifs are on average **538KB**. The JPEGs seem a little on the small side, but TIFFs look like they will retain most of the quality.\n\nBefore we open up the images, let's take a look at the `train.csv`.\n## Training Data","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"366130cd-aa02-8aaf-0d9c-6da2dc102601","_active":false},"outputs":[],"source":"df_train = pd.read_csv('../input/train.csv')\ndf_train.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"68e37d62-8f30-90e7-74c9-a1cae0a816b4","_active":false},"source":"Okay, so our training metadata is super basic. It looks like we are just given names and the corresponding tags. Let's parse them and do some analysis","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4b7cea33-53a9-4b83-55c5-bba735bb57a9","_active":false},"outputs":[],"source":"labels = df_train['tags'].apply(lambda x: x.split(' '))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c80513f7-17ec-5c39-82ef-a4099e0ddff6","_active":false},"source":"So it looks like we are not given much metadata, only the filenames and the corresponding tags. Let's parse these tags so that we can analyze them further.","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74ebfc4d-dd4e-e655-717b-b6637c0d57c6","_active":false},"outputs":[],"source":"labels = df_train['tags'].apply(lambda x: x.split(' '))\nfrom collections import Counter, defaultdict\ncounts = defaultdict(int)\nfor l in labels:\n    for l2 in l:\n        counts[l2] += 1\n\ndata=[go.Bar(x=list(counts.keys()), y=list(counts.values()))]\nlayout=dict(height=800, width=800, title='Distribution of training labels')\nfig=dict(data=data, layout=layout)\npy.iplot(data, filename='train-label-dist')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ccbe4f2e-b00c-8e8a-ace4-67fb2df95016","_active":false},"outputs":[],"source":"# Co-occurence Matrix\ncom = np.zeros([len(counts)]*2)\nfor i, l in enumerate(list(counts.keys())):\n    for i2, l2 in enumerate(list(counts.keys())):\n        c = 0\n        cy = 0\n        for row in labels.values:\n            if l in row:\n                c += 1\n                if l2 in row: cy += 1\n        com[i, i2] = cy / c\n\ndata=[go.Heatmap(z=com, x=list(counts.keys()), y=list(counts.keys()))]\nlayout=go.Layout(height=800, width=800, title='Co-occurence matrix of training labels')\nfig=dict(data=data, layout=layout)\npy.iplot(data, filename='train-com')"},{"cell_type":"markdown","metadata":{"_cell_guid":"fcb01864-76f0-65f7-6897-7b229b6c6413","_active":false},"source":"It's worth noting that this co-occurence matrix shows **what percentage of the X label also has the Y label** - I think this shows more information than the standard symmetrical matrix.\n\nWe can see that the label \"primary\" has the highest proportion of labels.","outputs":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"459143d7-618c-5c12-10a6-62b30a798a3b","_active":false},"source":"## Images\nNow, what you all came for. Let's load some of the images, and their corresponding labels.","outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7a52aa1f-a8c4-a3e1-7aee-0e6865f16c4b","_active":false},"outputs":[],"source":"import cv2\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\ni = 0\nfor f, l in df_train[:9].values:\n    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n    #ax[i // 4, i % 4].show()\n    i += 1\n    \nplt.show()"}]}