{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting the sales of items from different stores for a russian company\n## Tushar Pasricha - April 2020"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Plotting Libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# settings\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#  Fetching all the files in pandas dataframes\nshops = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\nsales = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\ntest = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")\nitem = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\nitem_catg = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Exploration**"},{"metadata":{},"cell_type":"markdown","source":"## **sales_train data** "},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('training data has {} columns and {} rows'.format(sales.shape[1],sales.shape[0]))\nprint('test data has {} columns and {} rows'.format(test.shape[1],test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#formatting the date column correctly\nimport datetime\nsales.date=sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"item_cnt_day column has negative values as well, I will be considering them as the items returned to the stores on that day"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking the items which are present in test set but not in training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_only = test[~test['item_id'].isin(sales['item_id'].unique())]['item_id'].unique()\nprint('test only items:', len(test_only))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping shops&items not in test data\nshops_in_test = test.shop_id.unique()\nitems_in_test = test.item_id.unique()\nsales = sales[sales.shop_id.isin(shops_in_test)]\nsales = sales[sales.item_id.isin(items_in_test)]\n\nprint('sales:', sales.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking for Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sales.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(sales.item_price.min(), sales.item_price.max()*1.1)\nsns.boxplot(x=sales.item_price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the first Boxplot \n    1. There are 2 outliers\n\nIn the second Boxplot\n    1. There is no outlier\n\n## Removing the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = sales[sales.item_cnt_day<1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nsns.boxplot(x=sales.item_cnt_day)\n\n\nplt.figure(figsize=(10,4))\nplt.xlim(sales.item_price.min(), sales.item_price.max()*1.1)\nsns.boxplot(x=sales.item_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking the number of items sold per month\nmonth_wise_items_sold = sales.groupby('date_block_num').agg({'item_cnt_day' : sum},inplace = True , reset_index = True)\nplt.figure(figsize=(18,5))\nplt.title('Items sold by the company')\nplt.xlabel('Time')\nplt.ylabel('Items sold')\nplt.plot(month_wise_items_sold);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As we can see there is a sudden peak after the 10th month and 22nd month, that probably signifies the increase in sales during holidays period around christmas in Russia"},{"metadata":{"trusted":true},"cell_type":"code","source":"calculating_revenue = sales\ncalculating_revenue['revenue'] = calculating_revenue['item_price'] * calculating_revenue['item_cnt_day']\ncalculating_revenue.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking the revenue generated by the company per month\nmonth_wise_revenue = calculating_revenue.groupby('date_block_num').agg({'revenue' : sum})\nplt.figure(figsize=(20,5))\nplt.title('revenue generated per month by the company')\nplt.xlabel('Time')\nplt.ylabel('Revenue generated')\nplt.plot(month_wise_revenue);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As we can see in the above graph the revenue generated is higher around 24th month in the series i.e December 2014 has the highest sales of all time"},{"metadata":{"trusted":true},"cell_type":"code","source":"shop_wise_revenue = calculating_revenue.groupby('shop_id').agg({'revenue' : sum})\nplt.figure(figsize=(20,5))\nplt.title('revenue generated by the individual shops')\nplt.xlabel('Shop id')\nplt.ylabel('Revenue generated')\nplt.plot(shop_wise_revenue);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shop id 31 has the highest revenue amongst all"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking number of returned items\nreturned_items = sales[sales['item_cnt_day'] < 0]\nmonth_wise_items_returned = returned_items.groupby('date_block_num').agg({'item_cnt_day' : sum})\nmonth_wise_items_returned['item_cnt_day'] = month_wise_items_returned['item_cnt_day'].abs()\nplt.figure(figsize=(20,5))\nplt.title('Items returned per month')\nplt.xlabel('Time')\nplt.ylabel('Items returned')\nplt.plot(month_wise_items_returned);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The maximum number of items were returned to the company in 24th month of the data provided i.e. December 2014"},{"metadata":{},"cell_type":"markdown","source":"# Exploring Time Series"},{"metadata":{"trusted":true},"cell_type":"code","source":"timeseries = month_wise_items_sold ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.plot(timeseries.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(timeseries.rolling(window=12,center=False).std(),label='Rolling sd');\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see in the above graph, there is an obvious \"seasonality\" (Eg: peak sales around a time of year) and a increasing \"Trend\".\n\nLet's check that with decomposition into Trend, seasonality and residuals."},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nprint('multiplicative model')\n# multiplicative\nmul_model = sm.tsa.seasonal_decompose(timeseries.values,freq=12,model=\"multiplicative\")\n\nfig = mul_model.plot()\n\n# ------------------------------------------------------------------------------------\nprint('Additive model') \n# Additive\nadd_model = sm.tsa.seasonal_decompose(timeseries.values,freq=12,model=\"additive\")\n\nfig = add_model.plot()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As we can see there is still some patterns left in the residual of additive model, we would assume the timeseries to be multiplicative that can be shown as yt=St x Tt x Et"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stationarity tests\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\n\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(timeseries)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As p value > 0.05 we take the series as seosanal time series\n\n## Decomposing time series data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To remove trend\nfrom pandas import Series as Series\n\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timeseries.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,16))\n\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\n\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now testing the stationarity again after de-seasonality\ntest_stationarity(new_ts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As p value is now less than 0.05, we can consider that the data is stationary"},{"metadata":{},"cell_type":"markdown","source":"# Time Series Forecasting\n### We  will apply prophet model for baseline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the dates to the Time-series as index\nts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nts=ts.reset_index()\nts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n\nts.columns=['ds','y']\n#instantiate Prophet with only yearly seasonality as our data is monthly \nmodel = Prophet( yearly_seasonality=True) \nmodel.fit(ts) #fit the model with your dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for five months in the furure and MS - month start is the frequency\nfuture = model.make_future_dataframe(periods = 5, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}