{"cells":[{"metadata":{"id":"KDvNYU7EsWgl"},"cell_type":"markdown","source":"## Credit Card Fraud Detection\n\nPredict fraudulent credit card transactions with the help of Machine learning models. \n\nImport the following libraries to get started."},{"metadata":{"id":"QsJfdrB2sWgn","outputId":"f03b49e4-3d53-4493-bb6b-5825a44932ac","scrolled":false,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import PowerTransformer\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"whwyM66qsWgx"},"cell_type":"markdown","source":"## Exploratory data analysis"},{"metadata":{"id":"Uc7O9H7QuckG","outputId":"d3036756-5f10-47a7-8635-d08ea5201c38","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/creditcardfraud/creditcard.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"w_wmJNbcsWg8","outputId":"6dda9d4d-1a31-4aeb-ff5c-58d2fc0eb6ff","trusted":true},"cell_type":"code","source":"#observe the different feature type present in the data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"kqik9l6LsWhC"},"cell_type":"markdown","source":"Here we will observe the distribution of our classes"},{"metadata":{"id":"YPlQ4ojlsWhD","outputId":"0e99a2ad-df92-421f-c138-283e5878d3b0","trusted":true},"cell_type":"code","source":"classes=df['Class'].value_counts()\nnormal_share=classes[0]/df['Class'].count()*100\nfraud_share=classes[1]/df['Class'].count()*100\n\nprint(\"normal_share=\",normal_share,\"            \",\"fraud_share=\",fraud_share)\n\nimbalance= (fraud_share/normal_share)*100\nprint('Imbalance Percentage = ' + str(imbalance))","execution_count":null,"outputs":[]},{"metadata":{"id":"-6KkNkZdsWhI","outputId":"3a4c3dbf-58a3-4816-ca4a-27eaf042beb5","trusted":true},"cell_type":"code","source":"# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\nfig, ax = plt.subplots(1, 2, figsize=(18,4))\n\nclasses.plot(kind='bar', rot=0, ax=ax[0])\nax[0].set_title('Number of Class Distributions \\n (0: No Fraud || 1: Fraud)')\n\n(classes/df['Class'].count()*100).plot(kind='bar', rot=0, ax=ax[1])\nax[1].set_title('Percentage of Distributions \\n (0: No Fraud || 1: Fraud)')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Gw8fxIXDsWhQ","outputId":"dc41e601-1475-4980-c23a-950fd5041656","trusted":true},"cell_type":"code","source":"# Create a scatter plot to observe the distribution of classes with time\ndf.plot.scatter(y='Class', x='Time',figsize=(18,4))","execution_count":null,"outputs":[]},{"metadata":{"id":"dIZ6VqptsWhc","outputId":"6960bc19-60bc-49d9-c9a7-1ebe4f85bd0e","trusted":true},"cell_type":"code","source":"# Create a scatter plot to observe the distribution of classes with Amount\ndf.plot.scatter(y='Class', x='Amount',figsize=(18,4))","execution_count":null,"outputs":[]},{"metadata":{"id":"yvfSTuqdLrFQ"},"cell_type":"markdown","source":"'Time' variable is uniformly distributed and thus doesn't provide any variation for classification. This can be dropped."},{"metadata":{"id":"wWrL8xxZsWhh","outputId":"6a391be6-51ff-4126-ae49-c44f67334ae6","scrolled":true,"trusted":true},"cell_type":"code","source":"# Drop unnecessary columns\ndf = df.drop(['Time'],axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"fL42Z_fysWhl"},"cell_type":"markdown","source":"### Splitting the data into train & test data\n"},{"metadata":{"id":"Jswdt_wKsWhm","trusted":true},"cell_type":"code","source":"y= df['Class']\nX= df.loc[:, df.columns != 'Class']","execution_count":null,"outputs":[]},{"metadata":{"id":"bMjVtA_VsWhq","trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X,y, train_size = 0.7, test_size = 0.3, random_state = 42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"id":"soruZIrZsWhv"},"cell_type":"markdown","source":"##### Preserve X_test & y_test to evaluate on the test data once you build the model"},{"metadata":{"id":"UJydw89lsWhw","outputId":"50e5c147-d30b-42d0-fe74-5634e571e66e","trusted":true},"cell_type":"code","source":"print(np.sum(y))\nprint(np.sum(y_train))\nprint(np.sum(y_test))","execution_count":null,"outputs":[]},{"metadata":{"id":"vS5GjkrEsWh4"},"cell_type":"markdown","source":"### Plotting the distribution of variables"},{"metadata":{"id":"q4aUi_vXsWh5","outputId":"13b1722e-f0f6-4c2a-a479-ef4e7b95a5b3","trusted":true},"cell_type":"code","source":"# plot the histogram of a variable from the dataset to see the skewness\n\nk=0\nfig, ax = plt.subplots(7, 4, figsize=(20,20))\nfor i in range(7):\n    for j in range(4):\n        k=k+1\n        sns.distplot(X_train['V'+str(k)], ax=ax[i][j])\n        ax[i][j].set_title('V'+str(k))\n       ","execution_count":null,"outputs":[]},{"metadata":{"id":"1qHFxApysWh-"},"cell_type":"markdown","source":"### There is skewness present in the distribution use:\n- <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian"},{"metadata":{"id":"wwE3Wq02sWh_","trusted":true},"cell_type":"code","source":"# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data\npt= preprocessing.PowerTransformer(method='yeo-johnson', copy=True)\npt.fit(X_train)                       \n\nX_train_pt = pt.transform(X_train)\nX_test_pt = pt.transform(X_test)\n\ny_train_pt = y_train\ny_test_pt = y_test","execution_count":null,"outputs":[]},{"metadata":{"id":"LtKPOs9xFZAP","outputId":"bd5c40ac-7760-4c8a-c01e-e5bead9e02bf","trusted":true},"cell_type":"code","source":"print(X_train_pt.shape)\nprint(y_train_pt.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZUQb-qecsWiD","outputId":"7d215752-fe3e-4235-b272-5ea3f16df033","scrolled":false,"trusted":true},"cell_type":"code","source":"# plot the histogram of a variable from the dataset again to see the result \nX_train_pt_df = pd.DataFrame(X_train_pt,columns=X_train.columns)\nk=0\nfig, ax = plt.subplots(7, 4, figsize=(20,20))\nfor i in range(7):\n    for j in range(4):\n        k=k+1\n        sns.distplot(X_train_pt_df['V'+str(k)], ax=ax[i][j])\n        ax[i][j].set_title('V'+str(k))","execution_count":null,"outputs":[]},{"metadata":{"id":"1nJyvs_KsWio"},"cell_type":"markdown","source":"## Model building\n\n* Build XGBOOST\n* Perform class balancing with SMOTE\n* Perform Hyperparameter tuning using Cross Validation\n* Evaluate using ROC-AUC score on test set"},{"metadata":{"id":"SCLOWO88sWiq","trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom imblearn import over_sampling\n","execution_count":null,"outputs":[]},{"metadata":{"id":"QPSSo33qsWjB","outputId":"b81cf98e-b886-44ee-a8dd-f061335a41ad","trusted":true},"cell_type":"code","source":"# perfom cross validation on the X_train & y_train \nskf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n\nprint(\"XGBOOST Classifier: --------------------------\")\ncv_score_mean=0\nfor n_estimators in [100,50]:\n    for learning_rate in [0.2,0.6]:\n        for subsample in [0.3, 0.6, 0.9]:\n            print(\"n_estimators=\",n_estimators,\"learning_rate=\",learning_rate, \"subsample=\",subsample)\n            for train_index, test_index in skf.split(X_train_pt, y_train_pt):\n                print(\"Train:\", train_index, \"Test:\", test_index)\n                X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]\n                y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]\n\n                ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)\n                X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)\n\n                xgboost_classifier= XGBClassifier(n_estimators=n_estimators,\n                                                learning_rate=learning_rate,\n                                                subsample=subsample, n_jobs=-1)\n                xgboost_classifier.fit(X_ros_cv,y_ros_cv)\n\n                y_test_pred= xgboost_classifier.predict_proba(X_test_cv)\n                cv_score= metrics.roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])\n                cv_score_mean=cv_score_mean+cv_score\n            print(\"Cross Val ROC-AUC Score=\", cv_score_mean/3)\n  ","execution_count":null,"outputs":[]},{"metadata":{"id":"fbGX8J-ZM5ue"},"cell_type":"markdown","source":"### Use the best model to Predict on the test dataset"},{"metadata":{"id":"ytVvSnp1UYvB","outputId":"445e7202-d689-404b-b0a1-5162f4db719b","trusted":true},"cell_type":"code","source":"clf = XGBClassifier(n_estimators=100,learning_rate=0.2,subsample=0.3, n_jobs=-1) \nros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)\nX_ros,y_ros = ros.fit_resample(X_train,y_train) \nclf.fit(X_ros.values,y_ros)\ny_pred= clf.predict_proba(X_test.values)\nscore= metrics.roc_auc_score(y_true=y_test,y_score=y_pred[:,1])\nprint(\"XGBOOST Classifier Test ROC-AUC Score =\", score)","execution_count":null,"outputs":[]},{"metadata":{"id":"1fnW8bNtsWjY"},"cell_type":"markdown","source":"### Print the important features of the best model to understand the dataset"},{"metadata":{"id":"pgpckCT2sWjY","outputId":"74c0f084-1edb-4ad7-9ea8-0900b9088371","trusted":true},"cell_type":"code","source":"var_imp = []\n\nfor i in clf.feature_importances_:\n    var_imp.append(i)\nprint('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\nprint('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\nprint('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n\n# Variable on Index-13 and Index-9 seems to be the top 2 variables\ntop_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\nsecond_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n\nX_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\nX_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n\nnp.random.shuffle(X_train_0)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.figsize'] = [20, 20]\n\nplt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\nplt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n            label='Actual Class-0 Examples')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"id":"X4OK19JSgI1u"},"cell_type":"markdown","source":"### Print the best threshold from the roc curve"},{"metadata":{"id":"lTUeodXGsWji","outputId":"ab458323-8b44-4d82-dd4e-485eb074107d","trusted":true},"cell_type":"code","source":"print('Train auc =', metrics.roc_auc_score(y_test, y_pred[:,1]))\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred[:,1])\nthreshold = thresholds[np.argmax(tpr-fpr)]\nprint(threshold)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Difierent \"Thresholds\" can be used to calculate Precision and Recall. Then a decision can be made to choose a threshold for higher Precision or higher Recall.\n \n* Is it more important for a predicted fraud to actually be a fraud (higher Precision)?\n* Or prediction potential fraud is more important sych that none escapes (higher Recall)?"}],"metadata":{"colab":{"collapsed_sections":["whwyM66qsWgx","vS5GjkrEsWh4","1qHFxApysWh-","7NXqU07wsWiG","_-MuEma9sWip","UXN2APqpsWi7","MdUYFo-_sWjF","1fnW8bNtsWjY"],"name":"Credit_card_fraud_detection_RR.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}