{"cells":[{"metadata":{"_cell_guid":"a9798604-b0ed-4ea9-b894-52b8fad97b7b","_uuid":"ff2644fd-b910-43e5-9a2f-959c0adeb15a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nimport re\nfrom string import punctuation\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nimport keras\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom keras.utils import plot_model\nimport keras.backend as K\nimport tensorflow as tf\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1fbf87f8-5122-4daf-bc70-3e8d31bb5856","_uuid":"fb699687-2bf2-471a-845e-d498aeee7eac","trusted":true},"cell_type":"code","source":"env = nflrush.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4f97b8fd-2dac-4fe0-aa0b-8c1d1cc7d66f","_uuid":"72f9ce60-48f7-4666-80a4-c343e94bcc5a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"89c007b1-c569-4323-b5c9-e7e5b3357fa5","_uuid":"b1676ce2-3fa9-4417-bdcc-c44fa6ecbde1"},"cell_type":"markdown","source":"# Overall analysis"},{"metadata":{"_cell_guid":"f352f6e7-a676-424f-99a6-667d329b75cc","_uuid":"77f26cc6-4a5a-42ef-9871-8fe4d2b204af","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from https://www.kaggle.com/prashantkikani/nfl-starter-lgb-feature-engg\ntrain['DefendersInTheBox_vs_Distance'] = train['DefendersInTheBox'] / train['Distance']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bbf962b7-28fe-4b1d-8ce7-af815b5ffe9d","_uuid":"9dd3edf6-c372-4e94-a018-b9fdbc13996a"},"cell_type":"markdown","source":"# Categorical features"},{"metadata":{"_cell_guid":"2996d6a4-18fc-4ce8-a2d0-a0a58b2b2391","_uuid":"a4f3359c-ab23-413e-b87a-5e9bfa406be6","trusted":true},"cell_type":"code","source":"cat_features = []\nfor col in train.columns:\n    if train[col].dtype =='object':\n        cat_features.append((col, len(train[col].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f07d9476-d360-4f37-9118-5954fb6b591d","_uuid":"1c43c14a-5a9c-4245-8510-285e435ae314"},"cell_type":"markdown","source":"Let's preprocess some of those features."},{"metadata":{},"cell_type":"markdown","source":"## Stadium Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['StadiumType'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We already can see some typos, let's fix them."},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_StadiumType(txt):\n    if pd.isna(txt):\n        return np.nan\n    txt = txt.lower()\n    txt = ''.join([c for c in txt if c not in punctuation])\n    txt = re.sub(' +', ' ', txt)\n    txt = txt.strip()\n    txt = txt.replace('outside', 'outdoor')\n    txt = txt.replace('outdor', 'outdoor')\n    txt = txt.replace('outddors', 'outdoor')\n    txt = txt.replace('outdoors', 'outdoor')\n    txt = txt.replace('oudoor', 'outdoor')\n    txt = txt.replace('indoors', 'indoor')\n    txt = txt.replace('ourdoor', 'outdoor')\n    txt = txt.replace('retractable', 'rtr.')\n    return txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['StadiumType'] = train['StadiumType'].apply(clean_StadiumType)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By pareto's principle we are just going to focus on the words: outdoor, indoor, closed and open."},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_StadiumType(txt):\n    if pd.isna(txt):\n        return np.nan\n    if 'outdoor' in txt or 'open' in txt:\n        return 1\n    if 'indoor' in txt or 'closed' in txt:\n        return 0\n    \n    return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['StadiumType'] = train['StadiumType'].apply(transform_StadiumType)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turf"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112681#latest-649087\nTurf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n        'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n        'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n        'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n        'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n\ntrain['Turf'] = train['Turf'].map(Turf)\ntrain['Turf'] = train['Turf'] == 'Natural'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Possession Team"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['PossessionTeam']!=train['HomeTeamAbbr']) & (train['PossessionTeam']!=train['VisitorTeamAbbr'])][['PossessionTeam', 'HomeTeamAbbr', 'VisitorTeamAbbr']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have some problem with the enconding of the teams such as BLT and BAL or ARZ and ARI.\n\nLet's try to fix them manually."},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(train['HomeTeamAbbr'].unique()) == sorted(train['VisitorTeamAbbr'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_abbr = []\nfor x,y  in zip(sorted(train['HomeTeamAbbr'].unique()), sorted(train['PossessionTeam'].unique())):\n    if x!=y:\n        print(x + \" \" + y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently these are the only three problems, let's fix it."},{"metadata":{"trusted":true},"cell_type":"code","source":"map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\nfor abb in train['PossessionTeam'].unique():\n    map_abbr[abb] = abb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['PossessionTeam'] = train['PossessionTeam'].map(map_abbr)\ntrain['HomeTeamAbbr'] = train['HomeTeamAbbr'].map(map_abbr)\ntrain['VisitorTeamAbbr'] = train['VisitorTeamAbbr'].map(map_abbr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['HomePossesion'] = train['PossessionTeam'] == train['HomeTeamAbbr']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Field_eq_Possession'] = train['FieldPosition'] == train['PossessionTeam']\ntrain['HomeField'] = train['FieldPosition'] == train['HomeTeamAbbr']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Offense formation"},{"metadata":{"trusted":true},"cell_type":"code","source":"off_form = train['OffenseFormation'].unique()\ntrain['OffenseFormation'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since I don't have any knowledge about formations, I am just goig to one-hot encode this feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([train.drop(['OffenseFormation'], axis=1), pd.get_dummies(train['OffenseFormation'], prefix='Formation')], axis=1)\ndummy_col = train.columns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d7f81adc-1a29-492d-ba29-b64c98485431","_uuid":"bb13b517-32ff-4cdd-93f3-31b3b79dbbc5"},"cell_type":"markdown","source":"## Game Clock"},{"metadata":{"_cell_guid":"b19b1526-cf9f-49f6-b462-b0a771b9209a","_uuid":"8e4d32ec-3096-4d7c-8be4-2bb93e2d7a3b"},"cell_type":"markdown","source":"Game clock is supposed to be a numerical feature."},{"metadata":{"_cell_guid":"416aa3ed-50f2-422c-9b0d-07e9b83460d7","_uuid":"3009010a-053c-46a6-b442-d20b20b20eb3","trusted":true},"cell_type":"code","source":"train['GameClock'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e5250758-ca1a-4e4b-927e-9e9de65fbe0d","_uuid":"5cb3fab2-337c-4edd-a540-2dc5574785d4"},"cell_type":"markdown","source":"Since we already have the quarter feature, we can just divide the Game Clock by 15 minutes so we can get the normalized time left in the quarter."},{"metadata":{"_cell_guid":"1d691a4f-b74c-49fa-b269-e129b0a95173","_uuid":"d67573bc-dc38-42fc-9f30-a5e397206e0f","trusted":true},"cell_type":"code","source":"def strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"af428630-c6ff-4e4f-a293-c18a11738d15","_uuid":"a8cdc425-6d86-4be2-8d73-d368d94b8231","trusted":true},"cell_type":"code","source":"train['GameClock'] = train['GameClock'].apply(strtoseconds)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"99fb1a0a-6688-4eb1-8754-f82454775876","_uuid":"363e6275-6ad9-4c89-af4c-2c435a7d5d1c","trusted":true},"cell_type":"code","source":"sns.distplot(train['GameClock'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f58a2052-0669-449f-8e82-4c1be7ef9e8a","_uuid":"0cc3cefd-a51c-482e-b921-c15940d4cbc3"},"cell_type":"markdown","source":"## Player height"},{"metadata":{"_cell_guid":"fd1c0d2e-e465-46fe-84e5-7943cff06e4a","_uuid":"32568e2c-dd0f-44e2-a516-5a8a9fc82cd9","trusted":true},"cell_type":"code","source":"train['PlayerHeight']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"86749dbf-0889-4167-9b5a-640601da94b8","_uuid":"98e1a5b4-5329-4966-aae4-ab203617b352"},"cell_type":"markdown","source":"We know that 1ft=12in, thus:"},{"metadata":{"_cell_guid":"0f0f6f7c-fb7b-49df-aa9d-32108abeb911","_uuid":"00e6126d-2c75-4b0d-9a39-ffa00799cd48","trusted":true},"cell_type":"code","source":"train['PlayerHeight'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['PlayerBMI'] = 703*(train['PlayerWeight']/(train['PlayerHeight'])**2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ca1fd3b8-911c-4c95-9a75-a29336960281","_uuid":"4731392d-85b3-4f06-ad10-d2e855259404"},"cell_type":"markdown","source":"## Time handoff and snap and Player BirthDate"},{"metadata":{"_cell_guid":"6303a87a-570f-40c5-a368-5727515d085f","_uuid":"1ee8517c-ad58-4dd0-94a5-13a9d3657393","trusted":true},"cell_type":"code","source":"train['TimeHandoff']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4925fa7-aa2d-45dc-9c67-73e7465852c9","_uuid":"3f9ded81-1d2a-4c36-84dd-efcb60f184bc","trusted":true},"cell_type":"code","source":"train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\ntrain['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0abdaa4-da54-463b-8d14-9791f7e58c21","_uuid":"3ac57217-a252-42ec-b067-cefa2b5fd72b","trusted":true},"cell_type":"code","source":"train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"74726374-d122-472d-ab55-3bdec8169a3c","_uuid":"1469462e-2416-4b55-a62f-0b7f4016d633","trusted":true},"cell_type":"code","source":"train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d35c0fc1-af5b-4cfa-bf94-cfb0b455605b","_uuid":"8f6c0a58-2fd9-4da4-a775-935d30f01870"},"cell_type":"markdown","source":"Let's use the time handoff to calculate the players age"},{"metadata":{"_cell_guid":"df4b2c6a-3b1d-4434-acea-b7b5281e162c","_uuid":"81518246-4fd1-4a17-aa5f-4b6fe58de355","trusted":true},"cell_type":"code","source":"seconds_in_year = 60*60*24*365.25\ntrain['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4b49a9d6-7ebb-4b9d-8574-7e547c3db476","_uuid":"901347f8-8e6b-43a2-aa0e-545df16da154","trusted":true},"cell_type":"code","source":"train = train.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a53e8cdd-fe2b-45de-89f8-0c443d7bc99d","_uuid":"9e964c7d-fabd-49f2-afe9-1629d9753a86"},"cell_type":"markdown","source":"## Wind Speed and Direction"},{"metadata":{"_cell_guid":"6a6cb596-038c-4d87-85af-bfbf1fcfe490","_uuid":"027714f6-7b58-4476-b825-c5fc0c7490cc","trusted":true},"cell_type":"code","source":"train['WindSpeed'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e84b4ef8-137b-43e1-b8d1-59af7df321c4","_uuid":"c9011df9-0fad-43e0-b6ae-d424eebac52b"},"cell_type":"markdown","source":"We can see there are some values that are not standardized(e.g. 12mph), we are going to remove mph from all our values."},{"metadata":{"_cell_guid":"c15a9234-d9bc-42c2-96f1-8cfdc4ff330e","_uuid":"2176aa4b-3acc-4487-bb42-e0f0f1f9d73f","trusted":true},"cell_type":"code","source":"train['WindSpeed'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b837d9a5-d033-4701-ba15-f57acbce9af0","_uuid":"ab6dcae3-76ca-4e05-8b52-43213d566f1a","trusted":true},"cell_type":"code","source":"train['WindSpeed'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eca7f782-002a-40f6-9ed9-d63a91f4f5f6","_uuid":"5f3aade2-e103-4d79-aaaf-3491a08dc3e7","trusted":true},"cell_type":"code","source":"#let's replace the ones that has x-y by (x+y)/2\n# and also the ones with x gusts up to y\ntrain['WindSpeed'] = train['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\ntrain['WindSpeed'] = train['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2599fa48-430f-4fe8-a4f2-22db4439c87a","_uuid":"0a40d464-1af1-4413-b967-cb600c39c289","trusted":true},"cell_type":"code","source":"def str_to_float(txt):\n    try:\n        return float(txt)\n    except:\n        return -1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98329992-3f20-439c-b7da-4e5edde2c7f3","_uuid":"765da928-abe6-4c84-b998-f09531cf4f1e","trusted":true},"cell_type":"code","source":"train['WindSpeed'] = train['WindSpeed'].apply(str_to_float)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"10ef0c46-fa71-4131-ae52-3dc8402e4208","_uuid":"41c59356-856f-43c8-9b47-fe469c256eb5","scrolled":true,"trusted":true},"cell_type":"code","source":"train['WindDirection'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_WindDirection(txt):\n    if pd.isna(txt):\n        return np.nan\n    txt = txt.lower()\n    txt = ''.join([c for c in txt if c not in punctuation])\n    txt = txt.replace('from', '')\n    txt = txt.replace(' ', '')\n    txt = txt.replace('north', 'n')\n    txt = txt.replace('south', 's')\n    txt = txt.replace('west', 'w')\n    txt = txt.replace('east', 'e')\n    return txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['WindDirection'] = train['WindDirection'].apply(clean_WindDirection)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['WindDirection'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_WindDirection(txt):\n    if pd.isna(txt):\n        return np.nan\n    \n    if txt=='n':\n        return 0\n    if txt=='nne' or txt=='nen':\n        return 1/8\n    if txt=='ne':\n        return 2/8\n    if txt=='ene' or txt=='nee':\n        return 3/8\n    if txt=='e':\n        return 4/8\n    if txt=='ese' or txt=='see':\n        return 5/8\n    if txt=='se':\n        return 6/8\n    if txt=='ses' or txt=='sse':\n        return 7/8\n    if txt=='s':\n        return 8/8\n    if txt=='ssw' or txt=='sws':\n        return 9/8\n    if txt=='sw':\n        return 10/8\n    if txt=='sww' or txt=='wsw':\n        return 11/8\n    if txt=='w':\n        return 12/8\n    if txt=='wnw' or txt=='nww':\n        return 13/8\n    if txt=='nw':\n        return 14/8\n    if txt=='nwn' or txt=='nnw':\n        return 15/8\n    return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['WindDirection'] = train['WindDirection'].apply(transform_WindDirection)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5bcc44c6-9495-4d62-8551-dd88ce4f4de2","_uuid":"4dfb519d-24fa-4bf7-a9c7-a59b285caa4a"},"cell_type":"markdown","source":"## PlayDirection"},{"metadata":{"_cell_guid":"97451668-f804-4c81-b8b9-15f2be5614c2","_uuid":"5b93e997-86ec-4227-8437-b8889d6e78ed","trusted":true},"cell_type":"code","source":"train['PlayDirection'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b04eae61-9135-4fbf-a331-f39c7df71656","_uuid":"6f987647-ccf7-4cb3-b8a0-2701e4488052","trusted":true},"cell_type":"code","source":"train['PlayDirection'] = train['PlayDirection'].apply(lambda x: x.strip() == 'right')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e23f8f1c-5a59-4354-afd9-1852aabb148a","_uuid":"2c0a1fd0-4e2c-4bf0-8c9b-95bc6e20c1d7"},"cell_type":"markdown","source":"## Team"},{"metadata":{"_cell_guid":"29f59ee0-aa87-4552-812f-488eac6647ef","_uuid":"753a80be-f9f4-4b3e-9aff-6c0226302583","trusted":true},"cell_type":"code","source":"train['Team'] = train['Team'].apply(lambda x: x.strip()=='home')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9fd464a2-9e74-4682-a2a7-10481313f476","_uuid":"c5dc1be2-77b4-4c09-8bb5-ea1052603e10"},"cell_type":"markdown","source":"## Game Weather"},{"metadata":{"_cell_guid":"77190f8e-9f1d-43df-99b0-bebd20936106","_uuid":"19cb48f4-e188-4eff-8b44-5f3651e3a301","trusted":true},"cell_type":"code","source":"train['GameWeather'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"75ba864e-c328-4929-8090-4310ec34397f","_uuid":"c2eb5e45-9f3d-45ec-9312-136db8918163"},"cell_type":"markdown","source":"We are going to apply the following preprocessing:\n \n- Lower case\n- N/A Indoor, N/A (Indoors) and Indoor => indoor Let's try to cluster those together.\n- coudy and clouidy => cloudy\n- party => partly\n- sunny and clear => clear and sunny\n- skies and mostly => \"\""},{"metadata":{"_cell_guid":"7ad94b8c-5414-48b4-a495-cb3a2ba13522","_uuid":"68de9ad0-dbb7-4cbc-b40d-7b81d55222e7","trusted":true},"cell_type":"code","source":"train['GameWeather'] = train['GameWeather'].str.lower()\nindoor = \"indoor\"\ntrain['GameWeather'] = train['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\ntrain['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\ntrain['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\ntrain['GameWeather'] = train['GameWeather'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"36bcdbfb-a2eb-4980-876f-efa5ffa14409","_uuid":"10cea94f-b2b5-4206-850d-07dbdc22abb0","trusted":true},"cell_type":"code","source":"train['GameWeather'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c78e1f1c-d73f-4a2e-989f-bb02c180ca0f","_uuid":"ed2134d8-fa03-4264-a801-00b7bc66ddef"},"cell_type":"markdown","source":"Let's now look at the most common words we have in the weather description"},{"metadata":{"_cell_guid":"61ddf642-4584-4147-931c-13ae480cee0d","_uuid":"2ac09166-d193-4758-8b39-4ea87f971b89","trusted":true},"cell_type":"code","source":"from collections import Counter\nweather_count = Counter()\nfor weather in train['GameWeather']:\n    if pd.isna(weather):\n        continue\n    for word in weather.split():\n        weather_count[word]+=1\n        \nweather_count.most_common()[:15]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2cc3150c-51c5-4668-b221-a13d6a041cd1","_uuid":"bbcb19d3-3003-433e-b7d1-fc444cd7c431"},"cell_type":"markdown","source":"To encode our weather we are going to do the following map:\n \n- climate controlled or indoor => 3, sunny or sun => 2, clear => 1, cloudy => -1, rain => -2, snow => -3, others => 0\n- partly => multiply by 0.5\n\nI don't have any expercience with american football so I don't know if playing in a climate controlled or indoor stadium is good or not, if someone has a good idea on how to encode this it would be nice to leave it in the comments :)"},{"metadata":{"_cell_guid":"8756e015-060c-45f2-a6c8-4a81ac9de59f","_uuid":"15d456c6-3600-4468-9893-e1482238a813","trusted":true},"cell_type":"code","source":"def map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ff5f7d03-205e-4935-b22b-962382004e5b","_uuid":"f26ae854-d725-4242-a753-209e7664f032","trusted":true},"cell_type":"code","source":"train['GameWeather'] = train['GameWeather'].apply(map_weather)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8692b4e2-3846-43a1-b4a4-8c4333cc2ea1","_uuid":"b8a66d46-4635-4a89-a2c6-ec65e1bddfb2"},"cell_type":"markdown","source":"## NflId NflIdRusher"},{"metadata":{"_cell_guid":"6276a197-f31c-4bf5-8663-397fc89b51b0","_uuid":"df832e5b-3d72-4763-9d3d-051ab24f8cd5","trusted":true},"cell_type":"code","source":"train['IsRusher'] = train['NflId'] == train['NflIdRusher']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"99320871-af57-4927-b38f-4df49e163082","_uuid":"3de6f253-7a26-4364-8ee1-b2585278bc64","trusted":true},"cell_type":"code","source":"train.drop(['NflId', 'NflIdRusher'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PlayDirection problems"},{"metadata":{},"cell_type":"markdown","source":"As we can see, we have a problem if some features such as X and Y because of the play direction, let's fix those issues"},{"metadata":{},"cell_type":"markdown","source":"### X, orientation and direction"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['X'] = train.apply(lambda row: row['X'] if row['PlayDirection'] else 120-row['X'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from https://www.kaggle.com/scirpus/hybrid-gp-and-nn\ndef new_orientation(angle, play_direction):\n    if play_direction == 0:\n        new_angle = 360.0 - angle\n        if new_angle == 360.0:\n            new_angle = 0.0\n        return new_angle\n    else:\n        return angle\n    \ntrain['Orientation'] = train.apply(lambda row: new_orientation(row['Orientation'], row['PlayDirection']), axis=1)\ntrain['Dir'] = train.apply(lambda row: new_orientation(row['Dir'], row['PlayDirection']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## YardsLeft\n\nLet's compute how many yards are left to the end-zone."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['YardsLeft'] = train.apply(lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\ntrain['YardsLeft'] = train.apply(lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"((train['YardsLeft']<train['Yards']) | (train['YardsLeft']-100>train['Yards'])).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly:\nYards<=YardsLeft and YardsLeft-100<=Yards, thus we are going to drop those wrong lines."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(train.index[(train['YardsLeft']<train['Yards']) | (train['YardsLeft']-100>train['Yards'])], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"280b0090-ad48-4c21-91fb-4f762159b74e","_uuid":"14db5230-0ae7-448c-b595-b9683230fe91"},"cell_type":"markdown","source":"# Baseline model"},{"metadata":{"_cell_guid":"277c1578-7565-4c59-bca9-c7830f203a09","_uuid":"e075f454-f0e4-4913-bc36-b8f1425f3a58"},"cell_type":"markdown","source":"Let's drop the categorical features and run a simple random forest in our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sort_values(by=['PlayId', 'Team', 'IsRusher', 'JerseyNumber']).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['GameId', 'PlayId', 'index', 'IsRusher', 'Team'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"27659cfa-4c5a-42a5-93bf-2ccefd5aff09","_uuid":"d93d3612-a452-46d0-a796-ed8813158517","trusted":true},"cell_type":"code","source":"cat_features = []\nfor col in train.columns:\n    if train[col].dtype =='object':\n        cat_features.append(col)\n        \ntrain = train.drop(cat_features, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94a6f68f-b249-41cb-92c0-0b9ffd2fe60b","_uuid":"742c41b8-26fa-4f36-b8a1-9dd7d2b53d52"},"cell_type":"markdown","source":"We are now going to make one big row for each play where the rusher is the last one"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna(-999, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"players_col = []\nfor col in train.columns:\n    if train[col][:22].std()!=0:\n        players_col.append(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(train[players_col]).reshape(-1, len(players_col)*22)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"play_col = train.drop(players_col+['Yards'], axis=1).columns\nX_play_col = np.zeros(shape=(X_train.shape[0], len(play_col)))\nfor i, col in enumerate(play_col):\n    X_play_col[:, i] = train[col][::22]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate([X_train, X_play_col], axis=1)\ny_train = np.zeros(shape=(X_train.shape[0], 199))\nfor i,yard in enumerate(train['Yards'][::22]):\n    y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RAdam(keras.optimizers.Optimizer):\n    \"\"\"RAdam optimizer.\n    # Arguments\n        learning_rate: float >= 0. Learning rate.\n        beta_1: float, 0 < beta < 1. Generally close to 1.\n        beta_2: float, 0 < beta < 1. Generally close to 1.\n        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n        decay: float >= 0. Learning rate decay over each update.\n        weight_decay: float >= 0. Weight decay for each param.\n        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n            algorithm from the paper \"On the Convergence of Adam and\n            Beyond\".\n        total_steps: int >= 0. Total number of training steps. Enable warmup by setting a positive value.\n        warmup_proportion: 0 < warmup_proportion < 1. The proportion of increasing steps.\n        min_lr: float >= 0. Minimum learning rate after warmup.\n    # References\n        - [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n        - [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf)\n    \"\"\"\n\n    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n                 epsilon=None, decay=0., weight_decay=0., amsgrad=False,\n                 total_steps=0, warmup_proportion=0.1, min_lr=0., **kwargs):\n        learning_rate = kwargs.pop('lr', learning_rate)\n        super(RAdam, self).__init__(**kwargs)\n        with K.name_scope(self.__class__.__name__):\n            self.iterations = K.variable(0, dtype='int64', name='iterations')\n            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n            self.beta_1 = K.variable(beta_1, name='beta_1')\n            self.beta_2 = K.variable(beta_2, name='beta_2')\n            self.decay = K.variable(decay, name='decay')\n            self.weight_decay = K.variable(weight_decay, name='weight_decay')\n            self.total_steps = K.variable(total_steps, name='total_steps')\n            self.warmup_proportion = K.variable(warmup_proportion, name='warmup_proportion')\n            self.min_lr = K.variable(min_lr, name='min_lr')\n        if epsilon is None:\n            epsilon = K.epsilon()\n        self.epsilon = epsilon\n        self.initial_decay = decay\n        self.initial_weight_decay = weight_decay\n        self.initial_total_steps = total_steps\n        self.amsgrad = amsgrad\n\n    def get_updates(self, loss, params):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n\n        if self.initial_decay > 0:\n            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations, K.dtype(self.decay))))\n\n        t = K.cast(self.iterations, K.floatx()) + 1\n\n        if self.initial_total_steps > 0:\n            warmup_steps = self.total_steps * self.warmup_proportion\n            decay_steps = K.maximum(self.total_steps - warmup_steps, 1)\n            decay_rate = (self.min_lr - lr) / decay_steps\n            lr = K.switch(\n                t <= warmup_steps,\n                lr * (t / warmup_steps),\n                lr + decay_rate * K.minimum(t - warmup_steps, decay_steps),\n            )\n\n        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='m_' + str(i)) for (i, p) in enumerate(params)]\n        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='v_' + str(i)) for (i, p) in enumerate(params)]\n\n        if self.amsgrad:\n            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p), name='vhat_' + str(i)) for (i, p) in enumerate(params)]\n        else:\n            vhats = [K.zeros(1, name='vhat_' + str(i)) for i in range(len(params))]\n\n        self.weights = [self.iterations] + ms + vs + vhats\n\n        beta_1_t = K.pow(self.beta_1, t)\n        beta_2_t = K.pow(self.beta_2, t)\n\n        sma_inf = 2.0 / (1.0 - self.beta_2) - 1.0\n        sma_t = sma_inf - 2.0 * t * beta_2_t / (1.0 - beta_2_t)\n\n        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n\n            m_corr_t = m_t / (1.0 - beta_1_t)\n            if self.amsgrad:\n                vhat_t = K.maximum(vhat, v_t)\n                v_corr_t = K.sqrt(vhat_t / (1.0 - beta_2_t))\n                self.updates.append(K.update(vhat, vhat_t))\n            else:\n                v_corr_t = K.sqrt(v_t / (1.0 - beta_2_t))\n\n            r_t = K.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n                         (sma_t - 2.0) / (sma_inf - 2.0) *\n                         sma_inf / sma_t)\n\n            p_t = K.switch(sma_t >= 5, r_t * m_corr_t / (v_corr_t + self.epsilon), m_corr_t)\n\n            if self.initial_weight_decay > 0:\n                p_t += self.weight_decay * p\n\n            p_t = p - lr * p_t\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n            new_p = p_t\n\n            # Apply constraints.\n            if getattr(p, 'constraint', None) is not None:\n                new_p = p.constraint(new_p)\n\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    @property\n    def lr(self):\n        return self.learning_rate\n\n    @lr.setter\n    def lr(self, learning_rate):\n        self.learning_rate = learning_rate\n\n    def get_config(self):\n        config = {\n            'learning_rate': float(K.get_value(self.learning_rate)),\n            'beta_1': float(K.get_value(self.beta_1)),\n            'beta_2': float(K.get_value(self.beta_2)),\n            'decay': float(K.get_value(self.decay)),\n            'weight_decay': float(K.get_value(self.weight_decay)),\n            'epsilon': self.epsilon,\n            'amsgrad': self.amsgrad,\n            'total_steps': float(K.get_value(self.total_steps)),\n            'warmup_proportion': float(K.get_value(self.warmup_proportion)),\n            'min_lr': float(K.get_value(self.min_lr)),\n        }\n        base_config = super(RAdam, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from https://www.kaggle.com/davidcairuz/nfl-neural-network-w-softmax\ndef crps(y_true, y_pred):\n    return K.mean(K.square(y_true - K.cumsum(y_pred, axis=1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    x = keras.layers.Input(shape=[X_train.shape[1]])\n    fc1 = keras.layers.Dense(units=450, input_shape=[X_train.shape[1]])(x)\n    act1 = keras.layers.PReLU()(fc1)\n    bn1 = keras.layers.BatchNormalization()(act1)\n    dp1 = keras.layers.Dropout(0.55)(bn1)\n    gn1 = keras.layers.GaussianNoise(0.15)(dp1)\n    concat1 = keras.layers.Concatenate()([x, gn1])\n    fc2 = keras.layers.Dense(units=600)(concat1)\n    act2 = keras.layers.PReLU()(fc2)\n    bn2 = keras.layers.BatchNormalization()(act2)\n    dp2 = keras.layers.Dropout(0.55)(bn2)\n    gn2 = keras.layers.GaussianNoise(0.15)(dp2)\n    concat2 = keras.layers.Concatenate()([concat1, gn2])\n    fc3 = keras.layers.Dense(units=400)(concat2)\n    act3 = keras.layers.PReLU()(fc3)\n    bn3 = keras.layers.BatchNormalization()(act3)\n    dp3 = keras.layers.Dropout(0.55)(bn3)\n    gn3 = keras.layers.GaussianNoise(0.15)(dp3)\n    concat3 = keras.layers.Concatenate([concat2, gn3])\n    output = keras.layers.Dense(units=199, activation='softmax')(concat2)\n    model = keras.models.Model(inputs=[x], outputs=[output])\n    return model\n\n\ndef train_model(X_train, y_train, X_val, y_val):\n    model = get_model()\n    model.compile(optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-7), loss=crps)\n    er = EarlyStopping(patience=20, min_delta=1e-4, restore_best_weights=True, monitor='val_loss')\n    model.fit(X_train, y_train, epochs=200, callbacks=[er], validation_data=[X_val, y_val], batch_size=batch_size)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RepeatedKFold\n\nrkf = RepeatedKFold(n_splits=5, n_repeats=5)\n\nmodels = []\n\nfor tr_idx, vl_idx in rkf.split(X_train, y_train):\n    \n    x_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n    x_vl, y_vl = X_train[vl_idx], y_train[vl_idx]\n    \n    model = train_model(x_tr, y_tr, x_vl, y_vl)\n    models.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pred(df, sample, env, models):\n    df['StadiumType'] = df['StadiumType'].apply(clean_StadiumType)\n    df['StadiumType'] = df['StadiumType'].apply(transform_StadiumType)\n    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n    df['OffenseFormation'] = df['OffenseFormation'].apply(lambda x: x if x in off_form else np.nan)\n    df = pd.concat([df.drop(['OffenseFormation'], axis=1), pd.get_dummies(df['OffenseFormation'], prefix='Formation')], axis=1)\n    missing_cols = set( dummy_col ) - set( df.columns )-set('Yards')\n    for c in missing_cols:\n        df[c] = 0\n    df = df[dummy_col]\n    df.drop(['Yards'], axis=1, inplace=True)\n    df['Turf'] = df['Turf'].map(Turf)\n    df['Turf'] = df['Turf'] == 'Natural'\n    df['PossessionTeam'] = df['PossessionTeam'].map(map_abbr)\n    df['HomeTeamAbbr'] = df['HomeTeamAbbr'].map(map_abbr)\n    df['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].map(map_abbr)\n    df['HomePossesion'] = df['PossessionTeam'] == df['HomeTeamAbbr']\n    df['Field_eq_Possession'] = df['FieldPosition'] == df['PossessionTeam']\n    df['HomeField'] = df['FieldPosition'] == df['HomeTeamAbbr']\n    df['GameClock'] = df['GameClock'].apply(strtoseconds)\n    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n    df['PlayerBMI'] = 703*(df['PlayerWeight']/(df['PlayerHeight'])**2)\n    df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    df['PlayerBirthDate'] = df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n    seconds_in_year = 60*60*24*365.25\n    df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n    df['WindSpeed'] = df['WindSpeed'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    df['WindSpeed'] = df['WindSpeed'].apply(str_to_float)\n    df['WindDirection'] = df['WindDirection'].apply(clean_WindDirection)\n    df['WindDirection'] = df['WindDirection'].apply(transform_WindDirection)\n    df['PlayDirection'] = df['PlayDirection'].apply(lambda x: x.strip() == 'right')\n    df['Team'] = df['Team'].apply(lambda x: x.strip()=='home')\n    indoor = \"indoor\"\n    df['GameWeather'] = df['GameWeather'].apply(lambda x: indoor if not pd.isna(x) and indoor in x else x)\n    df['GameWeather'] = df['GameWeather'].apply(lambda x: x.lower().replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly').replace('clear and sunny', 'sunny and clear').replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    df['GameWeather'] = df['GameWeather'].apply(map_weather)\n    df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n    df['X'] = df.apply(lambda row: row['X'] if row['PlayDirection'] else 120-row['X'], axis=1)\n    df['Orientation'] = df.apply(lambda row: new_orientation(row['Orientation'], row['PlayDirection']), axis=1)\n    df['Dir'] = df.apply(lambda row: new_orientation(row['Dir'], row['PlayDirection']), axis=1)\n    df['YardsLeft'] = df.apply(lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\n    df['YardsLeft'] = df.apply(lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)\n    df = df.sort_values(by=['PlayId', 'Team', 'IsRusher', 'JerseyNumber']).reset_index()\n    df = df.drop(['TimeHandoff', 'TimeSnap', 'PlayerBirthDate', 'NflId', 'NflIdRusher', 'GameId', 'PlayId', 'index', 'IsRusher', 'Team'], axis=1)\n    cat_features = []\n    for col in df.columns:\n        if df[col].dtype =='object':\n            cat_features.append(col)\n\n    df = df.drop(cat_features, axis=1)\n    df.fillna(-999, inplace=True)\n    X = np.array(df[players_col]).reshape(-1, len(players_col)*22)\n    play_col = df.drop(players_col, axis=1).columns\n    X_play_col = np.zeros(shape=(X.shape[0], len(play_col)))\n    for i, col in enumerate(play_col):\n        X_play_col[:, i] = df[col][::22]\n    X = np.concatenate([X, X_play_col], axis=1)\n    X = scaler.transform(X)\n    y_pred = np.mean([np.cumsum(model.predict(X), axis=1) for model in models], axis=0)\n    yardsleft = np.array(df['YardsLeft'][::22])\n    \n    for i in range(len(yardsleft)):\n        y_pred[i, :yardsleft[i]-1] = 0\n        y_pred[i, yardsleft[i]+100:] = 1\n    env.predict(pd.DataFrame(data=y_pred.clip(0,1),columns=sample.columns))\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for test, sample in tqdm.tqdm(env.iter_test()):\n     make_pred(test, sample, env, models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b5211633-aa3d-4655-bb8b-ab24801ffef7","_uuid":"6029f120-f8c5-4933-b02d-774383cd2164"},"cell_type":"markdown","source":"# End\n\nIf you reached this far please comment and upvote this kernel, feel free to make improvements on the kernel and please share if you found anything useful!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}