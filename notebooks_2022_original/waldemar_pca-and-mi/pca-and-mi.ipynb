{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{"tags":[]}},{"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all' #'last_expr'\n\nimport math, time, datetime as dt, os, sys \nfrom pathlib import Path\n\nimport pandas as pd\npd.options.display.max_columns = None\npd.options.display.max_colwidth = 999\npd.options.display.max_rows = 101\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# sns.set_theme()\n\nimport numpy as np\nnp.set_printoptions(edgeitems=5,linewidth=250)\n\n# Feature Engineering and Pre Processing\nfrom scipy.stats import ks_2samp, boxcox\nfrom scipy.special import inv_boxcox\nfrom sklearn.feature_selection import mutual_info_classif, mutual_info_regression\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, power_transform, StandardScaler\nfrom sklearn.decomposition import PCA\n\ndata_raw_path = '/kaggle/input/tabular-playground-series-may-2022'\ndata_processed_path = 'data-processed'","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:04:57.362921Z","iopub.execute_input":"2022-05-01T14:04:57.363719Z","iopub.status.idle":"2022-05-01T14:04:57.409486Z","shell.execute_reply.started":"2022-05-01T14:04:57.36366Z","shell.execute_reply":"2022-05-01T14:04:57.408788Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_variance(pca, width=8, dpi=100):\n    # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:04:57.411282Z","iopub.execute_input":"2022-05-01T14:04:57.411577Z","iopub.status.idle":"2022-05-01T14:04:57.45529Z","shell.execute_reply.started":"2022-05-01T14:04:57.411545Z","shell.execute_reply":"2022-05-01T14:04:57.45438Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(f'{data_raw_path}/train.csv', index_col='id')\ndf_sub = pd.read_csv(f'{data_raw_path}/test.csv', index_col='id')\n\ntarget_col = 'target'\nfature_cols = df_sub.columns[1:].to_numpy()\n\nfloat_cols = df_sub.select_dtypes('float64').columns.to_list()\nint_cols = df_sub.select_dtypes('int64').columns.to_list()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:04:57.456794Z","iopub.execute_input":"2022-05-01T14:04:57.457026Z","iopub.status.idle":"2022-05-01T14:05:11.826754Z","shell.execute_reply.started":"2022-05-01T14:04:57.456998Z","shell.execute_reply":"2022-05-01T14:05:11.82585Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA - floats + ints","metadata":{}},{"cell_type":"code","source":"ss = StandardScaler()\ncols = float_cols + int_cols\nX = pd.DataFrame(ss.fit_transform(df_train[cols]), columns = cols)\n# X = df_train[float_cols] # no standard scaller\ny = df_train[target_col]\n\ncomp_count = 10\npca = PCA(n_components=comp_count, random_state=42)\nX_pca = pca.fit_transform(X, y)\n\npc_cols = [f'PC_{i+1}' for i in range(comp_count)]\npd.DataFrame(\n    pca.components_.T,\n    columns=pc_cols,\n    index=X.columns,\n)\n\nplot_variance(pca)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:05:11.828889Z","iopub.execute_input":"2022-05-01T14:05:11.82911Z","iopub.status.idle":"2022-05-01T14:05:18.020465Z","shell.execute_reply.started":"2022-05-01T14:05:11.829082Z","shell.execute_reply":"2022-05-01T14:05:18.019605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA - floats","metadata":{"tags":[]}},{"cell_type":"code","source":"ss = StandardScaler()\ncols = float_cols\nX = pd.DataFrame(ss.fit_transform(df_train[cols]), columns = cols)\n# X = df_train[float_cols] # no standard scaller\ny = df_train[target_col]\n\ncomp_count = 8\npca = PCA(n_components=comp_count, random_state=42)\nX_pca = pca.fit_transform(X, y)\n\npc_cols = [f'PC_{i+1}' for i in range(comp_count)]\npd.DataFrame(\n    pca.components_.T,\n    columns=pc_cols,\n    index=X.columns,\n)\n\nplot_variance(pca)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:05:18.022199Z","iopub.execute_input":"2022-05-01T14:05:18.022869Z","iopub.status.idle":"2022-05-01T14:05:22.376955Z","shell.execute_reply.started":"2022-05-01T14:05:18.022816Z","shell.execute_reply":"2022-05-01T14:05:22.376192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores = mutual_info_classif(X_pca, y)\npd.Series(data=mi_scores, index=pc_cols)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:05:22.378001Z","iopub.execute_input":"2022-05-01T14:05:22.37829Z","iopub.status.idle":"2022-05-01T14:06:19.177702Z","shell.execute_reply.started":"2022-05-01T14:05:22.378249Z","shell.execute_reply":"2022-05-01T14:06:19.176757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA - ints","metadata":{}},{"cell_type":"code","source":"ss = StandardScaler()\ncols = float_cols\nX = pd.DataFrame(ss.fit_transform(df_train[cols]), columns = cols)\n# X = df_train[float_cols] # no standard scaller\ny = df_train[target_col]\n\ncomp_count = 6\npca = PCA(n_components=comp_count, random_state=42)\nX_pca = pca.fit_transform(X, y)\n\npc_cols = [f'PC_{i+1}' for i in range(comp_count)]\npd.DataFrame(\n    pca.components_.T,\n    columns=pc_cols,\n    index=X.columns,\n)\n\nplot_variance(pca)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:06:19.178796Z","iopub.execute_input":"2022-05-01T14:06:19.178997Z","iopub.status.idle":"2022-05-01T14:06:23.478419Z","shell.execute_reply.started":"2022-05-01T14:06:19.178972Z","shell.execute_reply":"2022-05-01T14:06:23.477533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores = mutual_info_classif(X_pca, y)\npd.Series(data=mi_scores, index=pc_cols)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:06:23.47986Z","iopub.execute_input":"2022-05-01T14:06:23.480054Z","iopub.status.idle":"2022-05-01T14:07:05.792765Z","shell.execute_reply.started":"2022-05-01T14:06:23.480031Z","shell.execute_reply":"2022-05-01T14:07:05.791856Z"},"trusted":true},"execution_count":null,"outputs":[]}]}