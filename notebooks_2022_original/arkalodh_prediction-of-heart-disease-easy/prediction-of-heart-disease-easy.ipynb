{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 2020 annual CDC survey data of 400k adults related to their health status","metadata":{}},{"cell_type":"markdown","source":"## What topic does the dataset cover?","metadata":{}},{"cell_type":"markdown","source":"According to the CDC, heart disease is one of the leading causes of death for people of most races in the US (African Americans, American Indians and Alaska Natives, and white people). About half of all Americans (47%) have at least 1 of 3 key risk factors for heart disease: high blood pressure, high cholesterol, and smoking. Other key indicator include diabetic status, obesity (high BMI), not getting enough physical activity or drinking too much alcohol. Detecting and preventing the factors that have the greatest impact on heart disease is very important in healthcare. Computational developments, in turn, allow the application of machine learning methods to detect \"patterns\" from the data that can predict a patient's condition.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# \n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T18:20:48.300231Z","iopub.execute_input":"2022-05-05T18:20:48.301483Z","iopub.status.idle":"2022-05-05T18:20:48.314044Z","shell.execute_reply.started":"2022-05-05T18:20:48.301431Z","shell.execute_reply":"2022-05-05T18:20:48.312706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the Libraries","metadata":{}},{"cell_type":"code","source":"# Libraries for Data Preprocessing\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Libraries for Classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\n\n# Libraries for measuring accuracy\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt \nfrom matplotlib.legend_handler import HandlerBase\nfrom matplotlib.text import Text\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:20:48.316084Z","iopub.execute_input":"2022-05-05T18:20:48.3165Z","iopub.status.idle":"2022-05-05T18:20:50.052177Z","shell.execute_reply.started":"2022-05-05T18:20:48.316466Z","shell.execute_reply":"2022-05-05T18:20:50.050811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the Dataset","metadata":{}},{"cell_type":"code","source":"# read_csv function is used to read a csv file. It takes the filepath as argument\ndf = pd.read_csv('../input/personal-key-indicators-of-heart-disease/heart_2020_cleaned.csv')\n# this prints the first 5 rows of the dataset by default\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:20:50.054563Z","iopub.execute_input":"2022-05-05T18:20:50.054916Z","iopub.status.idle":"2022-05-05T18:20:51.226856Z","shell.execute_reply.started":"2022-05-05T18:20:50.054872Z","shell.execute_reply":"2022-05-05T18:20:51.225696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Changing Grid Style to Dark","metadata":{}},{"cell_type":"code","source":"# this changes the style of the plots in seaborn. Changing the grid to dark\nsns.set_style(\"darkgrid\", {\"grid.color\": \".6\"})","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:20:51.228708Z","iopub.execute_input":"2022-05-05T18:20:51.228955Z","iopub.status.idle":"2022-05-05T18:20:51.234706Z","shell.execute_reply.started":"2022-05-05T18:20:51.228925Z","shell.execute_reply":"2022-05-05T18:20:51.233476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Counting Variation of all Categorical Variables","metadata":{}},{"cell_type":"code","source":"# This list of lists contains all the columns which have binary categorical values\ncolRange = [['Smoking','AlcoholDrinking','Stroke'],['DiffWalking','Sex','PhysicalActivity'],['Asthma','KidneyDisease','SkinCancer']]\n# This function prints the countplots counting the number of people in each category\ndef printCount(cols):\n    fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n    row=0\n    col=0\n    p_count=1\n    for row in range(3):\n        for col in range(3):\n            # reads column name from the list\n            column = colRange[row][col]\n            # plots the counts of the particular column\n            sns.countplot(ax=axes[row,col],x=df[column],hue=df['HeartDisease'])\n            # sets the title of the corresponding plot along with plot number\n            axes[row,col].set_title(\"Counts of {} (Plot {})\".format(column,p_count))\n            p_count += 1\n# Calling the function\nprintCount(colRange)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:20:51.237481Z","iopub.execute_input":"2022-05-05T18:20:51.238476Z","iopub.status.idle":"2022-05-05T18:20:58.501659Z","shell.execute_reply.started":"2022-05-05T18:20:51.238414Z","shell.execute_reply":"2022-05-05T18:20:58.500298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation\n1. Plot 1 - According to the plot people who smoke have a higher chance of Heart Diseases than people who don't\n2. Plot 2 - According to the plot people who do not drink alcohol have a lower of Heart Disease \n3. Plot 3 - According to the plot people having Heart Disease have a lower chance of having a Stroke\n4. Plot 4 - According to the plot people who do not have any difficulty in walking have a lower chance of Heart Disease \n5. Plot 5 - According to the plot Males have a higher chance of Heart Disease than Females\n6. Plot 6 - According to the plot People who participate in Physical Activity cause Heart Diseases\n7. Plot 7 - According to the plot People who have asthma have a lower chance of Heart Disease","metadata":{}},{"cell_type":"markdown","source":"## Checking Heart Disease among Different Races","metadata":{}},{"cell_type":"code","source":"# This statement enlarges the image\nplt.figure(figsize=(12,6))\n# countplot plots the counts of each type of value in a particular column\n# hue property is used to color code the counts according to a second categorical variable.\n# plotting the graph\nsns.countplot(df['Race'],hue=df['HeartDisease'])\nplt.title('Variation of Heart Disease amoung Races')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:20:58.503519Z","iopub.execute_input":"2022-05-05T18:20:58.50387Z","iopub.status.idle":"2022-05-05T18:20:59.398257Z","shell.execute_reply.started":"2022-05-05T18:20:58.503825Z","shell.execute_reply":"2022-05-05T18:20:59.397176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation\nWhite races have a higher chance of heart disease","metadata":{}},{"cell_type":"markdown","source":"## Checking Spread of Heart Disease among Diabetic People","metadata":{}},{"cell_type":"code","source":"# This statement enlarges the image\nplt.figure(figsize=(12,6))\n# plotting the graph\nsns.countplot(df['Diabetic'],hue=df['HeartDisease'])\nplt.title('Variation of Heart Disease among Diabetic People')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:20:59.399845Z","iopub.execute_input":"2022-05-05T18:20:59.400133Z","iopub.status.idle":"2022-05-05T18:21:00.272397Z","shell.execute_reply.started":"2022-05-05T18:20:59.4001Z","shell.execute_reply":"2022-05-05T18:21:00.271564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation\nPeople with no Diabetes have a higher chance of Heart Disease","metadata":{}},{"cell_type":"markdown","source":"## Plotting Variation of BMI with Heart Disease ","metadata":{}},{"cell_type":"code","source":"# This statement enlarges the image\nplt.figure(figsize=(12,6))\n# histplot plots the distribution of values in the particular column\n# kde plots 'kernel distribution estimate' of that particular column\n# plotting both graph on top of each other\nsns.histplot(data=df[df['HeartDisease']=='Yes'],x='BMI',kde=True,color='red')\nsns.histplot(data=df[df['HeartDisease']=='No'],x='BMI',kde=True,color='blue')\nplt.title('Distribution of BMI Among People')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:00.273938Z","iopub.execute_input":"2022-05-05T18:21:00.274945Z","iopub.status.idle":"2022-05-05T18:21:03.204914Z","shell.execute_reply.started":"2022-05-05T18:21:00.274892Z","shell.execute_reply":"2022-05-05T18:21:03.204266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation\nPeople with heart disease have a higher BMI than people who don't have heart disease","metadata":{}},{"cell_type":"markdown","source":"## Checking variation of Physical Health among people with and without Heart Disease","metadata":{}},{"cell_type":"code","source":"# This statement enlarges the image\nplt.figure(figsize=(12,6))\n# kdeplots show an estimated, smooth distribution of a single numerical variable\n# plotting both graphs on top of each other\nsns.kdeplot(df[df['HeartDisease']=='Yes']['PhysicalHealth'],shade=True,color='red')\nsns.kdeplot(df[df['HeartDisease']=='No']['PhysicalHealth'],shade=True,color='blue')\nplt.title('Physical Health Pattern')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:03.20679Z","iopub.execute_input":"2022-05-05T18:21:03.207396Z","iopub.status.idle":"2022-05-05T18:21:05.153805Z","shell.execute_reply.started":"2022-05-05T18:21:03.207356Z","shell.execute_reply":"2022-05-05T18:21:05.152604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation\nPeople with Heart Disease have a lower Physical Health ","metadata":{}},{"cell_type":"markdown","source":"## Checking Variation of Mental health among people with and without Heart Diseases","metadata":{}},{"cell_type":"code","source":"# This statement enlarges the image\nplt.figure(figsize=(12,6))\n# plotting both graphs on top of each other\nsns.kdeplot(df[df['HeartDisease']=='Yes']['MentalHealth'],shade=True,color='red')\nsns.kdeplot(df[df['HeartDisease']=='No']['MentalHealth'],shade=True,color='blue')\nplt.title('Variation of Mental Health')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:05.155552Z","iopub.execute_input":"2022-05-05T18:21:05.1558Z","iopub.status.idle":"2022-05-05T18:21:07.025403Z","shell.execute_reply.started":"2022-05-05T18:21:05.155769Z","shell.execute_reply":"2022-05-05T18:21:07.024308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation\nPeople with Heart Disease have a lower Mental Health ","metadata":{}},{"cell_type":"markdown","source":"## Drawing the correlation graph","metadata":{}},{"cell_type":"code","source":"# importing matplotlib library\nimport matplotlib\n# This statement reduces the size of image\nplt.figure(figsize=(9,6))\n# plotting the graph\nsns.heatmap(df.corr(),annot=True,cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:07.028963Z","iopub.execute_input":"2022-05-05T18:21:07.029295Z","iopub.status.idle":"2022-05-05T18:21:07.379413Z","shell.execute_reply.started":"2022-05-05T18:21:07.029249Z","shell.execute_reply":"2022-05-05T18:21:07.378526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking Columns of the Dataset","metadata":{}},{"cell_type":"code","source":"# the info() function gives information about all the columns in the dataset\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:07.38104Z","iopub.execute_input":"2022-05-05T18:21:07.381653Z","iopub.status.idle":"2022-05-05T18:21:07.885101Z","shell.execute_reply.started":"2022-05-05T18:21:07.381608Z","shell.execute_reply":"2022-05-05T18:21:07.884187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking unique Values in Categorical Columns","metadata":{}},{"cell_type":"code","source":"# the unique() function prints the unique values in a particular column. It is used to check the values in a categorical column.\n# printing all the unique values of each column \nprint(df['Smoking'].unique())\nprint(df['AlcoholDrinking'].unique())\nprint(df['Stroke'].unique())\nprint(df['DiffWalking'].unique())\nprint(df['Sex'].unique())\nprint(df['AgeCategory'].unique())\nprint(df['Race'].unique())\nprint(df['Diabetic'].unique())\nprint(df['PhysicalActivity'].unique())\nprint(df['GenHealth'].unique())\nprint(df['Asthma'].unique())\nprint(df['KidneyDisease'].unique())\nprint(df['SkinCancer'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:07.886715Z","iopub.execute_input":"2022-05-05T18:21:07.889283Z","iopub.status.idle":"2022-05-05T18:21:08.196103Z","shell.execute_reply.started":"2022-05-05T18:21:07.88923Z","shell.execute_reply":"2022-05-05T18:21:08.194913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoding all Binary Categorical Columns","metadata":{}},{"cell_type":"code","source":"# this is a user defined function that encodes the categorical columns\ndef change(col):\n    if col=='Yes':\n        return 1\n    elif col=='No':\n        return 0\n# the apply() function puts value of each row one by one in a column to encode that whole column\n# encoding all categorical columns having binary values\ndf['Smoking'] = df['Smoking'].apply(change)\ndf['AlcoholDrinking'] = df['AlcoholDrinking'].apply(change)\ndf['Stroke'] = df['Stroke'].apply(change)\ndf['DiffWalking'] = df['DiffWalking'].apply(change)\ndf['PhysicalActivity'] = df['PhysicalActivity'].apply(change)\ndf['Asthma'] = df['Asthma'].apply(change)\ndf['KidneyDisease'] = df['KidneyDisease'].apply(change)\ndf['SkinCancer'] = df['SkinCancer'].apply(change)\ndf['HeartDisease'] = df['HeartDisease'].apply(change)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:08.197337Z","iopub.execute_input":"2022-05-05T18:21:08.197552Z","iopub.status.idle":"2022-05-05T18:21:10.238161Z","shell.execute_reply.started":"2022-05-05T18:21:08.197525Z","shell.execute_reply":"2022-05-05T18:21:10.237109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking State of dataset","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:10.239618Z","iopub.execute_input":"2022-05-05T18:21:10.240027Z","iopub.status.idle":"2022-05-05T18:21:10.263787Z","shell.execute_reply.started":"2022-05-05T18:21:10.239978Z","shell.execute_reply":"2022-05-05T18:21:10.262563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Encoding all categorical columns with more than 2 values","metadata":{}},{"cell_type":"code","source":"# making an instance of the label encoder class\nle = LabelEncoder()\n# label encoding all the categorical columns that have more than 2 unique values\ndf['Sex']=le.fit_transform(df['Sex'])\ndf['AgeCategory']=le.fit_transform(df['AgeCategory'])\ndf['Race']=le.fit_transform(df['Race'])\ndf['Diabetic']=le.fit_transform(df['Diabetic'])\ndf['GenHealth']=le.fit_transform(df['GenHealth'])","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:10.265745Z","iopub.execute_input":"2022-05-05T18:21:10.266051Z","iopub.status.idle":"2022-05-05T18:21:10.800622Z","shell.execute_reply.started":"2022-05-05T18:21:10.266016Z","shell.execute_reply":"2022-05-05T18:21:10.799577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking state of Dataset","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:10.802141Z","iopub.execute_input":"2022-05-05T18:21:10.80245Z","iopub.status.idle":"2022-05-05T18:21:10.824626Z","shell.execute_reply.started":"2022-05-05T18:21:10.802408Z","shell.execute_reply":"2022-05-05T18:21:10.823763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dividing Dataset into Training and Test Set","metadata":{}},{"cell_type":"code","source":"# iloc[] function is used to select values from the dataset\n# independent variables\nX = df.iloc[:,1:].values\n# dependent variable\ny = df.iloc[:,0].values","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:10.825834Z","iopub.execute_input":"2022-05-05T18:21:10.826168Z","iopub.status.idle":"2022-05-05T18:21:10.932393Z","shell.execute_reply.started":"2022-05-05T18:21:10.826126Z","shell.execute_reply":"2022-05-05T18:21:10.931302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting dataset into Training and Test Set","metadata":{}},{"cell_type":"code","source":"# train_test_split() is used to divide dataset into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:10.93417Z","iopub.execute_input":"2022-05-05T18:21:10.934452Z","iopub.status.idle":"2022-05-05T18:21:11.074296Z","shell.execute_reply.started":"2022-05-05T18:21:10.934417Z","shell.execute_reply":"2022-05-05T18:21:11.073267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Scaling","metadata":{}},{"cell_type":"code","source":"# declaring an object of standardscaler class\nsc = StandardScaler()\n# fit_transform() method first trains the Scaler on dataset and then transforms it between 0 and 1\nX_train = sc.fit_transform(X_train)\n# transform() method only transforms the dataset based on what it has learnt on the dataset before\nX_test = sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:11.078541Z","iopub.execute_input":"2022-05-05T18:21:11.078838Z","iopub.status.idle":"2022-05-05T18:21:11.222427Z","shell.execute_reply.started":"2022-05-05T18:21:11.078806Z","shell.execute_reply":"2022-05-05T18:21:11.221327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Models","metadata":{}},{"cell_type":"markdown","source":"### 1. Logistic Regression","metadata":{}},{"cell_type":"code","source":"# declaring a object of Logistic regression class\nclf1 = LogisticRegression()\n# fit() function trains the model\n# fitting the object with the training data\nclf1.fit(X_train, y_train)\n# predict() function predicts results from validation data\n# predicting result using the trained data\ny_pred1 = clf1.predict(X_test)\n# confusion_matrix() gives the true_positives, false positives, true negatives, false negatives\n# making confusion matrix using predicted and given results in validation data\ncm1=confusion_matrix(y_test,y_pred1)\n# printing the confusion matrix\nprint(cm1)\n# accuracy_score() is used to find the accuracy of the model\nprint(accuracy_score(y_test,y_pred1))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:11.223774Z","iopub.execute_input":"2022-05-05T18:21:11.224032Z","iopub.status.idle":"2022-05-05T18:21:11.842734Z","shell.execute_reply.started":"2022-05-05T18:21:11.224003Z","shell.execute_reply":"2022-05-05T18:21:11.841754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. K Nearest Neighbors","metadata":{}},{"cell_type":"code","source":"# declaring a object of K Neighbors Classifier class\nclf2 = KNeighborsClassifier()\nclf2.fit(X_train, y_train)\ny_pred2 = clf2.predict(X_test)\ncm2 = confusion_matrix(y_test,y_pred2)\nprint(cm2)\nprint(accuracy_score(y_test,y_pred2))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:21:11.844861Z","iopub.execute_input":"2022-05-05T18:21:11.845569Z","iopub.status.idle":"2022-05-05T18:27:41.781285Z","shell.execute_reply.started":"2022-05-05T18:21:11.845516Z","shell.execute_reply":"2022-05-05T18:27:41.780297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Naive Bayes","metadata":{}},{"cell_type":"code","source":"# declaring a object of GaussianNB class\nclf3 = GaussianNB()\nclf3.fit(X_train, y_train)\ny_pred3 = clf3.predict(X_test)\ncm3 = confusion_matrix(y_test,y_pred3)\nprint(cm3)\nprint(accuracy_score(y_test,y_pred3))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:27:41.782739Z","iopub.execute_input":"2022-05-05T18:27:41.783012Z","iopub.status.idle":"2022-05-05T18:27:41.932768Z","shell.execute_reply.started":"2022-05-05T18:27:41.782968Z","shell.execute_reply":"2022-05-05T18:27:41.931784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Support Vector Machine ( Not Recommended due to very long execution time {more than 4 hours} ) ","metadata":{}},{"cell_type":"code","source":"# clf4 = SVC()\n# clf4.fit(X_train,y_train)\n# y_pred4 = clf4.predict(X_test)\n# cm4 = confusion_matrix(y_test,y_pred4)\n# print(cm4)\n# print(accuracy_score(y_test,y_pred4))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:27:41.934373Z","iopub.execute_input":"2022-05-05T18:27:41.935438Z","iopub.status.idle":"2022-05-05T18:27:41.939958Z","shell.execute_reply.started":"2022-05-05T18:27:41.935376Z","shell.execute_reply":"2022-05-05T18:27:41.939243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rand_grid = {\n#     'kernel':['linear','poly','rbf','sigmoid'],\n#     'C':[int(x) for x in np.linspace(start = 2, stop = 10,num = 10)],\n#     'gamma':[int(x) for x in np.linspace(start = 0.1, stop = 1, num = 5)]\n# }","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:27:41.941167Z","iopub.execute_input":"2022-05-05T18:27:41.942173Z","iopub.status.idle":"2022-05-05T18:27:41.958352Z","shell.execute_reply.started":"2022-05-05T18:27:41.942129Z","shell.execute_reply":"2022-05-05T18:27:41.957153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rcv = RandomizedSearchCV(estimator=clf4,param_distributions=rand_grid,n_iter=100,cv=3,verbose=2,random_state=0,n_jobs=-1)\n# rcv.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:27:41.960335Z","iopub.execute_input":"2022-05-05T18:27:41.960648Z","iopub.status.idle":"2022-05-05T18:27:41.973623Z","shell.execute_reply.started":"2022-05-05T18:27:41.96061Z","shell.execute_reply":"2022-05-05T18:27:41.972088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(rcv.best_params_)\n# print(rcv.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:27:41.975486Z","iopub.execute_input":"2022-05-05T18:27:41.976082Z","iopub.status.idle":"2022-05-05T18:27:41.987733Z","shell.execute_reply.started":"2022-05-05T18:27:41.97604Z","shell.execute_reply":"2022-05-05T18:27:41.986457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Decision Tree","metadata":{}},{"cell_type":"code","source":"# declaring a object of Decision Tree Classifier class\nclf5 = DecisionTreeClassifier(criterion='entropy')\nclf5.fit(X_train, y_train)\ny_pred5 = clf5.predict(X_test)\ncm5 = confusion_matrix(y_test,y_pred5)\nprint(cm5)\nprint(accuracy_score(y_test,y_pred5))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:27:41.989666Z","iopub.execute_input":"2022-05-05T18:27:41.990195Z","iopub.status.idle":"2022-05-05T18:27:43.868964Z","shell.execute_reply.started":"2022-05-05T18:27:41.990152Z","shell.execute_reply":"2022-05-05T18:27:43.867429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Random Forest","metadata":{}},{"cell_type":"code","source":"# declaring a object of Random Forest Classifier class\nclf6 = RandomForestClassifier(criterion='entropy',n_estimators=50)\nclf6.fit(X_train, y_train)\ny_pred6 = clf6.predict(X_test)\ncm6 = confusion_matrix(y_test,y_pred6)\nprint(cm6)\nprint(accuracy_score(y_test,y_pred6))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:27:43.874283Z","iopub.execute_input":"2022-05-05T18:27:43.874714Z","iopub.status.idle":"2022-05-05T18:28:03.98097Z","shell.execute_reply.started":"2022-05-05T18:27:43.874666Z","shell.execute_reply":"2022-05-05T18:28:03.980011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Applying Hyperparameter Tuning on Random Forest","metadata":{}},{"cell_type":"markdown","source":"### RandomizedSearchCV","metadata":{}},{"cell_type":"markdown","source":"###     a) Making the Parameter Grid","metadata":{}},{"cell_type":"code","source":"# making the set of parameters to test the RandomizedSearchCV \nparam_grid = {\n    'n_estimators': [int(x) for x in np.linspace(start=2,stop=100,num=10)],\n    'max_features': ['auto','sqrt','log2'],\n    'max_depth': [int(x) for x in np.linspace(10,1000,10)],\n    'min_samples_split': [2,5,7,10,12,14],\n    'min_samples_leaf': [1,2,4,6,8],\n    'criterion': ['entropy','gini']\n}\nprint(param_grid)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:28:03.982632Z","iopub.execute_input":"2022-05-05T18:28:03.982898Z","iopub.status.idle":"2022-05-05T18:28:03.991481Z","shell.execute_reply.started":"2022-05-05T18:28:03.982864Z","shell.execute_reply":"2022-05-05T18:28:03.990616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### b) Running RandomizedSearchCV to find best parameters","metadata":{}},{"cell_type":"code","source":"# RandomizedSearchCV randomly assigns a best class and checks if it is best by training the model on those parameters\n# making an object of the RandomizedSearchCV class\nrcv = RandomizedSearchCV(estimator=clf6,param_distributions=param_grid,n_iter=100,cv=5,verbose=2,n_jobs=-1)\n# training the RandomizedSearchCV to find the best parameters\nrcv.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:28:03.99265Z","iopub.execute_input":"2022-05-05T18:28:03.992914Z","iopub.status.idle":"2022-05-05T19:15:38.07488Z","shell.execute_reply.started":"2022-05-05T18:28:03.992881Z","shell.execute_reply":"2022-05-05T19:15:38.07282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### c) Checking Best Parameters","metadata":{}},{"cell_type":"code","source":"# this best_params_ attribute prints the best attributes that were found by RandomizedSearchCV\nrcv.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:15:38.076724Z","iopub.execute_input":"2022-05-05T19:15:38.076989Z","iopub.status.idle":"2022-05-05T19:15:38.084702Z","shell.execute_reply.started":"2022-05-05T19:15:38.076956Z","shell.execute_reply":"2022-05-05T19:15:38.083803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### d) Checking Best Estimator","metadata":{}},{"cell_type":"code","source":"# this best_estimator_ prints the best model that was found by RandomizedSearchCV\nrcv.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:15:38.086511Z","iopub.execute_input":"2022-05-05T19:15:38.087032Z","iopub.status.idle":"2022-05-05T19:15:38.103753Z","shell.execute_reply.started":"2022-05-05T19:15:38.086972Z","shell.execute_reply":"2022-05-05T19:15:38.102448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### e) Training Random Forest with Best Parameters Found","metadata":{}},{"cell_type":"code","source":"# making another object of the Random Forest Classifier to test it with the best parameters\nclf8 = RandomForestClassifier(criterion='gini',n_estimators=56,max_depth=10,max_features='log2',min_samples_split=5,min_samples_leaf=1)\nclf8.fit(X_train, y_train)\ny_pred8 = clf8.predict(X_test)\ncm8 = confusion_matrix(y_test,y_pred8)\nprint(cm8)\nprint(accuracy_score(y_test,y_pred8))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:44:17.242501Z","iopub.execute_input":"2022-05-05T19:44:17.242864Z","iopub.status.idle":"2022-05-05T19:44:30.389112Z","shell.execute_reply.started":"2022-05-05T19:44:17.242833Z","shell.execute_reply":"2022-05-05T19:44:30.388012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7) XGBoost","metadata":{}},{"cell_type":"code","source":"# making an object of the XGBoost class \nclf7 = XGBClassifier()\nclf7.fit(X_train, y_train)\ny_pred7 = clf7.predict(X_test)\ncm7 = confusion_matrix(y_test,y_pred7)\nprint(cm7)\nprint(accuracy_score(y_test,y_pred7))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:16:04.172906Z","iopub.execute_input":"2022-05-05T19:16:04.173152Z","iopub.status.idle":"2022-05-05T19:16:21.846153Z","shell.execute_reply.started":"2022-05-05T19:16:04.173121Z","shell.execute_reply":"2022-05-05T19:16:21.845479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Here we are able to see that XGBoost Classifier beats even HyperTuned Random Forest Classifier","metadata":{}},{"cell_type":"markdown","source":"### XGBoost achieves an accuracy of 91.496%","metadata":{}},{"cell_type":"markdown","source":"## Congratulations you have reached the end of this notebook!!!","metadata":{}},{"cell_type":"markdown","source":"# Please Upvote if you like it. It motivates me to do more.","metadata":{}}]}