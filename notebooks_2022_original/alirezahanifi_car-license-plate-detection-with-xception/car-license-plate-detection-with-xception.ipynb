{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- [Import Libraries](#1)\n- [Reading the Dataset](#2)\n- [Data Pre-processing](#3)\n- [Modeling](#4)\n- [Conclusions](#5)\n- [References](#6)","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries <a id = '1'></a>","metadata":{}},{"cell_type":"code","source":"import cv2\nimport glob\nfrom lxml import etree\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf \nfrom tensorflow import keras \nfrom keras.layers import BatchNormalization, Conv2D, Dense,Dropout, Flatten, GlobalAveragePooling2D, MaxPool2D, ReLU\nfrom tensorflow.keras.applications import Xception\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T14:43:01.056397Z","iopub.execute_input":"2022-05-04T14:43:01.056678Z","iopub.status.idle":"2022-05-04T14:43:01.062809Z","shell.execute_reply.started":"2022-05-04T14:43:01.056647Z","shell.execute_reply":"2022-05-04T14:43:01.061667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the Dataset <a id = '2'></a>","metadata":{}},{"cell_type":"markdown","source":"- <a href = 'https://www.kaggle.com/datasets/andrewmvd/car-plate-detection'>Link to the dataset in the Kaggel.</a>\n\n<i>\"This dataset contains 433 images with bounding box annotations of the car license plates within the image.\nAnnotations are provided in the PASCAL VOC format.\"</i>","metadata":{}},{"cell_type":"code","source":"img_list = [] \nannot_list = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if os.path.join(dirname, filename)[-3:]!=\"xml\":\n            img_list.append(os.path.join(dirname, filename))\n        else:\n            annot_list.append(os.path.join(dirname, filename))\n            \nimg_list.sort()\nannot_list.sort()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:01.122992Z","iopub.execute_input":"2022-05-04T14:43:01.123287Z","iopub.status.idle":"2022-05-04T14:43:01.138754Z","shell.execute_reply.started":"2022-05-04T14:43:01.123259Z","shell.execute_reply":"2022-05-04T14:43:01.1381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-processing <a id = '3'></a>","metadata":{}},{"cell_type":"code","source":"def get_annotation(annotation):\n    \n    tree = etree.parse(annotation)\n    \n    for dim in tree.xpath(\"size\"):\n        width = int(dim.xpath(\"width\")[0].text)\n        height = int(dim.xpath(\"height\")[0].text)\n        \n    for dim in tree.xpath(\"object/bndbox\"):\n        xmin = int(dim.xpath(\"xmin\")[0].text)\n        ymin = int(dim.xpath(\"ymin\")[0].text)\n        xmax = int(dim.xpath(\"xmax\")[0].text)\n        ymax = int(dim.xpath(\"ymax\")[0].text)\n        \n    return [int(xmax), int(ymax), int(xmin), int(ymin), int(width), int(height)]\n\nannot_coor = []\n\nfor annotation in annot_list:\n    annot_coor.append(get_annotation(annotation))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:01.143881Z","iopub.execute_input":"2022-05-04T14:43:01.144369Z","iopub.status.idle":"2022-05-04T14:43:01.65664Z","shell.execute_reply.started":"2022-05-04T14:43:01.14434Z","shell.execute_reply":"2022-05-04T14:43:01.65582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_width = [i[4] for i in annot_coor]\nimages_height = [i[5] for i in annot_coor]\n\nj_plot = sns.jointplot(x = images_width, y = images_height, kind = 'reg', height = 8)\nj_plot.set_axis_labels('width', 'height', fontsize = 16)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:01.659326Z","iopub.execute_input":"2022-05-04T14:43:01.65957Z","iopub.status.idle":"2022-05-04T14:43:02.354725Z","shell.execute_reply.started":"2022-05-04T14:43:01.659537Z","shell.execute_reply":"2022-05-04T14:43:02.35404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_width = 400\nimg_height = 280","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:02.356155Z","iopub.execute_input":"2022-05-04T14:43:02.3567Z","iopub.status.idle":"2022-05-04T14:43:02.360315Z","shell.execute_reply.started":"2022-05-04T14:43:02.356645Z","shell.execute_reply":"2022-05-04T14:43:02.359498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []\n\nfor i in img_list:\n    img = cv2.imread(i) \n    img = cv2.resize(img, (img_width, img_height))\n    X.append(np.array(img))\n\nX_arr = np.array(X)\nprint(f'Shape of images(X): {X_arr.shape} (m, height, width, channels)')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:02.362642Z","iopub.execute_input":"2022-05-04T14:43:02.363142Z","iopub.status.idle":"2022-05-04T14:43:08.804024Z","shell.execute_reply.started":"2022-05-04T14:43:02.363066Z","shell.execute_reply":"2022-05-04T14:43:08.803239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize_annotation(annotation):\n    \n    tree = etree.parse(annotation)\n    \n    for dim in tree.xpath(\"size\"):\n        width = int(dim.xpath(\"width\")[0].text)\n        height = int(dim.xpath(\"height\")[0].text)\n        \n    for dim in tree.xpath(\"object/bndbox\"):\n        xmin = int(dim.xpath(\"xmin\")[0].text)/(width/img_width)\n        ymin = int(dim.xpath(\"ymin\")[0].text)/(height/img_height)\n        xmax = int(dim.xpath(\"xmax\")[0].text)/(width/img_width)\n        ymax = int(dim.xpath(\"ymax\")[0].text)/(height/img_height)\n        \n    return [int(xmax), int(ymax), int(xmin), int(ymin)]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:08.805294Z","iopub.execute_input":"2022-05-04T14:43:08.80554Z","iopub.status.idle":"2022-05-04T14:43:08.813862Z","shell.execute_reply.started":"2022-05-04T14:43:08.805505Z","shell.execute_reply":"2022-05-04T14:43:08.813026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = []\n\nfor annotation in annot_list:\n    y.append(resize_annotation(annotation))\n    \ny_arr = np.array(y)\nprint(f'Shape of annotations(y): {y_arr.shape} (m, bbox[xmax, ymax, xmin, ymin])')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:08.815125Z","iopub.execute_input":"2022-05-04T14:43:08.81597Z","iopub.status.idle":"2022-05-04T14:43:09.308123Z","shell.execute_reply.started":"2022-05-04T14:43:08.815918Z","shell.execute_reply":"2022-05-04T14:43:09.307268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20, 15))\n\nfor num, i in enumerate(np.random.randint(X_arr.shape[0],size = 9)):\n    \n    plt.subplot(3, 3, num + 1)\n    \n    img_rec = cv2.rectangle(\n        X_arr[i], #image\n        (y_arr[i][0], y_arr[i][1]), #start_point\n        (y_arr[i][2], y_arr[i][3]), #end_point\n        (255, 0, 0), #color\n        2 #thickness\n    )\n    plt.imshow(img_rec)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:09.309538Z","iopub.execute_input":"2022-05-04T14:43:09.31206Z","iopub.status.idle":"2022-05-04T14:43:10.715997Z","shell.execute_reply.started":"2022-05-04T14:43:09.312019Z","shell.execute_reply":"2022-05-04T14:43:10.715105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_arr_norm = X_arr / 255.\ny_arr_norm = y_arr / float(img_width)\n\nx_train, x_test, y_train, y_test = train_test_split(X_arr_norm, y_arr_norm, test_size = 0.2)\nprint(f'Shape of x_train: {x_train.shape}')\nprint(f'Shape of y_train: {y_train.shape}')\nprint(f'Shape of x_test: {x_test.shape}')\nprint(f'Shape of y_test: {y_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:10.717241Z","iopub.execute_input":"2022-05-04T14:43:10.717493Z","iopub.status.idle":"2022-05-04T14:43:11.445629Z","shell.execute_reply.started":"2022-05-04T14:43:10.71746Z","shell.execute_reply":"2022-05-04T14:43:11.444784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling <a id = '4'></a>","metadata":{}},{"cell_type":"code","source":"base_xception = Xception(\n    input_shape = (img_height, img_width, 3),\n    include_top = False,\n    weights = 'imagenet',\n    )","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-04T14:43:11.447077Z","iopub.execute_input":"2022-05-04T14:43:11.44762Z","iopub.status.idle":"2022-05-04T14:43:15.417634Z","shell.execute_reply.started":"2022-05-04T14:43:11.447573Z","shell.execute_reply":"2022-05-04T14:43:15.416801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = base_xception.output\nx = MaxPool2D(pool_size = 3)(x)\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.5)(x)\nx = Dense(64, activation = 'relu')(x)\nx = BatchNormalization(axis = -1)(x)\nx = Dropout(0.2)(x)\noutputs_xception = Dense(4, activation = 'sigmoid')(x)\n\nxception_fine = keras.Model(inputs = base_xception.inputs, outputs = outputs_xception, name = 'xception_pretrained')\n\nxception_fine.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-04T14:43:15.420237Z","iopub.execute_input":"2022-05-04T14:43:15.420435Z","iopub.status.idle":"2022-05-04T14:43:15.531144Z","shell.execute_reply.started":"2022-05-04T14:43:15.42041Z","shell.execute_reply":"2022-05-04T14:43:15.530494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, layer in enumerate(xception_fine.layers):\n    print(f'Layer number {i}: {layer.name}')    ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-04T14:43:15.532479Z","iopub.execute_input":"2022-05-04T14:43:15.532715Z","iopub.status.idle":"2022-05-04T14:43:15.555232Z","shell.execute_reply.started":"2022-05-04T14:43:15.532682Z","shell.execute_reply":"2022-05-04T14:43:15.554586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in xception_fine.layers[:116]:\n    layer.trainable = False\n    \nfor layer in xception_fine.layers[116:]:\n    layer.trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:43:15.556328Z","iopub.execute_input":"2022-05-04T14:43:15.556624Z","iopub.status.idle":"2022-05-04T14:43:15.565331Z","shell.execute_reply.started":"2022-05-04T14:43:15.556588Z","shell.execute_reply":"2022-05-04T14:43:15.564633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception_fine.compile(\n    loss =  'mse',\n    optimizer = 'adam'\n)\n\nepochs = 50\n\nhistory_xception_fine = xception_fine.fit(\n    x_train,\n    y_train,\n    batch_size = 64,\n    epochs = epochs,\n    shuffle = True,\n    validation_split = 0.2\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-04T14:43:15.566485Z","iopub.execute_input":"2022-05-04T14:43:15.566717Z","iopub.status.idle":"2022-05-04T14:44:40.806292Z","shell.execute_reply.started":"2022-05-04T14:43:15.566684Z","shell.execute_reply":"2022-05-04T14:44:40.805378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history_of_model):\n    plt.figure(figsize = (20, 5))\n    \n    plt.subplot(1, 1, 1)\n    plt.title('Loss on training and validation data')\n    sns.lineplot(x = range(1, epochs + 1), y = history_of_model.history['loss'])\n    sns.lineplot(x = range(1, epochs + 1), y = history_of_model.history['val_loss'])\n    plt.xlabel('epochs')\n    plt.xticks(list(range(1, epochs + 1))[::2])\n    plt.legend(['training loss', 'validation loss'], loc = 'upper left')\n    \n    plt.show() \n    \nplot_history(history_xception_fine)  ","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:44:40.808266Z","iopub.execute_input":"2022-05-04T14:44:40.808607Z","iopub.status.idle":"2022-05-04T14:44:41.067117Z","shell.execute_reply.started":"2022-05-04T14:44:40.808566Z","shell.execute_reply":"2022-05-04T14:44:41.066231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_xception_loss = xception_fine.evaluate(x_test, y_test)\nprint(f'Loss on testing data with a Xception model: {test_xception_loss:0.4}')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:44:41.068303Z","iopub.execute_input":"2022-05-04T14:44:41.068618Z","iopub.status.idle":"2022-05-04T14:44:42.51573Z","shell.execute_reply.started":"2022-05-04T14:44:41.068581Z","shell.execute_reply":"2022-05-04T14:44:42.514614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = (xception_fine.predict(x_test) * img_width).astype('int')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:44:42.517993Z","iopub.execute_input":"2022-05-04T14:44:42.518715Z","iopub.status.idle":"2022-05-04T14:44:44.057867Z","shell.execute_reply.started":"2022-05-04T14:44:42.518674Z","shell.execute_reply":"2022-05-04T14:44:44.057074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predd = (xception_fine.predict(x_test[16][np.newaxis, ...]) * img_width).astype('int')\n\nprint(y_test[16] * 400)\ny_predd","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:44:44.059072Z","iopub.execute_input":"2022-05-04T14:44:44.05936Z","iopub.status.idle":"2022-05-04T14:44:44.209513Z","shell.execute_reply.started":"2022-05-04T14:44:44.059325Z","shell.execute_reply":"2022-05-04T14:44:44.208744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (20, 15))\n\nfor num, i in enumerate(np.random.randint(x_test.shape[0],size = 9)):\n    \n    plt.suptitle('Ground Truth bbox: Green, Predicted bbox: Red', size = 20)\n   \n    plt.subplot(3, 3, num + 1)\n    cv2.rectangle(\n        x_test[i], #image\n        (int(y_test[i][0] * img_width), int(y_test[i][1] * img_width)), #start_point\n        (int(y_test[i][2] * img_width), int(y_test[i][3] * img_width)), #end_point\n        (0, 255, 0), #color: green\n        3 #thickness\n    )\n    plt.text(\n        int(y_test[i][0] * img_width),\n        int(y_test[i][1] * img_width) + 8,\n        'GT BB',\n        fontsize = 14,\n        color = 'g'\n    )\n    \n    cv2.rectangle(\n        x_test[i], #image\n        (y_pred[i][0], y_pred[i][1]), #start_point\n        (y_pred[i][2], y_pred[i][3]), #end_point\n        (255, 0, 0), #color: red\n        3 #thickness\n    )\n    plt.text(\n        y_pred[i][2],\n        y_pred[i][3] - 8,\n        'P BB',\n        fontsize = 14,\n        color = 'r'\n    )    \n    \n    plt.imshow(x_test[i])\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:00:15.92071Z","iopub.execute_input":"2022-05-04T15:00:15.920992Z","iopub.status.idle":"2022-05-04T15:00:17.316552Z","shell.execute_reply.started":"2022-05-04T15:00:15.920959Z","shell.execute_reply":"2022-05-04T15:00:17.315168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusions <a id = '5'></a>","metadata":{}},{"cell_type":"markdown","source":"From the plots above, it is clear that this model does not recognize license plates well. Finding metrics and losses is currently one of the biggest challenges. Yolo must be used in the next step!","metadata":{}},{"cell_type":"markdown","source":"# References <a id = '6'></a>","metadata":{}},{"cell_type":"markdown","source":"- <a href = 'https://www.kaggle.com/code/mclikmb4/vehicle-license-plate-detection-vgg16'>Vehicle License Plate Detection | VGG16</a>","metadata":{}}]}