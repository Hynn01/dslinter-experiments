{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Bitcoin (BTC) Forecasting with Advanced FE (original approach)\n\n## Dataset \"[Forecasting Top Cryptocurrencies](https://www.kaggle.com/datasets/vbmokin/forecasting-top-cryptocurrencies)\"\n## Data download from API [Yahoo.Finance](https://finance.yahoo.com/cryptocurrencies/)","metadata":{"papermill":{"duration":0.03935,"end_time":"2022-04-16T14:17:11.929278","exception":false,"start_time":"2022-04-16T14:17:11.889928","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Acknowledgements:\n* FE - the notebook [GResearch Simple LGB Starter](https://www.kaggle.com/code1110/gresearch-simple-lgb-starter)\n* about cryptocurrencies - dataset [Forecasting Top Cryptocurrencies](https://www.kaggle.com/datasets/vbmokin/forecasting-top-cryptocurrencies)\n* data source via API: https://finance.yahoo.com/cryptocurrencies/","metadata":{"papermill":{"duration":0.037249,"end_time":"2022-04-16T14:17:12.006463","exception":false,"start_time":"2022-04-16T14:17:11.969214","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download data](#2)\n1. [FE](#3)\n1. [Model training](#4)\n1. [Prediction](#5)\n    - [Training data](#5.1)\n    - [Test data](#5.2)","metadata":{"papermill":{"duration":0.038491,"end_time":"2022-04-16T14:17:12.084185","exception":false,"start_time":"2022-04-16T14:17:12.045694","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.039489,"end_time":"2022-04-16T14:17:12.162239","exception":false,"start_time":"2022-04-16T14:17:12.12275","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# !pip install tsfresh","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:16:13.271988Z","iopub.execute_input":"2022-04-27T09:16:13.272451Z","iopub.status.idle":"2022-04-27T09:16:13.278825Z","shell.execute_reply.started":"2022-04-27T09:16:13.272409Z","shell.execute_reply":"2022-04-27T09:16:13.277441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import libraries\nimport random\nimport os\nimport numpy as np \nimport pandas as pd \nimport requests\nimport pandas_datareader as web\n\n# Date\nimport datetime as dt\nfrom datetime import date, timedelta, datetime\n\n# EDA\nimport matplotlib.pyplot as plt\nfrom matplotlib.pylab import rcParams\n\n# FE\nfrom tsfresh import extract_features, select_features\nfrom functools import reduce\n\n# Metrics\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n\n# Modeling and preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nimport xgboost as xgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"papermill":{"duration":1.533893,"end_time":"2022-04-16T14:17:13.737208","exception":false,"start_time":"2022-04-16T14:17:12.203315","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.281279Z","iopub.execute_input":"2022-04-27T09:16:13.281924Z","iopub.status.idle":"2022-04-27T09:16:13.300141Z","shell.execute_reply.started":"2022-04-27T09:16:13.281882Z","shell.execute_reply":"2022-04-27T09:16:13.299435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set main parameters\ncryptocurrency = 'BTC'\ntarget = 'Close'\nforecasting_days = 10    # requires > 1","metadata":{"papermill":{"duration":0.047009,"end_time":"2022-04-16T14:17:13.8983","exception":false,"start_time":"2022-04-16T14:17:13.851291","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.302336Z","iopub.execute_input":"2022-04-27T09:16:13.302971Z","iopub.status.idle":"2022-04-27T09:16:13.322223Z","shell.execute_reply.started":"2022-04-27T09:16:13.302856Z","shell.execute_reply":"2022-04-27T09:16:13.321433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random state\ndef fix_all_seeds(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nrandom_state = 42\nfix_all_seeds(random_state)","metadata":{"papermill":{"duration":0.047164,"end_time":"2022-04-16T14:17:13.985788","exception":false,"start_time":"2022-04-16T14:17:13.938624","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.324412Z","iopub.execute_input":"2022-04-27T09:16:13.325224Z","iopub.status.idle":"2022-04-27T09:16:13.340073Z","shell.execute_reply.started":"2022-04-27T09:16:13.325172Z","shell.execute_reply":"2022-04-27T09:16:13.339312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set time interval of data for given cryptocurrency - the period of coronavirus in 2020-2021\ndate_start = dt.datetime(2020, 4, 1)\n# date_end = dt.datetime.now()\ndate_end = dt.datetime(2021, 12, 31)\nprint(f\"Time interval: from {date_start} to {date_end}\")","metadata":{"papermill":{"duration":0.048257,"end_time":"2022-04-16T14:17:14.150546","exception":false,"start_time":"2022-04-16T14:17:14.102289","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.342867Z","iopub.execute_input":"2022-04-27T09:16:13.343482Z","iopub.status.idle":"2022-04-27T09:16:13.359854Z","shell.execute_reply.started":"2022-04-27T09:16:13.343427Z","shell.execute_reply":"2022-04-27T09:16:13.358485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Download data <a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.038261,"end_time":"2022-04-16T14:17:14.229398","exception":false,"start_time":"2022-04-16T14:17:14.191137","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Download information about cryptocurrencies\ndf_about = pd.read_csv(\"../input/forecasting-top-cryptocurrencies/about_top_cryptocurrencies_1B_information.csv\", sep=\";\")\ndf_about","metadata":{"papermill":{"duration":0.104532,"end_time":"2022-04-16T14:17:14.37311","exception":false,"start_time":"2022-04-16T14:17:14.268578","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.361832Z","iopub.execute_input":"2022-04-27T09:16:13.362191Z","iopub.status.idle":"2022-04-27T09:16:13.424978Z","shell.execute_reply.started":"2022-04-27T09:16:13.362143Z","shell.execute_reply":"2022-04-27T09:16:13.423885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_rank_cryptocurrency(df_about, cryptocurrency):\n    # Get rank by Market Cap for code of the cryptocurrency\n    # df_about from the dataset from https://www.kaggle.com/datasets/vbmokin/forecasting-top-cryptocurrencies\n    \n    place = df_about.index[df_about['code'] == cryptocurrency].tolist()[0]\n    if place==0:\n        place_end = 'st'\n    elif place < 3:\n        place_end = 'nd'\n    else: place_end = 'th'\n        \n    print(f\"{df_about.loc[place, 'name']} was {place+1}{place_end}\",\n          \"among the world's cryptocurrencies by market capitalization (2022-04-11)\")","metadata":{"papermill":{"duration":0.050549,"end_time":"2022-04-16T14:17:14.463689","exception":false,"start_time":"2022-04-16T14:17:14.41314","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.42694Z","iopub.execute_input":"2022-04-27T09:16:13.427277Z","iopub.status.idle":"2022-04-27T09:16:13.436714Z","shell.execute_reply.started":"2022-04-27T09:16:13.42723Z","shell.execute_reply":"2022-04-27T09:16:13.434881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get rank by Market Cap of the cryptocurrency\nget_rank_cryptocurrency(df_about, cryptocurrency)","metadata":{"papermill":{"duration":0.05969,"end_time":"2022-04-16T14:17:14.56451","exception":false,"start_time":"2022-04-16T14:17:14.50482","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.439593Z","iopub.execute_input":"2022-04-27T09:16:13.439919Z","iopub.status.idle":"2022-04-27T09:16:13.46088Z","shell.execute_reply.started":"2022-04-27T09:16:13.439881Z","shell.execute_reply":"2022-04-27T09:16:13.459808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(cryptocurrency, date_start, date_end=None):\n    # Get data for given cryptocurrency in USD from Yahoo.finance and https://coinmarketcap.com/\n    # date_end = None means that the date_end is the current day\n    \n    if date_end is None:\n        date_end = dt.datetime.now()\n    df = web.DataReader(f'{cryptocurrency}-USD', 'yahoo', date_start, date_end)\n    df = df[['High', 'Low', 'Open', 'Close', 'Volume']].reset_index(drop=False)\n    \n    return df","metadata":{"papermill":{"duration":0.054042,"end_time":"2022-04-16T14:17:14.661516","exception":false,"start_time":"2022-04-16T14:17:14.607474","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.463449Z","iopub.execute_input":"2022-04-27T09:16:13.464298Z","iopub.status.idle":"2022-04-27T09:16:13.479175Z","shell.execute_reply.started":"2022-04-27T09:16:13.46424Z","shell.execute_reply":"2022-04-27T09:16:13.477251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download data of the cryptocurrency via API\ndata = get_data(cryptocurrency, date_start, date_end)\ndata","metadata":{"papermill":{"duration":1.993606,"end_time":"2022-04-16T14:17:16.697397","exception":false,"start_time":"2022-04-16T14:17:14.703791","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:13.481198Z","iopub.execute_input":"2022-04-27T09:16:13.481708Z","iopub.status.idle":"2022-04-27T09:16:15.427748Z","shell.execute_reply.started":"2022-04-27T09:16:13.481663Z","shell.execute_reply":"2022-04-27T09:16:15.426536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. FE <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.040146,"end_time":"2022-04-16T14:17:16.866619","exception":false,"start_time":"2022-04-16T14:17:16.826473","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_target(data):\n    # Get df and target (regression task)\n    #data['Close2'] = data['Close'].diff()                            # for classification task\n    #data['Close_growth'] = (data['Close2'] > 0).astype('int')        # for classification task\n    #data['target'] = data['Close_growth'].shift(-forecasting_days)   # for classification task\n    data['target'] = data['Close'].shift(-forecasting_days)\n    data = data.dropna().reset_index(drop=True)\n    data['target'] = data['target'].astype('int')\n    #data = data.drop(columns=['Close2', 'Close_growth', 'Volume'])   # for classification task\n    data = data.drop(columns=['Volume'])\n    target = data.pop('target')\n    return data, target","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:16:15.430278Z","iopub.execute_input":"2022-04-27T09:16:15.430573Z","iopub.status.idle":"2022-04-27T09:16:15.438722Z","shell.execute_reply.started":"2022-04-27T09:16:15.430541Z","shell.execute_reply":"2022-04-27T09:16:15.437184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data, target = get_target(data)\ndata","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:16:15.441056Z","iopub.execute_input":"2022-04-27T09:16:15.441691Z","iopub.status.idle":"2022-04-27T09:16:15.479088Z","shell.execute_reply.started":"2022-04-27T09:16:15.441639Z","shell.execute_reply":"2022-04-27T09:16:15.478043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stat_features(data):\n    # Get statistic features using library TSFRESH \n    \n    data = data.reset_index(drop=False)\n    \n    # Extract features\n    extracted_features = extract_features(data, column_id=\"index\", column_sort=\"Date\")\n    \n    # Drop features with NaN\n    extracted_features_clean = extracted_features.dropna(axis=1, how='all').reset_index(drop=True)\n    \n    # Drop features with constants\n    extracted_features_clean = extracted_features_clean.loc[:, (extracted_features_clean != extracted_features_clean.iloc[0]).any()]\n    \n    extracted_features_clean['Date'] = data['Date']   # For the merging\n    \n    return extracted_features_clean","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:16:15.480815Z","iopub.execute_input":"2022-04-27T09:16:15.481785Z","iopub.status.idle":"2022-04-27T09:16:15.491826Z","shell.execute_reply.started":"2022-04-27T09:16:15.481728Z","shell.execute_reply":"2022-04-27T09:16:15.490477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_relations_for_one_feature(data, feature):\n    # Get relations for feature in data\n    \n    df = pd.DataFrame(index=data.index)\n    df['Date'] = data['Date']   # For For the merging\n    time_intervals = [1, 2, 3, 7, 14]\n    for time_item in time_intervals:\n        df[feature+str(time_item)] = data[feature]/data[feature].shift(-time_item)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:16:15.495006Z","iopub.execute_input":"2022-04-27T09:16:15.495688Z","iopub.status.idle":"2022-04-27T09:16:15.514608Z","shell.execute_reply.started":"2022-04-27T09:16:15.495635Z","shell.execute_reply":"2022-04-27T09:16:15.513795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_math_for_one_feature(data, feature):\n    # get mathematic relations for feature in data\n    \n    #print(feature)\n    df = pd.DataFrame(index=data.index)\n    df['Date'] = data['Date']   # For the merging\n    \n    try:\n        df[feature+'_sqr'] = data[feature] ** 2\n    except: pass\n        \n    try:\n        df[feature+'_sqrt'] = data[feature] ** .5\n    except: pass\n\n    try:\n        df[feature+'_log1p'] = np.log1p(data[feature])\n    except: pass\n    \n    return df","metadata":{"papermill":{"duration":0.079283,"end_time":"2022-04-16T14:17:17.281017","exception":false,"start_time":"2022-04-16T14:17:17.201734","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:15.515924Z","iopub.execute_input":"2022-04-27T09:16:15.51691Z","iopub.status.idle":"2022-04-27T09:16:15.531621Z","shell.execute_reply.started":"2022-04-27T09:16:15.516854Z","shell.execute_reply":"2022-04-27T09:16:15.530619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features_for_one_feature(data, function_type=\"get_math_for_one_feature\"):\n    # Get features\n    \n    # Result\n    data_F = pd.DataFrame(index=data.index)\n    data_F['Date'] = data['Date']   # For the merging\n    \n    # Get features\n    data_cols = data.columns.tolist()\n    if 'Date' in data_cols:\n        data_cols.remove('Date')\n    \n    # Calculation\n    if function_type==\"get_math_for_one_feature\":\n        for col in data_cols:\n            df_i = get_math_for_one_feature(data, col)\n            #data_F = pd.concat([data_F, df_i], axis=1)\n            data_F = data_F.merge(df_i, how='left', on='Date')\n    \n    elif function_type==\"get_relations_for_one_feature\":\n        pass\n    \n    return data_F","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:16:15.533378Z","iopub.execute_input":"2022-04-27T09:16:15.53365Z","iopub.status.idle":"2022-04-27T09:16:15.548036Z","shell.execute_reply.started":"2022-04-27T09:16:15.533617Z","shell.execute_reply":"2022-04-27T09:16:15.547099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_math_for_many_features(data):\n    # get mathematic relations for OHLC-features in data\n    \n    df = pd.DataFrame(index=data.index)\n    df['Date'] = data['Date']   # For the merging\n    \n    df['Upper_Shadow'] = data['High'] - np.maximum(data['Close'], data['Open'])\n    df['Lower_Shadow'] = np.minimum(data['Close'], data['Open']) - data['Low']\n    df['high2low'] = data['High'] / data['Low']\n    \n    return df","metadata":{"papermill":{"duration":0.050872,"end_time":"2022-04-16T14:17:17.039389","exception":false,"start_time":"2022-04-16T14:17:16.988517","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:16:15.549289Z","iopub.execute_input":"2022-04-27T09:16:15.549712Z","iopub.status.idle":"2022-04-27T09:16:15.571442Z","shell.execute_reply.started":"2022-04-27T09:16:15.549677Z","shell.execute_reply":"2022-04-27T09:16:15.569919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Advanced FE\n\n# Statistic features\ndata_S = get_stat_features(data)\nprint(f'Received {data_S.shape[1]} statistic features')\n\n# One-Function features\ndata_F = get_features_for_one_feature(data)\nprint(f'Received {data_F.shape[1]} One-Function features')\n\n# Many-Functions features\ndata_Fs = get_math_for_many_features(data)\nprint(f'Received {data_Fs.shape[1]} Many-Function features')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:16:15.573611Z","iopub.execute_input":"2022-04-27T09:16:15.574007Z","iopub.status.idle":"2022-04-27T09:17:02.413354Z","shell.execute_reply.started":"2022-04-27T09:16:15.573966Z","shell.execute_reply":"2022-04-27T09:17:02.41208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Statistic features for One-Function features \ndata_SF = get_stat_features(data_F)\nprint(f'Received {data_SF.shape[1]} Statistic features for One-Function features')\n\n# Statistic features for Many-Function features \ndata_SFs = get_stat_features(data_Fs)\nprint(f'Received {data_SFs.shape[1]} Statistic features for Many-Function features')\n\n# One-Function features for Many-Functions features\ndata_FFs = get_features_for_one_feature(data_Fs)\nprint(f'Received {data_FFs.shape[1]} One-Function features for Many-Functions features')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:17:02.415555Z","iopub.execute_input":"2022-04-27T09:17:02.416118Z","iopub.status.idle":"2022-04-27T09:19:51.860019Z","shell.execute_reply.started":"2022-04-27T09:17:02.416035Z","shell.execute_reply":"2022-04-27T09:19:51.8579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_FFs.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:19:51.862111Z","iopub.execute_input":"2022-04-27T09:19:51.863088Z","iopub.status.idle":"2022-04-27T09:19:51.888486Z","shell.execute_reply.started":"2022-04-27T09:19:51.863028Z","shell.execute_reply":"2022-04-27T09:19:51.885669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data_for_training(df, test_option, test_size):\n    # Get test and training datasets\n    # test_option = \"end\" for prediction problem or \"random\" for EDA\n    # test_size in days in the end of the time interval for prediction problem (test_option = \"random\")\n    # test_size in part of the days in all data (1 = 100%) for EDA problem (test_option = \"end\")\n    \n    df = df.drop(columns = ['Date'])\n    df = df.dropna(how=\"any\")\n    y = df.pop('target')\n    \n    # Standartization data\n    scaler = StandardScaler()\n    df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n    #display(df)\n\n    if test_option == \"random\":\n        train, test, ytrain, ytest = train_test_split(df, y, test_size=test_size, random_state=random_state)\n    else:\n        # test_option == \"end\"\n        train_len = len(df)-test_size\n        test = df[train_len:]\n        train = df[:train_len]\n        ytest = y[train_len:]\n        ytrain = y[:train_len]\n        \n    print(f'Get training dataset with {len(train)} rows and test dataset with {len(test)} rows for test option - \"{test_option}\"')\n    \n    return train, test, ytrain, ytest","metadata":{"papermill":{"duration":0.05558,"end_time":"2022-04-16T14:17:17.380577","exception":false,"start_time":"2022-04-16T14:17:17.324997","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:19:51.890895Z","iopub.execute_input":"2022-04-27T09:19:51.891312Z","iopub.status.idle":"2022-04-27T09:19:51.905377Z","shell.execute_reply.started":"2022-04-27T09:19:51.891271Z","shell.execute_reply":"2022-04-27T09:19:51.904452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(data_frames, target, forecasting_days):\n    # Get data for training from list of dataframes with id in 'Date'\n    \n    for i in range(len(data_frames)):\n        if 'target' in data_frames[i].columns.tolist():\n            data_frames[i] = data_frames[i].drop(columns=['target'])\n    \n    df = reduce(lambda left, right: pd.merge(left,right,on=['Date'], \n                                             how='left'), data_frames)\n    print(f'Total received {df.shape[1]} features')\n    \n    df['target'] = target\n    \n    train, test, target_train, target_test = get_data_for_training(df, 'end', forecasting_days)\n    \n    return train, test, target_train, target_test","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:19:51.906699Z","iopub.execute_input":"2022-04-27T09:19:51.907067Z","iopub.status.idle":"2022-04-27T09:19:51.927052Z","shell.execute_reply.started":"2022-04-27T09:19:51.907011Z","shell.execute_reply":"2022-04-27T09:19:51.924969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Model training and prediction <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.043629,"end_time":"2022-04-16T14:17:17.674294","exception":false,"start_time":"2022-04-16T14:17:17.630665","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def print_acc(x,y):\n    # Calculation and printing errors and metrics for list with real values x and prediction values y\n    # Metrics: r2_score, the relative error (WAPE), RMSE\n    \n    def error_wape(x,y):\n        # Calculation of the relative error for list with real values x and prediction values y\n        return mean_absolute_error(x,y)*len(x)/sum(x)\n\n    r2 = round(r2_score(x, y),4)\n    wape = round(100*error_wape(x,y),2)\n    rmse = round(mean_squared_error(x,y, squared=False),4)\n    print(f\"Errors: r2_score - {r2}, relative error (WAPE) - {wape}%, RMSE - {rmse}\")\n    \n    return r2, wape, rmse","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:19:51.9315Z","iopub.execute_input":"2022-04-27T09:19:51.932076Z","iopub.status.idle":"2022-04-27T09:19:51.948059Z","shell.execute_reply.started":"2022-04-27T09:19:51.932035Z","shell.execute_reply":"2022-04-27T09:19:51.947029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xgb_training(train, target_train):\n    # XGB Regressor Training\n    \n    xgbr = xgb.XGBRegressor() \n    param_grid_xgb = {'max_depth': [5],\n                      'n_estimators': [50], \n                      'learning_rate': [0.05],\n                      'random_state': [random_state]}\n    \n    # Training model\n    xgb_CV = GridSearchCV(xgbr, param_grid=param_grid_xgb, cv=3, verbose=False)\n    xgb_CV.fit(train, target_train)\n    \n    return xgb_CV","metadata":{"papermill":{"duration":0.058586,"end_time":"2022-04-16T14:17:17.862615","exception":false,"start_time":"2022-04-16T14:17:17.804029","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-27T09:19:51.949681Z","iopub.execute_input":"2022-04-27T09:19:51.950125Z","iopub.status.idle":"2022-04-27T09:19:51.967168Z","shell.execute_reply.started":"2022-04-27T09:19:51.950082Z","shell.execute_reply":"2022-04-27T09:19:51.96585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(res, res_acc, data_frames, target, forecasting_days, col_name):\n    # Model tuning and prediction for given list of the dataframes and save it into res[col_name]\n    # Errors save into dataframe res_acc\n    \n    print(col_name)\n    train, test, target_train, target_test = get_data(data_frames, target, forecasting_days)\n    \n    # Model tuning\n    model = xgb_training(train, target_train)\n    \n    # Prediction of test data\n    ypred_test = model.predict(test)\n    res[col_name] = ypred_test\n    \n    # Errors\n    _, wape, rmse = print_acc(target_test, ypred_test)\n    n = len(res_acc)\n    res_acc.loc[n,'FE_model'] = col_name\n    res_acc.loc[n,'WAPE'] = wape\n    res_acc.loc[n,'RMSE'] = rmse\n    \n    return res, res_acc","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:19:51.968836Z","iopub.execute_input":"2022-04-27T09:19:51.969405Z","iopub.status.idle":"2022-04-27T09:19:51.987628Z","shell.execute_reply.started":"2022-04-27T09:19:51.969355Z","shell.execute_reply":"2022-04-27T09:19:51.985733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test predictions of the models\nres_pred = pd.DataFrame()\ntarget_test = target[(len(target)-forecasting_days):]\nres_pred['test_target'] = target_test\n\nres_acc = pd.DataFrame(columns = ['FE_model', 'WAPE', 'RMSE'])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:19:51.98946Z","iopub.execute_input":"2022-04-27T09:19:51.99043Z","iopub.status.idle":"2022-04-27T09:19:52.021282Z","shell.execute_reply.started":"2022-04-27T09:19:51.990371Z","shell.execute_reply":"2022-04-27T09:19:52.020199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Statistic features\nres_pred, res_acc = main(res_pred, res_acc, [data_S], target, forecasting_days, 'S')\n\n# One-Function features\nres_pred, res_acc = main(res_pred, res_acc, [data_F], target, forecasting_days, 'F')\n\n# Many-Functions features\nres_pred, res_acc = main(res_pred, res_acc, [data_Fs], target, forecasting_days, 'Fs')\n\n# Statistic features for One-Function features \nres_pred, res_acc = main(res_pred, res_acc, [data_SF], target, forecasting_days, 'SF')\n\n# Statistic features for Many-Function features \nres_pred, res_acc = main(res_pred, res_acc, [data_SFs], target, forecasting_days, 'SFs')\n\n# One-Function features for Many-Functions features\nres_pred, res_acc = main(res_pred, res_acc, [data_FFs], target, forecasting_days, 'FFs')\n\n# S, SF\nres_pred, res_acc = main(res_pred, res_acc, [data_S, data_SF], target, forecasting_days, 'S_SF')\n\n# F, SF\nres_pred, res_acc = main(res_pred, res_acc, [data_F, data_SF], target, forecasting_days, 'F_SF')\n\n# F, Fs, FFs\nres_pred, res_acc = main(res_pred, res_acc, [data_F, data_Fs, data_FFs], target, forecasting_days, 'F_Fs_FFs')\n\n# All features\ndata_frames = [data_S, data_F, data_Fs, data_SF, data_SFs, data_FFs]\nres_pred, res_acc = main(res_pred, res_acc, data_frames, target, forecasting_days, 'All features')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:19:52.023041Z","iopub.execute_input":"2022-04-27T09:19:52.023408Z","iopub.status.idle":"2022-04-27T09:20:13.952839Z","shell.execute_reply.started":"2022-04-27T09:19:52.023354Z","shell.execute_reply":"2022-04-27T09:20:13.952061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(res_pred)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:20:13.954369Z","iopub.execute_input":"2022-04-27T09:20:13.95483Z","iopub.status.idle":"2022-04-27T09:20:13.978785Z","shell.execute_reply.started":"2022-04-27T09:20:13.954781Z","shell.execute_reply":"2022-04-27T09:20:13.977701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_acc.columns = ['FE_model', 'WAPE,%', 'RMSE']\ndisplay(res_acc.sort_values(['WAPE,%', 'RMSE']))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:20:13.98052Z","iopub.execute_input":"2022-04-27T09:20:13.981545Z","iopub.status.idle":"2022-04-27T09:20:13.99665Z","shell.execute_reply.started":"2022-04-27T09:20:13.981492Z","shell.execute_reply":"2022-04-27T09:20:13.995457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = res_acc['FE_model'].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:20:13.999012Z","iopub.execute_input":"2022-04-27T09:20:13.999304Z","iopub.status.idle":"2022-04-27T09:20:14.014557Z","shell.execute_reply.started":"2022-04-27T09:20:13.999271Z","shell.execute_reply":"2022-04-27T09:20:14.012288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building plot for prediction for the test data \nx = np.arange(len(target_test))\nplt.figure(figsize=(12,8))\nplt.plot(x, target_test, label = \"Target values of the test data\", color = 'g')\nfor model_name in models:\n    plt.plot(x, res_pred[model_name], label = model_name)\nplt.title('Prediction for the test data - relative errors (WAPE), %')\nplt.legend(loc='best')\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T09:20:14.016858Z","iopub.execute_input":"2022-04-27T09:20:14.01727Z","iopub.status.idle":"2022-04-27T09:20:14.441616Z","shell.execute_reply.started":"2022-04-27T09:20:14.017217Z","shell.execute_reply":"2022-04-27T09:20:14.440594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.","metadata":{"papermill":{"duration":0.054271,"end_time":"2022-04-16T14:17:45.893957","exception":false,"start_time":"2022-04-16T14:17:45.839686","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"[Go to Top](#0)","metadata":{"papermill":{"duration":0.052551,"end_time":"2022-04-16T14:17:45.997117","exception":false,"start_time":"2022-04-16T14:17:45.944566","status":"completed"},"tags":[]}}]}