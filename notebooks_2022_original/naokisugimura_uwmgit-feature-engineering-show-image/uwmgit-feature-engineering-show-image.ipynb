{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport cv2\nfrom matplotlib.patches import Rectangle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T13:29:59.924276Z","iopub.execute_input":"2022-05-07T13:29:59.925237Z","iopub.status.idle":"2022-05-07T13:29:59.95809Z","shell.execute_reply.started":"2022-05-07T13:29:59.925168Z","shell.execute_reply":"2022-05-07T13:29:59.957025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:29:59.959788Z","iopub.execute_input":"2022-05-07T13:29:59.960262Z","iopub.status.idle":"2022-05-07T13:30:00.300648Z","shell.execute_reply.started":"2022-05-07T13:29:59.960222Z","shell.execute_reply":"2022-05-07T13:30:00.299951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:00.301732Z","iopub.execute_input":"2022-05-07T13:30:00.302228Z","iopub.status.idle":"2022-05-07T13:30:00.325147Z","shell.execute_reply.started":"2022-05-07T13:30:00.302188Z","shell.execute_reply":"2022-05-07T13:30:00.32436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RLE decoder and encoder","metadata":{}},{"cell_type":"markdown","source":"Inspired by [UWMGI: Mask Data](https://www.kaggle.com/code/awsaf49/uwmgi-mask-data)","metadata":{}},{"cell_type":"code","source":"def rle_decoder(size, mask):\n    mask_list = np.asarray(mask.split(), dtype=int)\n    starts = mask_list[0::2] - 1\n    lengths = mask_list[1::2]\n    ends = starts + lengths\n    img = np.zeros(size[0]*size[1], dtype=np.uint8)\n    for i, j in zip(starts, ends):\n        img[i:j] = 1\n    return img.reshape(size)  # Return  the image which annotation value is 1\n    \n\ndef rle_encoder(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:00.327024Z","iopub.execute_input":"2022-05-07T13:30:00.327668Z","iopub.status.idle":"2022-05-07T13:30:00.339233Z","shell.execute_reply.started":"2022-05-07T13:30:00.327616Z","shell.execute_reply":"2022-05-07T13:30:00.337404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Inspired by [Detailed data visualization for beignners](https://www.kaggle.com/code/subinek/detailed-data-visualization-for-beignners)","metadata":{}},{"cell_type":"markdown","source":"return data\n\n* Path\n* CaseNum_Day\n* SliceNum\n* Case\n* Day\n* Slice\n* Height\n* Width\n* id\n* class\n* segmentation (encode)","metadata":{}},{"cell_type":"code","source":"def feat_eng():\n    #Generate the list of images\n    images_list = glob('../input/uw-madison-gi-tract-image-segmentation/train/*/*/scans/*.png')\n\n    #extract details from the path\n    images_metadata = pd.DataFrame({'Path':images_list})\n\n\n    \n    #split the path to get individual parameters\n    path_split = images_metadata['Path'].str.split('/',n=7,expand=True)\n    \n\n    #we need to extract [5] and [7]\n    images_metadata['CaseNum_Day'] = path_split[5]\n    images_metadata['SliceNum'] = path_split[7]\n\n    #Resplitting to extract case, day, slice, height and width\n    case_split = images_metadata['CaseNum_Day'].str.split('_',n=2, expand=True)\n    images_metadata['Case'] = case_split[0].str[4:].astype(int)\n    images_metadata['Day'] = case_split[1].str[3:].astype(int)\n\n    #Resplitting to extract slice, height and width\n    fileName_split = images_metadata['SliceNum'].str.split('_',n=6, expand=True)\n    images_metadata['Slice'] = fileName_split[1].astype(int)\n    images_metadata['Height'] = fileName_split[2].astype(int)\n    images_metadata['Width'] = fileName_split[3].astype(int)\n    \n    images_metadata['id'] = path_split[5] + '_slice_' + fileName_split[1]\n    \n    # merge train.csv and images_metadata\n    df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\n    \n    df = pd.merge(images_metadata, df, on='id')\n    \n    # remove null mask row\n    df = df[df['segmentation'].notnull()] \n    df = df.reset_index(drop=True)\n    \n    a = df.groupby(['id'])['segmentation'].apply(list)\n    b = df.groupby(['id'])['class'].apply(list)\n    \n    dataframe = pd.DataFrame({'id':df.id.unique()})\n    dataframe = pd.merge(dataframe, a, on = 'id')    \n    dataframe = pd.merge(dataframe, b, on = 'id')    \n    dataframe = pd.merge(dataframe, df, on = 'id')   \n    dataframe = dataframe.drop(['class_y', 'segmentation_y'], axis = 1)\n    dataframe = dataframe.rename(columns={'segmentation_x': 'segmentation', 'class_x': 'class'})\n\n    return  dataframe","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:00.341903Z","iopub.execute_input":"2022-05-07T13:30:00.342837Z","iopub.status.idle":"2022-05-07T13:30:00.359257Z","shell.execute_reply.started":"2022-05-07T13:30:00.342778Z","shell.execute_reply":"2022-05-07T13:30:00.358477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = feat_eng()\na","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:00.360326Z","iopub.execute_input":"2022-05-07T13:30:00.36109Z","iopub.status.idle":"2022-05-07T13:30:02.770372Z","shell.execute_reply.started":"2022-05-07T13:30:00.361042Z","shell.execute_reply":"2022-05-07T13:30:02.769231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# show image","metadata":{}},{"cell_type":"markdown","source":"Inspired by [UWMGI: Mask Data](https://www.kaggle.com/code/awsaf49/uwmgi-mask-data)","metadata":{}},{"cell_type":"code","source":"def load_img(path):\n    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n    img = img.astype('float32') # original is uint16\n    img = (img - img.min())/(img.max() - img.min())*255.0 # scale image to [0, 255]\n    img = img.astype('uint8')\n#     img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n    return img\n\ndef shows(img, mask=None):\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    img = clahe.apply(img)\n#     plt.figure(figsize=(10,10))\n    plt.imshow(img, cmap='bone')\n    \n    if mask is not None:\n        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n        plt.imshow(mask, alpha=0.5)\n        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n        labels = [ \"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n        plt.legend(handles,labels)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:02.773566Z","iopub.execute_input":"2022-05-07T13:30:02.773847Z","iopub.status.idle":"2022-05-07T13:30:02.785161Z","shell.execute_reply.started":"2022-05-07T13:30:02.773816Z","shell.execute_reply":"2022-05-07T13:30:02.783788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_img(idx):\n    train_df = feat_eng()\n#     classes = dict(zip(train_df['class'].unique(), [0,1,2]))\n    row = train_df.iloc[idx]\n    path = row['Path']\n    size = (row['Height'], row['Width'])\n    part = row['class']\n    seg = row['segmentation']\n    img = load_img(path)\n    seg_dict = dict(zip(part,seg))\n    ans = 0\n    zero_img = np.zeros(size, dtype=np.uint8)\n    if 'large_bowel' in list(seg_dict.keys()):\n        label = seg_dict['large_bowel']\n        label = rle_decoder(size, label)\n        l_label = np.stack([label, zero_img, zero_img], axis=-1)\n        ans += l_label\n    if 'small_bowel' in list(seg_dict.keys()):\n        label = seg_dict['small_bowel']\n        label = rle_decoder(size, label)\n        s_label = np.stack([zero_img, label, zero_img], axis=-1)\n        ans += s_label\n    if 'stomach' in list(seg_dict.keys()):\n        label = seg_dict['stomach']\n        label = rle_decoder(size, label)\n        st_label = np.stack([zero_img, zero_img, label], axis=-1)\n        ans += st_label\n    ans *=255\n    plt.title(f'{part}')\n    shows(img, ans)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:02.786784Z","iopub.execute_input":"2022-05-07T13:30:02.787422Z","iopub.status.idle":"2022-05-07T13:30:02.806273Z","shell.execute_reply.started":"2022-05-07T13:30:02.787377Z","shell.execute_reply":"2022-05-07T13:30:02.805013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img(1)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:02.808855Z","iopub.execute_input":"2022-05-07T13:30:02.809737Z","iopub.status.idle":"2022-05-07T13:30:05.2894Z","shell.execute_reply.started":"2022-05-07T13:30:02.809683Z","shell.execute_reply":"2022-05-07T13:30:05.288358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# datasets","metadata":{}},{"cell_type":"code","source":"def mklabel(seg_dict, size):\n    ans = 0\n    zero_img = np.zeros(size, dtype=np.uint8)\n    if 'large_bowel' in list(seg_dict.keys()):\n        label = seg_dict['large_bowel']\n        label = rle_decoder(size, label)\n        l_label = np.stack([label, zero_img, zero_img], axis=-1)\n        ans += l_label\n    if 'small_bowel' in list(seg_dict.keys()):\n        label = seg_dict['small_bowel']\n        label = rle_decoder(size, label)\n        s_label = np.stack([zero_img, label, zero_img], axis=-1)\n        ans += s_label\n    if 'stomach' in list(seg_dict.keys()):\n        label = seg_dict['stomach']\n        label = rle_decoder(size, label)\n        st_label = np.stack([zero_img, zero_img, label], axis=-1)\n        ans += st_label\n    return label","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:05.292561Z","iopub.execute_input":"2022-05-07T13:30:05.293745Z","iopub.status.idle":"2022-05-07T13:30:05.304348Z","shell.execute_reply.started":"2022-05-07T13:30:05.293693Z","shell.execute_reply":"2022-05-07T13:30:05.303315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torchvision.io import read_image\nfrom torchvision.transforms import ToTensor\n\nclass UWMGITdatasets(Dataset):\n    def __init__(self, transform = None):\n        self.df = feat_eng()\n        self.img_path = self.df['Path']\n        self.classes = self.df['class']\n        self.seg = self.df['segmentation']\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        self.seg_dict = dict(zip(self.classes[idx], self.seg[idx]))\n        self.size = (self.df.loc[idx,'Height'], self.df.loc[idx,'Width'])\n        self.label = mklabel(seg_dict = self.seg_dict, size = self.size)\n        self.img = read_image(self.img_path[idx])\n        self.label = ToTensor(self.label)\n        self.label = self.img + self.label\n        \n#         if self.transform:\n#             out_data = self.transform(out_data)\n\n        return self.img, self.label","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:05.306047Z","iopub.execute_input":"2022-05-07T13:30:05.306559Z","iopub.status.idle":"2022-05-07T13:30:05.323264Z","shell.execute_reply.started":"2022-05-07T13:30:05.306513Z","shell.execute_reply":"2022-05-07T13:30:05.322309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = feat_eng()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:05.324823Z","iopub.execute_input":"2022-05-07T13:30:05.325268Z","iopub.status.idle":"2022-05-07T13:30:07.673852Z","shell.execute_reply.started":"2022-05-07T13:30:05.32522Z","shell.execute_reply":"2022-05-07T13:30:07.672826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = a.loc[1,'Path']","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:21.395094Z","iopub.execute_input":"2022-05-07T13:30:21.395427Z","iopub.status.idle":"2022-05-07T13:30:21.412855Z","shell.execute_reply.started":"2022-05-07T13:30:21.395393Z","shell.execute_reply":"2022-05-07T13:30:21.411511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:19.185089Z","iopub.execute_input":"2022-05-07T13:30:19.185895Z","iopub.status.idle":"2022-05-07T13:30:19.203483Z","shell.execute_reply.started":"2022-05-07T13:30:19.185851Z","shell.execute_reply":"2022-05-07T13:30:19.202398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"read_image(d)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T13:30:14.957855Z","iopub.execute_input":"2022-05-07T13:30:14.95862Z","iopub.status.idle":"2022-05-07T13:30:14.974501Z","shell.execute_reply.started":"2022-05-07T13:30:14.958581Z","shell.execute_reply":"2022-05-07T13:30:14.973131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}