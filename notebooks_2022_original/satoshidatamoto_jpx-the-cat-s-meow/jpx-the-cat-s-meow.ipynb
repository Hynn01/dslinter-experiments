{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":">### PurgedGroupTimeSeries CV - Catboost Version\n>This is a simple starter notebook for Kaggle's JPX Comp showing purged group timeseries KFold with extra data. Purged Times Series is explained [here][1]. There are many configuration variables below to allow you to experiment. Use either CPU or GPU. You can control which years are loaded, which type of models are used, and whether to use feature engineering. You can experiment with different data preprocessing, model hyperparameters, loss, and number of seeds to ensemble. The extra datasets contain the full history of the assets at the same format of the competition, so you can input that into your model too.\n>\n>**NOTE:** this notebook lets you run a different experiment in each fold if you want to run lots of experiments. (Then it is like running multiple holdout validation experiments but in that case note that the overall CV score is meaningless because LB will be much different when the multiple experiments are ensembled to predict test). **If you want a proper CV with a reliable overall CV score you need to choose the same configuration for each fold.**\n>\n\n[1]: TBD","metadata":{"_cell_guid":"8af163ff-915a-4fae-aefe-6447e64952e5","_uuid":"b328cc9e-a536-4347-beed-d033e9f5ac6a","papermill":{"duration":0.028098,"end_time":"2021-11-29T16:04:40.679773","exception":false,"start_time":"2021-11-29T16:04:40.651675","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<center><img src=\"https://i.ibb.co/pRVvYsf/images.png\" height=250 width=250></center>\n<hr>\n\nCatboost is among the most used algorithms on kaggle and it doesn't look like it is going anywhere soon!\nIt is basiclly a version of gradient boosting machines framework that aims to increases efficiency, speed and performance. \n\n**It is usually one of the main algorithms everyone on Kaggle try when facing a tabular dataset**\n\n><h4>TL;DR: What makes Catboost so great:</h4>\n>\n>1. LGBM was developed and maintained by Yandex themselves so it gets constant maintenance and support.\n>2. Easy to use.\n>3. It is fast.\n>4. A Powerful gradient boosting. \n\n\n<h3>The CatBoost Algorithm</h3>\n\nCatBoost does gradient boosting in a very elegant manner. Below is an explanation of CatBoost using a toy example\n\nLet‚Äôs say, we have 10 data points in our dataset and are ordered in time as shown below.\n\n<img src=\"https://miro.medium.com/max/303/1*K-2XayuU9Y4OklIlDWg1AQ.png\"></img>\n\n> If data doesn‚Äôt have time, CatBoost randomly creates an artificial time for each datapoint.\n\n* **Step 1:** Calculate residuals for each datapoint using a model that has been trained on all the other data points at that time (For Example, to calculate residual for x5 datapoint, we train one model using x1, x2, x3 and x4 ). Hence we train different models for different data points . At the end we are calculating residuals for each datapoint that it‚Äôs corresponding model has never seen that datapoint before.\n* **Step 2:** Train the model using the residuals of each datapoint\n* **Step 3:** Repeat Step 1 & Step 2 (for n iterations)\n\nFor the above toy dataset, we should train 9 different models to get residuals for 9 data points. This is computationally expensive when we have more number of data points.\nHence by default, instead of training different model for each datapoint, it trains only log(num_of_datapoints) models. Now if a model has been trained on n data points then that model is used to calculate residuals for the next n data points.\n\n* A model that has been trained on first data point is used for calculating residuals of second data point.\n* An another model that has been trained on the first two data points is used for calculating residuals of third and fourth data points\n\nIn the above toy dataset, now we calculate residuals of x5,x6,x7 and x8 using a model that has been trained on x1, x2,x3 and x4.\n\nAll this procedure that I have explained until now is known as ordered boosting\n\n<h4>Random Permutations:</h4>\n\nCatBoost actually divides a given dataset into random permutations and apply ordered boosting on those random permutations. By default CatBoost creates four random permutations. With this randomness we can further stop overfitting our model. We can further control this randomness by tuning parameter bagging_temperature. This is something that you have already seen in other boosting algorithms\n\n<h4>Leaf growth algorithm in CatBoost</h4>\n\nCatboost grows a balanced tree. In each level of such a tree, the feature-split pair that brings to the lowest loss (according to a penalty function) is selected and is used for all the level‚Äôs nodes. It is possible to change its policy using the grow-policy parameter.`\n\n<h4>Categorical Feature Handling</h4>\n\nMost of the GBDT algorithms and Kaggle competitors are already familiar with the use of Target Statistic (or target mean encoding).\n\n> It‚Äôs a simple yet effective approach in which we encode each categorical feature with the estimate of the expected target y conditioned by the category.\n\nWell, it turns out that applying this encoding carelessly (average value of y over the training examples with the same category) results in a target leakage.\n\nTo fight this prediction shift CatBoost uses a more effective strategy. It relies on the ordering principle and is inspired by online learning algorithms which get training examples sequentially in time. In this setting, the values of TS for each example rely only on the observed history.\n\nTo adapt this idea to a standard offline setting, Catboost introduces an artificial ‚Äútime‚Äù‚Äî a random permutation œÉ1 of the training examples.\n\nThen, for each example, it uses all the available ‚Äúhistory‚Äù to compute its Target Statistic.\nNote that, using only one random permutation, results in preceding examples with higher variance in Target Statistic than subsequent ones. To this end, CatBoost uses different permutations for different steps of gradient boosting.\n\n<h4>One-Hot Encoding:</h4>\n\n- By default, CatBoost internally represents all the categorical features with One-hot encoding if and only if a categorical feature has two different categories.\n\n- If you would like to implement One-hot encoding on a categorical feature that has N different categories then you can change parameter one_hot_max_size = N.\n\n\n<h4>Handling Numerical Features</h4>\n\nCatBoost handle the numerical features in the same way that other tree algorithms do. We select the best possible split based on the Information Gain.\n\n<h4>The Secret of CatBoost</h4>\n\nCatboost introduces two critical algorithmic advances - the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features.\nBoth techniques are using random permutations of the training examples to fight the prediction shift caused by a special kind of target leakage present in all existing implementations of gradient boosting algorithms.\n\n____\n\n\n<h4>Tuning CatBoost</h4>\n\n- **cat_features** ‚Äî This parameter is a must in order to leverage Catboost preprocessing of categorical features, if you encode the categorical features yourself and don‚Äôt pass the columns indices as cat_features you are missing the essence of Catboost.\n\n- **one_hot_max_size** - As Catboost uses one-hot encoding for all features with at most one_hot_max_size unique values. In our case, the categorical features have a lot of unique values, so we won‚Äôt use \none hot encoding, but depending on the dataset it may be a good idea to adjust this parameter.\n\n- **learning_rate & n_estimators** ‚Äî The smaller the learning_rate, the more n_estimators needed to utilize the model. Usually, the approach is to start with a relative high learning_rate, tune other parameters and then decrease the \nlearning_rate while increasing n_estimators.\n\n- **max_depth** ‚Äî Depth of the base trees, this parameter has an high impact on training time.\n\n- **subsample** ‚Äî Sample rate of rows, can‚Äôt be used in a Bayesian boosting type setting.\n\n- **colsample_bylevel**, **colsample_bytree**, **colsample_bynode**‚Äî Sample rate of columns.\n\n- **l2_leaf_reg** ‚Äî L2 regularization coefficient\n\n- **random_strength** ‚Äî Every split gets a score and random_strength is adding some randomness to the score, it helps to reduce overfitting.\n\n____\n\n\n<div class=\"alert alert-block alert-warning\">\n<b>Introduction Credits:</b>\n<ul>\n    <li><a href = \"https://www.kaggle.com/shivansh002/your-friendly-neighbour-lightgbm\">Your Friendly Neighbour LightGBM</a> By @shivansh002. Thank you @shivansh002 for a great introduction! </li>\n    <li><a href = \"https://www.kaggle.com/abhinand05/catboost-a-deeper-dive\">CatBoost: A Deeper Dive</a> By @abhinand05. Thank you @abhinand05 for a great deep dive! </li>\n</ul>\n</div>","metadata":{"papermill":{"duration":0.028816,"end_time":"2021-11-29T16:04:41.215682","exception":false,"start_time":"2021-11-29T16:04:41.186866","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#### Code starts here ‚¨á","metadata":{}},{"cell_type":"code","source":"import os\nimport traceback\nimport seaborn as sns\nfrom scipy.stats import pearsonr\nimport pandas as pd, numpy as np\nimport jpx_tokyo_market_prediction\nfrom sklearn.metrics import r2_score\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_squared_error","metadata":{"papermill":{"duration":1.362436,"end_time":"2021-11-29T16:04:42.724071","exception":false,"start_time":"2021-11-29T16:04:41.361635","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:06:01.323289Z","iopub.execute_input":"2022-04-23T10:06:01.323602Z","iopub.status.idle":"2022-04-23T10:06:02.518531Z","shell.execute_reply.started":"2022-04-23T10:06:01.323523Z","shell.execute_reply":"2022-04-23T10:06:02.517818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"config\">Configuration üéöÔ∏è</span>\n<hr >\n\nIn order to be a proper cross validation with a meaningful overall CV score, **you need to choose the same** `INC2022`, `INC2021`, `INC2020`, `INC2019`, `INC2018`, `INC2017`, `INCCOMP`, `INCSUPP`, and `NUM_LEAVES`, `MAX_DEPTH` **for each fold**. If your goal is to just run lots of experiments, then you can choose to have a different experiment in each fold. Then each fold is like a holdout validation experiment. When you find a configuration you like, you can use that configuration for all folds.\n* DEVICE - is CPU or GPU\n* SEED - a different seed produces a different triple stratified kfold split.\n* FOLDS - number of folds. Best set to 3, 5, or 15 but can be any number between 2 and 15\n* LOAD_STRICT - This controls whether to load strict at proposed [here](https://www.kaggle.com/julian3833/proposal-for-a-meaningful-lb-strict-lgbm)\n* INC2022 - This controls whether to include the extra historical prices during 2022.\n* INC2021 - This controls whether to include the extra historical prices during 2021.\n* INC2020 - This controls whether to include the extra historical prices during 2020.\n* INC2019 - This controls whether to include the extra historical prices during 2019.\n* INC2018 - This controls whether to include the extra historical prices during 2018.\n* INC2017 - This controls whether to include the extra historical prices during 2017.\n* INCSUPP - This controls whether to include the supplemented train data that was released with the competition.\n* N_ESTIMATORS - is a list of length FOLDS. These are n_estimators for each fold. For maximum speed, it is best to use the smallest number of estimators as your GPU or CPU allows.\n* MAX_DEPTH - is a list of length FOLDS. These are max_depth for each fold. For maximum speed, it is best to use the smallest number of estimators as your GPU or CPU allows.\n* LEARNING_RATE - is a list of length FOLDS. These are max_depth for each fold. For maximum speed, it is best to use the smallest number of estimators as your GPU or CPU allows.","metadata":{}},{"cell_type":"code","source":"DEVICE = \"CPU\" #or \"GPU\"\n\nSEED = 42\n\n# CV PARAMS\nFOLDS = 5\nGROUP_GAP = 130\nMAX_TEST_GROUP_SIZE = 180\nMAX_TRAIN_GROUP_SIZE = 280\n\n# WHICH YEARS TO INCLUDE? YES=1 NO=0\nINC2022 = 1\nINC2021 = 1\nINC2020 = 1\nINC2019 = 1\nINC2018 = 1\nINC2017 = 1\nINCSUPP = 1\n\n# HYPER PARAMETERS\nLEARNING_RATE = [0.09, 0.09, 0.09, 0.09, 0.09]\nN_ESTIMATORS = [1000, 1000, 1000, 1000, 1000]\nMAX_DEPTH = [10, 10, 10, 10, 10]","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":0.038783,"end_time":"2021-11-29T16:04:42.851285","exception":false,"start_time":"2021-11-29T16:04:42.812502","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:06:02.520086Z","iopub.execute_input":"2022-04-23T10:06:02.521379Z","iopub.status.idle":"2022-04-23T10:06:02.527509Z","shell.execute_reply.started":"2022-04-23T10:06:02.52134Z","shell.execute_reply":"2022-04-23T10:06:02.526395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"loading\">Data Loading üóÉÔ∏è</span>\n<hr>\n\nHere we choose which years to load. We can use either 2017, 2018, 2019, 2020, 2021, Original, Supplement by changing the `INC2021`, `INC2020`, `INC2019`, `INC2018`, `INC2017`, `INCSUPP` variables in the preceeding code section. These datasets are discussed [here][1].\n\n[1]: TBD","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-11-29T16:04:42.971486Z","iopub.status.busy":"2021-11-29T16:04:42.97045Z","iopub.status.idle":"2021-11-29T16:05:08.113562Z","shell.execute_reply":"2021-11-29T16:05:08.11296Z","shell.execute_reply.started":"2021-11-07T07:23:23.943091Z"},"papermill":{"duration":25.175522,"end_time":"2021-11-29T16:05:08.11372","exception":false,"start_time":"2021-11-29T16:04:42.938198","status":"completed"},"pycharm":{"name":"#%% md\n"},"tags":[]}},{"cell_type":"code","source":"stock_list = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")\nprices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")\nstock_list = stock_list.loc[stock_list['SecuritiesCode'].isin(prices['SecuritiesCode'].unique())]\nstock_name_dict = {stock_list['SecuritiesCode'].tolist()[idx]: stock_list['Name'].tolist()[idx] for idx in range(len(stock_list))}\n\ndef load_training_data(asset_id = None):\n    prices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")\n    supplemental_prices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\")\n    df_train = pd.concat([prices, supplemental_prices]) if INCSUPP else prices\n    df_train = pd.merge(df_train, stock_list[['SecuritiesCode', 'Name']], left_on = 'SecuritiesCode', right_on = 'SecuritiesCode', how = 'left')\n    df_train['date'] = pd.to_datetime(df_train['Date'])\n    df_train['year'] = df_train['date'].dt.year\n    if not INC2022: df_train = df_train.loc[df_train['year'] != 2022]\n    if not INC2021: df_train = df_train.loc[df_train['year'] != 2021]\n    if not INC2020: df_train = df_train.loc[df_train['year'] != 2020]\n    if not INC2019: df_train = df_train.loc[df_train['year'] != 2019]\n    if not INC2018: df_train = df_train.loc[df_train['year'] != 2018]\n    if not INC2017: df_train = df_train.loc[df_train['year'] != 2017]\n    # asset_id = 1301 # Remove before flight\n    if asset_id is not None: df_train = df_train.loc[df_train['SecuritiesCode'] == asset_id]\n    # df_train = df_train[:1000] # Remove before flight\n    return df_train","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2022-04-23T10:06:02.528872Z","iopub.execute_input":"2022-04-23T10:06:02.529408Z","iopub.status.idle":"2022-04-23T10:06:07.929352Z","shell.execute_reply.started":"2022-04-23T10:06:02.529369Z","shell.execute_reply":"2022-04-23T10:06:07.928607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"features\">Feature Engineering üî¨</span>\n<hr>\n\nThis notebook uses upper_shadow, lower_shadow, high_div_low, open_sub_close, seasonality/datetime features first shown in this notebook [here][1] and successfully used by julian3833 [here][2].\n\nAdditionally we can decide to use external data by changing the variables `INC2021`, `INC2020`, `INC2019`, `INC2018`, `INC2017`, `INCCOMP`, `INCSUPP` in the preceeding code section. These variables respectively indicate whether to load last year 2021 data and/or year 2020, 2019, 2018, 2017, the original, supplemented data. These datasets are discussed [here][3]\n\nConsider experimenting with different feature engineering and/or external data. The code to extract features out of the dataset is taken from julian3833' notebook [here][2]. Thank you julian3833, this is great work.\n\n[1]: https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition\n[2]: https://www.kaggle.com/julian3833\n[3]: TBD","metadata":{"papermill":{"duration":0.029505,"end_time":"2021-11-29T16:05:08.174071","exception":false,"start_time":"2021-11-29T16:05:08.144566","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def upper_shadow(df): return df['High'] - np.maximum(df['Close'], df['Open'])\ndef lower_shadow(df): return np.minimum(df['Close'], df['Open']) - df['Low']\n\ndef get_features(df):\n    df_feat = df[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n    df_feat['upper_Shadow'] = upper_shadow(df_feat)\n    df_feat['lower_Shadow'] = lower_shadow(df_feat)\n    df_feat[\"high_div_low\"] = df_feat[\"High\"] / df_feat[\"Low\"]\n    df_feat[\"open_sub_close\"] = df_feat[\"Open\"] - df_feat[\"Close\"]\n    return df_feat","metadata":{"papermill":{"duration":0.044276,"end_time":"2021-11-29T16:05:08.248372","exception":false,"start_time":"2021-11-29T16:05:08.204096","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:06:07.931412Z","iopub.execute_input":"2022-04-23T10:06:07.931653Z","iopub.status.idle":"2022-04-23T10:06:07.938481Z","shell.execute_reply.started":"2022-04-23T10:06:07.93162Z","shell.execute_reply":"2022-04-23T10:06:07.937556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"modelconf\">Configure the model ‚öôÔ∏è</span>\n<hr>\n\nThis is a simple model with simple set of hyperparameters. Consider experimenting with different models, parameters, ensembles and so on.","metadata":{"papermill":{"duration":0.029229,"end_time":"2021-11-29T16:05:08.307476","exception":false,"start_time":"2021-11-29T16:05:08.278247","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**The Model**","metadata":{"papermill":{"duration":0.029345,"end_time":"2021-11-29T16:05:08.497354","exception":false,"start_time":"2021-11-29T16:05:08.468009","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def build_model(fold, weight = 1.0):\n\n    model = CatBoostRegressor(iterations = N_ESTIMATORS[fold], depth = MAX_DEPTH[fold], learning_rate = LEARNING_RATE[fold], task_type = \"GPU\" if DEVICE == 'GPU' else None)\n\n    return model","metadata":{"papermill":{"duration":0.04062,"end_time":"2021-11-29T16:05:08.567848","exception":false,"start_time":"2021-11-29T16:05:08.527228","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:06:07.940018Z","iopub.execute_input":"2022-04-23T10:06:07.940379Z","iopub.status.idle":"2022-04-23T10:06:07.953182Z","shell.execute_reply.started":"2022-04-23T10:06:07.940341Z","shell.execute_reply":"2022-04-23T10:06:07.952515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Time Series Cross Validation\n\n> \"There are many different ways one can do cross-validation, and **it is the most critical step when building a good machine learning model** which is generalizable when it comes to unseen data.\"\n-- **Approaching (Almost) Any Machine Learning Problem**, by Abhishek Thakur\n\nCV is the **first** step, but very few notebooks are talking about this. Here we look at \"purged rolling time series CV\" and actually apply it in hyperparameter tuning for a basic estimator. This notebook owes a debt of gratitude to the notebook [\"Found the Holy Grail GroupTimeSeriesSplit\"](https://www.kaggle.com/jorijnsmit/found-the-holy-grail-grouptimeseriessplit). That notebook is excellent and this solution is an extention of the quoted pending sklearn estimator. I modify that estimator to make it more suitable for the task at hand in this competition. The changes are\n\n- you can specify a **gap** between each train and validation split. This is important because even though the **group** aspect keeps whole days together, we suspect that the anonymized features have some kind of lag or window calculations in them (which would be standard for financial features). By introducing a gap, we mitigate the risk that we leak information from train into validation\n- we can specify the size of the train and validation splits in terms of **number of days**. The ability to specify a validation set size is new and the the ability to specify days, as opposed to samples, is new.\n\nThe code for `PurgedTimeSeriesSplit` is below. I've hidden it because it is really meant to act as an imported class. If you want to see the code and copy for your work, click on the \"Code\" box.","metadata":{"papermill":{"duration":0.029203,"end_time":"2021-11-29T16:05:08.627056","exception":false,"start_time":"2021-11-29T16:05:08.597853","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\nclass GroupTimeSeriesSplit(_BaseKFold):\n    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n    Provides train/test indices to split time series data samples\n    that are observed at fixed time intervals according to a\n    third-party provided group.\n    In each split, test indices must be higher than before, and thus shuffling\n    in cross validator is inappropriate.\n    This cross-validation object is a variation of :class:`KFold`.\n    In the kth split, it returns first k folds as train set and the\n    (k+1)th fold as test set.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    Note that unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n    max_train_size : int, default=None\n        Maximum size for a single training set.\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.model_selection import GroupTimeSeriesSplit\n    >>> groups = np.array(['a', 'a', 'a', 'a', 'a', 'a',\\\n                           'b', 'b', 'b', 'b', 'b',\\\n                           'c', 'c', 'c', 'c',\\\n                           'd', 'd', 'd'])\n    >>> gtss = GroupTimeSeriesSplit(n_splits=3)\n    >>> for train_idx, test_idx in gtss.split(groups, groups=groups):\n    ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n    ...     print(\"TRAIN GROUP:\", groups[train_idx],\\\n                  \"TEST GROUP:\", groups[test_idx])\n    TRAIN: [0, 1, 2, 3, 4, 5] TEST: [6, 7, 8, 9, 10]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a']\\\n    TEST GROUP: ['b' 'b' 'b' 'b' 'b']\n    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] TEST: [11, 12, 13, 14]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b']\\\n    TEST GROUP: ['c' 'c' 'c' 'c']\n    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\\\n    TEST: [15, 16, 17]\n    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b' 'c' 'c' 'c' 'c']\\\n    TEST GROUP: ['d' 'd' 'd']\n    \"\"\"\n    @_deprecate_positional_args\n    def __init__(self,\n                 n_splits=5,\n                 *,\n                 max_train_size=None\n                 ):\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.max_train_size = max_train_size\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n        X, y, groups = indexable(X, y, groups)\n        n_samples = _num_samples(X)\n        n_splits = self.n_splits\n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n        group_test_size = n_groups // n_folds\n        group_test_starts = range(n_groups - n_splits * group_test_size,\n                                  n_groups, group_test_size)\n        for group_test_start in group_test_starts:\n            train_array = []\n            test_array = []\n            for train_group_idx in unique_groups[:group_test_start]:\n                train_array_tmp = group_dict[train_group_idx]\n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n            train_end = train_array.size\n            if self.max_train_size and self.max_train_size < train_end:\n                train_array = train_array[train_end -\n                                          self.max_train_size:train_end]\n            for test_group_idx in unique_groups[group_test_start:\n                                                group_test_start +\n                                                group_test_size]:\n                test_array_tmp = group_dict[test_group_idx]\n                test_array = np.sort(np.unique(\n                                              np.concatenate((test_array,\n                                                              test_array_tmp)),\n                                     axis=None), axis=None)\n            yield [int(i) for i in train_array], [int(i) for i in test_array]\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n# modified code for group gaps; source\n# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\nclass PurgedGroupTimeSeriesSplit(_BaseKFold):\n    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n    Allows for a gap in groups to avoid potentially leaking info from\n    train into test if the model has windowed or lag features.\n    Provides train/test indices to split time series data samples\n    that are observed at fixed time intervals according to a\n    third-party provided group.\n    In each split, test indices must be higher than before, and thus shuffling\n    in cross validator is inappropriate.\n    This cross-validation object is a variation of :class:`KFold`.\n    In the kth split, it returns first k folds as train set and the\n    (k+1)th fold as test set.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    Note that unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n    max_train_group_size : int, default=Inf\n        Maximum group size for a single training set.\n    group_gap : int, default=None\n        Gap between train and test\n    max_test_group_size : int, default=Inf\n        We discard this number of groups from the end of each train split\n    \"\"\"\n\n    @_deprecate_positional_args\n    def __init__(self,\n                 n_splits=5,\n                 *,\n                 max_train_group_size=np.inf,\n                 max_test_group_size=np.inf,\n                 group_gap=None,\n                 verbose=False\n                 ):\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.max_train_group_size = max_train_group_size\n        self.group_gap = group_gap\n        self.max_test_group_size = max_test_group_size\n        self.verbose = verbose\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n        X, y, groups = indexable(X, y, groups)\n        n_samples = _num_samples(X)\n        n_splits = self.n_splits\n        group_gap = self.group_gap\n        max_test_group_size = self.max_test_group_size\n        max_train_group_size = self.max_train_group_size\n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n\n        group_test_size = min(n_groups // n_folds, max_test_group_size)\n        group_test_starts = range(n_groups - n_splits * group_test_size,\n                                  n_groups, group_test_size)\n        for group_test_start in group_test_starts:\n            train_array = []\n            test_array = []\n\n            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n                train_array_tmp = group_dict[train_group_idx]\n\n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n\n            train_end = train_array.size\n\n            for test_group_idx in unique_groups[group_test_start:\n                                                group_test_start +\n                                                group_test_size]:\n                test_array_tmp = group_dict[test_group_idx]\n                test_array = np.sort(np.unique(\n                                              np.concatenate((test_array,\n                                                              test_array_tmp)),\n                                     axis=None), axis=None)\n\n            test_array  = test_array[group_gap:]\n\n\n            if self.verbose > 0:\n                    pass\n\n            yield [int(i) for i in train_array], [int(i) for i in test_array]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.083099,"end_time":"2021-11-29T16:05:08.739695","exception":false,"start_time":"2021-11-29T16:05:08.656596","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:06:07.956766Z","iopub.execute_input":"2022-04-23T10:06:07.956981Z","iopub.status.idle":"2022-04-23T10:06:07.991953Z","shell.execute_reply.started":"2022-04-23T10:06:07.956942Z","shell.execute_reply":"2022-04-23T10:06:07.991303Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"training\">Training üèãÔ∏è</span>\n<hr>\nOur model will be trained for the number of FOLDS and ESTIMATORS you chose in the configuration above. Each fold the model with lowest validation loss will be saved and used to predict OOF and test. Adjust the variable `VERBOSE`. The variable `VERBOSE=1 or 2` will display the training and validation loss for each iteration as text.","metadata":{"papermill":{"duration":0.029972,"end_time":"2021-11-29T16:05:08.800261","exception":false,"start_time":"2021-11-29T16:05:08.770289","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Let's take a look at our CV**","metadata":{"papermill":{"duration":0.030261,"end_time":"2021-11-29T16:05:08.860586","exception":false,"start_time":"2021-11-29T16:05:08.830325","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\ndef plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n    cmap_cv = plt.cm.coolwarm\n    jet = plt.cm.get_cmap('jet', 256)\n    seq = np.linspace(0, 1, 256)\n    _ = np.random.shuffle(seq)   # inplace\n    cmap_data = ListedColormap(jet(seq))    \n    for ii, (tr, tt) in enumerate(list(cv.split(X=X, y=y, groups=group))):\n        indices = np.array([np.nan] * len(X))\n        indices[tt] = 1\n        indices[tr] = 0        \n        ax.scatter(range(len(indices)), [ii + .5] * len(indices), c=indices, marker='_', lw=lw, cmap=cmap_cv, vmin=-.2, vmax=1.2)\n    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n    ax.scatter(range(len(X)), [ii + 2.5] * len(X), c=group, marker='_', lw=lw, cmap=cmap_data)\n    yticklabels = list(range(n_splits)) + ['target', 'day']\n    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels, xlabel='Sample index', ylabel=\"CV iteration\", ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n    return ax\n\ndef plot_importance(importances, features_names, PLOT_TOP_N = 20, figsize=(12, 20)):\n    try: plt.close()\n    except: pass\n    importance_df = pd.DataFrame(data=importances, columns=features_names)\n    sorted_indices = importance_df.median(axis=0).sort_values(ascending=False).index\n    sorted_importance_df = importance_df.loc[:, sorted_indices]\n    plot_cols = sorted_importance_df.columns[:PLOT_TOP_N]\n    _, ax = plt.subplots(figsize=figsize)\n    ax.grid()\n    ax.set_xscale('log')\n    ax.set_ylabel('Feature')\n    ax.set_xlabel('Importance')\n    plt.title('Feature Importances')\n    sns.boxplot(data=sorted_importance_df[plot_cols], orient='h', ax=ax)\n    plt.show()\n    \nasset_id = 1301\ndf = load_training_data(asset_id)\ndf_proc = get_features(df)\ndf_proc['date'] = df['date'].copy()\ndf_proc['y'] = df['Target']\ndf_proc = df_proc.dropna(how=\"any\")\nX = df_proc.drop(\"y\", axis=1)\ny = df_proc[\"y\"]\ngroups = pd.factorize(X['date'].dt.day.astype(str) + '_' + X['date'].dt.month.astype(str) + '_' + X['date'].dt.year.astype(str))[0]\nX = X.drop(columns = 'date')\n\nfig, ax = plt.subplots(figsize = (12, 6))\ncv = PurgedGroupTimeSeriesSplit(n_splits = FOLDS, group_gap = GROUP_GAP, max_train_group_size=MAX_TRAIN_GROUP_SIZE, max_test_group_size=MAX_TEST_GROUP_SIZE)\nplot_cv_indices(cv, X, y, groups, ax, FOLDS, lw=20)","metadata":{"papermill":{"duration":163.992763,"end_time":"2021-11-29T16:07:52.88309","exception":false,"start_time":"2021-11-29T16:05:08.890327","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:06:07.993318Z","iopub.execute_input":"2022-04-23T10:06:07.993727Z","iopub.status.idle":"2022-04-23T10:06:14.078353Z","shell.execute_reply.started":"2022-04-23T10:06:07.993691Z","shell.execute_reply":"2022-04-23T10:06:14.077716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Main Training Function**","metadata":{"papermill":{"duration":0.03126,"end_time":"2021-11-29T16:07:52.945673","exception":false,"start_time":"2021-11-29T16:07:52.914413","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\nVERBOSE = 0\n\ndef get_Xy_and_model():\n    df = load_training_data()\n    orig_close = df['Close'].copy()\n    orig_sec_code = df['SecuritiesCode'].copy()\n    df_proc = get_features(df)\n    df_proc['date'] = df['date'].copy()\n    df_proc['y'] = df['Target']\n    df_proc = df_proc.dropna(how=\"any\")\n    X = df_proc.drop(\"y\", axis=1)\n    y = df_proc[\"y\"]\n    groups = pd.factorize(X['date'].dt.day.astype(str) + '_' + X['date'].dt.month.astype(str) + '_' + X['date'].dt.year.astype(str))[0]\n    X = X.drop(columns = 'date')\n    oof_preds = np.zeros(len(X))\n    importances, scores, models = [], [], []\n    for fold, (train_idx, val_idx) in enumerate(PurgedGroupTimeSeriesSplit(n_splits = FOLDS, group_gap = GROUP_GAP, max_train_group_size = MAX_TRAIN_GROUP_SIZE, max_test_group_size = MAX_TEST_GROUP_SIZE).split(X, y, groups)):\n        # GET TRAINING, VALIDATION SET\n        x_train, x_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        # DISPLAY FOLD INFO\n        print('#' * 25); print('#### FOLD', fold + 1)\n        print('#### Training N_ESTIMATORS %s | MAX_DEPTH %s | LEARNING_RATE %s' % (N_ESTIMATORS[fold], MAX_DEPTH[fold], LEARNING_RATE[fold]))\n\n        model = build_model(fold)\n\n        # TRAIN\n        model.fit( x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds = 50, verbose = VERBOSE)\n\n        # PREDICT OOF\n        pred = model.predict(x_val)\n        models.append(model)       \n        \n        # REPORT RESULTS\n        try: mse = mean_squared_error(np.nan_to_num(y_val), np.nan_to_num(pred))\n        except: mse = 0.0\n        scores.append(mse)\n        print('#### FOLD %i OOF MSE %.3f' % (fold + 1, mse))\n\n        oof_preds[val_idx] = pred\n        importances.append(model.get_feature_importance())\n\n    df_proc['SecuritiesCode'] = orig_sec_code\n    df = df_proc\n    df['oof_preds'] = np.nan_to_num(oof_preds)\n    df['Close'] = orig_close\n    print('\\n\\n' + ('-' * 80) + '\\n' + 'Finished trainings. Results:')\n    print('Model: r2_score: %s | pearsonr: %s ' % (r2_score(df['y'], df['oof_preds']), pearsonr(df['y'], df['oof_preds'])[0]))\n    print('Predictions std: %s | Target std: %s' % (df['oof_preds'].std(), df['y'].std()))\n\n    try: plt.close()\n    except: pass\n    df2 = df.reset_index().set_index('date')\n    df2 = df2.loc[df2['SecuritiesCode'] == 1301] # For demonstration purpose only.\n    fig = plt.figure(figsize = (12, 6))\n    # fig, ax_left = plt.subplots(figsize = (12, 6))\n    ax_left = fig.add_subplot(111)\n    ax_left.set_facecolor('azure')\n    ax_right = ax_left.twinx()\n    ax_left.plot(df2['y'].rolling(3 * 30 * 24 * 60).corr(df2['oof_preds']).iloc[::24 * 60], color = 'crimson', label = \"Corr\")\n    ax_right.plot(df2['Close'].iloc[::24 * 60], color = 'darkgrey', label = \"%s Close\" % stock_name_dict[asset_id])\n    plt.legend()\n    plt.grid()\n    plt.xlabel('Time')\n    plt.title('3 month rolling pearsonr for %s' % (stock_name_dict[asset_id]))\n    plt.show()\n\n    plot_importance(np.array(importances), list(X.columns), PLOT_TOP_N = 20)\n    \n    return scores, oof_preds, models, y\n\nprint(f\"Training model\")\ncur_scores, cur_oof_preds, cur_models, cur_targets = get_Xy_and_model()\nscores, oof_preds, models, targets = cur_scores, cur_oof_preds, cur_models, cur_targets\n","metadata":{"papermill":{"duration":701.136862,"end_time":"2021-11-29T16:19:34.11381","exception":false,"start_time":"2021-11-29T16:07:52.976948","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:06:14.079454Z","iopub.execute_input":"2022-04-23T10:06:14.079814Z","iopub.status.idle":"2022-04-23T10:07:31.107458Z","shell.execute_reply.started":"2022-04-23T10:06:14.079782Z","shell.execute_reply":"2022-04-23T10:07:31.106791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"codebook\">Calculate OOF MSE</span>\nThe OOF (out of fold) predictions are saved to disk. If you wish to ensemble multiple models, use the OOF to determine what are the best weights to blend your models with. Choose weights that maximize OOF CV score when used to blend OOF. Then use those same weights to blend your test predictions.","metadata":{"papermill":{"duration":0.133132,"end_time":"2021-11-29T16:19:34.380227","exception":false,"start_time":"2021-11-29T16:19:34.247095","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print('Overall MEAN OOF MSE %s' % np.mean(list(scores)))","metadata":{"papermill":{"duration":170.494306,"end_time":"2021-11-29T16:22:25.007487","exception":false,"start_time":"2021-11-29T16:19:34.513181","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:07:31.108796Z","iopub.execute_input":"2022-04-23T10:07:31.109254Z","iopub.status.idle":"2022-04-23T10:07:31.114528Z","shell.execute_reply.started":"2022-04-23T10:07:31.109218Z","shell.execute_reply":"2022-04-23T10:07:31.113716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"submit\">Submit To Kaggle üá∞</span>\n<hr>","metadata":{"papermill":{"duration":0.138773,"end_time":"2021-11-29T16:22:25.284693","exception":false,"start_time":"2021-11-29T16:22:25.14592","status":"completed"},"tags":[]}},{"cell_type":"code","source":"env = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\nfor (df_test, options, financials, trades, secondary_prices, df_pred) in iter_test:\n    x_test = get_features(df_test)\n    y_pred = np.mean(np.concatenate([np.expand_dims(model.predict(x_test), axis = 0) for model in models], axis = 0), axis = 0)\n    df_pred['Target'] = y_pred\n    df_pred = df_pred.sort_values(by = \"Target\", ascending = False)\n    df_pred['Rank'] = np.arange(0,2000)\n    df_pred = df_pred.sort_values(by = \"SecuritiesCode\", ascending = True)\n    df_pred.drop([\"Target\"], axis = 1)\n    submission = df_pred[[\"Date\", \"SecuritiesCode\", \"Rank\"]]\n    env.predict(submission)","metadata":{"papermill":{"duration":0.86007,"end_time":"2021-11-29T16:22:26.284257","exception":false,"start_time":"2021-11-29T16:22:25.424187","status":"completed"},"pycharm":{"name":"#%%\n"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:07:31.117129Z","iopub.execute_input":"2022-04-23T10:07:31.117627Z","iopub.status.idle":"2022-04-23T10:07:31.327254Z","shell.execute_reply.started":"2022-04-23T10:07:31.117592Z","shell.execute_reply":"2022-04-23T10:07:31.326532Z"},"trusted":true},"execution_count":null,"outputs":[]}]}