{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"EDA\"></a>\n# EDA - exploratory data analysis","metadata":{}},{"cell_type":"markdown","source":"#### Основные библиотеки: seaborn, matplotlib, plotly","metadata":{}},{"cell_type":"markdown","source":"1. Посмотреть на отсутствующие значения в процентах, подумать, какие фичи можно вовсе убрать\n2. Подумать, одинаковое ли распределение на train и test, сколько NA в них, как будем обучаться с учётом этой информации (иногда на тесте могут быть NA, которых не было в тесте), lightgbm хорошо работает с NA\n3. Для временных рядов: есть ли тренд? Если есть, то вычесть его (запомнить), затем сделать предсказание и домножить на тренд.\n4. Выбросы - есть ли? Посмотреть внимательно на pairplot\n5. Посмотреть на гистограммы (либо оценки плотностей) в зависимости от категориальных данных, есть ли влияние, нужно ли его учитывать, и как?\n6. Некоторые интересные тренды можно добавлять в качестве доп. переменных (особенно сезонные!!!)\n7. Если каких-то особенных индивидов очень мало (небольшая неоднородность), то имеет смысл для них построить отдельную модель\n8. Корреляции, убрать слишком сильно коррелирующие","metadata":{}},{"cell_type":"markdown","source":"<a id=\"Валидация\"></a>\n# Валидация","metadata":{}},{"cell_type":"markdown","source":"### Стратегии валидации:\n* Holdout - просто разбиваем на train и test\n* KFold - самый обычный\n* GroupKFold - в зависимости от группы, например, если сделали кластеризацию\n* StratifiedGroupKFold - пытается строить сбалансированные фолды \n* TimeSeriesSplit\n* LOOCV ","metadata":{}},{"cell_type":"markdown","source":"Корректна ли валидация? \nНужно попытаться сделать процедуру кросс-валидации  наиболее похожей на данный train-test","metadata":{}},{"cell_type":"markdown","source":"<a id=\"Feature generation\"></a>\n# Feature generation","metadata":{}},{"cell_type":"markdown","source":"Одно из основных -- это statistical features","metadata":{}},{"cell_type":"markdown","source":"#### Категориальные переменные: \n* label encoding vs one-code-encoding? Если много категорий, то получается очень много нулей. Альтернатива - либо объединить маленькие группы, либо label encoding и подать модели, с пометкой, что это категориальная переменная.\n* numerical aggregation -- min/max/std/meadian/mean\n* Target Encoding -- закодировать средним targetа, аккуратно использовать (возможен leakage)","metadata":{}},{"cell_type":"markdown","source":"#### Переменнные относящиеся ко времени:\n* месяц\n* год\n* день недели\n* выходной ли \n* час \n\nИ многие другие. Если замеры идут через разные промежутки времени, то можно ещё учитывать разницу во времени с предыдущим, число записей за некоторый промежуток времени, предыдущее время фиксации и так далее...","metadata":{}},{"cell_type":"markdown","source":"<a id=\"Feature Selection\"></a>\n# Feature Selection","metadata":{}},{"cell_type":"markdown","source":"1. Forward - Backward pass - постепенно прибавляем-удаляем фичи, и оставляем лучшие\n2. Linear Regression - обучить LASSO модель, оставить фичи с ненулевыми коэффициентами (не забыть нормализовать фичи)\n3. Genetic feature selection \n4. SHAP (считает \"важность\" фичи) + Boruta (рандомно перемешивает значения) = BorutaShap, считается весьма надежным способом\n5. Class weight retraining - решение проблемы несбалансированных классов\n","metadata":{}},{"cell_type":"markdown","source":"* Blending - обучаем несколько моделей и потом усредняем предсказания, в случае классификации это Voting\n* Stacking - обучимся лесами или бустингом, запишем вероятности n моделей в матрицу, добавим ещё фичи (перемножить, сложить, поделить каждый с каждым), затем обучаем ещё одну модель на этом -- lightgbm или ridge регрессию \n\n#### Откуда брать разные модели? \nExternal bagging - берем каждый к-ый объект, повторяем и усредняем","metadata":{}},{"cell_type":"markdown","source":"#### Для линейных моделей\n* можно добавить новые фичи, такие как abs(x-k), sign(x-a), (x-a)**b\n","metadata":{}},{"cell_type":"markdown","source":"#### Изотононическая регрессия \nДобавить как фичу, если переменная монотонно не убывает ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"Tips and tricks\"></a>\n# Tips and tricks\n* Фиксировать random state и смотреть, стабильно ли поведение модели в зависимости от него\n* Можно усреднять не только значение метрики для кросс-валидации, но и сами результаты - вероятности и проч.\n* holdout для гиперпараметров обычно больше не делают\n* для цикличных переменных можно закодировать с помощью двух фичей - cos-sin\n* сделать get_features для train и test сразу и вообще для всего - для feature, для split, для train, и для predict\n* winsorization - всё что больше каких-то границ назначаем одно граничное значение\n* target transformation - попробовать предсказывать не только y, но и y^2, log(y+1), sqrt(y) и т. д.\n* postprocessing \n* своя собственная модель для каждого индивида","metadata":{}},{"cell_type":"markdown","source":"Не совсем понял:\n1. SMAPE becames very close to MAE when using log of target\n2. Threshold optimization\n3. Rank average","metadata":{}},{"cell_type":"markdown","source":"by the way: инсайд, надо подумать, как сделать фичи с окном в 7 дней","metadata":{}}]}