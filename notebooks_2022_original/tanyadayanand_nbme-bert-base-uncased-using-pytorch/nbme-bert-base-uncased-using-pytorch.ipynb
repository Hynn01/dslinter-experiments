{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# All the important imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport transformers\nimport tokenizers\nimport torch\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm.autonotebook import tqdm\n\nfrom ast import literal_eval\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:44.013074Z","iopub.execute_input":"2022-05-04T22:11:44.013335Z","iopub.status.idle":"2022-05-04T22:11:44.018352Z","shell.execute_reply.started":"2022-05-04T22:11:44.013306Z","shell.execute_reply":"2022-05-04T22:11:44.017424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:44.267177Z","iopub.execute_input":"2022-05-04T22:11:44.267832Z","iopub.status.idle":"2022-05-04T22:11:44.272228Z","shell.execute_reply.started":"2022-05-04T22:11:44.267796Z","shell.execute_reply":"2022-05-04T22:11:44.271188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = \"../input/nbme-score-clinical-patient-notes/\"\nfeatures_df = pd.read_csv(BASE_PATH + \"features.csv\")\npatient_notes_df = pd.read_csv(BASE_PATH + \"patient_notes.csv\")\ntrain_df = pd.read_csv(BASE_PATH + \"train.csv\")\ntest_df = pd.read_csv(BASE_PATH + \"test.csv\")\nsubmission_df = pd.read_csv(BASE_PATH + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:44.666361Z","iopub.execute_input":"2022-05-04T22:11:44.667119Z","iopub.status.idle":"2022-05-04T22:11:45.02322Z","shell.execute_reply.started":"2022-05-04T22:11:44.667075Z","shell.execute_reply":"2022-05-04T22:11:45.022447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:45.026572Z","iopub.execute_input":"2022-05-04T22:11:45.027193Z","iopub.status.idle":"2022-05-04T22:11:45.034187Z","shell.execute_reply.started":"2022-05-04T22:11:45.027155Z","shell.execute_reply":"2022-05-04T22:11:45.033429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:45.076803Z","iopub.execute_input":"2022-05-04T22:11:45.077114Z","iopub.status.idle":"2022-05-04T22:11:45.086063Z","shell.execute_reply.started":"2022-05-04T22:11:45.077083Z","shell.execute_reply":"2022-05-04T22:11:45.085237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:45.363763Z","iopub.execute_input":"2022-05-04T22:11:45.364627Z","iopub.status.idle":"2022-05-04T22:11:45.376318Z","shell.execute_reply.started":"2022-05-04T22:11:45.364566Z","shell.execute_reply":"2022-05-04T22:11:45.375435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:45.617146Z","iopub.execute_input":"2022-05-04T22:11:45.617674Z","iopub.status.idle":"2022-05-04T22:11:45.626874Z","shell.execute_reply.started":"2022-05-04T22:11:45.617631Z","shell.execute_reply":"2022-05-04T22:11:45.625846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:45.863656Z","iopub.execute_input":"2022-05-04T22:11:45.864286Z","iopub.status.idle":"2022-05-04T22:11:45.961376Z","shell.execute_reply.started":"2022-05-04T22:11:45.864251Z","shell.execute_reply":"2022-05-04T22:11:45.960492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:46.121013Z","iopub.execute_input":"2022-05-04T22:11:46.12123Z","iopub.status.idle":"2022-05-04T22:11:46.138096Z","shell.execute_reply.started":"2022-05-04T22:11:46.121203Z","shell.execute_reply":"2022-05-04T22:11:46.137266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:46.35954Z","iopub.execute_input":"2022-05-04T22:11:46.360193Z","iopub.status.idle":"2022-05-04T22:11:46.377236Z","shell.execute_reply.started":"2022-05-04T22:11:46.360152Z","shell.execute_reply":"2022-05-04T22:11:46.376621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.merge(train_df, features_df, on=['feature_num','case_num'], how='inner')\ndf =pd.merge(df, patient_notes_df, on=['pn_num','case_num'], how='inner')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:46.765304Z","iopub.execute_input":"2022-05-04T22:11:46.765553Z","iopub.status.idle":"2022-05-04T22:11:46.797182Z","shell.execute_reply.started":"2022-05-04T22:11:46.765524Z","shell.execute_reply":"2022-05-04T22:11:46.796481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:47.140519Z","iopub.execute_input":"2022-05-04T22:11:47.141031Z","iopub.status.idle":"2022-05-04T22:11:47.172452Z","shell.execute_reply.started":"2022-05-04T22:11:47.140994Z","shell.execute_reply":"2022-05-04T22:11:47.171792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['feature_text'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:47.383933Z","iopub.execute_input":"2022-05-04T22:11:47.384421Z","iopub.status.idle":"2022-05-04T22:11:47.396475Z","shell.execute_reply.started":"2022-05-04T22:11:47.384384Z","shell.execute_reply":"2022-05-04T22:11:47.395656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The 'annotation' is picked form the 'pn_history' and the text location is mentiond in 'location' column. Location:Character spans indicating the location(s) of the feature within the note.\n\n","metadata":{}},{"cell_type":"code","source":"df['pn_history'][1]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:47.628993Z","iopub.execute_input":"2022-05-04T22:11:47.629217Z","iopub.status.idle":"2022-05-04T22:11:47.634625Z","shell.execute_reply.started":"2022-05-04T22:11:47.629191Z","shell.execute_reply":"2022-05-04T22:11:47.633875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df['pn_history'][1][668 : 693])\nprint(df['pn_history'][1][203 : 217])\nprint(df['pn_history'][1][696 : 724])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:47.873236Z","iopub.execute_input":"2022-05-04T22:11:47.873746Z","iopub.status.idle":"2022-05-04T22:11:47.879798Z","shell.execute_reply.started":"2022-05-04T22:11:47.87371Z","shell.execute_reply":"2022-05-04T22:11:47.879026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"annotation\"] = [literal_eval(x) for x in df[\"annotation\"]]\ndf[\"location\"] = [literal_eval(x) for x in df[\"location\"]]\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:48.109265Z","iopub.execute_input":"2022-05-04T22:11:48.109587Z","iopub.status.idle":"2022-05-04T22:11:48.338894Z","shell.execute_reply.started":"2022-05-04T22:11:48.109554Z","shell.execute_reply":"2022-05-04T22:11:48.338093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frames = []\ndf_split = np.array_split(df, 5)\nfor split in range(0, 5):\n    df_split[split]['kfold'] = split\n    frames.append(df_split[split])\ndfx = pd.concat(frames)\ndfx","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:48.347831Z","iopub.execute_input":"2022-05-04T22:11:48.348024Z","iopub.status.idle":"2022-05-04T22:11:48.37859Z","shell.execute_reply.started":"2022-05-04T22:11:48.348Z","shell.execute_reply":"2022-05-04T22:11:48.377826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = df['pn_history'].map(lambda x: len(x)).max()\nmax_len","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:48.594309Z","iopub.execute_input":"2022-05-04T22:11:48.594559Z","iopub.status.idle":"2022-05-04T22:11:48.608939Z","shell.execute_reply.started":"2022-05-04T22:11:48.59453Z","shell.execute_reply":"2022-05-04T22:11:48.60818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configrations | Hyperparameters","metadata":{}},{"cell_type":"code","source":"class config:\n    MAX_LEN = 416\n    TRAIN_BATCH_SIZE = 8\n    VALID_BATCH_SIZE = 8\n    EPOCHS = 5\n    BERT_PATH = \"../input/bert-base-uncased/\" \n    MODEL_PATH = \"model.bin\"\n    TOKENIZER = tokenizers.BertWordPieceTokenizer(f\"{BERT_PATH}/vocab.txt\" ,lowercase = True)\n    DROPOUT = 0.2\n    MAX_GRAD_NORM = 1.0\n    LEARNING_RATE = 1e-5\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:48.847021Z","iopub.execute_input":"2022-05-04T22:11:48.847531Z","iopub.status.idle":"2022-05-04T22:11:48.887091Z","shell.execute_reply.started":"2022-05-04T22:11:48.847495Z","shell.execute_reply":"2022-05-04T22:11:48.886091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"first = df.loc[3]\nexample = {\n    \"feature_text\": first.feature_text,\n    \"pn_history\": first.pn_history,\n    \"location\": first.location,\n    \"annotation\": first.annotation\n}\nfor key in example.keys():\n    print(key)\n    print(example[key])\n    print(\"=\" * 100)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:49.09165Z","iopub.execute_input":"2022-05-04T22:11:49.092089Z","iopub.status.idle":"2022-05-04T22:11:49.102653Z","shell.execute_reply.started":"2022-05-04T22:11:49.092055Z","shell.execute_reply":"2022-05-04T22:11:49.1018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loc_list_to_ints(loc_list):\n    to_return = []\n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n    return to_return\n\nexample_loc_ints = loc_list_to_ints(example[\"location\"])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:49.321658Z","iopub.execute_input":"2022-05-04T22:11:49.321877Z","iopub.status.idle":"2022-05-04T22:11:49.32743Z","shell.execute_reply.started":"2022-05-04T22:11:49.321852Z","shell.execute_reply":"2022-05-04T22:11:49.326507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_data_tokenize(pn_history, feature_text, annotation, location, tokenizer, max_len):    ##X , Y, selected_text  \n    \n    location_list = loc_list_to_ints(location)        \n    char_targets = [0] * len(pn_history) #creating empty list(all zeros) of character;it will be made 1 if annotation in text   \n    \n    for loc,anno in zip(location_list,annotation): \n        len_st = loc[1] - loc[0]\n\n        idx0 = None\n        idx1 = None\n        for ind in (i for i, e in enumerate(pn_history) if (e == anno[0] and i == loc[0])):\n            if pn_history[ind: ind+len_st] == anno:\n\n                idx0 = ind\n                idx1 = ind + len_st - 1\n                if idx0 != None and idx1 != None:\n                    for ct in range(idx0, idx1 + 1):\n                        char_targets[ct] = 1  #replacing zeros with 1 if that part of the text is selected text\n        \n                break\n      \n    tokenized_input = tokenizer.encode(feature_text,pn_history)\n    \n        \n    input_ids = tokenized_input.ids\n    mask = tokenized_input.attention_mask\n    token_type_ids = tokenized_input.type_ids\n    offsets = tokenized_input.offsets\n    \n    target_idx = []\n    for j, (offset1, offset2) in enumerate(offsets):\n        if sum(char_targets[offset1: offset2]) > 0:\n            target_idx.append(j)\n            \n    #padding\n    padding_length = max_len - len(input_ids)\n    if padding_length > 0:\n        input_ids = input_ids + ([0] * padding_length)\n        mask = mask + ([0] * padding_length)\n        token_type_ids = token_type_ids + ([0] * padding_length)\n        offsets = offsets + ([(0, 0)] * padding_length)\n       \n    #creating label\n    ignore_idxes = np.where(np.array(token_type_ids) != 1)[0]\n\n    label = np.zeros(len(offsets))\n    label[ignore_idxes] = -1\n    label[target_idx] = 1\n\n    \n    return {\n    'ids': input_ids,\n    'mask': mask,\n    'token_type_ids': token_type_ids,\n    'labels': label,\n    'offsets': offsets\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:51.221908Z","iopub.execute_input":"2022-05-04T22:11:51.222329Z","iopub.status.idle":"2022-05-04T22:11:51.235309Z","shell.execute_reply.started":"2022-05-04T22:11:51.222296Z","shell.execute_reply":"2022-05-04T22:11:51.234638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = process_data_tokenize(example[\"pn_history\"],example[\"feature_text\"],example[\"annotation\"],example[\"location\"],config.TOKENIZER,config.MAX_LEN)\n\nfor key in output.keys():\n    print(key)\n    print(output[key])\n    print(\"=\" * 100)\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:51.454569Z","iopub.execute_input":"2022-05-04T22:11:51.455013Z","iopub.status.idle":"2022-05-04T22:11:51.460822Z","shell.execute_reply.started":"2022-05-04T22:11:51.454981Z","shell.execute_reply":"2022-05-04T22:11:51.459579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"class NBMEDataset:\n    def __init__(self, pn_history, feature_text, annotation, location):   #text(X) #label(Y), #selected_text #start:end\n        self.pn_history = pn_history\n        self.feature_text = feature_text\n        self.annotation = annotation\n        self.location = location\n        self.tokenizer = config.TOKENIZER\n        self.max_len = config.MAX_LEN\n        \n    def __len__(self):\n        return len(self.pn_history)\n        \n    def __getitem__(self, item):\n        data = process_data_tokenize(\n            self.pn_history[item],\n            self.feature_text[item],\n            self.annotation[item],\n            self.location[item],\n            self.tokenizer,\n            self.max_len\n        )\n        \n        return {\n            'ids': torch.tensor(data[\"ids\"]), #input_ids\n            'mask': torch.tensor(data[\"mask\"], dtype=torch.long), #attention_mask\n            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long), #segment_ids\n            'labels': torch.tensor(data[\"labels\"], dtype=torch.long), \n            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n        }\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:51.701061Z","iopub.execute_input":"2022-05-04T22:11:51.701294Z","iopub.status.idle":"2022-05-04T22:11:51.710707Z","shell.execute_reply.started":"2022-05-04T22:11:51.701267Z","shell.execute_reply":"2022-05-04T22:11:51.709955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Model","metadata":{}},{"cell_type":"code","source":"class NBMEModel(transformers.BertPreTrainedModel):    #torch.nn.Module\n    def __init__(self,conf):\n        super(NBMEModel,self).__init__(conf)\n        self.bert = transformers.BertModel.from_pretrained(config.BERT_PATH, config=conf)\n        self.dropout = torch.nn.Dropout(config.DROPOUT)\n        self.classifier = torch.nn.Linear(768, 1)\n        torch.nn.init.normal_(self.classifier.weight, std=0.02) \n        \n    def forward(self, ids, mask, token_type_ids):\n        sequence_out = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)[0] #last_hidden_state\n        batch_size,max_len,feat_dim = sequence_out.shape\n        sequence_output = self.dropout(sequence_out)\n        logits = self.classifier(sequence_output)\n        logits = logits.squeeze(-1) \n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:51.947973Z","iopub.execute_input":"2022-05-04T22:11:51.948708Z","iopub.status.idle":"2022-05-04T22:11:51.988911Z","shell.execute_reply.started":"2022-05-04T22:11:51.94866Z","shell.execute_reply":"2022-05-04T22:11:51.988244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility Function","metadata":{}},{"cell_type":"code","source":"class AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:52.191042Z","iopub.execute_input":"2022-05-04T22:11:52.192783Z","iopub.status.idle":"2022-05-04T22:11:52.198074Z","shell.execute_reply.started":"2022-05-04T22:11:52.192752Z","shell.execute_reply":"2022-05-04T22:11:52.1974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss Function","metadata":{}},{"cell_type":"code","source":"def loss_fn(logits, labels):\n    loss_fct = torch.nn.BCEWithLogitsLoss(reduction = \"none\")\n    loss = loss_fct(logits,labels)\n    return loss\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:52.436834Z","iopub.execute_input":"2022-05-04T22:11:52.437517Z","iopub.status.idle":"2022-05-04T22:11:52.442787Z","shell.execute_reply.started":"2022-05-04T22:11:52.437466Z","shell.execute_reply":"2022-05-04T22:11:52.442108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Function","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:52.676425Z","iopub.execute_input":"2022-05-04T22:11:52.676941Z","iopub.status.idle":"2022-05-04T22:11:52.74511Z","shell.execute_reply.started":"2022-05-04T22:11:52.676904Z","shell.execute_reply":"2022-05-04T22:11:52.744333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(dataloader, model, optimizer, scheduler=None):\n    model.train()\n    losses = AverageMeter() # Computes and stores the average and current value\n    tk = tqdm(dataloader, total=len(dataloader)) #tqdm is a Python library for adding progress bar. \n    \n    for batch, data in enumerate(tk):\n        ids = data['ids']\n        token_type_ids = data[\"token_type_ids\"]\n        mask = data[\"mask\"]\n        labels = data[\"labels\"]\n        offsets = data[\"offsets\"]\n        \n        #adding the below data to device ;device enables you to specify the device type responsible to load a tensor into memory.\n        ids = ids.to(DEVICE, dtype=torch.long)\n        token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n        mask = mask.to(DEVICE, dtype=torch.long)\n        labels = labels.to(DEVICE, dtype=torch.float64)\n\n        model.zero_grad()\n        logits = model(ids=ids, mask=mask, token_type_ids=token_type_ids) #last_hidden_state\n\n        loss = loss_fn(logits, labels)\n        loss = torch.masked_select(loss, labels > -1.0).mean()\n        losses.update(loss.item(),ids.size(0))\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n        optimizer.step()\n        scheduler.step() ## Update learning rate schedule\n        \n        #output = torch.argmax(torch.softmax(logits, dim=2),dim=2).cpu().detach().numpy()\n        tk.set_postfix(loss=losses.avg)\n        \n    return losses.avg","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:52.922042Z","iopub.execute_input":"2022-05-04T22:11:52.922463Z","iopub.status.idle":"2022-05-04T22:11:52.933442Z","shell.execute_reply.started":"2022-05-04T22:11:52.922429Z","shell.execute_reply":"2022-05-04T22:11:52.93276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation Functions","metadata":{}},{"cell_type":"code","source":"def eval_fn(dataloader, model):\n    model.eval()\n    losses = AverageMeter() # Computes and stores the average and current value\n\n    with torch.no_grad():\n        tk = tqdm(dataloader, total=len(dataloader)) \n        for batch, data in enumerate(tk):\n\n            ids = data['ids']\n            token_type_ids = data[\"token_type_ids\"]\n            mask = data[\"mask\"]\n            labels = data[\"labels\"]\n            offsets = data[\"offsets\"]\n\n            ids = ids.to(DEVICE, dtype=torch.long)\n            token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n            mask = mask.to(DEVICE, dtype=torch.long)\n            labels = labels.to(DEVICE, dtype=torch.float64)\n\n            logits = model(ids=ids, mask=mask, token_type_ids=token_type_ids) #last_hidden_state\n            \n            loss = loss_fn(logits, labels)\n            loss = torch.masked_select(loss, labels > -1.0).mean()\n            losses.update(loss.item(),ids.size(0))\n            tk.set_postfix(loss=losses.avg)\n        \n        return losses.avg\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:53.152356Z","iopub.execute_input":"2022-05-04T22:11:53.152763Z","iopub.status.idle":"2022-05-04T22:11:53.163095Z","shell.execute_reply.started":"2022-05-04T22:11:53.152728Z","shell.execute_reply":"2022-05-04T22:11:53.162001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def run(fold):\n    \n    train_loss_data, valid_loss_data = [], []\n    best_loss = np.inf\n    since = time.time()\n   \n    df_train = dfx[dfx.kfold != fold].reset_index(drop=True) \n    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n    \n    train_dataset = NBMEDataset(\n        pn_history=df_train.pn_history.values,\n        feature_text=df_train.feature_text.values,\n        annotation=df_train.annotation.values,\n        location=df_train.location.values\n        \n    )\n    \n    train_data_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=config.TRAIN_BATCH_SIZE,\n        num_workers=4\n    )\n\n    valid_dataset = NBMEDataset(\n        pn_history=df_valid.pn_history.values,\n        feature_text=df_valid.feature_text.values,\n        annotation=df_valid.annotation.values,\n        location=df_valid.location.values\n    )\n\n    valid_data_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=config.VALID_BATCH_SIZE,\n        num_workers=2\n    )\n\n    model_config = transformers.BertConfig.from_pretrained(config.BERT_PATH)\n    model_config.output_hidden_states = True\n    model = NBMEModel(conf=model_config)\n    model.to(DEVICE)\n    \n    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n    ]\n    optimizer = AdamW(optimizer_parameters, lr=config.LEARNING_RATE)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, \n        num_warmup_steps=0, \n        num_training_steps=num_train_steps\n    )\n\n    best_loss = np.inf\n    \n    for i in range(config.EPOCHS):\n        print(\"Epoch: {}/{}\".format(i + 1, config.EPOCHS))\n    \n        # train model\n        train_loss = train_fn(train_data_loader, model, optimizer, scheduler=scheduler)\n        train_loss_data.append(train_loss)\n        print(f\"Train loss: {train_loss}\")\n\n        # evaluate model\n        valid_loss = eval_fn(valid_data_loader, model)\n        valid_loss_data.append(valid_loss)\n        print(f\"Valid loss: {valid_loss}\")\n\n\n        if valid_loss < best_loss:\n            best_loss = valid_loss\n            torch.save(model.state_dict(), \"model_fold1.bin\")\n\n\n        time_elapsed = time.time() - since\n        print('Training completed in {:.0f}m {:.0f}s'.format(\n            time_elapsed // 60, time_elapsed % 60))\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:53.637391Z","iopub.execute_input":"2022-05-04T22:11:53.638536Z","iopub.status.idle":"2022-05-04T22:11:53.664565Z","shell.execute_reply.started":"2022-05-04T22:11:53.638464Z","shell.execute_reply":"2022-05-04T22:11:53.663663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run(fold=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T22:11:54.181247Z","iopub.execute_input":"2022-05-04T22:11:54.181496Z","iopub.status.idle":"2022-05-04T23:00:53.734374Z","shell.execute_reply.started":"2022-05-04T22:11:54.181468Z","shell.execute_reply":"2022-05-04T23:00:53.733545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run(fold=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T23:00:53.736907Z","iopub.execute_input":"2022-05-04T23:00:53.737707Z","iopub.status.idle":"2022-05-04T23:11:03.888209Z","shell.execute_reply.started":"2022-05-04T23:00:53.737666Z","shell.execute_reply":"2022-05-04T23:11:03.886474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run(fold=2)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T23:11:03.889043Z","iopub.status.idle":"2022-05-04T23:11:03.889339Z","shell.execute_reply.started":"2022-05-04T23:11:03.889187Z","shell.execute_reply":"2022-05-04T23:11:03.889206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run(fold=3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run(fold=4)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T23:11:03.891459Z","iopub.status.idle":"2022-05-04T23:11:03.892013Z","shell.execute_reply.started":"2022-05-04T23:11:03.891781Z","shell.execute_reply":"2022-05-04T23:11:03.891807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Do the evauation on test data\n##### [inference in progress...]","metadata":{}},{"cell_type":"code","source":"# df_tst = pd.merge(test_df, features_df, on=['feature_num','case_num'], how='inner')\n# df_tst = pd.merge(df_tst, patient_notes_df, on=['pn_num','case_num'], how='inner')\n# df_tst.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T23:11:03.894707Z","iopub.status.idle":"2022-05-04T23:11:03.895261Z","shell.execute_reply.started":"2022-05-04T23:11:03.895016Z","shell.execute_reply":"2022-05-04T23:11:03.895043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\")\n# model_config = transformers.BertConfig.from_pretrained(config.BERT_PATH)\n# model_config.output_hidden_states = True\n\n# #similarly this can be done for all 5 models\n# model1 = NBMEModel(conf=model_config)\n# model1.to(config.DEVICE)\n# model1.load_state_dict(torch.load(\"model_fold1.bin\"))\n# model1.eval()\n\n# test_dataset = NBMEDataset(\n#     pn_history=df_test.pn_history.values,\n#     feature_text=df_test.feature_text.values,\n#     annotation=df_test.annotation.values,\n#     location=df_test.location.values\n\n# )\n\n# data_loader = torch.utils.data.DataLoader(\n#     test_dataset,\n#     shuffle=False,\n#     batch_size=config.TRAIN_BATCH_SIZE,\n#     num_workers=1\n# )\n\n# with torch.no_grad():\n#     tk = tqdm(data_loader, total=len(data_loader)) #tqdm is a Python library for adding progress bar. \n\n#     for batch, data in enumerate(tk):\n#         ids = data['ids']\n#         token_type_ids = data[\"token_type_ids\"]\n#         mask = data[\"mask\"]\n#         labels = data[\"labels\"]\n#         offsets = data[\"offsets\"]\n\n#         ids = ids.to(DEVICE, dtype=torch.long)\n#         token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n#         mask = mask.to(DEVICE, dtype=torch.long)\n#         labels = labels.to(DEVICE, dtype=torch.float64)\n\n#         logits = model(ids=ids, mask=mask, token_type_ids=token_type_ids) #last_hidden_state\n\n","metadata":{},"execution_count":null,"outputs":[]}]}