{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDAðŸ”Ž and baseline with Lightningâš¡Flash & DeepLab-v3 & albumentations\n\nsee: https://lightning-flash.readthedocs.io/en/stable/reference/semantic_segmentation.html","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y torchtext\n# !pip install -q --upgrade torch torchvision\n!pip install -q \"lightning-flash[image]\" \"torchmetrics<0.8\" --no-index --find-links ../input/demo-flash-semantic-segmentation/frozen_packages\n!pip install -q -U timm segmentation-models-pytorch --no-index --find-links ../input/demo-flash-semantic-segmentation/frozen_packages\n!pip install -q 'kaggle-imsegm' --no-index --find-links ../input/tract-segm-eda-3d-interactive-viewer/frozen_packages\n\n! pip list | grep torch\n! pip list | grep lightning\n! nvidia-smi -L","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-29T08:36:50.89363Z","iopub.execute_input":"2022-04-29T08:36:50.894052Z","iopub.status.idle":"2022-04-29T08:38:10.759486Z","shell.execute_reply.started":"2022-04-29T08:36:50.893902Z","shell.execute_reply":"2022-04-29T08:38:10.758618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nDATASET_FOLDER = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\ndf_train = pd.read_csv(os.path.join(DATASET_FOLDER, \"train.csv\"))\ndisplay(df_train.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-29T08:38:10.762482Z","iopub.execute_input":"2022-04-29T08:38:10.762776Z","iopub.status.idle":"2022-04-29T08:38:11.252262Z","shell.execute_reply.started":"2022-04-29T08:38:10.762737Z","shell.execute_reply":"2022-04-29T08:38:11.251475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_imgs = glob.glob(os.path.join(DATASET_FOLDER, \"train\", \"case*\", \"case*_day*\", \"scans\", \"*.png\"))\nall_imgs = [p.replace(DATASET_FOLDER, \"\") for p in all_imgs]\n\nprint(f\"images: {len(all_imgs)}\")\nprint(f\"annotated: {len(df_train['id'].unique())}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:38:11.253629Z","iopub.execute_input":"2022-04-29T08:38:11.253869Z","iopub.status.idle":"2022-04-29T08:38:14.604113Z","shell.execute_reply.started":"2022-04-29T08:38:11.253833Z","shell.execute_reply":"2022-04-29T08:38:14.603231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ðŸ”Ž Explore and enrich dataset\n\nTake the input train table and parse some additiona informations","metadata":{}},{"cell_type":"code","source":"from pprint import pprint\nfrom kaggle_imsegm.data import extract_tract_details\n\npprint(extract_tract_details(df_train['id'].iloc[0], DATASET_FOLDER))\n\ndf_train[['Case','Day','Slice', 'image', 'image_path', 'height', 'width']] = df_train['id'].apply(\n    lambda x: pd.Series(extract_tract_details(x, DATASET_FOLDER))\n)\ndisplay(df_train.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:38:14.606241Z","iopub.execute_input":"2022-04-29T08:38:14.606516Z","iopub.status.idle":"2022-04-29T08:40:22.770796Z","shell.execute_reply.started":"2022-04-29T08:38:14.606478Z","shell.execute_reply":"2022-04-29T08:40:22.770094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compare timeseries and stack sizes","metadata":{}},{"cell_type":"markdown","source":"## Browse the 3D image\n\nsee the full version (without importing own package) in https://www.kaggle.com/code/jirkaborovec/tract-segm-eda-3d-data-browser","metadata":{}},{"cell_type":"code","source":"from ipywidgets import interact, IntSlider\nfrom kaggle_imsegm.data import load_volume_from_images, create_tract_segm\nfrom kaggle_imsegm.visual import show_tract_volume\n\nCASE = 108\nDAY = 10\nIMAGE_FOLDER = os.path.join(DATASET_FOLDER, \"train\", f\"case{CASE}\", f\"case{CASE}_day{DAY}\", \"scans\")\nvol = load_volume_from_images(img_dir=IMAGE_FOLDER)\nprint(vol.shape)\n\ndf_ = df_train[(df_train[\"Case\"] == CASE) & (df_train[\"Day\"] == DAY)]\nsegm = create_tract_segm(df_vol=df_, vol_shape=vol.shape)\n\ndef interactive_show(volume):\n    vol_shape = volume.shape\n    interact(\n        lambda x, y, z: plt.show(show_tract_volume(volume, segm, z, y, x)),\n        z=IntSlider(min=0, max=vol_shape[0], step=5, value=int(vol_shape[0] / 2)),\n        y=IntSlider(min=0, max=vol_shape[1], step=5, value=int(vol_shape[1] / 2)),\n        x=IntSlider(min=0, max=vol_shape[2], step=5, value=int(vol_shape[2] / 2)),\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:40:22.772203Z","iopub.execute_input":"2022-04-29T08:40:22.772603Z","iopub.status.idle":"2022-04-29T08:40:26.180561Z","shell.execute_reply.started":"2022-04-29T08:40:22.772564Z","shell.execute_reply":"2022-04-29T08:40:26.17978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interactive_show(vol)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:40:26.181736Z","iopub.execute_input":"2022-04-29T08:40:26.182704Z","iopub.status.idle":"2022-04-29T08:40:26.784271Z","shell.execute_reply.started":"2022-04-29T08:40:26.182664Z","shell.execute_reply":"2022-04-29T08:40:26.78363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare flatten dataset","metadata":{}},{"cell_type":"code","source":"DATASET_IMAGES = \"/kaggle/temp/dataset-flash/images\"\nDATASET_SEGMS = \"/kaggle/temp/dataset-flash/segms\"\n\nfor rdir in (DATASET_IMAGES, DATASET_SEGMS):\n    for sdir in (\"train\", \"val\"):\n        os.makedirs(os.path.join(rdir, sdir), exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:40:26.785252Z","iopub.execute_input":"2022-04-29T08:40:26.785522Z","iopub.status.idle":"2022-04-29T08:40:26.792733Z","shell.execute_reply.started":"2022-04-29T08:40:26.785488Z","shell.execute_reply":"2022-04-29T08:40:26.791915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Case_Day'] = [f\"case{r['Case']}_day{r['Day']}\" for _, r in df_train.iterrows()]\n\nCASES_DAYS = list(df_train['Case_Day'].unique())\nVAL_SPLIT = 0.1\nVAL_CASES_DAYS = CASES_DAYS[-int(VAL_SPLIT * len(CASES_DAYS)):]\n\nprint(f\"all case-day: {len(CASES_DAYS)}\")\nprint(f\"val case-day: {len(VAL_CASES_DAYS)}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:40:26.794071Z","iopub.execute_input":"2022-04-29T08:40:26.794469Z","iopub.status.idle":"2022-04-29T08:40:32.233692Z","shell.execute_reply.started":"2022-04-29T08:40:26.794431Z","shell.execute_reply":"2022-04-29T08:40:32.232131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nfrom kaggle_imsegm.data import preprocess_tract_scan\n\nLABELS = sorted(df_train[\"class\"].unique())\nprint(LABELS)\n\ndef _chose_sfolder(df_, val_cases_days=VAL_CASES_DAYS) -> str:\n    case, day = df_.iloc[0][[\"Case\", \"Day\"]]\n    case_day = f\"case{case}_day{day}\"\n    return 'val' if case_day in val_cases_days else 'train'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-29T08:40:32.235148Z","iopub.execute_input":"2022-04-29T08:40:32.235408Z","iopub.status.idle":"2022-04-29T08:40:32.297721Z","shell.execute_reply.started":"2022-04-29T08:40:32.235372Z","shell.execute_reply":"2022-04-29T08:40:32.297002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\n_args = dict(\n    dir_data=os.path.join(DATASET_FOLDER, \"train\"),\n    dir_imgs=DATASET_IMAGES,\n    dir_segm=DATASET_SEGMS,\n    labels=LABELS,\n)\ndf_train[\"Case_Day\"] = [f\"case{r['Case']}_day{r['Day']}\" for _, r in df_train.iterrows()]\n_= Parallel(n_jobs=6)(\n    delayed(preprocess_tract_scan)(dfg, sfolder=_chose_sfolder(dfg), **_args)\n    for _, dfg in tqdm(df_train.groupby(\"Case_Day\"))\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:43:45.696965Z","iopub.execute_input":"2022-04-29T08:43:45.697229Z","iopub.status.idle":"2022-04-29T09:03:15.539282Z","shell.execute_reply.started":"2022-04-29T08:43:45.697195Z","shell.execute_reply":"2022-04-29T09:03:15.538412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spl_imgs = glob.glob(os.path.join(DATASET_IMAGES, \"*\", \"*.png\"))[:3]\nfig, axarr = plt.subplots(ncols=2, nrows=len(spl_imgs), figsize=(6, 3 * len(spl_imgs)))\n\nfor i, img in enumerate(spl_imgs):\n    segm = img.replace(DATASET_IMAGES, DATASET_SEGMS)\n    axarr[i, 0].imshow(plt.imread(img))\n    axarr[i, 1].imshow(plt.imread(segm))\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:03:15.541598Z","iopub.execute_input":"2022-04-29T09:03:15.541862Z","iopub.status.idle":"2022-04-29T09:03:16.601067Z","shell.execute_reply.started":"2022-04-29T09:03:15.541821Z","shell.execute_reply":"2022-04-29T09:03:16.600418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lightningâš¡Flash\n\nlets follow the Semantinc segmentation example: https://lightning-flash.readthedocs.io/en/stable/reference/semantic_segmentation.html","metadata":{}},{"cell_type":"code","source":"import torch\n\nimport flash\nfrom flash.core.data.utils import download_data\nfrom flash.image import SemanticSegmentation, SemanticSegmentationData","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:03:16.602502Z","iopub.execute_input":"2022-04-29T09:03:16.602977Z","iopub.status.idle":"2022-04-29T09:03:26.62597Z","shell.execute_reply.started":"2022-04-29T09:03:16.602936Z","shell.execute_reply":"2022-04-29T09:03:26.625121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Create the DataModule","metadata":{}},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import Any, Callable, Dict, Mapping, Sequence, Tuple, Union\nimport albumentations as alb\nfrom flash.core.data.io.input_transform import InputTransform\nfrom flash.image.segmentation.input_transform import prepare_target, remove_extra_dimensions\nfrom kaggle_imsegm.augment import FlashAlbumentationsAdapter\n\n@dataclass\nclass SemanticSegmentationInputTransform(InputTransform):\n    # https://albumentations.ai/docs/examples/pytorch_semantic_segmentation\n\n    image_size: Tuple[int, int] = (128, 128)\n\n    def train_per_sample_transform(self) -> Callable:\n        return FlashAlbumentationsAdapter([\n            alb.Resize(*self.image_size),\n            alb.VerticalFlip(p=0.5),\n            alb.HorizontalFlip(p=0.5),\n            alb.RandomRotate90(p=0.5),\n            alb.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.03, rotate_limit=5, p=1.),\n            alb.GaussNoise(var_limit=(0.001, 0.005), mean=0, per_channel=False, p=1.0),\n            alb.OneOf([\n                alb.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n                alb.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0),\n            ], p=0.25),\n            #alb.ElasticTransform(p=1, alpha=100, sigma=100 * 0.05, alpha_affine=100 * 0.03),\n            #alb.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25, p=0.5),\n            alb.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.8),\n        ])\n\n    def per_sample_transform(self) -> Callable:\n        return FlashAlbumentationsAdapter([alb.Resize(*self.image_size)])\n\n    def predict_input_per_sample_transform(self) -> Callable:\n        return FlashAlbumentationsAdapter([alb.Resize(*self.image_size)])\n\n    def target_per_batch_transform(self) -> Callable:\n        return prepare_target\n\n    def predict_per_batch_transform(self) -> Callable:\n        return remove_extra_dimensions\n\n    def serve_per_batch_transform(self) -> Callable:\n        return remove_extra_dimensions","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:03:26.628599Z","iopub.execute_input":"2022-04-29T09:03:26.628877Z","iopub.status.idle":"2022-04-29T09:03:26.644591Z","shell.execute_reply.started":"2022-04-29T09:03:26.62884Z","shell.execute_reply":"2022-04-29T09:03:26.643944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datamodule = SemanticSegmentationData.from_folders(\n    train_folder=os.path.join(DATASET_IMAGES, 'train'),\n    train_target_folder=os.path.join(DATASET_SEGMS, 'train'),\n    val_folder=os.path.join(DATASET_IMAGES, 'val'),\n    val_target_folder=os.path.join(DATASET_SEGMS, 'val'),\n    #val_split=0.1,\n    train_transform=SemanticSegmentationInputTransform,\n    val_transform=SemanticSegmentationInputTransform,\n    # predict_transform=SemanticSegmentationInputTransform,\n    transform_kwargs=dict(image_size=(256, 256)),\n    num_classes=len(LABELS) + 1,\n    batch_size=24,\n    num_workers=3,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:12:32.796996Z","iopub.execute_input":"2022-04-29T09:12:32.797622Z","iopub.status.idle":"2022-04-29T09:12:33.682046Z","shell.execute_reply.started":"2022-04-29T09:12:32.797579Z","shell.execute_reply":"2022-04-29T09:12:33.681254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datamodule.show_train_batch()\n\nfig, axarr = plt.subplots(ncols=2, nrows=5, figsize=(8, 20))\nrunning_i = 0\n\nfor batch in datamodule.train_dataloader():\n    print(batch.keys())\n    for i in range(len(batch['input'])):\n        segm = batch['target'][i].numpy()\n        if np.sum(segm) == 0 or np.max(segm) <= 1:\n            continue\n        img = np.rollaxis(batch['input'][i].cpu().numpy(), 0, 3)\n        axarr[running_i, 0].imshow(img)\n        axarr[running_i, 1].imshow(segm)\n        running_i += 1\n        if running_i >= 5:\n            break\n    if running_i >= 5:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:12:33.683907Z","iopub.execute_input":"2022-04-29T09:12:33.684303Z","iopub.status.idle":"2022-04-29T09:12:37.030165Z","shell.execute_reply.started":"2022-04-29T09:12:33.684265Z","shell.execute_reply":"2022-04-29T09:12:37.029353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Build the task","metadata":{}},{"cell_type":"code","source":"model = SemanticSegmentation(\n    backbone=\"resnext50_32x4d\",\n    head=\"deeplabv3\",\n    pretrained=False,\n    optimizer=\"AdamW\",\n    learning_rate=1e-2,\n    num_classes=datamodule.num_classes,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:12:37.031744Z","iopub.execute_input":"2022-04-29T09:12:37.032175Z","iopub.status.idle":"2022-04-29T09:12:37.562218Z","shell.execute_reply.started":"2022-04-29T09:12:37.032134Z","shell.execute_reply":"2022-04-29T09:12:37.56143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Create the trainer and finetune the model","metadata":{}},{"cell_type":"code","source":"import pytorch_lightning as pl\n\nlogger = pl.loggers.CSVLogger(save_dir='logs/')\ntrainer = flash.Trainer(\n    max_epochs=10,\n    logger=logger,\n    # precision=16,\n    gpus=torch.cuda.device_count(),\n#     limit_train_batches=0.2,\n#     limit_val_batches=0.2,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:12:37.564394Z","iopub.execute_input":"2022-04-29T09:12:37.564765Z","iopub.status.idle":"2022-04-29T09:12:37.573353Z","shell.execute_reply.started":"2022-04-29T09:12:37.564722Z","shell.execute_reply":"2022-04-29T09:12:37.572617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer.finetune(model, datamodule=datamodule, strategy=\"no_freeze\")\n\n# Save the model!\ntrainer.save_checkpoint(\"semantic_segmentation_model.pt\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-29T09:12:37.574791Z","iopub.execute_input":"2022-04-29T09:12:37.575199Z","iopub.status.idle":"2022-04-29T09:28:32.486711Z","shell.execute_reply.started":"2022-04-29T09:12:37.575162Z","shell.execute_reply":"2022-04-29T09:28:32.485809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sn\n\nmetrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\ndel metrics[\"step\"]\nmetrics.set_index(\"epoch\", inplace=True)\ndisplay(metrics.dropna(axis=1, how=\"all\").head())\ng = sn.relplot(data=metrics, kind=\"line\")\nplt.gcf().set_size_inches(12, 4)\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:28:32.490483Z","iopub.execute_input":"2022-04-29T09:28:32.490746Z","iopub.status.idle":"2022-04-29T09:28:33.290093Z","shell.execute_reply.started":"2022-04-29T09:28:32.490717Z","shell.execute_reply":"2022-04-29T09:28:33.289349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Segment a few images!","metadata":{}},{"cell_type":"code","source":"sample_imgs = glob.glob(os.path.join(DATASET_FOLDER, \"test\", \"**\", \"*.png\"), recursive=True)\nif not sample_imgs:\n    sample_imgs = glob.glob(os.path.join(DATASET_FOLDER, \"train\", \"**\", \"*.png\"), recursive=True)\nprint(f\"images: {len(sample_imgs)}\")\nsample_imgs = sample_imgs[:5]\n\ndatamodule = SemanticSegmentationData.from_files(\n    predict_files=sample_imgs,\n    predict_transform=SemanticSegmentationInputTransform,\n    transform_kwargs=dict(image_size=(256, 256)),\n    batch_size=3,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:28:33.291545Z","iopub.execute_input":"2022-04-29T09:28:33.291816Z","iopub.status.idle":"2022-04-29T09:28:37.028765Z","shell.execute_reply.started":"2022-04-29T09:28:33.291779Z","shell.execute_reply":"2022-04-29T09:28:37.027974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axarr = plt.subplots(ncols=5, nrows=len(sample_imgs), figsize=(15, 3 * len(sample_imgs)))\nrunning_i = 0\nfor preds in trainer.predict(model, datamodule=datamodule):\n    for pred in preds:\n        # print(pred.keys())\n        img = np.rollaxis(pred['input'].cpu().numpy(), 0, 3)\n        axarr[running_i, 0].imshow(img)\n        for j, seg in enumerate(pred['preds'].cpu().numpy()):\n            axarr[running_i, j + 1].imshow(seg)\n        running_i += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:28:37.03016Z","iopub.execute_input":"2022-04-29T09:28:37.030602Z","iopub.status.idle":"2022-04-29T09:28:40.593005Z","shell.execute_reply.started":"2022-04-29T09:28:37.030544Z","shell.execute_reply":"2022-04-29T09:28:40.592397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axarr = plt.subplots(ncols=2, nrows=len(sample_imgs), figsize=(8, 4 * len(sample_imgs)))\nrunning_i = 0\nfor preds in trainer.predict(model, datamodule=datamodule, output=\"labels\"):\n    for pred in preds:\n        # print(pred)\n        img = plt.imread(sample_imgs[running_i])\n        axarr[running_i, 0].imshow(img, cmap=\"gray\")\n        axarr[running_i, 1].imshow(pred)\n        running_i += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:28:40.59493Z","iopub.execute_input":"2022-04-29T09:28:40.59544Z","iopub.status.idle":"2022-04-29T09:28:43.866926Z","shell.execute_reply.started":"2022-04-29T09:28:40.595398Z","shell.execute_reply":"2022-04-29T09:28:43.866238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"model = SemanticSegmentation.load_from_checkpoint(\n    \"semantic_segmentation_model.pt\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:28:43.869336Z","iopub.execute_input":"2022-04-29T09:28:43.870728Z","iopub.status.idle":"2022-04-29T09:28:44.872099Z","shell.execute_reply.started":"2022-04-29T09:28:43.870684Z","shell.execute_reply":"2022-04-29T09:28:44.871213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred = pd.read_csv(os.path.join(DATASET_FOLDER, \"sample_submission.csv\"))\nsfolder = \"test\"\ndisplay(df_pred.head())\n\nif df_pred.empty:\n    sfolder = \"train\"\n    df_pred = pd.read_csv(os.path.join(DATASET_FOLDER, \"train.csv\"))\n    df_pred = df_pred[df_pred[\"id\"].str.startswith(\"case123_day\")]\n\nos.makedirs(os.path.join(DATASET_IMAGES, sfolder), exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:28:44.877452Z","iopub.execute_input":"2022-04-29T09:28:44.879735Z","iopub.status.idle":"2022-04-29T09:28:45.255333Z","shell.execute_reply.started":"2022-04-29T09:28:44.879686Z","shell.execute_reply":"2022-04-29T09:28:45.254502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint\nfrom kaggle_imsegm.data import extract_tract_details\n\npprint(extract_tract_details(df_pred['id'].iloc[0], DATASET_FOLDER, folder=sfolder))\n\ndf_pred[['Case','Day','Slice', 'image', 'image_path', 'height', 'width']] = df_pred['id'].apply(\n    lambda x: pd.Series(extract_tract_details(x, DATASET_FOLDER, folder=sfolder))\n)\ndf_pred[\"Case_Day\"] = [f\"case{r['Case']}_day{r['Day']}\" for _, r in df_pred.iterrows()]\ndisplay(df_pred.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:28:45.256475Z","iopub.execute_input":"2022-04-29T09:28:45.256754Z","iopub.status.idle":"2022-04-29T09:28:47.181131Z","shell.execute_reply.started":"2022-04-29T09:28:45.256716Z","shell.execute_reply":"2022-04-29T09:28:47.180438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions for test scans","metadata":{}},{"cell_type":"code","source":"from joblib import Parallel, delayed\nfrom kaggle_imsegm.data import preprocess_tract_scan\n\n_args = dict(\n    dir_data=os.path.join(DATASET_FOLDER, sfolder),\n    dir_imgs=DATASET_IMAGES,\n    dir_segm=None,\n    labels=LABELS,\n    sfolder=sfolder,\n)\ntest_scans = Parallel(n_jobs=6)(\n    delayed(preprocess_tract_scan)(dfg, **_args)\n    for _, dfg in df_pred.groupby(\"Case_Day\")\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom itertools import chain\nfrom kaggle_imsegm.mask import rle_encode\n\npreds = []\nfor test_imgs in test_scans:\n    dm = SemanticSegmentationData.from_files(\n        predict_files=test_imgs,\n        predict_transform=SemanticSegmentationInputTransform,\n        transform_kwargs=dict(image_size=(256, 256)),\n        num_classes=len(LABELS) + 1,\n        batch_size=10,\n        num_workers=3,\n    )\n    pred = trainer.predict(model, datamodule=dm, output=\"labels\")\n    pred = list(chain(*pred))\n    for img, seg in zip(test_imgs, pred):\n        rle = rle_encode(np.array(seg)) if np.sum(seg) > 1 else {}\n        name, _ = os.path.splitext(os.path.basename(img))\n        id_ = \"_\".join(name.split(\"_\")[:4])\n        preds += [{\"id\": id_, \"class\": lb, \"predicted\": rle.get(i + 1, \"\")} for i, lb in enumerate(LABELS)]\n\ndf_pred = pd.DataFrame(preds)\ndisplay(df_pred[df_pred[\"predicted\"] != \"\"].head())","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-29T09:28:47.182237Z","iopub.execute_input":"2022-04-29T09:28:47.184718Z","iopub.status.idle":"2022-04-29T09:31:14.124131Z","shell.execute_reply.started":"2022-04-29T09:28:47.184675Z","shell.execute_reply":"2022-04-29T09:31:14.123414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finalize submissions","metadata":{}},{"cell_type":"code","source":"df_ssub = pd.read_csv(os.path.join(DATASET_FOLDER, \"sample_submission.csv\"))\ndel df_ssub['predicted']\ndf_pred = df_ssub.merge(df_pred, on=['id','class'])\n\ndf_pred[['id', 'class', 'predicted']].to_csv(\"submission.csv\", index=False)\n\n!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-04-29T09:31:14.125705Z","iopub.execute_input":"2022-04-29T09:31:14.126192Z","iopub.status.idle":"2022-04-29T09:31:14.941043Z","shell.execute_reply.started":"2022-04-29T09:31:14.126152Z","shell.execute_reply":"2022-04-29T09:31:14.9401Z"},"trusted":true},"execution_count":null,"outputs":[]}]}