{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport datetime\nimport scipy.stats\nimport math\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Activation,Input, InputLayer, Dense, BatchNormalization, Dropout,LayerNormalization\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T15:07:54.170111Z","iopub.execute_input":"2022-05-05T15:07:54.170551Z","iopub.status.idle":"2022-05-05T15:08:01.324945Z","shell.execute_reply.started":"2022-05-05T15:07:54.170515Z","shell.execute_reply":"2022-05-05T15:08:01.323965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/train.csv')\ntest=pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:01.326383Z","iopub.execute_input":"2022-05-05T15:08:01.326673Z","iopub.status.idle":"2022-05-05T15:08:17.345032Z","shell.execute_reply.started":"2022-05-05T15:08:01.326639Z","shell.execute_reply":"2022-05-05T15:08:17.344066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:17.346554Z","iopub.execute_input":"2022-05-05T15:08:17.346891Z","iopub.status.idle":"2022-05-05T15:08:17.384887Z","shell.execute_reply.started":"2022-05-05T15:08:17.346841Z","shell.execute_reply":"2022-05-05T15:08:17.384065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:17.38711Z","iopub.execute_input":"2022-05-05T15:08:17.387806Z","iopub.status.idle":"2022-05-05T15:08:17.39402Z","shell.execute_reply.started":"2022-05-05T15:08:17.387765Z","shell.execute_reply":"2022-05-05T15:08:17.393193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:17.395264Z","iopub.execute_input":"2022-05-05T15:08:17.395749Z","iopub.status.idle":"2022-05-05T15:08:17.406006Z","shell.execute_reply.started":"2022-05-05T15:08:17.395691Z","shell.execute_reply":"2022-05-05T15:08:17.405257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:17.407175Z","iopub.execute_input":"2022-05-05T15:08:17.408017Z","iopub.status.idle":"2022-05-05T15:08:17.595334Z","shell.execute_reply.started":"2022-05-05T15:08:17.407973Z","shell.execute_reply":"2022-05-05T15:08:17.594416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:17.596767Z","iopub.execute_input":"2022-05-05T15:08:17.597165Z","iopub.status.idle":"2022-05-05T15:08:17.751179Z","shell.execute_reply.started":"2022-05-05T15:08:17.59712Z","shell.execute_reply":"2022-05-05T15:08:17.750373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train['f_27'].value_counts())\nprint(train['f_27'].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:17.752218Z","iopub.execute_input":"2022-05-05T15:08:17.752531Z","iopub.status.idle":"2022-05-05T15:08:18.913174Z","shell.execute_reply.started":"2022-05-05T15:08:17.752501Z","shell.execute_reply":"2022-05-05T15:08:18.912061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encode_columns(df, columns, encoders=None):\n\tif encoders is None:\n\t\tencoders = {}\n\t\n\t\tfor col in columns:\n\n\t\t\tunique_values = list(df[col].unique())\n\t\t\tunique_values.append('Unseen')\n\t\t\tle = LabelEncoder().fit(unique_values)\n\t\t\tdf[col] = le.transform(df[col])\n\t\t\tencoders[col] = le\n\t\n\telse:\n\t\tfor col in columns:\n\t\t\tle = encoders.get(col)\n\t\t\tdf[col] = [x if x in le.classes_ else 'Unseen' for x in df[col]]\n\t\t\tdf[col] = le.transform(df[col])\n\n\treturn df, encoders","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:18.914607Z","iopub.execute_input":"2022-05-05T15:08:18.915126Z","iopub.status.idle":"2022-05-05T15:08:18.92279Z","shell.execute_reply.started":"2022-05-05T15:08:18.915086Z","shell.execute_reply":"2022-05-05T15:08:18.921612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def processCol_str(df,colName,n):\n    Newtrain=df[colName].str.split('',n=0,expand=True)\n    for ncol in np.arange(1,n+1):\n        df[colName+'_'+ str(ncol)]=Newtrain[ncol]\n        \n    df=df.drop(colName,axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:18.925501Z","iopub.execute_input":"2022-05-05T15:08:18.925814Z","iopub.status.idle":"2022-05-05T15:08:18.936501Z","shell.execute_reply.started":"2022-05-05T15:08:18.925781Z","shell.execute_reply":"2022-05-05T15:08:18.935619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processCol_str(train,'f_27',10)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:18.937638Z","iopub.execute_input":"2022-05-05T15:08:18.937854Z","iopub.status.idle":"2022-05-05T15:08:25.44892Z","shell.execute_reply.started":"2022-05-05T15:08:18.937827Z","shell.execute_reply":"2022-05-05T15:08:25.447828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processCol_str(test,'f_27',10)\ncatcol=[ 'f_27_1', 'f_27_2', 'f_27_3',\n       'f_27_4', 'f_27_5', 'f_27_6', 'f_27_7', 'f_27_8', 'f_27_9', 'f_27_10']","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:25.450411Z","iopub.execute_input":"2022-05-05T15:08:25.450641Z","iopub.status.idle":"2022-05-05T15:08:30.177185Z","shell.execute_reply.started":"2022-05-05T15:08:25.450614Z","shell.execute_reply":"2022-05-05T15:08:30.176462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain,encoder = label_encode_columns(train,catcol)\ntest,encoder=label_encode_columns(test,catcol,encoder)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:08:30.180657Z","iopub.execute_input":"2022-05-05T15:08:30.180929Z","iopub.status.idle":"2022-05-05T15:09:09.749828Z","shell.execute_reply.started":"2022-05-05T15:08:30.180897Z","shell.execute_reply":"2022-05-05T15:09:09.74913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=train['target']\nX=train.drop(['id','target'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:09:09.751191Z","iopub.execute_input":"2022-05-05T15:09:09.751642Z","iopub.status.idle":"2022-05-05T15:09:10.028903Z","shell.execute_reply.started":"2022-05-05T15:09:09.751609Z","shell.execute_reply":"2022-05-05T15:09:10.028158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:09:10.030365Z","iopub.execute_input":"2022-05-05T15:09:10.030811Z","iopub.status.idle":"2022-05-05T15:09:10.034517Z","shell.execute_reply.started":"2022-05-05T15:09:10.030779Z","shell.execute_reply":"2022-05-05T15:09:10.033715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:09:10.035573Z","iopub.execute_input":"2022-05-05T15:09:10.035964Z","iopub.status.idle":"2022-05-05T15:09:10.063956Z","shell.execute_reply.started":"2022-05-05T15:09:10.035923Z","shell.execute_reply":"2022-05-05T15:09:10.063409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=[ 'f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_07',\n       'f_08', 'f_09', 'f_10', 'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16',\n       'f_17', 'f_18', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25',\n       'f_26', 'f_28', 'f_29', 'f_30', 'f_27_1', 'f_27_2', 'f_27_3', 'f_27_4',\n       'f_27_5', 'f_27_6', 'f_27_7', 'f_27_8', 'f_27_9', 'f_27_10']","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:09:10.065165Z","iopub.execute_input":"2022-05-05T15:09:10.065567Z","iopub.status.idle":"2022-05-05T15:09:10.071337Z","shell.execute_reply.started":"2022-05-05T15:09:10.06553Z","shell.execute_reply":"2022-05-05T15:09:10.070498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history, *, n_epochs=None, plot_lr=False, title=None, bottom=None, top=None):\n    \"\"\"Plot (the last n_epochs epochs of) the training history\n    \n    Plots loss and optionally val_loss and lr.\"\"\"\n    plt.figure(figsize=(15, 6))\n    from_epoch = 0 if n_epochs is None else max(len(history['loss']) - n_epochs, 0)\n    \n    # Plot training and validation losses\n    plt.plot(np.arange(from_epoch, len(history['loss'])), history['loss'][from_epoch:], label='Training loss')\n    try:\n        plt.plot(np.arange(from_epoch, len(history['loss'])), history['val_loss'][from_epoch:], label='Validation loss')\n        best_epoch = np.argmin(np.array(history['val_loss']))\n        best_val_loss = history['val_loss'][best_epoch]\n        if best_epoch >= from_epoch:\n            plt.scatter([best_epoch], [best_val_loss], c='r', label=f'Best val_loss = {best_val_loss:.5f}')\n        if best_epoch > 0:\n            almost_epoch = np.argmin(np.array(history['val_loss'])[:best_epoch])\n            almost_val_loss = history['val_loss'][almost_epoch]\n            if almost_epoch >= from_epoch:\n                plt.scatter([almost_epoch], [almost_val_loss], c='orange', label='Second best val_loss')\n    except KeyError:\n        pass\n    if bottom is not None: plt.ylim(bottom=bottom)\n    if top is not None: plt.ylim(top=top)\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='lower left')\n    if title is not None: plt.title(title)\n        \n    # Plot learning rate\n    if plot_lr and 'lr' in history:\n        ax2 = plt.gca().twinx()\n        ax2.plot(np.arange(from_epoch, len(history['lr'])), np.array(history['lr'][from_epoch:]), color='g', label='Learning rate')\n        ax2.set_ylabel('Learning rate')\n        ax2.legend(loc='upper right')\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:09:10.072771Z","iopub.execute_input":"2022-05-05T15:09:10.073269Z","iopub.status.idle":"2022-05-05T15:09:10.095378Z","shell.execute_reply.started":"2022-05-05T15:09:10.073239Z","shell.execute_reply":"2022-05-05T15:09:10.094744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_model():\n    \"\"\"Simple sequential neural network with three hidden layers.\n    \n    Returns a (not yet compiled) instance of tensorflow.keras.models.Model.\n    \"\"\"\n    activation = 'swish'\n    inputs = Input(shape=(len(features)))\n    x = Dense(256,\n              kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n               use_bias = True,\n              activation=activation,\n             )(inputs)\n    x = Dense(128, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              use_bias = True,\n              activation=activation,\n             )(inputs)\n    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              use_bias = True,\n              activation=activation,\n             )(x)\n    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              use_bias = True,\n              activation=activation,\n             )(x)\n    x = Dense(32, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              use_bias = True,\n              activation=activation,\n             )(x)\n    x = Dense(16, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    x = Dense(1,\n              use_bias = True,\n              kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation='sigmoid',\n             )(x)\n    model = Model(inputs, x)\n    return model\n\nplot_model(my_model(), show_layer_names=True, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:46:37.095402Z","iopub.execute_input":"2022-05-05T15:46:37.095749Z","iopub.status.idle":"2022-05-05T15:46:37.340288Z","shell.execute_reply.started":"2022-05-05T15:46:37.095713Z","shell.execute_reply":"2022-05-05T15:46:37.339321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Cross-validation of the classifier\n\nEPOCHS = 200\nEPOCHS_COSINEDECAY = 100\nVERBOSE = 0 # set to 0 for less output, or to 2 for more output\nDIAGRAMS = True\nUSE_PLATEAU = False\nBATCH_SIZE = 4096\n\n# see https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\nnp.random.seed(1)\nrandom.seed(1)\ntf.random.set_seed(1)\n\ndef fit_model(X_tr, y_tr, X_va=None, y_va=None, run=0):\n    \"\"\"Scale the data, fit a model, plot the training history and optionally validate the model\n    \n    Returns a trained instance of tensorflow.keras.models.Model.\n    \n    As a side effect, updates y_va_pred, history_list and score_list.\n    \"\"\"\n    global y_va_pred\n    start_time = datetime.datetime.now()\n    \n    scaler = StandardScaler()\n    X_tr = scaler.fit_transform(X_tr)\n    \n    if X_va is not None:\n        X_va = scaler.transform(X_va)\n        validation_data = (X_va, y_va)\n    else:\n        validation_data = None\n\n    # Define the learning rate schedule and EarlyStopping\n    lr_start=0.01\n    if USE_PLATEAU and X_va is not None: # use early stopping\n        epochs = EPOCHS\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, \n                               patience=4, verbose=VERBOSE)\n        es = EarlyStopping(monitor=\"val_loss\",\n                           patience=12, \n                           verbose=1,\n                           mode=\"min\", \n                           restore_best_weights=True)\n        callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n\n    else: # use cosine learning rate decay rather than early stopping\n        epochs = EPOCHS_COSINEDECAY\n        lr_end=0.0002\n        def cosine_decay(epoch):\n            if epochs > 1:\n                w = (1 + math.cos(epoch / (epochs-1) * math.pi)) / 2\n            else:\n                w = 1\n            return w * lr_start + (1 - w) * lr_end\n\n        lr = LearningRateScheduler(cosine_decay, verbose=0)\n        callbacks = [lr, tf.keras.callbacks.TerminateOnNaN()]\n        \n    # Construct and compile the model\n    model = my_model()\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_start),\n                  #metrics='acc',\n                  loss=tf.keras.losses.BinaryCrossentropy())\n    #model.compile(optimizer=tf.keras.optimizers.SGD(), loss='mse')\n\n    # Train the model\n    history = model.fit(X_tr, y_tr, \n                        validation_data=validation_data, \n                        epochs=epochs,\n                        verbose=VERBOSE,\n                        batch_size=BATCH_SIZE,\n                        shuffle=True,\n                        callbacks=callbacks)\n\n    history_list.append(history.history)\n    callbacks, es, lr, history = None, None, None, None\n    print(f\"Training loss:   {history_list[-1]['loss'][-1]:.3f}\")\n    \n    if X_va is not None:\n        # Inference for validation\n        y_va_pred = model.predict(X_va, batch_size=BATCH_SIZE, verbose=VERBOSE)\n        #oof_list[run][val_idx] = y_va_pred\n        \n        # Evaluation: Execution time and AUC\n        score = roc_auc_score(y_va, y_va_pred)\n        print(f\"Fold {run}.{fold} | {str(datetime.datetime.now() - start_time)[-12:-7]}\"\n              f\" | AUC: {score:.5f}\")\n        score_list.append(score)\n        \n        if DIAGRAMS and fold == 0 and run == 0:\n            # Plot training history\n            plot_history(history_list[-1], \n                         title=f\"Learning curve (validation AUC = {score:.5f})\",\n                         plot_lr=True, n_epochs=110)\n\n            # Plot y_true vs. y_pred\n            plt.figure(figsize=(10, 4))\n            plt.hist(y_va_pred[y_va == 0], bins=np.linspace(0, 1, 21),\n                     alpha=0.5, density=True)\n            plt.hist(y_va_pred[y_va == 1], bins=np.linspace(0, 1, 21),\n                     alpha=0.5, density=True)\n            plt.xlabel('y_pred')\n            plt.ylabel('density')\n            plt.title('OOF Predictions')\n            plt.show()\n\n    return model, scaler\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:46:37.868979Z","iopub.execute_input":"2022-05-05T15:46:37.869447Z","iopub.status.idle":"2022-05-05T15:46:37.891033Z","shell.execute_reply.started":"2022-05-05T15:46:37.86941Z","shell.execute_reply":"2022-05-05T15:46:37.890079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_list = []\nscore_list = []\nkf = KFold(n_splits=5)\nfor fold, (idx_tr, idx_va) in enumerate(kf.split(X)):\n    X_tr = X.iloc[idx_tr][features]\n    X_va = X.iloc[idx_va][features]\n    y_tr = y.iloc[idx_tr]\n    y_va = y.iloc[idx_va]\n  \n    fit_model(X_tr, y_tr, X_va, y_va)\n    break # we only need the first fold","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:46:38.291054Z","iopub.execute_input":"2022-05-05T15:46:38.291344Z","iopub.status.idle":"2022-05-05T15:51:34.912071Z","shell.execute_reply.started":"2022-05-05T15:46:38.29131Z","shell.execute_reply":"2022-05-05T15:51:34.911118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submission\n# Create submission\nprint(f\"{len(features)} features\")\n\nX_tr = X\ny_tr = y\n\npred_list = []\nfor seed in range(10):\n    # see https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    model, scaler = fit_model(X_tr, y_tr, run=seed)\n    pred_list.append(scipy.stats.rankdata(model.predict(scaler.transform(test[features]),\n                                                        batch_size=BATCH_SIZE, verbose=VERBOSE)))\n    print(f\"{seed:2}\", pred_list[-1])\nprint()\nsubmission = test[['id']].copy()\nsubmission['target'] = np.array(pred_list).mean(axis=0)\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:02:55.103038Z","iopub.execute_input":"2022-05-03T21:02:55.103337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"refrence:\n    https://www.kaggle.com/code/ambrosm/tpsmay22-keras-quickstart/notebook?scriptVersionId=94617937","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ord('A')","metadata":{"execution":{"iopub.status.busy":"2022-05-03T19:22:40.614633Z","iopub.execute_input":"2022-05-03T19:22:40.614943Z","iopub.status.idle":"2022-05-03T19:22:40.621223Z","shell.execute_reply.started":"2022-05-03T19:22:40.614905Z","shell.execute_reply":"2022-05-03T19:22:40.620496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T00:47:10.539525Z","iopub.execute_input":"2022-05-02T00:47:10.540584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T00:35:04.322276Z","iopub.execute_input":"2022-05-02T00:35:04.322523Z","iopub.status.idle":"2022-05-02T00:41:02.411322Z","shell.execute_reply.started":"2022-05-02T00:35:04.322488Z","shell.execute_reply":"2022-05-02T00:41:02.408971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}