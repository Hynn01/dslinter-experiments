{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T15:31:34.388784Z","iopub.execute_input":"2022-05-07T15:31:34.38955Z","iopub.status.idle":"2022-05-07T15:31:35.452158Z","shell.execute_reply.started":"2022-05-07T15:31:34.389447Z","shell.execute_reply":"2022-05-07T15:31:35.451281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv(\"../input/nft-art-dataset/dataset/dataset.csv\")\ndataset.head()\n\nlist(dataset.columns)\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:35.453899Z","iopub.execute_input":"2022-05-07T15:31:35.454122Z","iopub.status.idle":"2022-05-07T15:31:35.543291Z","shell.execute_reply.started":"2022-05-07T15:31:35.454095Z","shell.execute_reply":"2022-05-07T15:31:35.542367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Initial EDA**\n\n\n\nTake a look at the images and try out possible image processing technique\n\n\nBoilerplate","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nfrom spectral import *\nimport seaborn as sns\n%matplotlib inline\n\npal = sns.color_palette()\nsns.set_style(\"whitegrid\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:35.544584Z","iopub.execute_input":"2022-05-07T15:31:35.54502Z","iopub.status.idle":"2022-05-07T15:31:35.598545Z","shell.execute_reply.started":"2022-05-07T15:31:35.544989Z","shell.execute_reply":"2022-05-07T15:31:35.597945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Files","metadata":{}},{"cell_type":"code","source":"print('# File sizes')\nfolder = '../input/nft-art-dataset/dataset/'\n\nfor f in os.listdir(folder):\n    if not os.path.isdir(folder + f):\n        print(f.ljust(30) + str(round(os.path.getsize(folder + f) / 1000000, 2)) + 'MB')\n    else:\n        sizes = [os.path.getsize(folder+f+'/'+x)/1000000 for x in os.listdir(folder + f)]\n        print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + ' ({} files)'.format(len(sizes)))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:35.600517Z","iopub.execute_input":"2022-05-07T15:31:35.600971Z","iopub.status.idle":"2022-05-07T15:31:45.007156Z","shell.execute_reply.started":"2022-05-07T15:31:35.60093Z","shell.execute_reply":"2022-05-07T15:31:45.006331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(folder + \"dataset.csv\")\ntrain_df.head()\ntrain_df = dataset [ dataset['type'] == 'PHOTO' ] [[\"name\", \"path\"]]\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:45.008388Z","iopub.execute_input":"2022-05-07T15:31:45.009097Z","iopub.status.idle":"2022-05-07T15:31:45.058464Z","shell.execute_reply.started":"2022-05-07T15:31:45.009062Z","shell.execute_reply":"2022-05-07T15:31:45.057803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**View some JPEGs**","metadata":{}},{"cell_type":"code","source":"import cv2\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(12, 12))\ni = 0\nst = 200\nfor f, l in train_df[st:st+9].values:\n    file = folder + \"image/\" + l.split('/')[-1]\n    img = cv2.imread(file)    \n    up_width = 600\n    up_height = 400\n    up_points = (up_width, up_height)\n\n    img2 = cv2.resize(img, up_points, interpolation = cv2.INTER_LINEAR)\n    \n    ax[i // 3, i % 3].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n    ax[i // 3, i % 3].set_title('{}'.format(f))\n#     ax[i // 4, i % 4].show()\n#     print('../input/train-tif/{}.tif'.format(f))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:45.059688Z","iopub.execute_input":"2022-05-07T15:31:45.060054Z","iopub.status.idle":"2022-05-07T15:31:49.174264Z","shell.execute_reply.started":"2022-05-07T15:31:45.060025Z","shell.execute_reply":"2022-05-07T15:31:49.173441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Basic Information**","metadata":{}},{"cell_type":"code","source":"\ntotal = len(dataset)\nphotos = len(dataset[ dataset['type'] == 'PHOTO' ])\ngifs = len(dataset[ dataset['type'] == 'GIF' ])\nvideos = len(dataset[ dataset['type'] == 'VIDEO' ])\n\n\nprint(f\"There are {total} records in the dataset in total, in the form of gifs, images, and videos.\")\nprint(f\"There are {photos} photos in the dataset.\")\nprint(f\"There are {gifs} gifs in the dataset.\")\nprint(f\"There are {videos} videos in the dataset\")\nprint(\"\\n\")\n\ntotal_creators = len(dataset['creator'].unique())\nphoto_creators = len(dataset[ dataset['type'] == 'PHOTO']['creator'].unique())\ngif_creators = len(dataset[ dataset['type'] == 'GIF']['creator'].unique())\nvideo_creators = len(dataset[ dataset['type'] == 'VIDEO']['creator'].unique())\n\nprint(f\"The dataset contains the works of {total_creators} unique artists in total.\")\nprint(f\"The photos artwork is made by {photo_creators} unique artists in total.\")\nprint(f\"The gifs artwork is made by {gif_creators} unique artists in total.\")\nprint(f\"The videos artwork is made by {video_creators} unique artists in total.\")\nprint(\"\\n\")\n\ntotal_art_series = total_creators = len(dataset['art_series'].unique())\nprint(f\"There are {total_art_series} art serieses in total\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:49.175388Z","iopub.execute_input":"2022-05-07T15:31:49.175589Z","iopub.status.idle":"2022-05-07T15:31:49.199406Z","shell.execute_reply.started":"2022-05-07T15:31:49.175563Z","shell.execute_reply":"2022-05-07T15:31:49.19838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Content","metadata":{}},{"cell_type":"code","source":"\ncounts = dataset['type'].value_counts()\n#define data\ndata = list(counts.values)\nlabels = list(counts.index)\n\n#define Seaborn color palette to use\ncolors = sns.color_palette('pastel')[0:5]\n\n#create pie chart\nplt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')\nplt.title(\"Types of Artwork\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:32:52.320998Z","iopub.execute_input":"2022-05-07T15:32:52.32194Z","iopub.status.idle":"2022-05-07T15:32:52.42287Z","shell.execute_reply.started":"2022-05-07T15:32:52.321882Z","shell.execute_reply":"2022-05-07T15:32:52.421869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The likes counter","metadata":{}},{"cell_type":"code","source":"likes = dataset[\"likes\"].value_counts()\nsns.set_theme(style=\"whitegrid\")\ntips = sns.load_dataset(\"tips\")\n\nfor i in range(0, 10 ):\n    print(f\"There are {list(likes.values)[i]} art piece(s) that has {list(likes.index)[i]} likes.\")\n\nax = sns.barplot(x=list(likes.index), y=list(likes.values) )","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:49.296799Z","iopub.status.idle":"2022-05-07T15:31:49.297477Z","shell.execute_reply.started":"2022-05-07T15:31:49.297196Z","shell.execute_reply":"2022-05-07T15:31:49.297223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prices distribution**","metadata":{}},{"cell_type":"code","source":"prices = dataset[['price','year']]\nsns.displot(prices.price.values, bins = [10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000]).set(title=\"Prices in Hive, 1 Hive = 0.9359 USD\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:49.299104Z","iopub.status.idle":"2022-05-07T15:31:49.299448Z","shell.execute_reply.started":"2022-05-07T15:31:49.299281Z","shell.execute_reply":"2022-05-07T15:31:49.2993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Price Statistics**","metadata":{}},{"cell_type":"code","source":"print(f\"The average price of all art pieces is { '{0:.1f}'.format(prices.price.mean()) } coins\")\nprint(f\"The median price of all art pieces is { '{0:.1f}'.format(prices.price.median()) } coins\")\nprint(f\"The standard deviation of the prices is { '{0:.1f}'.format(prices.price.std()) } coins\")\nprint(\"\\n\\n\")\n\nsum,cnt = 0, 0 \nlst = []\n\nfor year in range(2017, 2022):\n    min_price = prices[ prices['year'] == year ].price.min()\n    max_price = prices[ prices['year'] == year ].price.max()\n    \n    art_count = len(prices[ prices['year'] == year ])\n    sorted_prices = sorted(prices[(prices['year'] == year)].price)\n\n    low_1 = sorted_prices[ int(art_count*0.01) ]\n    top_1 = sorted_prices[ int(art_count*0.99) ]\n        \n    data_without_outliers = prices[ (prices['year'] == year) & (prices['price'] > low_1) & (prices['price'] < top_1) ]\n    sum += data_without_outliers.price.sum()\n    cnt += len(data_without_outliers)\n    lst = lst + list(data_without_outliers.price)\n    \n    print(f\"Number of art pieces in {year} is { len(data_without_outliers) }\")\n    print(f\"The average price of art pieces in {year} is { '{0:.1f}'.format(data_without_outliers.price.mean()) }\")\n    print(f\"The median price of art pieces in {year} is { '{0:.1f}'.format(data_without_outliers.price.median()) }\")\n    print(\"\\n\")\n\nprint(f\"In total there are {len(lst)} piece(s), with average {'{0:.1f}'.format(np.mean(lst))}, and median {'{0:.1f}'.format(np.median(lst))}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:49.301038Z","iopub.status.idle":"2022-05-07T15:31:49.301489Z","shell.execute_reply.started":"2022-05-07T15:31:49.301245Z","shell.execute_reply":"2022-05-07T15:31:49.30127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The year the artpieces were creater**","metadata":{}},{"cell_type":"markdown","source":"The Kernel Density Estimate (KDE) shows that most of the art pieces were created between 2018 and 2021","metadata":{}},{"cell_type":"code","source":"year_dataset = dataset[ (dataset['year'] >= 2017) & (dataset['year'] <= 2021) ]\n# sns.kdeplot(data=year_dataset, x=\"year\")\n\n\nyear_freq = year_dataset['year'].value_counts()\n\nax = sns.barplot(x=list(year_freq.index), y=list(year_freq.values) )\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:31:49.302994Z","iopub.status.idle":"2022-05-07T15:31:49.303443Z","shell.execute_reply.started":"2022-05-07T15:31:49.303199Z","shell.execute_reply":"2022-05-07T15:31:49.303224Z"},"trusted":true},"execution_count":null,"outputs":[]}]}