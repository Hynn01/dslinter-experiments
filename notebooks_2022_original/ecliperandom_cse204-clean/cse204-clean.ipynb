{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\nimport sklearn\nimport sklearn.linear_model\nimport sklearn.ensemble\nimport sklearn.metrics\nimport sklearn.tree\nimport sklearn.neighbors\n\nimport tensorflow as tf\nimport keras\nimport math\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.mode.chained_assignment = None  # default='warn'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T17:27:16.155275Z","iopub.execute_input":"2022-05-07T17:27:16.155533Z","iopub.status.idle":"2022-05-07T17:27:16.162702Z","shell.execute_reply.started":"2022-05-07T17:27:16.155506Z","shell.execute_reply":"2022-05-07T17:27:16.161785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = '/kaggle/input'\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:16.191361Z","iopub.execute_input":"2022-05-07T17:27:16.193083Z","iopub.status.idle":"2022-05-07T17:27:16.196788Z","shell.execute_reply.started":"2022-05-07T17:27:16.193044Z","shell.execute_reply":"2022-05-07T17:27:16.195899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(ticker):\n    \"\"\"\n    Returns the data frame corresponding to the stock specified in ticker.\n    \"\"\"\n    return pd.read_csv(f'{root_dir}/price-volume-data-for-all-us-stocks-etfs/Stocks/{ticker}.us.txt')\n\ndef date_to_weekday(df):\n    \"\"\"\n    Returns a new data frame identical to df, except for the 'Date' column that\n    will be substituted for binary columns 'Mon', 'Tue',... corresponding to the\n    weekday.\n    \"\"\"\n    \n    df['Date'] = pd.Series(datetime.fromisoformat(date).weekday() for date in df['Date'])\n    \n    df['Mon'] = (df['Date'] == 0)*1.0\n    df['Tue'] = (df['Date'] == 1)*1.0\n    df['Wed'] = (df['Date'] == 2)*1.0\n    df['Thu'] = (df['Date'] == 3)*1.0\n    df['Fri'] = (df['Date'] == 4)*1.0\n    \n    df = df.drop('Date', axis=1)\n    \n    return df\n\ndef normalize_prices(df):\n    \"\"\"\n    Returns a new stock dataframe where the opening prices have\n    been normalized by the previous days prices and the 'High',\n    'Low', 'Close' have been normalized by the opening price of \n    the same day.\n    \"\"\"\n    \n    df['High'] /= df['Open']\n    df['Low'] /= df['Open']\n    df['Close'] /= df['Open']\n    df['Open'] = pd.Series(df['Open'].iloc[1:].to_numpy()/df['Open'].iloc[:-1].to_numpy())\n    \n    return df.iloc[1:]\n\ndef normalize_volume(df, scale_factor=1e8):\n    \"\"\"\n    Divides the volume by scale_factor.\n    \"\"\"\n    \n    df['Volume'] = df['Volume']/scale_factor\n    return df\n\ndef transform_dataframe(df):\n    \"\"\"\n    Transforms the data frame by using normalize_volume and normalize_prices \n    and date_to_weekday\n    \"\"\"\n    \n    df = normalize_prices(df)\n    df = normalize_volume(df)\n    df = date_to_weekday(df)\n    df.drop('OpenInt', axis=1)\n    \n    return df\n\ndef get_features_and_targets(df, binary_target=True, drop_features=None):\n    \"\"\"\n    From df, construct the features and targets for the stock\n    price prediction task.\n    \"\"\"\n    \n    if binary_target:\n        y = df['Open'].iloc[1:].to_numpy() >= df['Close'].iloc[:-1].to_numpy()\n    else:\n        y = df['Open'].iloc[1:].to_numpy()\n        \n    x = df.iloc[:-1]\n    \n    if drop_features is None:\n        drop_features = []\n        \n    x = x.drop(drop_features, axis=1)\n    \n    return x,y\n\ndef stock_train_test_split(x,y, train_test_proportion=0.8):\n    \"\"\"\n    Splits x,y into training and test subsets. Notice that \n    all samples in x_test, y_test correspond to dates that occur\n    after x_train, y_train (meaning that the test is 'the future')\n    \"\"\"\n    train_test_split = int(train_test_proportion * len(x))\n    \n    try:\n        x_train = x.iloc[:train_test_split]\n    except AttributeError:\n        x_train = x[:train_test_split]\n        \n    y_train =  1*y[:train_test_split]\n    \n    try:\n        x_test = x.iloc[train_test_split:]\n    except AttributeError:\n        x_test = x[train_test_split:]\n        \n    y_test = 1*y[train_test_split:]\n    \n    return (x_train, y_train), (x_test, y_test)\n\ndef get_clean_data(ticker, binary_target=True, drop_features=None):\n    \"\"\"\n    Returns (x_train, y_train), (x_test, y_test) after\n    properly transforming the data.\n    \"\"\"\n    \n    df = load_data(ticker)\n    df = transform_dataframe(df)\n    x, y = get_features_and_targets(df, binary_target=binary_target, drop_features=drop_features)\n    \n    return stock_train_test_split(x, y)\n\ndef probability_to_binary(y):\n    \"\"\"\n    For an array y with values in [0,1], rounds each\n    entry to the closest number in {0,1}.\n    \"\"\"\n    \n    return (y > 0.5) * 1.0","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:16.198659Z","iopub.execute_input":"2022-05-07T17:27:16.199157Z","iopub.status.idle":"2022-05-07T17:27:16.226864Z","shell.execute_reply.started":"2022-05-07T17:27:16.19912Z","shell.execute_reply":"2022-05-07T17:27:16.226011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_timeseries(x, y, window):\n    \"\"\"\n    Transforms the data frame to a time series format.\n    \n    Now, each row of x will contain the data of window\n    consecutive days.\n    \n    \"\"\"\n    try:\n        x = x.to_numpy()\n    except:\n        pass\n    \n    x_out = []\n    for time in range(x.shape[0]+1-window):\n        x_out.append([])\n        for i in range(window):\n            x_out[-1] += list(x[time+i])\n    \n    x_out = np.array(x_out)\n    \n    y_out = y[window-1:]\n        \n    return x_out, y_out\n\ndef get_clean_timeseries_data(ticker, window, binary_target=True, drop_features=None):\n    \"\"\"\n    Returns (x_train, y_train), (x_test, y_test) after\n    properly transforming the data. But now the data is in a time-series format.\n    \"\"\"\n        \n    df = load_data(ticker)\n    df = transform_dataframe(df)\n    x, y = get_features_and_targets(df, binary_target=binary_target, drop_features=drop_features)\n    \n    # To timeseries\n    x, y = to_timeseries(x,y,window)\n    return stock_train_test_split(x,y)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:16.243548Z","iopub.execute_input":"2022-05-07T17:27:16.244146Z","iopub.status.idle":"2022-05-07T17:27:16.254449Z","shell.execute_reply.started":"2022-05-07T17:27:16.244108Z","shell.execute_reply":"2022-05-07T17:27:16.25353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_stock_prices(ticker, log_scale=False, normalize=False):\n    \n    df = load_data(ticker)\n    min_date = df['Date'].min()\n    max_date = df['Date'].max()\n    \n    if normalize:\n        df = normalize_prices(df)\n        \n    n_samples = len(df)\n    \n    tab_time = np.arange(n_samples)\n    plt.plot(tab_time, df['Open'], label='Open')\n    \n    if log_scale:\n        plt.yscale('log')\n\n    plt.xticks([])\n    \n    plt.title(f'{ticker} stock prices from {min_date} to {max_date}')\n    plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:16.256801Z","iopub.execute_input":"2022-05-07T17:27:16.257209Z","iopub.status.idle":"2022-05-07T17:27:16.266587Z","shell.execute_reply.started":"2022-05-07T17:27:16.257176Z","shell.execute_reply":"2022-05-07T17:27:16.2658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_stock_prices('aapl')\nplot_stock_prices('googl')\nplot_stock_prices('fb')\nplot_stock_prices('nflx')\nplot_stock_prices('amzn')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:16.323584Z","iopub.execute_input":"2022-05-07T17:27:16.323824Z","iopub.status.idle":"2022-05-07T17:27:17.115754Z","shell.execute_reply.started":"2022-05-07T17:27:16.323792Z","shell.execute_reply":"2022-05-07T17:27:17.114963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predicting whether price will go up or down in the next day\n\n    (1) Using Logistic Regression\n    (2) Using Random Forests\n    (3) Using KNN\n    (4) Using LSTM","metadata":{}},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"def train_and_test_model_binary(model, ticker, testing_stocks=None, verbosity=True, drop_features=None):\n    \n    if testing_stocks == None:\n        testing_stocks = []\n    \n    (x_train, y_train), (x_test, y_test) = get_clean_data(ticker, binary_target=True, drop_features=drop_features)\n    model.fit(x_train, y_train)\n    \n    if verbosity:\n        y_train_pred = model.predict(x_train)\n        y_test_pred = model.predict(x_test)\n        \n        print(f\"Training in stock {ticker}\")\n        print(f\"Train accuracy: {sklearn.metrics.accuracy_score(y_train, y_train_pred)}\")\n        print(f\"Test accuracy: {sklearn.metrics.accuracy_score(y_test, y_test_pred)}\")\n        \n    for stock in testing_stocks:\n        (x_train, y_train), (x_test, y_test) = get_clean_data(stock, binary_target=True, drop_features=drop_features)\n        \n        pred = model.predict(x_test)\n        print(f\"Accuracy in {stock}: {sklearn.metrics.accuracy_score(y_test, pred)}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:17.117352Z","iopub.execute_input":"2022-05-07T17:27:17.117621Z","iopub.status.idle":"2022-05-07T17:27:17.128302Z","shell.execute_reply.started":"2022-05-07T17:27:17.117586Z","shell.execute_reply":"2022-05-07T17:27:17.127611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_stock = 'aapl'\ntesting_stocks = ['fb', 'googl', 'amzn', 'nflx']","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:17.130526Z","iopub.execute_input":"2022-05-07T17:27:17.131409Z","iopub.status.idle":"2022-05-07T17:27:17.139185Z","shell.execute_reply.started":"2022-05-07T17:27:17.131372Z","shell.execute_reply":"2022-05-07T17:27:17.138274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_logistic_regression = sklearn.linear_model.LogisticRegression()\ntrain_and_test_model_binary(model_logistic_regression, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:17.140419Z","iopub.execute_input":"2022-05-07T17:27:17.140963Z","iopub.status.idle":"2022-05-07T17:27:17.452207Z","shell.execute_reply.started":"2022-05-07T17:27:17.140913Z","shell.execute_reply":"2022-05-07T17:27:17.451484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forests","metadata":{}},{"cell_type":"code","source":"model_random_forest = sklearn.ensemble.RandomForestClassifier()\ntrain_and_test_model_binary(model_random_forest, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:17.454787Z","iopub.execute_input":"2022-05-07T17:27:17.455498Z","iopub.status.idle":"2022-05-07T17:27:18.949689Z","shell.execute_reply.started":"2022-05-07T17:27:17.455461Z","shell.execute_reply":"2022-05-07T17:27:18.948957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like overfitting is occurring here. Let's tweak the hyperparameters.","metadata":{}},{"cell_type":"code","source":"model_random_forest_5 = sklearn.ensemble.RandomForestClassifier(max_depth=5)\nmodel_random_forest_10 = sklearn.ensemble.RandomForestClassifier(max_depth=10)\nmodel_random_forest_20 = sklearn.ensemble.RandomForestClassifier(max_depth=20)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:18.951219Z","iopub.execute_input":"2022-05-07T17:27:18.953111Z","iopub.status.idle":"2022-05-07T17:27:18.958825Z","shell.execute_reply.started":"2022-05-07T17:27:18.953071Z","shell.execute_reply":"2022-05-07T17:27:18.957978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_test_model_binary(model_random_forest_5, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:18.960833Z","iopub.execute_input":"2022-05-07T17:27:18.961671Z","iopub.status.idle":"2022-05-07T17:27:19.728401Z","shell.execute_reply.started":"2022-05-07T17:27:18.961631Z","shell.execute_reply":"2022-05-07T17:27:19.726771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_test_model_binary(model_random_forest_10, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:19.730033Z","iopub.execute_input":"2022-05-07T17:27:19.731111Z","iopub.status.idle":"2022-05-07T17:27:20.797157Z","shell.execute_reply.started":"2022-05-07T17:27:19.731073Z","shell.execute_reply":"2022-05-07T17:27:20.796434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_test_model_binary(model_random_forest_20, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:20.798267Z","iopub.execute_input":"2022-05-07T17:27:20.798935Z","iopub.status.idle":"2022-05-07T17:27:22.168427Z","shell.execute_reply.started":"2022-05-07T17:27:20.798897Z","shell.execute_reply":"2022-05-07T17:27:22.164103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_random_forest_3 = sklearn.ensemble.RandomForestClassifier(max_depth=3)\nmodel_random_forest_4 = sklearn.ensemble.RandomForestClassifier(max_depth=4)\nmodel_random_forest_6 = sklearn.ensemble.RandomForestClassifier(max_depth=6)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:22.170476Z","iopub.execute_input":"2022-05-07T17:27:22.171245Z","iopub.status.idle":"2022-05-07T17:27:22.17766Z","shell.execute_reply.started":"2022-05-07T17:27:22.171206Z","shell.execute_reply":"2022-05-07T17:27:22.176989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_test_model_binary(model_random_forest_3, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:22.178799Z","iopub.execute_input":"2022-05-07T17:27:22.179547Z","iopub.status.idle":"2022-05-07T17:27:22.842421Z","shell.execute_reply.started":"2022-05-07T17:27:22.179511Z","shell.execute_reply":"2022-05-07T17:27:22.840407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_test_model_binary(model_random_forest_4, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:22.844197Z","iopub.execute_input":"2022-05-07T17:27:22.844928Z","iopub.status.idle":"2022-05-07T17:27:23.530927Z","shell.execute_reply.started":"2022-05-07T17:27:22.844889Z","shell.execute_reply":"2022-05-07T17:27:23.530231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_test_model_binary(model_random_forest_6, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:23.532019Z","iopub.execute_input":"2022-05-07T17:27:23.5324Z","iopub.status.idle":"2022-05-07T17:27:24.358426Z","shell.execute_reply.started":"2022-05-07T17:27:23.532363Z","shell.execute_reply":"2022-05-07T17:27:24.357586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's try some more sophisticated ensemble methods.","metadata":{}},{"cell_type":"code","source":"model_adaboost = sklearn.ensemble.AdaBoostClassifier()\ntrain_and_test_model_binary(model_adaboost, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:24.362087Z","iopub.execute_input":"2022-05-07T17:27:24.362345Z","iopub.status.idle":"2022-05-07T17:27:25.119679Z","shell.execute_reply.started":"2022-05-07T17:27:24.36231Z","shell.execute_reply":"2022-05-07T17:27:25.118966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_bagging = sklearn.ensemble.BaggingClassifier()\ntrain_and_test_model_binary(model_bagging, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:25.12097Z","iopub.execute_input":"2022-05-07T17:27:25.121357Z","iopub.status.idle":"2022-05-07T17:27:25.548402Z","shell.execute_reply.started":"2022-05-07T17:27:25.121321Z","shell.execute_reply":"2022-05-07T17:27:25.546788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_bagging_6 = sklearn.ensemble.BaggingClassifier(sklearn.tree.DecisionTreeClassifier(max_depth = 6))\ntrain_and_test_model_binary(model_bagging_6, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:25.550216Z","iopub.execute_input":"2022-05-07T17:27:25.551006Z","iopub.status.idle":"2022-05-07T17:27:25.834892Z","shell.execute_reply.started":"2022-05-07T17:27:25.550965Z","shell.execute_reply":"2022-05-07T17:27:25.834184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### k-NN","metadata":{}},{"cell_type":"code","source":"model_knn = sklearn.neighbors.KNeighborsClassifier()\ntrain_and_test_model_binary(model_knn, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:25.836034Z","iopub.execute_input":"2022-05-07T17:27:25.83911Z","iopub.status.idle":"2022-05-07T17:27:26.38441Z","shell.execute_reply.started":"2022-05-07T17:27:25.83907Z","shell.execute_reply":"2022-05-07T17:27:26.380147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"K-NN has a very poor performance. \n\nPossibly this is happening because of the weekdays. When two data points contain two different weekdays, this difference will be responsible for most of the distance.\n\nAfter further consideration, I realized that volume was also a big responsible for the distance function.\n\nBelow I implement knn without volume or weekdays.","metadata":{}},{"cell_type":"code","source":"def train_and_test_model_binary_knn(model, ticker, testing_stocks=None, verbosity=True):\n    \n    if testing_stocks == None:\n        testing_stocks = []\n    \n    (x_train, y_train), (x_test, y_test) = get_clean_data(ticker, binary_target=True)\n    \n    weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri']\n    drop_features = ['Volume'] + weekdays\n    \n    x_train = x_train.drop(drop_features, axis=1)\n    x_test = x_test.drop(drop_features, axis=1)\n    \n    model.fit(x_train, y_train)\n    \n    if verbosity:\n        y_train_pred = model.predict(x_train)\n        y_test_pred = model.predict(x_test)\n        \n        print(f\"Training in stock {ticker}\")\n        print(f\"Train accuracy: {sklearn.metrics.accuracy_score(y_train, y_train_pred)}\")\n        print(f\"Test accuracy: {sklearn.metrics.accuracy_score(y_test, y_test_pred)}\")\n        \n    for stock in testing_stocks:\n        (x_train, y_train), (x_test, y_test) = get_clean_data(stock, binary_target=True)\n        \n        x_train = x_train.drop(drop_features, axis=1)\n        x_test = x_test.drop(drop_features, axis=1)\n        \n        pred = model.predict(x_test)\n        print(f\"Accuracy in {stock}: {sklearn.metrics.accuracy_score(y_test, pred)}\")\n        \nmodel_knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=12)\ntrain_and_test_model_binary_knn(model_knn, training_stock, testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:26.386195Z","iopub.execute_input":"2022-05-07T17:27:26.386973Z","iopub.status.idle":"2022-05-07T17:27:26.876269Z","shell.execute_reply.started":"2022-05-07T17:27:26.386922Z","shell.execute_reply":"2022-05-07T17:27:26.875558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using Time Series to Predict Stock Movement","metadata":{}},{"cell_type":"markdown","source":"Now we are going to put the data from several consecutive days as features to predict whether the stock price will go up or down. This improvement will be fundamental in the implementation of the LSTM.","metadata":{}},{"cell_type":"code","source":"def train_and_test_model_timeseries_binary(model, ticker, window=14, testing_stocks=None, verbosity=True, drop_features=None, reshape=False):\n    \n    if testing_stocks is None:\n        testing_stocks = []\n    \n    (x_train, y_train), (x_test, y_test) = get_clean_timeseries_data(ticker, window, binary_target=True, drop_features=drop_features)\n    \n    if reshape:\n        x_train = x_train.reshape((*x_train.shape, 1))\n        x_test = x_test.reshape((*x_test.shape, 1))\n        \n    model.fit(x_train, y_train)\n    \n    if verbosity:\n        y_train_pred = model.predict(x_train)\n        y_test_pred = model.predict(x_test)\n        \n        y_train_pred = probability_to_binary(y_train_pred)\n        y_test_pred = probability_to_binary(y_test_pred)\n                \n        print(f\"Training in stock {ticker}\")\n        print(f\"Train accuracy: {sklearn.metrics.accuracy_score(y_train, y_train_pred)}\")\n        print(f\"Test accuracy: {sklearn.metrics.accuracy_score(y_test, y_test_pred)}\")\n        \n    for stock in testing_stocks:\n        (x_train, y_train), (x_test, y_test) = get_clean_timeseries_data(ticker, window, binary_target=True, drop_features=drop_features)\n        if reshape:\n            x_train = x_train.reshape((*x_train.shape, 1))\n            x_test = x_test.reshape((*x_test.shape, 1))\n        \n        pred = model.predict(x_test)\n        pred = probability_to_binary(pred)\n        \n        print(f\"Accuracy in {stock}: {sklearn.metrics.accuracy_score(y_test, pred)}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:26.877574Z","iopub.execute_input":"2022-05-07T17:27:26.877971Z","iopub.status.idle":"2022-05-07T17:27:26.890839Z","shell.execute_reply.started":"2022-05-07T17:27:26.877921Z","shell.execute_reply":"2022-05-07T17:27:26.890144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_rf = sklearn.ensemble.RandomForestClassifier(max_depth=10)\ntrain_and_test_model_timeseries_binary(model_rf, training_stock, window=10, testing_stocks=testing_stocks)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:26.892564Z","iopub.execute_input":"2022-05-07T17:27:26.893941Z","iopub.status.idle":"2022-05-07T17:27:30.840202Z","shell.execute_reply.started":"2022-05-07T17:27:26.8939Z","shell.execute_reply":"2022-05-07T17:27:30.839429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's first try to see what happens if we only use the opening price to make predictions.","metadata":{}},{"cell_type":"code","source":"features_to_drop = ['High', 'Low', 'Close', 'Volume', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri']","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:30.841373Z","iopub.execute_input":"2022-05-07T17:27:30.842583Z","iopub.status.idle":"2022-05-07T17:27:30.84793Z","shell.execute_reply.started":"2022-05-07T17:27:30.84254Z","shell.execute_reply":"2022-05-07T17:27:30.847021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_rf = sklearn.ensemble.RandomForestClassifier(max_depth=10)\ntrain_and_test_model_timeseries_binary(model_rf, training_stock, window=10, testing_stocks=testing_stocks, drop_features=features_to_drop)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:30.84958Z","iopub.execute_input":"2022-05-07T17:27:30.850033Z","iopub.status.idle":"2022-05-07T17:27:33.038347Z","shell.execute_reply.started":"2022-05-07T17:27:30.849994Z","shell.execute_reply":"2022-05-07T17:27:33.037464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using LSTMs to predict stock price movements","metadata":{}},{"cell_type":"code","source":"def train_and_test_lstm(model, ticker, window=14, testing_stocks=None, verbosity=True, drop_features=None, reshape=True, epochs=100, batch_size=32):\n    \n    if testing_stocks is None:\n        testing_stocks = []\n    \n    (x_train, y_train), (x_test, y_test) = get_clean_timeseries_data(ticker, window, binary_target=True, drop_features=drop_features)\n    \n    if reshape:\n        x_train = x_train.reshape((*x_train.shape, 1))\n        x_test = x_test.reshape((*x_test.shape, 1))\n        \n    model.fit(x_train, y_train, epochs=epochs, batch_size=32)\n    \n    if verbosity:\n        y_train_pred = model.predict(x_train)\n        y_test_pred = model.predict(x_test)\n        \n        y_train_pred = probability_to_binary(y_train_pred)\n        y_test_pred = probability_to_binary(y_test_pred)\n                \n        print(f\"Training in stock {ticker}\")\n        print(f\"Train accuracy: {sklearn.metrics.accuracy_score(y_train, y_train_pred)}\")\n        print(f\"Test accuracy: {sklearn.metrics.accuracy_score(y_test, y_test_pred)}\")\n        \n    for stock in testing_stocks:\n        (x_train, y_train), (x_test, y_test) = get_clean_timeseries_data(ticker, window, binary_target=True, drop_features=drop_features)\n        if reshape:\n            x_train = x_train.reshape((*x_train.shape, 1))\n            x_test = x_test.reshape((*x_test.shape, 1))\n        \n        pred = model.predict(x_test)\n        pred = probability_to_binary(pred)\n        \n        print(f\"Accuracy in {stock}: {sklearn.metrics.accuracy_score(y_test, pred)}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:33.039985Z","iopub.execute_input":"2022-05-07T17:27:33.040324Z","iopub.status.idle":"2022-05-07T17:27:33.054493Z","shell.execute_reply.started":"2022-05-07T17:27:33.040284Z","shell.execute_reply":"2022-05-07T17:27:33.05372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 0:\n    window = 10\n\n    model_lstm = keras.models.Sequential()\n\n    model_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\n    model_lstm.add(keras.layers.Dropout(0.2))\n\n    model_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\n    model_lstm.add(keras.layers.Dropout(0.2))\n\n    model_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\n    model_lstm.add(keras.layers.Dropout(0.2))\n\n    model_lstm.add(keras.layers.LSTM(units=50, return_sequences=False, input_shape=(window, 1)))\n    model_lstm.add(keras.layers.Dropout(0.2))\n\n    model_lstm.add(keras.layers.Dense(units=1, activation='sigmoid'))\n\n    model_lstm.compile(optimizer='adam', loss='binary_crossentropy')\n    train_and_test_lstm(model_lstm, training_stock, window=window, testing_stocks=testing_stocks,\n                                           drop_features=features_to_drop, reshape=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:33.056214Z","iopub.execute_input":"2022-05-07T17:27:33.056848Z","iopub.status.idle":"2022-05-07T17:27:33.068846Z","shell.execute_reply.started":"2022-05-07T17:27:33.056809Z","shell.execute_reply":"2022-05-07T17:27:33.068165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 0:\n    window = 20\n\n    model_lstm = keras.models.Sequential()\n\n    model_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\n    model_lstm.add(keras.layers.Dropout(0.2))\n\n    model_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\n    model_lstm.add(keras.layers.Dropout(0.2))\n\n    model_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\n    model_lstm.add(keras.layers.Dropout(0.2))\n\n    model_lstm.add(keras.layers.LSTM(units=50, return_sequences=False, input_shape=(window, 1)))\n    model_lstm.add(keras.layers.Dropout(0.2))\n\n    model_lstm.add(keras.layers.Dense(units=1, activation='sigmoid'))\n\n    model_lstm.compile(optimizer='adam', loss='binary_crossentropy')\n    train_and_test_lstm(model_lstm, training_stock, window=window, testing_stocks=testing_stocks,\n                                           drop_features=features_to_drop, reshape=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:33.070596Z","iopub.execute_input":"2022-05-07T17:27:33.071353Z","iopub.status.idle":"2022-05-07T17:27:33.084602Z","shell.execute_reply.started":"2022-05-07T17:27:33.071216Z","shell.execute_reply":"2022-05-07T17:27:33.083699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"window = 10\n\nmodel_lstm = keras.models.Sequential()\n\nmodel_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\nmodel_lstm.add(keras.layers.Dropout(0.2))\n\nmodel_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\nmodel_lstm.add(keras.layers.Dropout(0.2))\n\nmodel_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\nmodel_lstm.add(keras.layers.Dropout(0.2))\n\nmodel_lstm.add(keras.layers.LSTM(units=50, return_sequences=False, input_shape=(window, 1)))\nmodel_lstm.add(keras.layers.Dropout(0.2))\n\nmodel_lstm.add(keras.layers.Dense(units=1, activation='sigmoid'))\n\nmodel_lstm.compile(optimizer='adam', loss='binary_crossentropy')\ntrain_and_test_lstm(model_lstm, training_stock, window=window, testing_stocks=testing_stocks,\n                                       drop_features=None, reshape=True, epochs=400)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:27:33.086044Z","iopub.execute_input":"2022-05-07T17:27:33.087133Z","iopub.status.idle":"2022-05-07T17:47:24.528899Z","shell.execute_reply.started":"2022-05-07T17:27:33.087094Z","shell.execute_reply":"2022-05-07T17:47:24.527559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"window = 20\n\nmodel_lstm = keras.models.Sequential()\n\nmodel_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\nmodel_lstm.add(keras.layers.Dropout(0.2))\n\nmodel_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\nmodel_lstm.add(keras.layers.Dropout(0.2))\n\nmodel_lstm.add(keras.layers.LSTM(units=50, return_sequences=True, input_shape=(window, 1)))\nmodel_lstm.add(keras.layers.Dropout(0.2))\n\nmodel_lstm.add(keras.layers.LSTM(units=50, return_sequences=False, input_shape=(window, 1)))\nmodel_lstm.add(keras.layers.Dropout(0.2))\n\nmodel_lstm.add(keras.layers.Dense(units=1, activation='sigmoid'))\n\nmodel_lstm.compile(optimizer='adam', loss='binary_crossentropy')\ntrain_and_test_lstm(model_lstm, training_stock, window=window, testing_stocks=testing_stocks,\n                                       drop_features=features_to_drop, reshape=True, epochs=400)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T17:47:49.187222Z","iopub.execute_input":"2022-05-07T17:47:49.187473Z","iopub.status.idle":"2022-05-07T18:05:26.281452Z","shell.execute_reply.started":"2022-05-07T17:47:49.187445Z","shell.execute_reply":"2022-05-07T18:05:26.277462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Summary:\n\n","metadata":{}}]}