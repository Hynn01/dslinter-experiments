{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport glob\nimport os.path as osp\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset,DataLoader\n\nPATH='../input/airbus-ship-detection/train_v2'\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T10:57:06.702079Z","iopub.execute_input":"2022-05-07T10:57:06.702336Z","iopub.status.idle":"2022-05-07T10:57:06.709699Z","shell.execute_reply.started":"2022-05-07T10:57:06.702307Z","shell.execute_reply":"2022-05-07T10:57:06.70889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Ship Detection: Image Visualizations and short EDA","metadata":{}},{"cell_type":"markdown","source":"## Loading the Datasets","metadata":{}},{"cell_type":"code","source":"class AirbusDS(Dataset):\n    \"\"\"\n    A customized data loader.\n    \"\"\"\n    def __init__(self, root):\n        \"\"\" Intialize the dataset\n        \"\"\"\n        self.filenames = []\n        self.root = root\n        self.transform = transforms.ToTensor()\n        filenames = glob.glob(osp.join(PATH, '*.jpg'))\n        for fn in filenames:\n            self.filenames.append(fn)\n        self.len = len(self.filenames)\n        \n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.open(self.filenames[index])\n        return self.transform(image)\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:57:07.724003Z","iopub.execute_input":"2022-05-07T10:57:07.724381Z","iopub.status.idle":"2022-05-07T10:57:07.732484Z","shell.execute_reply.started":"2022-05-07T10:57:07.724349Z","shell.execute_reply":"2022-05-07T10:57:07.731766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show data ","metadata":{}},{"cell_type":"code","source":"air_img = AirbusDS(PATH)\nprint(air_img.len)\n# Use the torch dataloader to iterate through the dataset\nloader = DataLoader(air_img, batch_size=24, shuffle=False, num_workers=0)\n\n# functions to show an image\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# get some images\ndataiter = iter(loader)\nimages = dataiter.next()\n\n# show images\nplt.figure(figsize=(16,8))\nimshow(torchvision.utils.make_grid(images))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:57:08.509758Z","iopub.execute_input":"2022-05-07T10:57:08.510092Z","iopub.status.idle":"2022-05-07T10:57:14.496231Z","shell.execute_reply.started":"2022-05-07T10:57:08.510056Z","shell.execute_reply":"2022-05-07T10:57:14.494953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Albumentations\n","metadata":{}},{"cell_type":"code","source":"# https://github.com/albu/albumentations\nfrom albumentations import (ToFloat, \n    CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, Blur, OpticalDistortion, \n    GridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, \n    MedianBlur, IAAPiecewiseAffine, IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, \n    Flip, OneOf, Compose\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:57:14.49768Z","iopub.execute_input":"2022-05-07T10:57:14.49838Z","iopub.status.idle":"2022-05-07T10:57:14.503375Z","shell.execute_reply.started":"2022-05-07T10:57:14.498345Z","shell.execute_reply":"2022-05-07T10:57:14.502779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Masks & Albumentations class","metadata":{}},{"cell_type":"code","source":"masks = pd.read_csv('../input/airbus-ship-detection/train_ship_segmentations_v2.csv')\nmasks.head()\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:57:14.504507Z","iopub.execute_input":"2022-05-07T10:57:14.505335Z","iopub.status.idle":"2022-05-07T10:57:14.99831Z","shell.execute_reply.started":"2022-05-07T10:57:14.5053Z","shell.execute_reply":"2022-05-07T10:57:14.997586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#an improve\nclass AirbusDS(Dataset):\n    \"\"\"\n    A customized data loader.\n    \"\"\"\n    def __init__(self, root, aug = False, mode='train'):\n        \"\"\" Intialize the dataset\n        \"\"\"\n        self.filenames = []\n        self.root = root\n        self.aug = aug\n        self.mode = 'test'\n        if mode == 'train':\n            self.mode = 'train'\n            self.masks = pd.read_csv('../input/airbus-ship-detection/train_ship_segmentations_v2.csv').fillna(-1)\n        if self.aug:\n            self.transform = OneOf([\n                                RandomRotate90(),\n                                Transpose(),\n                                Flip(),\n                            ], p=0.3)\n        else:\n            self.transform = transforms.ToTensor()\n        filenames = glob.glob(osp.join(PATH, '*.jpg'))\n        for fn in filenames:\n            self.filenames.append(fn)\n        self.len = len(self.filenames)\n        \n    # You must override __getitem__ and __len__\n    def get_mask(self, ImageId):\n        img_masks = self.masks.loc[self.masks['ImageId'] == ImageId, 'EncodedPixels'].tolist()\n\n        # Take the individual ship masks and create a single mask array for all ships\n        all_masks = np.zeros((768, 768))\n        if img_masks == [-1]:\n            return all_masks\n        for mask in img_masks:\n            all_masks += rle_decode(mask)\n        return all_masks\n    \n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.open(self.filenames[index])\n        ImageId = self.filenames[index].split('/')[-1]\n        if self.mode == 'train':\n            mask = self.get_mask(ImageId)\n        if self.aug:\n            if self.mode == 'train':\n                data = {\"image\": np.array(image), \"mask\": mask}\n            else:\n                data = {\"image\": np.array(image)}\n            transformed = self.transform(**data)\n            image = transformed['image']/255\n            image = np.transpose(image, (2, 0, 1))\n            if self.mode == 'train':\n                return image, transformed['mask'][np.newaxis,:,:] \n            else:\n                return image\n        else:\n            if self.mode == 'train':\n                return self.transform(image), mask[np.newaxis,:,:] \n            return self.transform(image)\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:57:15.001342Z","iopub.execute_input":"2022-05-07T10:57:15.001543Z","iopub.status.idle":"2022-05-07T10:57:15.015182Z","shell.execute_reply.started":"2022-05-07T10:57:15.001518Z","shell.execute_reply":"2022-05-07T10:57:15.014506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader ","metadata":{}},{"cell_type":"code","source":"airimg = AirbusDS(PATH, aug=True, mode='train')\n# Use the torch dataloader to iterate through the dataset\nloader = DataLoader(airimg, batch_size=24, shuffle=False, num_workers=0)\n\n# get some images\ndataiter = iter(loader)\nimages, masks = dataiter.next()\n\n# show images\nplt.figure(figsize=(16,16))\nplt.rcParams['figure.facecolor'] = 'blue'\nplt.subplot(211)\nimshow(torchvision.utils.make_grid(images))\nplt.subplot(212)\nimshow(torchvision.utils.make_grid(masks,pad_value=25.0))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:57:15.016561Z","iopub.execute_input":"2022-05-07T10:57:15.017021Z","iopub.status.idle":"2022-05-07T10:57:27.413357Z","shell.execute_reply.started":"2022-05-07T10:57:15.016983Z","shell.execute_reply":"2022-05-07T10:57:27.412736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TL;DR\n\n* First we created basic `AirbusDS` class for dataset- with no augmentaions nor masks.\n* Then using `https://www.kaggle.com/paulorzp/run-length-encode-and-decode` ww've got rle decode function for adding masks on the dataset.\n* After that we implemented `AirbusDS` class with albumentations and masks\n* Finally we use the dataloader to iterate and present sample of images and the segmentations.","metadata":{}}]}