{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 引入csv文件读取库\nimport pandas as pd\n# 引入画图库\nimport matplotlib.pyplot as plt\n#import seaborn as sns\n# 引入数学运算库\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV\n# 引入数据处理包\nimport sklearn\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler  # 对数据做归一化\nfrom sklearn.ensemble import RandomForestClassifier # 随机森林模型\nfrom  sklearn.tree import DecisionTreeClassifier # 决策树模型\nfrom sklearn.neural_network import MLPClassifier as DNN\nfrom sklearn.metrics import f1_score # f1_score评价指标\nfrom sklearn.model_selection import KFold, cross_val_score  # K折交叉验证\n#from imblearn.over_sampling import RandomOverSampler, SMOTE # 重采样解决样本不平衡\nimport scipy.stats as st # 数据分析包\n\n# 重新读一下数据\ndf_train = pd.read_csv('Dataset.csv')\ndf_test = pd.read_csv('Testing.csv')\n# 把ID去掉，没有作用\ntest_ID = df_test['ID'] # 后面用来包装csv\ndf_train = df_train.drop(columns='ID')\ndf_test = df_test.drop(columns='ID')\n\n# 去掉3号和9号\ndf_train = df_train.drop(index = df_train[df_train['quality'] == 3].index)\ndf_train = df_train.drop(index = df_train[df_train['quality'] == 9].index)\ndf_train = df_train.reset_index(drop=True)\n\n# 下面的内容和上面一样 ----------------------------\n\n# 把quality拿出来，因为是我们要预测的东西\nquality = df_train['quality']\ndf_train = df_train.drop(columns='quality')\n\n# 下面对所有数值型数据做归一化，就ok了\nmin_max_scaler = MinMaxScaler()\n# 这里直接对训练集和测试集都做了\nmin_max_scaler.fit(pd.concat([df_train,df_test]).values)\nall_data = min_max_scaler.transform(pd.concat([df_train,df_test]).values)\n\n# 把train和test的分出来, 到此，数据处理就结束了，这些数据已经可以送到模型中训练了\ntrain_data = all_data[:len(df_train)]\ntest_data = all_data[len(df_train):]\n#预测\n# 其实里面有不少参数，但这里就用默认的好了\n\ntemp_csv = pd.DataFrame()\nn_splits = 5\nmean_f1_score = 0\nkf = KFold(n_splits=n_splits, shuffle=True) # 使用sklearn自带划分k折的函数\n#scorel=[]\n#for i in range(165,175):\n#    model=RandomForestClassifier(n_estimators=i,n_jobs=-1,random_state=90)\n#    score=cross_val_score(model,train_data,quality,cv=10).mean()\n#    scorel.append(score)\n#print(max(scorel),(scorel.index(max(scorel))+165))\n#plt.figure(figsize=[20,5])\n#plt.plot(range(165,175),scorel)\n#plt.show()\n#param_grid={'max_features':range(3,11,1)}\n#model=RandomForestClassifier(n_estimators=173,random_state=90,criterion=\"gini\",max_depth=3)\n#GS=GridSearchCV(model,param_grid,cv=10)\n#GS.fit(train_data,quality)\n#print(GS.best_score_)\n#print(GS.best_params_)\n\n#dnn = DNN(hidden_layer_sizes=(100,),max_iter=500,random_state=420)\n\nfor fold, (trn_idx, val_idx) in enumerate(kf.split(train_data, quality)):\n    print('fold:', fold)\n    X_train, y_train = train_data[trn_idx], quality[trn_idx]\n    X_val, y_val = train_data[val_idx], quality[val_idx]\n    # 定义模型\n    #model=AdaBoostClassifier(DecisionTreeClassifier(max_depth=8,min_samples_split=20,min_samples_leaf=5),n_estimators=100,algorithm=\"SAMME\",learning_rate=0.8)\n    model=RandomForestClassifier(random_state=0)\n    #model=AdaBoostClassifier(DNN(hidden_layer_sizes=(200,),max_iter=500,random_state=420))\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_val)\n    # 调用skelarn计算f1 score的函数\n    f1 = f1_score(y_val, y_pred, average='macro')\n    mean_f1_score += f1\n    print('f1_socre is :', f1)\n   # 用这一轮的模型，去预测test\n    test_pred = model.predict(test_data)\n    pred_name = str(fold)+'_'+'quality'\n    temp_csv[pred_name] = test_pred\nprint('mean f1_score is :', mean_f1_score / n_splits)\nsbu_csv = pd.DataFrame()\nsbu_csv['ID'] = test_ID\n# 取所有预测的众数\nsbu_csv['quality'] = temp_csv.mode(axis=1)[0].map(lambda x:int(x))  # 取众数是float型，改为int型\nsbu_csv.to_csv('submission.csv', index=False)# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}