{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\n* This notebook demonstrates a way to apply meta-pseudo-labels for NBME token classification task\n* It uses code snippets from: \n    * https://www.kaggle.com/code/hengck23/playground-for-meta-pseudo-label\n    * https://www.kaggle.com/code/theoviel/evaluation-metric-folds-baseline\n\n\n* Meta Pseudo Labels paper:\n    * https://arxiv.org/abs/2003.10580\n    \n    \n* Thanks @hengck23, @theoviel for sharing these great notebooks!\n* Hope that you find this approach useful. Please let me know if there are mistakes. \n* Looking forward to your comments / feedback / queries. Thanks!","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import ast\nimport json\nimport itertools\nimport os\nimport re\nimport shutil\nimport sys\nimport traceback\nfrom dataclasses import dataclass\nfrom functools import partial\nfrom itertools import chain\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.checkpoint\nfrom IPython.core.debugger import set_trace\nfrom IPython.display import display\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import GroupKFold\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\nfrom transformers import (AutoModel, AutoTokenizer,\n                          DataCollatorForTokenClassification,\n                          get_cosine_schedule_with_warmup, get_scheduler)\nfrom transformers.trainer_pt_utils import get_parameter_names\n\npd.options.display.max_colwidth = None","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-04T12:19:22.87041Z","iopub.execute_input":"2022-05-04T12:19:22.870713Z","iopub.status.idle":"2022-05-04T12:19:23.765469Z","shell.execute_reply.started":"2022-05-04T12:19:22.870682Z","shell.execute_reply":"2022-05-04T12:19:23.764773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda list | grep cudatoolkit","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:19:23.767171Z","iopub.execute_input":"2022-05-04T12:19:23.767427Z","iopub.status.idle":"2022-05-04T12:19:43.208699Z","shell.execute_reply.started":"2022-05-04T12:19:23.767394Z","shell.execute_reply":"2022-05-04T12:19:43.207779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install -qq bitsandbytes-cuda110 # optimizer\n%pip install -qq pynvml\n%pip install -qq accelerate\n%pip install -qq datasets","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:19:43.212605Z","iopub.execute_input":"2022-05-04T12:19:43.212859Z","iopub.status.idle":"2022-05-04T12:20:21.37008Z","shell.execute_reply.started":"2022-05-04T12:19:43.212827Z","shell.execute_reply":"2022-05-04T12:20:21.368905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import bitsandbytes as bnb\nfrom accelerate import Accelerator\nfrom pynvml import nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlInit\nfrom datasets import Dataset, load_from_disk","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:21.372059Z","iopub.execute_input":"2022-05-04T12:20:21.372373Z","iopub.status.idle":"2022-05-04T12:20:21.380704Z","shell.execute_reply.started":"2022-05-04T12:20:21.372328Z","shell.execute_reply":"2022-05-04T12:20:21.379965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"config = {\n    \"debug\": False,\n    \n    \"num_layers_in_head\": 6, # Number of layer hidden states to be used in token classification head\n    \"mtl_tok_num_labels\": 3, # Predict Inside, Begin, End of answer spans\n    \"gradient_checkpointing\": True,\n    \"mixed_precision\": True,\n    \"n_freeze\": 2,\n    \n    \"batch_size\": 8,\n    \"train_folds\": [0, 1, 2, 3],\n    \"valid_folds\": [4],\n    \n    \"num_unlabelled\": 10000, # number of unlabelled data points to be used for Meta Pseudo Labels\n\n    \"base_model_path\": \"microsoft/deberta-large\", # backbone\n    \"student_model_dir\": \"./trained_student\", # save dir for student model\n    \"teacher_model_dir\": \"./trained_teacher\", # save dir for teacher model\n    \"teacher_save_name\": \"teacher\", # teacher checkpoint \n    \"student_save_name\": \"student\", # student checkpoint\n    \n    # data path\n    \"data_dir\": \"../input/nbme-score-clinical-patient-notes\",\n    \"train_path\": \"train.csv\",\n    \"features_path\": \"features.csv\",\n    \"notes_path\": \"patient_notes.csv\",\n    \n    # save tokenized datasets here\n    \"output_dir\": \"./\",\n    \"train_dataset_path\": \"train_dataset\",\n    \"valid_dataset_path\": \"valid_dataset\",\n    \n    # column names\n    \"text_col\": \"pn_history\",\n    \"feature_col\": \"feature_text\",\n    \"label_col\": \"label_spans\",\n    \"annotation_col\": \"annotation\",\n    \"text_sequence_identifier\": 1,\n    \"max_length\": 480,\n    \n    # optimizer & scheduler params\n    \"weight_decay\": 1e-3,\n    \"lr\": 2e-5,\n    \"eps\": 1e-6,\n    \"beta1\": 0.9,\n    \"beta2\": 0.99,\n    \"num_epochs\": 1,\n    \"grad_accumulation\": 1,\n    \"warmup_pct\": 0.02,\n    \"validation_interval\": 200\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:21.38498Z","iopub.execute_input":"2022-05-04T12:20:21.387988Z","iopub.status.idle":"2022-05-04T12:20:21.401979Z","shell.execute_reply.started":"2022-05-04T12:20:21.387941Z","shell.execute_reply":"2022-05-04T12:20:21.401179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\nprint_gpu_utilization()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:21.407032Z","iopub.execute_input":"2022-05-04T12:20:21.40969Z","iopub.status.idle":"2022-05-04T12:20:21.419487Z","shell.execute_reply.started":"2022-05-04T12:20:21.409651Z","shell.execute_reply":"2022-05-04T12:20:21.418554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"data_dir = config[\"data_dir\"]\ntrain_df = pd.read_csv(os.path.join(data_dir, config[\"train_path\"]))\nfeatures_df = pd.read_csv(os.path.join(data_dir, config[\"features_path\"]))\nnotes_df = pd.read_csv(os.path.join(data_dir, config[\"notes_path\"]))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:21.423466Z","iopub.execute_input":"2022-05-04T12:20:21.426023Z","iopub.status.idle":"2022-05-04T12:20:22.229169Z","shell.execute_reply.started":"2022-05-04T12:20:21.425987Z","shell.execute_reply":"2022-05-04T12:20:22.228267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process Data","metadata":{}},{"cell_type":"code","source":"def process_feature_text(text):\n    return re.sub('-', ' ', text)\n\ndef apply_ast(df):\n    columns = [\n        \"annotation\",\n        \"location\",\n    ]\n\n    for col in columns:\n        try:\n            if type(df[col].values[0]) != list:\n                df[col] = df[col].apply(ast.literal_eval)\n        except Exception as e:\n            print(e)\n            traceback.print_exc()\n\n    return df\n\ndef location2spans(location):\n    \"\"\"\n    a helper function to compute the label spans from the input location list\n    \"\"\"\n    spans = [loc.split(\";\") for loc in location]\n    spans = [list(map(int, s.split())) for s in chain(*spans)]\n    return spans\n\nfeatures_df[\"feature_text\"] = features_df[\"feature_text\"].apply(process_feature_text)\ntrain_df = apply_ast(train_df)\ntrain_df = pd.merge(train_df, features_df, on=['feature_num', 'case_num'], how='left')\ntrain_df = pd.merge(train_df, notes_df, on=['pn_num', 'case_num'], how='left')\ntrain_df['label_spans'] = train_df['location'].apply(location2spans)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:22.230357Z","iopub.execute_input":"2022-05-04T12:20:22.230612Z","iopub.status.idle":"2022-05-04T12:20:22.721087Z","shell.execute_reply.started":"2022-05-04T12:20:22.230579Z","shell.execute_reply":"2022-05-04T12:20:22.720253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sample()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:22.722373Z","iopub.execute_input":"2022-05-04T12:20:22.722645Z","iopub.status.idle":"2022-05-04T12:20:22.746402Z","shell.execute_reply.started":"2022-05-04T12:20:22.722611Z","shell.execute_reply":"2022-05-04T12:20:22.745663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unlabelled Data","metadata":{}},{"cell_type":"code","source":"train_patients = set(train_df[\"pn_num\"].unique())\nunlabelled_notes_df = notes_df[~notes_df[\"pn_num\"].isin(train_patients)].copy()\nunlabelled_df = pd.merge(unlabelled_notes_df, features_df, on=['case_num'], how='left')\nprint(f\"# unlabelled examples = {len(unlabelled_df)}\\n\")\ndisplay(unlabelled_df.sample())","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:22.747696Z","iopub.execute_input":"2022-05-04T12:20:22.747973Z","iopub.status.idle":"2022-05-04T12:20:22.88673Z","shell.execute_reply.started":"2022-05-04T12:20:22.74794Z","shell.execute_reply":"2022-05-04T12:20:22.885818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-Validation Split","metadata":{}},{"cell_type":"code","source":"# the code for train-validation split is taken from: \n# https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/315707\n\ndef make_fold(df):\n    df.loc[:,'fold']=-1\n    gkf = GroupKFold(n_splits=5)\n    for n, (train_index, valid_index) in enumerate(gkf.split(df['id'], df['location'], df['pn_num'])):\n        df.loc[valid_index, 'fold'] = n\n    return df\n\ntrain_df = make_fold(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:22.89038Z","iopub.execute_input":"2022-05-04T12:20:22.890656Z","iopub.status.idle":"2022-05-04T12:20:22.909228Z","shell.execute_reply.started":"2022-05-04T12:20:22.89062Z","shell.execute_reply":"2022-05-04T12:20:22.908471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sample()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:22.910553Z","iopub.execute_input":"2022-05-04T12:20:22.910831Z","iopub.status.idle":"2022-05-04T12:20:22.92817Z","shell.execute_reply.started":"2022-05-04T12:20:22.910796Z","shell.execute_reply":"2022-05-04T12:20:22.927552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Valid Dataset","metadata":{}},{"cell_type":"code","source":"df = train_df.copy()\n\nif config[\"debug\"]:\n    print(\"DEBUG Mode: sampling 1024 examples from train data\")\n    df = df.sample(min(1024, len(df)))\n    \ntrain_df = df[df['fold'].isin(config['train_folds'])].copy()\nvalid_df = df[df['fold'].isin(config['valid_folds'])].copy()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:22.930435Z","iopub.execute_input":"2022-05-04T12:20:22.931036Z","iopub.status.idle":"2022-05-04T12:20:22.94349Z","shell.execute_reply.started":"2022-05-04T12:20:22.931007Z","shell.execute_reply":"2022-05-04T12:20:22.942555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def strip_offset_mapping(text, offset_mapping):\n    \"\"\"process offset mapping produced by huggingface tokenizers\n    by stripping spaces from the tokens\n\n    :param text: input text that is tokenized\n    :type text: str\n    :param offset_mapping: offsets returned from huggingface tokenizers\n    :type offset_mapping: list\n    :return: processed offset mapping\n    :rtype: list\n    \"\"\"\n    to_return = []\n    for start, end in offset_mapping:\n        match = list(re.finditer('\\S+', text[start:end]))\n        if len(match) == 0:\n            to_return.append((start, end))\n        else:\n            span_start, span_end = match[0].span()\n            to_return.append((start + span_start, start + span_end))\n    return to_return\n\n\ndef get_sequence_ids(input_ids, tokenizer):\n    \"\"\"if a pair of texts are given to HF tokenizers, the first text\n    has sequence id of 0 and second text has sequence id 1. This function\n    derives sequence ids for a given tokenizer based on token input ids\n\n    :param input_ids: token input id sequence\n    :type input_ids: List[int]\n    :param tokenizer: HF tokenizer\n    :type tokenizer: PreTrainedTokenizer\n    :return: sequence ids\n    :rtype: List\n    \"\"\"\n    sequence_ids = [0]*len(input_ids)\n\n    switch = False\n    special_token_ids = set(\n        tokenizer.convert_tokens_to_ids(\n            tokenizer.special_tokens_map.values()\n        )\n    )\n    for i, input_id in enumerate(input_ids):\n        if input_id == tokenizer.sep_token_id:\n            switch = True\n        if switch:\n            sequence_ids[i] = 1\n        if input_id in special_token_ids:\n            sequence_ids[i] = None\n    return sequence_ids\n\n\nclass NbmeMTLDataset:\n    \"\"\"Dataset class for NBME token classification task\n    \"\"\"\n\n    def __init__(self, config):\n        self.config = config\n\n        # column names\n        self.text_col = self.config[\"text_col\"]\n        self.feature_col = self.config[\"feature_col\"]\n        self.label_col = self.config[\"label_col\"]\n        self.annotation_col = self.config[\"annotation_col\"]\n\n        # sequence number for patient history texts\n        self.focus_seq = self.config[\"text_sequence_identifier\"]\n\n        # load tokenizer\n        self.load_tokenizer()\n\n    def load_tokenizer(self):\n        \"\"\"load tokenizer as per config \n        \"\"\"\n        print(\"using auto tokenizer\")\n        self.tokenizer = AutoTokenizer.from_pretrained(self.config[\"base_model_path\"], trim_offsets=False)\n\n    def tokenize_function(self, examples):\n        if self.focus_seq == 0:\n            tz = self.tokenizer(\n                examples[self.text_col],\n                examples[self.feature_col],\n                padding=False,\n                truncation='only_first',\n                max_length=self.config[\"max_length\"],\n                add_special_tokens=True,\n                return_offsets_mapping=True,\n                return_token_type_ids=True,\n            )\n\n        elif self.focus_seq == 1:\n            tz = self.tokenizer(\n                examples[self.feature_col],\n                examples[self.text_col],\n                padding=False,\n                truncation='only_second',\n                max_length=self.config[\"max_length\"],\n                add_special_tokens=True,\n                return_offsets_mapping=True,\n                return_token_type_ids=True,\n            )\n\n        else:\n            raise ValueError(\"bad text_sequence_identifier in config\")\n        return tz\n\n    def add_sequence_ids(self, examples):\n        sequence_ids = []\n        input_ids = examples[\"input_ids\"]\n\n        for tok_ids in input_ids:\n            sequence_ids.append(get_sequence_ids(tok_ids, self.tokenizer))\n        return {\"sequence_ids\": sequence_ids}\n\n    def process_token_offsets(self, examples):\n        stripped_offsets, unstripped_offsets = [], []\n        prev_offset = None\n\n        for offsets, seq_ids, feature_text, pn_history in zip(\n            examples[\"offset_mapping\"],\n            examples['sequence_ids'],\n            examples[self.feature_col],\n            examples[self.text_col]\n        ):\n            current_stripped, current_unstripped = [],  []\n\n            for pos, offset in enumerate(offsets):\n                start, end = offset\n                seq_id = seq_ids[pos]\n\n                if seq_id is None:\n                    current_stripped.append(offset)\n                    current_unstripped.append(offset)\n                    prev_offset = offset\n                    continue\n\n                elif seq_id == self.focus_seq:\n                    focus_text = pn_history[start:end]\n                else:\n                    focus_text = feature_text[start:end]\n\n                # strip offsets\n                match = list(re.finditer('\\S+', focus_text))\n                if len(match) == 0:\n                    current_stripped.append((start, end))\n                else:\n                    span_start, span_end = match[0].span()\n                    current_stripped.append((start + span_start, start + span_end))\n\n                # upstrip offsets\n                if prev_offset[-1] != offset[0]:\n                    offset[0] = prev_offset[-1]\n                current_unstripped.append(offset)\n                prev_offset = offset\n\n            stripped_offsets.append(np.array(current_stripped))\n            unstripped_offsets.append(np.array(current_unstripped))\n\n        return {\n            'offset_mapping_stripped': stripped_offsets,\n            \"offset_mapping_unstripped\": unstripped_offsets\n        }\n\n    def generate_labels(self, examples):\n        labels = []\n        for offsets, inputs, seq_ids, locations in zip(\n            examples[\"offset_mapping_stripped\"],\n            examples[\"input_ids\"],\n            examples[\"sequence_ids\"],\n            examples[self.label_col]\n        ):\n            this_label = np.zeros(shape=(3, len(inputs)))\n            for idx, (seq_id, offset) in enumerate(zip(seq_ids, offsets)):\n                if seq_id != self.focus_seq:  # ignore this token\n                    this_label[:, idx] = -1.0\n                    continue\n\n                token_start_char_idx, token_end_char_idx = offset\n                for label_start_char_idx, label_end_char_idx in locations:\n                    # case 1: location char start is inside token\n                    if token_start_char_idx <= label_start_char_idx < token_end_char_idx:\n                        this_label[0, idx] = 1.0\n                        this_label[1, idx] = 1.0  # detection\n\n                    # case 2: location char end is inside token\n                    if token_start_char_idx < label_end_char_idx <= token_end_char_idx:\n                        this_label[0, idx] = 1.0\n                        this_label[2, idx] = 1.0  # termination\n\n                    # case 3: token in between location\n                    if label_start_char_idx < token_start_char_idx < label_end_char_idx:\n                        this_label[0, idx] = 1.0\n\n                    # break the loop if token is already detected positive\n                    if this_label[0, idx] > 0:\n                        break\n\n            labels.append(this_label)\n        return {\"labels\": labels}\n\n    def get_dataset(self, df, mode='train'):\n        \"\"\"main api for creating the NBME dataset\n\n        :param df: input dataframe\n        :type df: pd.DataFrame\n        :param mode: check if required for train or infer, defaults to 'train'\n        :type mode: str, optional\n        :return: the created dataset\n        :rtype: Dataset\n        \"\"\"\n\n        # create the dataset\n        nbme_dataset = Dataset.from_pandas(df)\n        nbme_dataset = nbme_dataset.map(self.tokenize_function, batched=True)\n        nbme_dataset = nbme_dataset.map(self.add_sequence_ids, batched=True)\n        nbme_dataset = nbme_dataset.map(self.process_token_offsets, batched=True)\n\n        if mode == \"train\":\n            nbme_dataset = nbme_dataset.map(self.generate_labels, batched=True)\n        try:\n            nbme_dataset = nbme_dataset.remove_columns(column_names=[\"__index_level_0__\"])\n        except Exception as e:\n            print(e)\n        return nbme_dataset","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:22.945215Z","iopub.execute_input":"2022-05-04T12:20:22.945485Z","iopub.status.idle":"2022-05-04T12:20:22.980761Z","shell.execute_reply.started":"2022-05-04T12:20:22.94545Z","shell.execute_reply":"2022-05-04T12:20:22.980072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_creator = NbmeMTLDataset(config)\ntrain_ds = dataset_creator.get_dataset(train_df, mode='train')\nvalid_ds = dataset_creator.get_dataset(valid_df, mode='train')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:20:22.983582Z","iopub.execute_input":"2022-05-04T12:20:22.983791Z","iopub.status.idle":"2022-05-04T12:24:23.244952Z","shell.execute_reply.started":"2022-05-04T12:20:22.983758Z","shell.execute_reply":"2022-05-04T12:24:23.244236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:24:23.246258Z","iopub.execute_input":"2022-05-04T12:24:23.246504Z","iopub.status.idle":"2022-05-04T12:24:23.25466Z","shell.execute_reply.started":"2022-05-04T12:24:23.24647Z","shell.execute_reply":"2022-05-04T12:24:23.253825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save train dataset\ntrain_dataset_path = os.path.join(\n    config[\"output_dir\"], config[\"train_dataset_path\"]\n)\ntrain_ds.save_to_disk(train_dataset_path)\n\n# save valid dataset\nvalid_dataset_path = os.path.join(\n    config[\"output_dir\"], config[\"valid_dataset_path\"]\n)\nvalid_ds.save_to_disk(valid_dataset_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:24:23.255995Z","iopub.execute_input":"2022-05-04T12:24:23.256319Z","iopub.status.idle":"2022-05-04T12:24:23.520091Z","shell.execute_reply.started":"2022-05-04T12:24:23.256282Z","shell.execute_reply":"2022-05-04T12:24:23.519309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unlabelled Dataset","metadata":{}},{"cell_type":"code","source":"print(\"loading unlabelled data...\")\nrequired_examples = config[\"num_unlabelled\"]\ndf = unlabelled_df.sample(required_examples)\nkeep_cols = [\"pn_history\", \"feature_text\", \"feature_num\"]\ndf = df[keep_cols].copy()\nprint(\"unlabelled data loaded and sampled ...\")\nprint(f\"shape of sampled unlabelled data: {df.shape}\")\n\n########### Create Unlabelled Dataset ##############\ndataset_creator = NbmeMTLDataset(config)\nunlabelled_ds = dataset_creator.get_dataset(df, mode='infer')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:24:23.521382Z","iopub.execute_input":"2022-05-04T12:24:23.521665Z","iopub.status.idle":"2022-05-04T12:26:22.858387Z","shell.execute_reply.started":"2022-05-04T12:24:23.521628Z","shell.execute_reply":"2022-05-04T12:26:22.857715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoaders","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass DataCollatorForMTLNeo(DataCollatorForTokenClassification):\n    \"\"\"\n    Data collator that will dynamically pad the inputs received\n    Multitask learning targets will be added to batch and padded\n    \"\"\"\n    tokenizer = None\n    padding = True\n    max_length = None\n    pad_to_multiple_of = None\n    label_pad_token_id = -1\n    return_tensors = \"pt\"\n\n    def torch_call(self, features):\n        label_name = \"labels\"\n        labels = None\n\n        if label_name in features[0].keys():\n            labels = [feature[label_name] for feature in features]\n\n        batch = self.tokenizer.pad(\n            features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\" if labels is None else None,\n        )\n\n        if labels is None:  # e.g. in eval mode\n            return batch\n\n        sequence_length = torch.tensor(batch[\"input_ids\"]).shape[1]\n\n        # main labels\n        num_labels, padded_labels = len(labels[0]), []\n\n        for this_example in labels:\n            padding_length = sequence_length - len(this_example[0])\n            padding_matrix = (self.label_pad_token_id)*np.ones(shape=(num_labels, padding_length))\n            this_example = (np.concatenate([np.array(this_example), padding_matrix], axis=1).T).tolist()\n            padded_labels.append(this_example)\n        batch[label_name] = padded_labels\n\n        batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n\n        # cast lables to float for bce loss\n        batch[label_name] = batch[label_name].to(torch.float32)\n        return batch\n    \n@dataclass\nclass DataCollatorForMPL(DataCollatorForTokenClassification):\n    \"\"\"\n    Data collator for unlabelled data\n    \"\"\"\n    tokenizer = None\n    padding = True\n    max_length = None\n    pad_to_multiple_of = None\n    label_pad_token_id = -1\n    return_tensors = \"pt\"\n\n    def torch_call(self, features):\n        buffer = [feature[\"sequence_ids\"] for feature in features]\n\n        batch = self.tokenizer.pad(\n            features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=None,\n        )\n\n        # create masks\n        sequence_length = torch.tensor(batch[\"input_ids\"]).shape[1]\n\n        # main labels\n        masks = []  # (batch, seq_len)\n\n        for seq in buffer:\n            padding_length = sequence_length - len(seq)\n            mask = [seq_id == 1 for seq_id in seq] + [False]*padding_length\n            masks.append(mask)\n            \n        batch['label_mask'] = masks\n        batch.pop('sequence_ids', None)\n\n        batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n        return batch","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:26:22.85971Z","iopub.execute_input":"2022-05-04T12:26:22.859973Z","iopub.status.idle":"2022-05-04T12:26:22.877258Z","shell.execute_reply.started":"2022-05-04T12:26:22.859939Z","shell.execute_reply":"2022-05-04T12:26:22.876547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config[\"base_model_path\"])\ndata_collator = DataCollatorForMTLNeo(tokenizer=tokenizer, label_pad_token_id=-1)\n\ntrain_ds.set_format(\n    type=None,\n    columns=['input_ids', 'attention_mask', 'token_type_ids', 'labels']\n)\n\ntrain_dl = DataLoader(\n    train_ds,\n    batch_size=config[\"batch_size\"],\n    collate_fn=data_collator,\n    pin_memory=True,\n    shuffle=True,\n)\n\nvalid_ds.set_format(\n    type=None,\n    columns=['input_ids', 'attention_mask', 'token_type_ids', 'labels']\n)\n\nvalid_dl = DataLoader(\n    valid_ds,\n    batch_size=config[\"batch_size\"],\n    collate_fn=data_collator,\n    pin_memory=True,\n    shuffle=False,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:26:22.878639Z","iopub.execute_input":"2022-05-04T12:26:22.879138Z","iopub.status.idle":"2022-05-04T12:26:34.222826Z","shell.execute_reply.started":"2022-05-04T12:26:22.8791Z","shell.execute_reply":"2022-05-04T12:26:34.222041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForMPL(tokenizer=tokenizer)\n\nunlabelled_ds.set_format(\n    type=None,\n    columns=['input_ids', 'attention_mask', 'token_type_ids', 'sequence_ids']\n)\n\nunlabelled_dl = DataLoader(\n    unlabelled_ds,\n    batch_size=config[\"batch_size\"],\n    collate_fn=data_collator,\n    pin_memory=True,\n    shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:26:34.224357Z","iopub.execute_input":"2022-05-04T12:26:34.224628Z","iopub.status.idle":"2022-05-04T12:26:34.230307Z","shell.execute_reply.started":"2022-05-04T12:26:34.22459Z","shell.execute_reply":"2022-05-04T12:26:34.22964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class NbmeMPL(nn.Module):\n    \"\"\"The Multi-task NBME model class for Meta Pseudo Labels\n    \"\"\"\n\n    def __init__(self, config):\n        super(NbmeMPL, self).__init__()\n\n        self.config = config\n\n        # base transformer\n        self.base_model = AutoModel.from_pretrained(\n            self.config[\"base_model_path\"],\n        )\n        self.base_model.gradient_checkpointing_enable()\n\n        n_freeze = config[\"n_freeze\"]\n        if n_freeze > 0:\n            print(f\"setting requires grad to false for last {n_freeze} layers\")\n            self.base_model.embeddings.requires_grad_(False)\n            self.base_model.encoder.layer[:n_freeze].requires_grad_(False)\n\n        hidden_size = self.base_model.config.hidden_size\n        num_layers_in_head = self.config[\"num_layers_in_head\"]\n\n        # token classification head\n        self.tok_classifier = nn.Linear(\n            in_features=hidden_size * num_layers_in_head,\n            out_features=self.config['mtl_tok_num_labels'],\n        )\n\n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n\n    def get_logits(self, batch):\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        token_type_ids = batch[\"token_type_ids\"]\n\n        out = self.base_model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            output_hidden_states=True\n        )\n\n        all_hidden_states = out[\"hidden_states\"]\n        # token classification logits\n        n = self.config[\"num_layers_in_head\"]\n        tok_output = torch.cat(all_hidden_states[-n:], dim=-1)\n\n        # pass through 5 dropout layers and take average\n        tok_output1 = self.dropout1(tok_output)\n        tok_output2 = self.dropout2(tok_output)\n        tok_output3 = self.dropout3(tok_output)\n        tok_output4 = self.dropout4(tok_output)\n        tok_output5 = self.dropout5(tok_output)\n        tok_output = (tok_output1 + tok_output2 + tok_output3 + tok_output4 + tok_output5)/5\n\n        tok_logits = self.tok_classifier(tok_output)\n\n        return tok_logits\n\n    def compute_loss(self, logits, labels, masks):\n        loss = F.binary_cross_entropy_with_logits(\n            logits, labels,\n            reduction='none'\n        )\n        loss = torch.masked_select(loss, masks).mean()\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:26:34.23174Z","iopub.execute_input":"2022-05-04T12:26:34.232235Z","iopub.status.idle":"2022-05-04T12:26:34.247582Z","shell.execute_reply.started":"2022-05-04T12:26:34.232198Z","shell.execute_reply":"2022-05-04T12:26:34.246634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer & Scheduler","metadata":{}},{"cell_type":"code","source":"def get_optimizer(model, config):\n    decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n    # print(decay_parameters)\n    decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n    # print(decay_parameters)\n\n    optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n            \"weight_decay\": config[\"weight_decay\"],\n        },\n        {\n            \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n            \"weight_decay\": 0.0,\n        },\n    ]\n\n    optimizer_kwargs = {\n        \"betas\": (config[\"beta1\"], config[\"beta2\"]),\n        \"eps\": config['eps'],\n    }\n\n    optimizer_kwargs[\"lr\"] = config[\"lr\"]\n\n    adam_bnb_optim = bnb.optim.Adam8bit(\n        optimizer_grouped_parameters,\n        betas=(config['beta1'], config['beta2']),\n        eps=config['eps'],\n        lr=config['lr'],\n    )\n\n    return adam_bnb_optim\n\n\ndef get_scheduler(optimizer, warmup_steps, total_steps):\n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer=optimizer,\n        num_warmup_steps=warmup_steps,\n        num_training_steps=total_steps\n    )\n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:26:34.24961Z","iopub.execute_input":"2022-05-04T12:26:34.250646Z","iopub.status.idle":"2022-05-04T12:26:34.261571Z","shell.execute_reply.started":"2022-05-04T12:26:34.250615Z","shell.execute_reply":"2022-05-04T12:26:34.260826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Utils","metadata":{}},{"cell_type":"code","source":"def get_lr(optimizer):\n    return optimizer.param_groups[0]['lr']*1e6\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\n       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n    \"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \ndef save_checkpoint(config, state, is_teacher, is_best):\n    if is_teacher:\n        os.makedirs(config[\"teacher_model_dir\"], exist_ok=True)\n        name = config[\"teacher_save_name\"]\n        filename = f'{config[\"teacher_model_dir\"]}/{name}_last.pth.tar'\n    else:\n        os.makedirs(config[\"student_model_dir\"], exist_ok=True)\n        name = config[\"student_save_name\"]\n        filename = f'{config[\"student_model_dir\"]}/{name}_last.pth.tar'\n    torch.save(state, filename, _use_new_zipfile_serialization=False)\n    if is_best:\n        if is_teacher:\n            shutil.copyfile(filename, f'{config[\"teacher_model_dir\"]}/{name}_best.pth.tar')\n        else:\n            shutil.copyfile(filename, f'{config[\"student_model_dir\"]}/{name}_best.pth.tar')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:26:34.262913Z","iopub.execute_input":"2022-05-04T12:26:34.263581Z","iopub.status.idle":"2022-05-04T12:26:34.275467Z","shell.execute_reply.started":"2022-05-04T12:26:34.263531Z","shell.execute_reply":"2022-05-04T12:26:34.274757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scorer","metadata":{}},{"cell_type":"code","source":"def perform_localization(char_probs, threshold=0.5):\n    \"\"\"convert character wise prediction to location spans\n\n    :param char_probs: character wise predictions\n    :type char_prob: list\n    :param threshold: threshold for label decision, defaults to 0.5\n    :type threshold: float, optional\n    :return: locations\n    :rtype: list\n    \"\"\"\n    results = np.where(char_probs >= threshold)[0]\n    results = [list(g) for _, g in itertools.groupby(\n        results, key=lambda n, c=itertools.count(): n - next(c))]\n    results = [[min(r), max(r)+1] for r in results]\n    return results\n\n\ndef postprocess_localization(text, span_offsets):\n    \"\"\"remove spaces at the beginning of label span prediction\n\n    :param span: input text (patient history)\n    :type text: str\n    :param span_offset: prediction span offsets\n    :type offset_mapping: list\n    :return: updated span offsets \n    :rtype: list\n    \"\"\"\n    to_return = []\n    for start, end in span_offsets:\n        match = list(re.finditer('\\S+', text[start:end]))\n        if len(match) == 0:\n            to_return.append((start, end))\n        else:\n            span_start, _ = match[0].span()\n            to_return.append((start + span_start, end))\n    return to_return\n\n\ndef token2char(text, quantities, offsets, seq_ids, focus_seq=1):\n    \"\"\"convert token prediction/truths to character wise predictions/truths\n\n    :param text: patient notes text\n    :type text: str\n    :param quantities: token level variable values\n    :type quantities: list\n    :param offsets: token offsets without stripping\n    :type offsets: list\n    :param seq_ids: sequence id of the tokens\n    :type seq_ids: list\n    :param focus_seq: which sequence to focus on\n    :type focus_seq: int\n    :return: character probabilities\n    :rtype: list\n    \"\"\"\n    results = np.zeros(len(text))\n    for q, offset, seq_id in zip(quantities, offsets, seq_ids):\n        if seq_id != focus_seq:\n            continue\n        char_start_idx, char_end_idx = offset[0], offset[1]\n        results[char_start_idx:char_end_idx] = q\n    return results\n\ndef micro_f1(preds, truths):\n    \"\"\"\n    Micro f1 on binary arrays.\n\n    Args:\n        preds (list of lists of ints): Predictions.\n        truths (list of lists of ints): Ground truths.\n\n    Returns:\n        float: f1 score.\n    \"\"\"\n    # Micro : aggregating over all instances\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n\n    return f1_score(truths, preds)\n\n\ndef spans_to_binary(spans, length=None):\n    \"\"\"\n    Converts spans to a binary array indicating whether each character is in the span.\n\n    Args:\n        spans (list of lists of two ints): Spans.\n\n    Returns:\n        np array [length]: Binarized spans.\n    \"\"\"\n    length = np.max(spans) if length is None else length\n    binary = np.zeros(length)\n    for start, end in spans:\n        binary[start:end] = 1\n\n    return binary\n\n\ndef span_micro_f1(preds, truths):\n    \"\"\"\n    Micro f1 on spans.\n\n    Args:\n        preds (list of lists of two ints): Prediction spans.\n        truths (list of lists of two ints): Ground truth spans.\n\n    Returns:\n        float: f1 score.\n    \"\"\"\n\n    bin_preds = []\n    bin_truths = []\n\n    for pred, truth in zip(preds, truths):\n        if not len(pred) and not len(truth):\n            continue\n\n        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n        bin_preds.append(spans_to_binary(pred, length))\n        bin_truths.append(spans_to_binary(truth, length))\n\n    return micro_f1(bin_preds, bin_truths)\n\ndef scorer(preds, valid_dataset, threshold=0.5, focus_seq=1):\n    \"\"\"scorer for evaluation during training of models\n\n    :param preds: model preds on valid dataset [char probs]\n    :type preds: list\n    :param valid_dataset: validation dataset\n    :type valid_dataset: dataset\n    :param threshold: threshold at which model is evaluated, defaults to 0.5\n    :type threshold: float, optional\n    :param focus_seq: patient notes sequence, defaults to 1\n    :type focus_seq: int, optional\n    :return: Leaderboard metric\n    :rtype: float\n    \"\"\"\n    info_df = pd.DataFrame()\n    required_cols = [\n        \"pn_history\",\n        \"sequence_ids\",\n        \"offset_mapping_unstripped\",\n        \"label_spans\",\n    ]\n\n    for col in required_cols:\n        info_df[col] = valid_dataset[col]\n\n    info_df[\"token_preds\"] = preds\n\n    # convert token preds to char preds\n    input_cols = [\"pn_history\", \"token_preds\", \"offset_mapping_unstripped\", \"sequence_ids\"]\n    info_df[\"char_probs\"] = info_df[input_cols].apply(\n        lambda x: token2char(x[0], x[1], x[2], x[3], focus_seq), axis=1\n    )\n\n    #  location\n    info_df[\"location_preds\"] = info_df[\"char_probs\"].apply(\n        lambda x: perform_localization(x, threshold)\n    )\n    info_df['location_preds'] = info_df[[\"pn_history\", \"location_preds\"]].apply(\n        lambda x: postprocess_localization(x[0], x[1]), axis=1\n    )\n    lb = span_micro_f1(info_df[\"label_spans\"].values, info_df[\"location_preds\"].values)\n    return lb","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:26:34.276899Z","iopub.execute_input":"2022-05-04T12:26:34.27733Z","iopub.status.idle":"2022-05-04T12:26:34.30075Z","shell.execute_reply.started":"2022-05-04T12:26:34.277292Z","shell.execute_reply":"2022-05-04T12:26:34.299991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"print(\"==\"*40)\nprint(\"GPU utilization at the very start:\")\nprint_gpu_utilization()\nprint(\"==\"*40)\n\n#------- load student and teacher into memory --------------------#\nstudent = NbmeMPL(config)\nteacher = NbmeMPL(config)\n\n#------- get optimizers for student and teacher ------------------#\ns_optimizer = get_optimizer(student, config)\nt_optimizer = get_optimizer(teacher, config)\n\n\n#------- prepare accelerator  ------------------------------------#\naccelerator = Accelerator(fp16=True)\nstudent, teacher, s_optimizer, t_optimizer, train_dl, valid_dl, unlabelled_dl = accelerator.prepare(\n    student, teacher, s_optimizer, t_optimizer, train_dl, valid_dl, unlabelled_dl\n)\nprint(\"==\"*40)\nprint(\"GPU utilization after accelerator preparation:\")\nprint_gpu_utilization()\nprint(\"==\"*40)\n\n#------- setup schedulers  ---------------------------------------#\nnum_epochs = config[\"num_epochs\"]\ngrad_accumulation_steps = config[\"grad_accumulation\"]\nwarmup_pct = config[\"warmup_pct\"]\n\nn_train_steps_per_epoch = len(train_dl)//grad_accumulation_steps\nn_mpl_steps_per_epoch = len(unlabelled_dl)//grad_accumulation_steps\nn_steps_per_epoch = max(n_train_steps_per_epoch, n_mpl_steps_per_epoch)\nnum_steps = num_epochs * n_steps_per_epoch\nnum_warmup_steps = int(warmup_pct*num_steps)\n\ns_scheduler = get_scheduler(s_optimizer, num_warmup_steps, num_steps)\nt_scheduler = get_scheduler(t_optimizer, num_warmup_steps, num_steps)\n\n#------- Scorer & Trackers ----------------------------------------#\nbest_teacher_score = 0\nbest_student_score = 0\n\nvalid_ds_path = os.path.join(config[\"output_dir\"], config[\"valid_dataset_path\"])\nvalid_ds = load_from_disk(valid_ds_path)\n\nscorer_fn = partial(\n    scorer,\n    valid_dataset=valid_ds,\n    threshold=0.5,\n    focus_seq=config[\"text_sequence_identifier\"]\n)\n\n#------------- Data Iterators -------------------------------------#\ntrain_iter = iter(train_dl)\nunlabelled_iter = iter(unlabelled_dl)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:26:34.303672Z","iopub.execute_input":"2022-05-04T12:26:34.303907Z","iopub.status.idle":"2022-05-04T12:28:37.439224Z","shell.execute_reply.started":"2022-05-04T12:26:34.303873Z","shell.execute_reply":"2022-05-04T12:28:37.43844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ------- Training Loop  ------------------------------------------#\nfor step in range(num_steps):\n\n    #------ Reset buffers After Validation ------------------------#\n    if step % config[\"validation_interval\"] == 0:\n        progress_bar = tqdm(range(min(config[\"validation_interval\"], num_steps)))\n        s_loss_meter = AverageMeter()\n        t_loss_meter = AverageMeter()\n\n    teacher.train()\n    student.train()\n\n    t_optimizer.zero_grad()\n    s_optimizer.zero_grad()\n\n    #------ Get Train & Unlabelled Batch -------------------------#\n    try:\n        train_b = train_iter.next()\n    except Exception as e:  # TODO: change to stop iteration error\n        train_b = next(train_dl.__iter__())\n\n    try:\n        unlabelled_b = unlabelled_iter.next()\n    except:\n        unlabelled_b = next(unlabelled_dl.__iter__())\n\n    #------- Meta Training Steps ---------------------------------#\n    # get loss of current student on labelled train data\n    s_logits_train_b = student.get_logits(train_b)\n\n    # get loss of current student on labelled train data\n    train_b_labels = train_b[\"labels\"]\n    train_b_masks = train_b_labels.gt(-0.5)\n    s_loss_train_b = student.compute_loss(\n        logits=s_logits_train_b.detach(),\n        labels=train_b_labels,\n        masks=train_b_masks,\n    )\n\n    # get teacher generated pseudo labels for unlabelled data\n    unlabelled_b_masks = unlabelled_b[\"label_mask\"].eq(1).unsqueeze(-1)\n    t_logits_unlabelled_b = teacher.get_logits(unlabelled_b)\n    pseudo_y_unlabelled_b = (t_logits_unlabelled_b.detach() > 0).float()  # hard pseudo label\n\n    #------ Train Student: With Pesudo Label Data ------------------#\n    s_logits_unlabelled_b = student.get_logits(unlabelled_b)\n    s_loss_unlabelled_b = student.compute_loss(\n        logits=s_logits_unlabelled_b,\n        labels=pseudo_y_unlabelled_b,\n        masks=unlabelled_b_masks\n    )\n\n    # backpropagation of student loss on unlabelled data\n    accelerator.backward(s_loss_unlabelled_b)\n    s_optimizer.step()  # update student params\n    s_scheduler.step()\n\n    #------ Train Teacher ------------------------------------------#\n    s_logits_train_b_new = student.get_logits(train_b)\n    s_loss_train_b_new = student.compute_loss(\n        logits=s_logits_train_b_new.detach(),\n        labels=train_b_labels,\n        masks=train_b_masks,\n    )\n    change = s_loss_train_b_new - s_loss_train_b  # performance improvement from student\n\n    t_logits_train_b = teacher.get_logits(train_b)\n    t_loss_train_b = teacher.compute_loss(\n        logits=t_logits_train_b,\n        labels=train_b_labels,\n        masks=train_b_masks\n    )\n\n    t_loss_mpl = change * F.binary_cross_entropy_with_logits(\n        t_logits_unlabelled_b, pseudo_y_unlabelled_b, reduction='none')  # mpl loss\n    t_loss_mpl = torch.masked_select(t_loss_mpl, unlabelled_b_masks).mean()\n    t_loss = t_loss_train_b + t_loss_mpl\n\n    # backpropagation of teacher's loss\n    accelerator.backward(t_loss)\n    t_optimizer.step()\n    t_scheduler.step()\n\n    #------ Progress Bar Updates ----------------------------------#\n    s_loss_meter.update(s_loss_train_b_new.item())\n    t_loss_meter.update(t_loss.item())\n\n    progress_bar.set_description(\n        f\"STEP: {step+1:5}/{num_steps:5}. \"\n        f\"LR: {get_lr(s_optimizer):.4f}. \"\n        f\"TL: {t_loss_meter.avg:.4f}. \"\n        f\"SL: {s_loss_meter.avg:.4f}. \"\n    )\n    progress_bar.update()\n\n    #------ Evaluation & Checkpointing -----------------------------#\n    if (step + 1) % config[\"validation_interval\"] == 0:\n        progress_bar.close()\n\n        #----- Teacher Evaluation  ---------------------------------#\n        teacher.eval()\n        teacher_preds = []\n        with torch.no_grad():\n            for batch in valid_dl:\n                p = teacher.get_logits(batch)\n                teacher_preds.append(p)\n        teacher_preds = [torch.sigmoid(p).detach().cpu().numpy()[:, :, 0] for p in teacher_preds]\n        teacher_preds = list(chain(*teacher_preds))\n        teacher_lb = scorer_fn(teacher_preds)\n        print(f\"After step {step+1} Teache LB: {teacher_lb}\")\n\n        # save teacher\n        accelerator.wait_for_everyone()\n        teacher = accelerator.unwrap_model(teacher)\n        teacher_state = {\n            'step': step + 1,\n            'state_dict': teacher.state_dict(),\n            'optimizer': t_optimizer.state_dict(),\n            'lb': teacher_lb\n        }\n        is_best = False\n        if teacher_lb > best_teacher_score:\n            best_teacher_score = teacher_lb\n            is_best = True\n        # save_checkpoint(config, teacher_state, is_teacher=True, is_best=is_best)\n\n        #----- Student Evaluation  ---------------------------------#\n        student.eval()\n        student_preds = []\n        with torch.no_grad():\n            for batch in valid_dl:\n                p = student.get_logits(batch)\n                student_preds.append(p)\n        student_preds = [torch.sigmoid(p).detach().cpu().numpy()[:, :, 0] for p in student_preds]\n        student_preds = list(chain(*student_preds))\n        student_lb = scorer_fn(student_preds)\n        print(f\"After step {step+1} Student LB: {student_lb}\")\n\n        # save student\n        accelerator.wait_for_everyone()\n        student = accelerator.unwrap_model(student)\n        student_state = {\n            'step': step + 1,\n            'state_dict': student.state_dict(),\n            'optimizer': s_optimizer.state_dict(),\n            'lb': student_lb\n        }\n        is_best = False\n        if student_lb > best_student_score:\n            best_student_score = student_lb\n            is_best = True\n        save_checkpoint(config, student_state, is_teacher=False, is_best=is_best)\n\n        print(\"==\"*40)\n        print(\"GPU utilization after eval:\")\n        print_gpu_utilization()\n        print(\"clearning the cache\")\n        torch.cuda.empty_cache()\n        print_gpu_utilization()\n        print(\"==\"*40)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T12:28:37.440798Z","iopub.execute_input":"2022-05-04T12:28:37.441227Z","iopub.status.idle":"2022-05-04T14:59:03.89316Z","shell.execute_reply.started":"2022-05-04T12:28:37.441188Z","shell.execute_reply":"2022-05-04T14:59:03.889602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Next Steps\n* Run MPL with more unlabelled examples\n    * Current run uses 10k examples, which is roughly equivalent to training for 0.85 epochs\n* Use task-adpapted models as backbone\n* Experiment with different hyperparameters\n* Experiment with soft pseudo labels\n* During MPL, the student model is trained only on unlabelled data using pseudo labels from teacher\n* So the student can be further fine-tuned on actual training data for additional performance boost","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}