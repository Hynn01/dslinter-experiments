{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score, roc_auc_score, cohen_kappa_score, precision_score, recall_score, accuracy_score, confusion_matrix\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.applications import *\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\n#from keras.layers.normalization import BatchNormalization\nfrom keras.layers import Input,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,AveragePooling2D,concatenate,Activation,ZeroPadding2D\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, multiply, Permute, Add,Lambda, Concatenate\nfrom keras.models import Model, Sequential\nfrom keras.applications.xception import Xception\nfrom keras.applications import *\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom PIL import Image\nimport glob\nimport random\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier \nfrom keras.callbacks import EarlyStopping\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras.utils import to_categorical\n\n#Max batch size= available GPU memory bytes / 4 / (size of tensors + trainable parameters)\n#model.summary()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T15:02:41.904952Z","iopub.execute_input":"2022-05-06T15:02:41.905252Z","iopub.status.idle":"2022-05-06T15:02:41.918642Z","shell.execute_reply.started":"2022-05-06T15:02:41.905219Z","shell.execute_reply":"2022-05-06T15:02:41.91756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lung_aca = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_aca/\"\n\nplt.figure(figsize = (10, 10))\nplt.subplot(131)\nimg = cv2.imread(lung_aca + os.listdir(lung_aca)[0])\nplt.title('Lung ACA') # lung adenocarcinoma (ACA)\nplt.imshow(img)\n\nplt.subplot(132)\nlung_n = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_n/\"\nimg = cv2.imread(lung_n + os.listdir(lung_n)[0])\nplt.title('Lung N')\nplt.imshow(img)\n\nplt.subplot(133)\nlung_scc = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/lung_scc/\"\nimg = cv2.imread(lung_scc + os.listdir(lung_scc)[0])\nplt.title('Lung SCC') #small cell carcinomas (SCCs)\nplt.imshow(img)\n\ncolon_aca= \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/colon_aca/\"\nplt.figure(figsize = (10, 10))\nplt.subplot(131)\nimg = cv2.imread(colon_aca + os.listdir(colon_aca)[0])\nplt.title('Colon ACA')\nplt.imshow(img)\n\nplt.subplot(132)\ncolon_n = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/colon_image_sets/colon_n/\"\nimg = cv2.imread(colon_n + os.listdir(colon_n)[0])\nplt.title('Colon N')\nplt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:41.963789Z","iopub.execute_input":"2022-05-06T15:02:41.964738Z","iopub.status.idle":"2022-05-06T15:02:43.255974Z","shell.execute_reply.started":"2022-05-06T15:02:41.964688Z","shell.execute_reply":"2022-05-06T15:02:43.25487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/\"\n\nSIZE_X = SIZE_Y = 128\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3)\n\ntrain_it = datagen.flow_from_directory(data_dir,\n                                       class_mode = \"categorical\",\n                                       target_size = (SIZE_X,SIZE_Y),\n                                       color_mode=\"rgb\",\n                                       batch_size = 32, \n                                       shuffle = False,\n                                       subset='training',\n                                       seed = 42)\n\nvalidate_it = datagen.flow_from_directory(data_dir,\n                                       class_mode = \"categorical\",\n                                       target_size = (SIZE_X, SIZE_Y),\n                                       color_mode=\"rgb\",\n                                       batch_size = 32, \n                                       shuffle = False,\n                                       subset='validation',\n                                       seed = 42)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:43.257807Z","iopub.execute_input":"2022-05-06T15:02:43.258082Z","iopub.status.idle":"2022-05-06T15:02:46.990223Z","shell.execute_reply.started":"2022-05-06T15:02:43.258041Z","shell.execute_reply":"2022-05-06T15:02:46.9882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_model(model, train_it, validate_it, epochs = 10):\n    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n    \n    for layer in model.layers:\n        layer.trainable = False\n    \n    flat1 = Flatten()(model.layers[-1].output)\n    output = Dense(len(train_it.class_indices), activation='softmax')(flat1)\n    \n    model = Model(inputs=model.inputs, outputs=output)\n    print(model.summary())\n    \n    model.compile(loss='categorical_crossentropy', optimizer ='adam', metrics=['accuracy'])\n    model.summary()\n    history = model.fit(train_it, validation_data=validate_it, epochs=epochs, verbose=1, callbacks=[es])\n    model.evaluate(validate_it)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:46.992015Z","iopub.execute_input":"2022-05-06T15:02:46.992533Z","iopub.status.idle":"2022-05-06T15:02:47.001931Z","shell.execute_reply.started":"2022-05-06T15:02:46.992466Z","shell.execute_reply":"2022-05-06T15:02:47.000842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_accuracy_metrics(model, train_it, validate_it):\n    y_val = validate_it.classes\n    \n    val_pred_proba = model.predict(validate_it)\n    \n    val_pred_proba, predicted_proba, y_val, y_test = train_test_split(val_pred_proba, y_val, test_size = 0.5, shuffle = True)\n    \n    val_pred = np.argmax(val_pred_proba, axis = 1)\n    predicted = np.argmax(predicted_proba, axis = 1)\n    \n    print(\"Train accuracy Score------------>\")\n    print (\"{0:.3f}\".format(accuracy_score(train_it.classes, np.argmax(model.predict(train_it), axis = 1))*100), \"%\")\n    \n    print(\"Val accuracy Score--------->\")\n    print(\"{0:.3f}\".format(accuracy_score(y_val, val_pred)*100), \"%\")\n    \n    print(\"Test accuracy Score--------->\")\n    print(\"{0:.3f}\".format(accuracy_score(y_test, predicted)*100), \"%\")\n    \n    print(\"F1 Score--------------->\")\n    print(\"{0:.3f}\".format(f1_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    print(\"Cohen Kappa Score------------->\")\n    print(\"{0:.3f}\".format(cohen_kappa_score(y_test, predicted)*100), \"%\")\n    \n    \n    print(\"ROC AUC Score------------->\")\n    print(\"{0:.3f}\".format(roc_auc_score(to_categorical(y_test, num_classes = 3), predicted_proba, multi_class='ovr')*100), \"%\")\n    \n    print(\"Recall-------------->\")\n    print(\"{0:.3f}\".format(recall_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    print(\"Precision-------------->\")\n    print(\"{0:.3f}\".format(precision_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    cf_matrix_test = confusion_matrix(y_test, predicted)\n    cf_matrix_val = confusion_matrix(y_val, val_pred)\n    \n    plt.figure(figsize = (12, 6))\n    plt.subplot(121)\n    sns.heatmap(cf_matrix_val, annot=True, cmap='Blues')\n    plt.title(\"Val Confusion matrix\")\n    \n    plt.subplot(122)\n    sns.heatmap(cf_matrix_test, annot=True, cmap='Blues')\n    plt.title(\"Test Confusion matrix\")\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:47.004986Z","iopub.execute_input":"2022-05-06T15:02:47.005879Z","iopub.status.idle":"2022-05-06T15:02:47.020142Z","shell.execute_reply.started":"2022-05-06T15:02:47.00583Z","shell.execute_reply":"2022-05-06T15:02:47.019288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def focal_loss(gamma=2.):            \n    def focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        return -K.sum( K.pow(1. - pt_1, gamma) * K.log(pt_1)) \n    return focal_loss_fixed","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:47.021473Z","iopub.execute_input":"2022-05-06T15:02:47.022042Z","iopub.status.idle":"2022-05-06T15:02:47.034905Z","shell.execute_reply.started":"2022-05-06T15:02:47.021993Z","shell.execute_reply":"2022-05-06T15:02:47.034101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Conv2d_BN(x, nb_filter,kernel_size, strides=(1,1), padding='same',name=None):  \n    if name is not None:  \n        bn_name = name + '_bn'  \n        conv_name = name + '_conv'  \n    else:  \n        bn_name = None  \n        conv_name = None  \n  \n    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)  \n    x = BatchNormalization(axis=3,name=bn_name)(x)  \n    return x  \n\ndef Conv_Block(inpt,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut=False):  \n    x = Conv2d_BN(inpt,nb_filter=nb_filter[0],kernel_size=(1,1),strides=strides,padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[1], kernel_size=(3,3), padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[2], kernel_size=(1,1), padding='same')  \n    if with_conv_shortcut:  \n        shortcut = Conv2d_BN(inpt,nb_filter=nb_filter[2],strides=strides,kernel_size=kernel_size)  \n        x = add([x,shortcut])  \n        return x  \n    else:  \n        x = add([x,inpt])  \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:47.036154Z","iopub.execute_input":"2022-05-06T15:02:47.036488Z","iopub.status.idle":"2022-05-06T15:02:47.050461Z","shell.execute_reply.started":"2022-05-06T15:02:47.036444Z","shell.execute_reply":"2022-05-06T15:02:47.049582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def channel_attention(input_feature, ratio=8): #final features are attained\n    print(\"Channel Attention:\")\n    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n    #channel = input_feature._keras_shape[channel_axis]\n    channel = input_feature.shape[channel_axis]\n    shared_layer_one = Dense(channel//ratio,\n                            kernel_initializer='he_normal',\n                            activation = 'relu',\n                            use_bias=True,\n                            bias_initializer='zeros')\n\n    shared_layer_two = Dense(channel,\n                            kernel_initializer='he_normal',\n                            use_bias=True,\n                            bias_initializer='zeros')\n\n    avg_pool = GlobalAveragePooling2D()(input_feature)    \n    avg_pool = Reshape((1,1,channel))(avg_pool)\n    #assert avg_pool._keras_shape[1:] == (1,1,channel)\n    assert avg_pool.shape[1:] == (1,1,channel)\n    avg_pool = shared_layer_one(avg_pool)\n    #assert avg_pool._keras_shape[1:] == (1,1,channel//ratio)\n    assert avg_pool.shape[1:] == (1,1,channel//ratio)    \n    avg_pool = shared_layer_two(avg_pool)\n    #assert avg_pool._keras_shape[1:] == (1,1,channel)\n    assert avg_pool.shape[1:] == (1,1,channel)    \n\n    max_pool = GlobalMaxPooling2D()(input_feature)\n    max_pool = Reshape((1,1,channel))(max_pool)\n    #assert max_pool._keras_shape[1:] == (1,1,channel)\n    assert max_pool.shape[1:] == (1,1,channel)    \n    max_pool = shared_layer_one(max_pool)\n    #assert max_pool._keras_shape[1:] == (1,1,channel//ratio)\n    assert max_pool.shape[1:] == (1,1,channel//ratio)    \n    max_pool = shared_layer_two(max_pool)\n    #assert max_pool._keras_shape[1:] == (1,1,channel)\n    assert max_pool.shape[1:] == (1,1,channel)    \n\n    cbam_feature = Add()([avg_pool,max_pool])\n    cbam_feature = Activation('hard_sigmoid')(cbam_feature)\n    if K.image_data_format() == \"channels_first\":\n        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n    return multiply([input_feature, cbam_feature])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:47.051825Z","iopub.execute_input":"2022-05-06T15:02:47.052116Z","iopub.status.idle":"2022-05-06T15:02:47.065647Z","shell.execute_reply.started":"2022-05-06T15:02:47.052085Z","shell.execute_reply":"2022-05-06T15:02:47.064687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the spatial attention concatenates the final features attained by channel\n#attention and convolved by a regular convolution layer, thereby generating the spatial attention map.\ndef spatial_attention(input_feature): \n    print(\"Spatial Attnetion:\")\n    kernel_size = 7\n    if K.image_data_format() == \"channels_first\":\n        #channel = input_feature._keras_shape[1]\n        channel = input_feature.shape[1]        \n        cbam_feature = Permute((2,3,1))(input_feature)\n    else:\n        #channel = input_feature._keras_shape[-1]\n        channel = input_feature.shape[-1]        \n        cbam_feature = input_feature\n\n    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n    #assert avg_pool._keras_shape[-1] == 1\n    assert avg_pool.shape[-1] == 1    \n    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n    #assert max_pool._keras_shape[-1] == 1\n    assert max_pool.shape[-1] == 1    \n    concat = Concatenate(axis=3)([avg_pool, max_pool])\n    #assert concat._keras_shape[-1] == 2\n    assert concat.shape[-1] == 2    \n    cbam_feature = Conv2D(filters = 1,\n                        kernel_size=kernel_size,\n                        activation = 'hard_sigmoid',\n                        strides=1,\n                        padding='same',\n                        kernel_initializer='he_normal',\n                        use_bias=False)(concat)\n    #assert cbam_feature._keras_shape[-1] == 1\n    assert cbam_feature.shape[-1] == 1    \n\n    if K.image_data_format() == \"channels_first\":\n        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n    return multiply([input_feature, cbam_feature])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:47.066992Z","iopub.execute_input":"2022-05-06T15:02:47.067214Z","iopub.status.idle":"2022-05-06T15:02:47.07944Z","shell.execute_reply.started":"2022-05-06T15:02:47.067185Z","shell.execute_reply":"2022-05-06T15:02:47.078528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cbam_block(cbam_feature,ratio=1):\n    cbam_feature = channel_attention(cbam_feature, ratio)\n    cbam_feature = spatial_attention(cbam_feature, )\n    return cbam_feature","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:47.080375Z","iopub.execute_input":"2022-05-06T15:02:47.080791Z","iopub.status.idle":"2022-05-06T15:02:47.093711Z","shell.execute_reply.started":"2022-05-06T15:02:47.080734Z","shell.execute_reply":"2022-05-06T15:02:47.092864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data_dir = \"../input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets/\"\n#batch_size increased from 32 to 64 by MS 5/5/2022\nbatch_size=64\n#Reduce from 30 to 17 5/5/2022 by MS \nepochs = 10\n\n#Log directory for TensorBoard\nboard_name1 = \"./obj_reco/stage1/' + now + '/\"\nboard_name2 = \"./obj_reco/stage2/' + now + '/\"\nnb_train_samples = len(glob.glob(data_dir + '/*/*.*'))  \nnb_validation_samples = len(glob.glob(data_dir + '/*/*.*'))    \n#---------Attention embedded MobileNetV2--------------------------------------------------------------\nimport tensorflow as tf\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras import backend as K\nfrom keras import regularizers\n\nprint(\"Attention embedded mobileNetV2:\")\nIMG_SHAPE=(128, 128, 3)\nimg_size = (128, 128) \nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False,weights=\"imagenet\")\n\nbase_model.trainable = True\nprint(\"Number of layers in the base model: \", len(base_model.layers))\nfine_tune_at = 100\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n    \nbase_out = base_model.output\n\nprint(\"Soft attention module started Conv2D:\")\n#--------------------Soft attention module-------------------------------------------------------------- \nipts = base_out\nmodel = BatchNormalization()(ipts)\nmodel = Conv2D(filters = 1280, kernel_size = (1, 1), strides=(1,1), padding = 'same', activation='relu')(model)\nmodel = BatchNormalization(-1)(model)\n\ncbam = cbam_block(model)\nbase_out = tf.keras.layers.add([base_out, model, cbam])\n\n#------------------------------------------------------------------------------------------------------------ \n\nx = GlobalAveragePooling2D()(base_out)\n\n# softmax\nprint(\"Sofmax as activation in prediction:\")\n#predictions = Dense(len(ont_hot_labels[0]), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\npredictions = Dense(len(train_it.class_indices), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n#base_learning_rate = 0.0001 #added 3/5/2022 by MS (https://blog.roboflow.com/how-to-train-mobilenetv2-on-a-custom-dataset/)\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',  metrics = ['accuracy'])  #rmsprop\n\n#model_checkpoint1 = ModelCheckpoint(filepath=MODEL_INIT, save_best_only=True, monitor='val_accuracy', mode='max')\nmodel_checkpoint1 = ModelCheckpoint(filepath=\"./model_checkpoint1/\", save_best_only=True, monitor='val_accuracy',mode='max',verbose=1)\nboard1 = TensorBoard(log_dir=board_name1,\n                     histogram_freq=10,\n                     write_graph=True,\n                     write_images=True)\ncallback_list1 = [model_checkpoint1, board1]\n\nprint(\"Softmax model fitting\")\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n\nmodel.fit(train_it, steps_per_epoch=nb_train_samples / float(batch_size),\n                           epochs = epochs,\n                           validation_steps=nb_validation_samples / float(batch_size),\n                           validation_data=validate_it,\n                           #callbacks=callback_list1, verbose=2)\n                           callbacks=[es], verbose=1) #Early stopping is implemented instead of callback by MS. 5/5/2022\n\n#---------------2-nd stage---------------------------------------------\nmodel_checkpoint2 = ModelCheckpoint(filepath=\"./model_checkpoint2/\",  monitor='val_accuracy')\nboard2 = TensorBoard(log_dir=board_name2,\n                     histogram_freq=0,\n                     write_graph=True,\n                     write_images=True)\ncallback_list2 = [model_checkpoint2, board2]\n\nmodel.save(\"./newModel.h5\")\nmodel.load_weights(\"./newModel.h5\")\nfor model1 in model.layers:\n    model1.trainable = True\n\n#model.compile(optimizer=optimizers.Adam(), loss =[focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\n#model.compile(optimizer=optimizers.Adadelta(), loss = [focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\nmodel.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001), loss = [focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\nmodel.summary()\n\n#Reduce 20 to 20 5/5/2022 by MS\nvalidation_steps=20\n\nloss0,accuracy0 = model.evaluate(validate_it, steps = validation_steps)\n\nprint(loss0, accuracy0)\nprint(\"Last history:\")\n#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nhistory=model.fit(train_it, steps_per_epoch=nb_train_samples / float(batch_size), epochs=epochs,\n                    validation_data=validate_it, validation_steps=nb_validation_samples / float(batch_size),\n                    #callbacks=callback_list2, verbose=2) #Early stopping is introduced to minimize loss. 5/5/2022 By MS\n                    callbacks=[es], verbose=1)\n\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nprint(\"Evaluation:\")\nmodel.evaluate(validate_it)\nprint(\"Accuracy:\")\nget_accuracy_metrics(model, train_it, validate_it)\n\nprint(\"Completed\")","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:02:47.096231Z","iopub.execute_input":"2022-05-06T15:02:47.096483Z","iopub.status.idle":"2022-05-06T16:09:24.147439Z","shell.execute_reply.started":"2022-05-06T15:02:47.096451Z","shell.execute_reply":"2022-05-06T16:09:24.14643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MobileNet-V2","metadata":{}},{"cell_type":"code","source":"#model = tf.keras.applications.MobileNetV2(include_top=False, input_shape=(SIZE_X, SIZE_Y, 3), weights='imagenet')\n#model = fit_model(model, train_it, validate_it)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:09:24.149129Z","iopub.execute_input":"2022-05-06T16:09:24.150207Z","iopub.status.idle":"2022-05-06T16:09:24.155275Z","shell.execute_reply.started":"2022-05-06T16:09:24.150159Z","shell.execute_reply":"2022-05-06T16:09:24.153948Z"},"trusted":true},"execution_count":null,"outputs":[]}]}