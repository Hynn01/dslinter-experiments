{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy as scp  #linear algebra\nimport seaborn as snc #drawing statistical graphics\nimport os   #creating,removing directory/fetching its contents(interact with operating systems)\nimport tensorflow as tf\nimport os \nfrom PIL import Image\nfrom glob import glob\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom PIL import Image\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:39:05.123347Z","iopub.execute_input":"2022-05-06T20:39:05.123623Z","iopub.status.idle":"2022-05-06T20:39:12.702698Z","shell.execute_reply.started":"2022-05-06T20:39:05.123595Z","shell.execute_reply":"2022-05-06T20:39:12.701465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load data**","metadata":{}},{"cell_type":"code","source":"data_dir='../input/massachusetts-buildings-dataset/tiff'\nx_train_dir='../input/massachusetts-buildings-dataset/tiff/train' #x_train_dir=os.path.join(data_dir,'train')\ny_tarin_dir='../input/massachusetts-buildings-dataset/tiff/train_labels' #y_train_dir=os.path.join(data_dir,'trainlabels')\n\nx_valid_dir='../input/massachusetts-buildings-dataset/tiff/val' #x_valid_dir=os.path.join(data_dir,'val')\ny_valid_dir='../input/massachusetts-buildings-dataset/tiff/val_labels' #y_valid_dir=os.path.join(data_dir,'val_labels')\n\nx_test_dir='../input/massachusetts-buildings-dataset/tiff/test' #x_test_dir=os.path.join(data_dir,'test')\ny_test_dir='../input/massachusetts-buildings-dataset/tiff/test_labels' #y_test_dir=os.path.join(dat_dir,'test_labels')\n\nclass_dict=pd.read_csv('../input/massachusetts-buildings-dataset/label_class_dict.csv')\nprint(class_dict)\nclass_names=class_dict['name'].tolist()\nprint(class_names)\nclass_rgb_values=class_dict[['r','g','b']].values.tolist()\nprint(class_rgb_values)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:39:12.704441Z","iopub.execute_input":"2022-05-06T20:39:12.704778Z","iopub.status.idle":"2022-05-06T20:39:12.754142Z","shell.execute_reply.started":"2022-05-06T20:39:12.704742Z","shell.execute_reply":"2022-05-06T20:39:12.752731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata = pd.read_csv(\"../input/massachusetts-buildings-dataset/metadata.csv\")\ntoy=False\nif toy:\n   metadata = metadata.sample(50000)\n\nmetadata.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:39:12.756146Z","iopub.execute_input":"2022-05-06T20:39:12.757489Z","iopub.status.idle":"2022-05-06T20:39:12.796054Z","shell.execute_reply.started":"2022-05-06T20:39:12.757417Z","shell.execute_reply":"2022-05-06T20:39:12.795057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating dataframe**","metadata":{}},{"cell_type":"code","source":"def GetData(folder,folder_labels):\n    path =\"../input/massachusetts-buildings-dataset/tiff\"\n    img_tiff=os.path.join(path,'./'+folder+'/')#load train\n    masked_tiff=os.path.join(path,'./'+folder_labels+'/')#load the labeles\n    img_list= os.listdir(img_tiff)\n    mask_list=os.listdir(masked_tiff)\n    img_list = [img_tiff+i for i in img_list] #create \"imgs\" list\n    mask_list = [masked_tiff+i for i in mask_list] #create \"masked \"list\n    Data = pd.DataFrame({'imgs':img_list,'labels':mask_list})\n    Data.head(5)\n    return Data","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:39:12.798608Z","iopub.execute_input":"2022-05-06T20:39:12.798951Z","iopub.status.idle":"2022-05-06T20:39:12.806254Z","shell.execute_reply.started":"2022-05-06T20:39:12.798907Z","shell.execute_reply":"2022-05-06T20:39:12.805332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=GetData('train','train_labels')\nval_data=GetData('val','val_labels')\ntest_data=GetData('test','test_labels')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:39:12.807742Z","iopub.execute_input":"2022-05-06T20:39:12.808241Z","iopub.status.idle":"2022-05-06T20:39:13.035971Z","shell.execute_reply.started":"2022-05-06T20:39:12.808176Z","shell.execute_reply":"2022-05-06T20:39:13.035313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data visualisation**","metadata":{}},{"cell_type":"code","source":"import cv2\ndef VizData(data,N):\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,3,1)\n    img=cv2.imread(data.imgs.iloc[N])\n    plt.imshow(img)\n    plt.subplot(1,3,2)\n    msk=cv2.imread(data.labels.iloc[N])\n    plt.imshow(msk)\n    plt.subplot(1,3,3)\n    plt.imshow(img)\n    plt.imshow(msk,alpha=0.65)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:39:13.039968Z","iopub.execute_input":"2022-05-06T20:39:13.04038Z","iopub.status.idle":"2022-05-06T20:39:13.416529Z","shell.execute_reply.started":"2022-05-06T20:39:13.040347Z","shell.execute_reply":"2022-05-06T20:39:13.415579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VizData(train_data,2)\nVizData(val_data,2)\nVizData(test_data,2)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:39:13.417931Z","iopub.execute_input":"2022-05-06T20:39:13.418306Z","iopub.status.idle":"2022-05-06T20:39:20.239238Z","shell.execute_reply.started":"2022-05-06T20:39:13.418258Z","shell.execute_reply":"2022-05-06T20:39:20.238425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Data augmentation**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(zoom_range=0.1,\n                            rotation_range=30,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest',\n                            rescale=1./255)\nimage_train=datagen.flow_from_dataframe(train_data,  \n                                    target_size=(256,256), \n                                    color_mode='rgb',\n                                    shuffle=True,\n                                    seed=42,\n                                    x_col =\"imgs\", \n                                    batch_size=32,\n                                    class_mode=None\n)\nmask_train=datagen.flow_from_dataframe(train_data, \n                                    target_size=(256,256), \n                                    color_mode='grayscale',\n                                    shuffle=True,\n                                    seed=42,\n                                    x_col =\"labels\", \n                                    batch_size=32,\n                                    class_mode=None)\n\nimage_val=datagen.flow_from_dataframe(val_data,  \n                                    target_size=(256,256), \n                                    color_mode='rgb',\n                                    shuffle=True,\n                                    seed=42,\n                                    x_col =\"imgs\", \n                                    batch_size=32,\n                                    class_mode=None)\nmask_val=datagen.flow_from_dataframe(val_data, \n                                    target_size=(256,256), \n                                    color_mode='grayscale',\n                                    shuffle=True,\n                                    seed=42,\n                                    x_col =\"labels\", \n                                    batch_size=32,\n                                    class_mode=None)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:41:27.491968Z","iopub.execute_input":"2022-05-06T20:41:27.492316Z","iopub.status.idle":"2022-05-06T20:41:27.713722Z","shell.execute_reply.started":"2022-05-06T20:41:27.492283Z","shell.execute_reply":"2022-05-06T20:41:27.712647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen=zip(image_train,mask_train)\nvalid_gen=zip(image_val,mask_val)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:41:28.073468Z","iopub.execute_input":"2022-05-06T20:41:28.074336Z","iopub.status.idle":"2022-05-06T20:41:28.079549Z","shell.execute_reply.started":"2022-05-06T20:41:28.074285Z","shell.execute_reply":"2022-05-06T20:41:28.078324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet(input_size=(256,256,3)):\n    inputs = layers.Input(input_size)\n    \n    conv1 = layers.Conv2D(64, (3, 3), padding='same')(inputs)\n    bn1 = layers.Activation('relu')(conv1)\n    conv1 = layers.Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = layers.BatchNormalization(axis=3)(conv1)\n    bn1 = layers.Activation('relu')(bn1)\n    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = layers.Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = layers.Activation('relu')(conv2)\n    conv2 = layers.Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = layers.BatchNormalization(axis=3)(conv2)\n    bn2 = layers.Activation('relu')(bn2)\n    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = layers.Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = layers.Activation('relu')(conv3)\n    conv3 = layers.Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = layers.BatchNormalization(axis=3)(conv3)\n    bn3 = layers.Activation('relu')(bn3)\n    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = layers.Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = layers.Activation('relu')(conv4)\n    conv4 = layers.Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = layers.BatchNormalization(axis=3)(conv4)\n    bn4 = layers.Activation('relu')(bn4)\n    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = layers.Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = layers.Activation('relu')(conv5)\n    conv5 = layers.Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = layers.BatchNormalization(axis=3)(conv5)\n    bn5 = layers.Activation('relu')(bn5)\n\n    up6 = layers.concatenate([layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = layers.Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = layers.Activation('relu')(conv6)\n    conv6 = layers.Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = layers.BatchNormalization(axis=3)(conv6)\n    bn6 = layers.Activation('relu')(bn6)\n\n    up7 = layers.concatenate([layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = layers.Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = layers.Activation('relu')(conv7)\n    conv7 = layers.Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = layers.BatchNormalization(axis=3)(conv7)\n    bn7 = layers.Activation('relu')(bn7)\n\n    up8 = layers.concatenate([layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = layers.Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = layers.Activation('relu')(conv8)\n    conv8 = layers.Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = layers.BatchNormalization(axis=3)(conv8)\n    bn8 = layers.Activation('relu')(bn8)\n\n    up9 = layers.concatenate([layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = layers.Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = layers.Activation('relu')(conv9)\n    conv9 = layers.Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = layers.BatchNormalization(axis=3)(conv9)\n    bn9 = layers.Activation('relu')(bn9)\n\n    conv10 = layers.Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return models.Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:41:29.477981Z","iopub.execute_input":"2022-05-06T20:41:29.478355Z","iopub.status.idle":"2022-05-06T20:41:29.508881Z","shell.execute_reply.started":"2022-05-06T20:41:29.478318Z","shell.execute_reply":"2022-05-06T20:41:29.507478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smooth=1\ndef dice_coef(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    union = K.sum(y_true) + K.sum(y_pred)\n    return (2.0 * intersection + smooth) / (union + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:41:30.206274Z","iopub.execute_input":"2022-05-06T20:41:30.206565Z","iopub.status.idle":"2022-05-06T20:41:30.21434Z","shell.execute_reply.started":"2022-05-06T20:41:30.206537Z","shell.execute_reply":"2022-05-06T20:41:30.213432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = unet(input_size=(256, 256, 3))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:41:31.180693Z","iopub.execute_input":"2022-05-06T20:41:31.181188Z","iopub.status.idle":"2022-05-06T20:41:31.894298Z","shell.execute_reply.started":"2022-05-06T20:41:31.181133Z","shell.execute_reply":"2022-05-06T20:41:31.8933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:41:35.756147Z","iopub.execute_input":"2022-05-06T20:41:35.756471Z","iopub.status.idle":"2022-05-06T20:41:35.789167Z","shell.execute_reply.started":"2022-05-06T20:41:35.756437Z","shell.execute_reply":"2022-05-06T20:41:35.788077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss=bce_dice_loss,\n    metrics=[dice_coef,'accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T21:27:30.006749Z","iopub.execute_input":"2022-05-06T21:27:30.007502Z","iopub.status.idle":"2022-05-06T21:27:30.026711Z","shell.execute_reply.started":"2022-05-06T21:27:30.007453Z","shell.execute_reply":"2022-05-06T21:27:30.026044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_gen,\n    validation_data=valid_gen,\n    epochs=5,\n    validation_steps=len(val_data) /32,\n    steps_per_epoch=len(train_data) /32\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T20:41:38.27168Z","iopub.execute_input":"2022-05-06T20:41:38.272186Z","iopub.status.idle":"2022-05-06T20:42:44.704771Z","shell.execute_reply.started":"2022-05-06T20:41:38.27215Z","shell.execute_reply":"2022-05-06T20:42:44.703494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}