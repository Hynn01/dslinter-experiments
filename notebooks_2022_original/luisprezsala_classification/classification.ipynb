{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Repositorio","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Se puede consultar la metodología de desarrollo del proyecto y el histórico de imágenes en el siguiente repositorio:\n\n- https://github.com/luperezsal/DM-Classification-Tree","metadata":{}},{"cell_type":"markdown","source":"[Dataset](https://github.com/JeffSackmann/tennis_atp)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:13.834764Z","iopub.execute_input":"2022-05-08T13:50:13.835126Z","iopub.status.idle":"2022-05-08T13:50:13.861311Z","shell.execute_reply.started":"2022-05-08T13:50:13.835032Z","shell.execute_reply":"2022-05-08T13:50:13.860401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Directory and version specifications","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Se definiarán variables globales como los directorios desde donde se leen los datos, directorios donde se guardan los resultados y el timestamp para guardar los archivos generados de cada ejecución indiviudal.","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n\nMODEL_TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d__%H-%M-%S\")\n\nDATA_PATH = '../input/atp-matches/'\n\nCLASSIFICATION_REPORTS_PATH = 'classification_reports/'\nCONFUSION_MATRIX_PATH = 'confusion_matrix/'\nCLASSIFICATION_TREE_PATH = 'tree/classification/'\nAUC_ROC_PATH = 'auc-roc_curves/'\n\n# Resolución de imágenes\nresolution = 300\n\nrandom_state = 2","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:13.864376Z","iopub.execute_input":"2022-05-08T13:50:13.864688Z","iopub.status.idle":"2022-05-08T13:50:13.870519Z","shell.execute_reply.started":"2022-05-08T13:50:13.86462Z","shell.execute_reply":"2022-05-08T13:50:13.869535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download and Store Data","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Se crea un método para descargar todos los datos de partidos pertenecientes al siguiente repositorio de [Github JeffSackmann/tennis_atp](https://github.com/JeffSackmann/tennis_atp) y posterior guardado de los csv.","metadata":{}},{"cell_type":"code","source":"# for index in range(0,22):\n#     index_str = str(index)\n\n#     print(index_str)\n    \n#     if len(index_str) == 1:\n#         index_str = '0' + index_str\n\n#     print(index_str)\n\n#     url = \"https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_20{}.csv\".format(index_str)\n#     print(url)\n\n#     FILE_NAME = \"atp_matches_20{}.csv\".format(index_str)\n\n#     df = pd.read_csv(url, index_col=0, parse_dates=[0])\n#     df.to_csv(DATA_PATH + FILE_NAME)\n\n# # data_frame = pd.read_csv(DATA_PATH + FILE_NAME)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-08T13:50:13.902373Z","iopub.execute_input":"2022-05-08T13:50:13.903253Z","iopub.status.idle":"2022-05-08T13:50:13.907743Z","shell.execute_reply.started":"2022-05-08T13:50:13.903195Z","shell.execute_reply":"2022-05-08T13:50:13.907104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Métod para cargar todos los datos de los partidos (desde el año 2000 hasta el 2022) en un único csv `atp`.","metadata":{}},{"cell_type":"code","source":"atp = pd.DataFrame()\n\nyears_index_20_22 = range(0,22)\n\nfor index in years_index_20_22:\n    index_str = str(index)\n\n    if len(index_str) == 1:\n        index_str = '0' + index_str\n\n    FILE_NAME = \"atp_matches_20{}.csv\".format(index_str)\n\n    data_frame_iter = pd.read_csv(DATA_PATH + FILE_NAME)\n    atp = pd.concat([atp, data_frame_iter])\n\npd.set_option('display.max_columns', None)\ndf_classification = atp\natp","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-08T13:50:13.955298Z","iopub.execute_input":"2022-05-08T13:50:13.955562Z","iopub.status.idle":"2022-05-08T13:50:14.052167Z","shell.execute_reply.started":"2022-05-08T13:50:13.955534Z","shell.execute_reply":"2022-05-08T13:50:14.050597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El objetivo de la sección de clasificación es averiguar el tipo de pista en la que se ha jugado el partido en función de una serie de variables, esto puede cobrar sentido ya que dependiendo de la superficie de la pista la velocidad con la que rebota la pelota es distinta, y por lo tanto puede influir en las variables del juego.\n\nA continuación analizaremos los campos de importancia que se utilizarán en este proyecto de cara a los experimentos:\n\n\n- `surface`: tipo de superficie de la pista en la que se ha jugado el partido, exiten cuatro tipos de pista:\n    - **Clay**: Tierra batida.\n    - **Hard**: Pista dura.\n    - **Carpet**: Moqueta.\n    - **Grass**: Césped.\n- `minutes`: número de minutos transcurridos en el partido.\n- `winner_ht, loser_ht`: altura del jugador ganador y del perdedor respectivamente.\n- `w_ace, l_ace`: número de aces (saques directos) del ganador y del perdedor respectivamente.\n- `w_svpt, l_svpt`: número de saques (service points) del ganador y del perdedor respectivamente.\n- `w_1stWon, l_1stWon`: número de puntos ganados con primer saque (1st service) del ganador y del perdedor respectivamente.\n- `w_2ndWon, l_2ndWon`: número de puntos ganados con segundo saque (2nd service) del ganador y del perdedor respectivamente.\n- `w_bpSaved, l_bpSaved`: número puntos de rotura de servicio (break points) que ha neutralizado el ganador y el perdedor respectivamente.\n- `w_bpFaced, l_bpFaced`: número puntos de rotura de servicio (break points) que han surfido el ganador y el perdedor respectivamente.\n- `w_SvGms, l_SvGms`: número de juegos ganados con servicio propio del ganador y perdedor respectivamente.\n- `winner_rank_points, loser_rank_points`: número de puntos en el ranking de la ATP del ganador y el perdedor.\n- `round`: ronda en la que se ha jugado el partido dentro del torneo.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Clean Dataset","metadata":{}},{"cell_type":"markdown","source":"Comenzaremos con la limpieza del dataset, donde obtendremos los campos mencionados en el apartado anterior:","metadata":{}},{"cell_type":"code","source":"COLUMNS_TO_GET = [\n                  \"surface\",\n                  \"minutes\",\n                  \"winner_ht\", \"loser_ht\",\n                  \"w_ace\", \"l_ace\",\n                  \"w_svpt\", \"l_svpt\", # service points\n                  \"w_1stWon\", \"l_1stWon\",\n                  \"w_2ndWon\", \"l_2ndWon\",\n                  \"w_bpSaved\", \"l_bpSaved\",\n                  \"w_bpFaced\", \"l_bpFaced\",\n                  \"w_SvGms\", \"l_SvGms\", # service games won\n                  \"winner_rank_points\", \"loser_rank_points\",\n                  \"round\",\n                 ]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:14.053662Z","iopub.status.idle":"2022-05-08T13:50:14.054136Z","shell.execute_reply.started":"2022-05-08T13:50:14.053878Z","shell.execute_reply":"2022-05-08T13:50:14.053902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comenzaremos con la limpieza del dataset, donde obtendremos los campos mencionados en el apartado anterior:","metadata":{}},{"cell_type":"code","source":"COLUMNS_TO_GET = [\n                  \"surface\",\n                  \"minutes\",\n                  \"winner_ht\", \"loser_ht\",\n                  \"w_ace\", \"l_ace\",\n                  \"w_svpt\", \"l_svpt\", # service points\n                  \"w_1stWon\", \"l_1stWon\",\n                  \"w_2ndWon\", \"l_2ndWon\",\n                  \"w_bpSaved\", \"l_bpSaved\",\n                  \"w_bpFaced\", \"l_bpFaced\",\n                  \"w_SvGms\", \"l_SvGms\", # service games won\n                  \"winner_rank_points\", \"loser_rank_points\",\n                  \"round\",\n                 ]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:14.055784Z","iopub.status.idle":"2022-05-08T13:50:14.056238Z","shell.execute_reply.started":"2022-05-08T13:50:14.055988Z","shell.execute_reply":"2022-05-08T13:50:14.056022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Eliminaremos aquellas filas donde el toreno no sigue la estructura habitual de la mayoría de competiciones, como son los torneos Round Robin (RR,ER,BR).","metadata":{}},{"cell_type":"code","source":"df_classification = df_classification.loc[:, df_classification.columns.isin(COLUMNS_TO_GET)]\n\ndf_classification = df_classification[df_classification['round'] != 'RR']\ndf_classification = df_classification[df_classification['round'] != 'ER']\ndf_classification = df_classification[df_classification['round'] != 'BR']\n\ndf_classification = df_classification.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:14.057374Z","iopub.status.idle":"2022-05-08T13:50:14.057846Z","shell.execute_reply.started":"2022-05-08T13:50:14.057575Z","shell.execute_reply":"2022-05-08T13:50:14.0576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación trataremos el campo `round` y lo transformaermos a numérico para que el árbol de decisión pueda tomar elecciones en función de la ronda del torneo a la que pertenece cada partido.","metadata":{}},{"cell_type":"code","source":"round_replace = {'R128': 128,\n                  'R64': 64,\n                  'R32': 32,\n                  'R16': 16,\n                  'QF': 4,\n                  'SF': 2,\n                  'F': 1\n}\n\n# Eliminamos las Round Robin (RR y ER)\ndf_classification['round'].replace(round_replace, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:14.068054Z","iopub.execute_input":"2022-05-08T13:50:14.068288Z","iopub.status.idle":"2022-05-08T13:50:14.084705Z","shell.execute_reply.started":"2022-05-08T13:50:14.068261Z","shell.execute_reply":"2022-05-08T13:50:14.082817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Data","metadata":{}},{"cell_type":"markdown","source":"Dividiremos los datos del dataframe en conjunto de entrenamiento y conjunto de test.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_classification_train, df_classification_test = train_test_split(df_classification, test_size = 0.3, random_state = random_state)\n\ny_train = df_classification_train[\"surface\"]\nX_train = df_classification_train.drop(columns = [\"surface\"])\n\ny_test = df_classification_test[\"surface\"]\nX_test = df_classification_test.drop(columns = [\"surface\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:14.135539Z","iopub.execute_input":"2022-05-08T13:50:14.136142Z","iopub.status.idle":"2022-05-08T13:50:15.337778Z","shell.execute_reply.started":"2022-05-08T13:50:14.136104Z","shell.execute_reply":"2022-05-08T13:50:15.335459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sesgos","metadata":{}},{"cell_type":"markdown","source":"En el dataset podemos observar que existe un sesgo en función del tipo de pista. Gran parte de los partidos se juegan en pista dura, que es menos costosa de mantener que las pistas de hierba y de moqueta. Este desbalanceo de datos podría afectar notablemente a las predicciones del modelo ya que aprendería más de aquellas muestras más numerosas en el conjunto de datos que del resto de ellas. Por lo tanto tendría una tendencia a predecir la superficie de la pista como dura, reduciendo la efectividad de las clases menos numerosas en el dataset.","metadata":{}},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.338525Z","iopub.status.idle":"2022-05-08T13:50:15.338825Z","shell.execute_reply.started":"2022-05-08T13:50:15.33867Z","shell.execute_reply":"2022-05-08T13:50:15.338685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Debido a este problema, aplicaremos distintas técnicas de Resampling sobre el conjunto de entrenamiento. Estas técnicas permiten operar sobre el conjunto de datos para balancearlo, con el objetivo de que el modelo no se vea muy afectado debido a la diferencia de las clases mayoritarias respecto a las minoritarias.\n\nAplicaremos distintas metodologías de Resampling:\n- **Undersampling**\n- **Upsampling**\n- **Generación de datos sintéticos**\n- **Generación de datos sintéticos aplicando Undersampling**\n\n[Metodologías de Resampling](https://towardsdatascience.com/5-techniques-to-work-with-imbalanced-data-in-machine-learning-80836d45d30c)","metadata":{}},{"cell_type":"markdown","source":"## Undersampling Data","metadata":{}},{"cell_type":"markdown","source":"El objetivo es eliminar muestras del conjunto de datos para crear un dataset con el mismo número de muestras de cada clase, esto lo conseguimos especificando la estrategia de `not minority` en nuestro [RandomUnderSampler](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html).","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler(sampling_strategy = 'not minority',\n                         random_state = random_state)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.341433Z","iopub.status.idle":"2022-05-08T13:50:15.341767Z","shell.execute_reply.started":"2022-05-08T13:50:15.341597Z","shell.execute_reply":"2022-05-08T13:50:15.341614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Una vez realizado el downsampling podemos comprobar que el número de muestras de cada clase es la misma, por lo tanto podemos comenzar a entrenar los modelos evitando el problema de desbalanceo.","metadata":{}},{"cell_type":"code","source":"X_testing_undersampler, y_testing_undersampler = rus.fit_resample(X_train, y_train)\ny_testing_undersampler.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.343017Z","iopub.status.idle":"2022-05-08T13:50:15.343478Z","shell.execute_reply.started":"2022-05-08T13:50:15.343311Z","shell.execute_reply":"2022-05-08T13:50:15.34333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Upsampling Data","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Al contrario que en el caso anterior, con el método\n[RandomOverSampler](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html)\nconstruimos un nuevo dataset que estará formado por el muestreo de instancias de las clases que no sean la mayoritaria, de tal forma que resultará en un nuevo dataset con un número igual de muestras para cada clase, igualando a la mayoritaria. Esto se realiza mediante la estrategia `not majority`.\n\n","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler(sampling_strategy = 'not majority',\n                        random_state = random_state)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.344325Z","iopub.status.idle":"2022-05-08T13:50:15.344666Z","shell.execute_reply.started":"2022-05-08T13:50:15.344472Z","shell.execute_reply":"2022-05-08T13:50:15.344494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hacemos un test del método y podemos comprobar que existen el mismo número de muestras para cada una de las clases, igualando el número de muestras mayoritario que existían en el dataset de entrenamiento original.","metadata":{}},{"cell_type":"code","source":"X_testing_uppersampler, y_testing_uppersampler = ros.fit_resample(X_train, y_train)\ny_testing_uppersampler.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.345936Z","iopub.status.idle":"2022-05-08T13:50:15.346485Z","shell.execute_reply.started":"2022-05-08T13:50:15.346282Z","shell.execute_reply":"2022-05-08T13:50:15.346304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Syntethic Data (Borderline SMOTE-2)","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Otro de los enfoques es la genereación de datos sintéticos de las clases minoritarias, difiere del upsampling en que se aplican variaciones a las muestras duplicadas de las clases minoritarias. Para lograr este comportamiento aplicaremos la técnica [Borderline SMOTE-2](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) de la librería Imbalanced Learn, configurando el tipo SMOTE a `borderline-2`.","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import BorderlineSMOTE\n\nsmote2 = BorderlineSMOTE(kind = 'borderline-2',\n                         random_state = random_state)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.34771Z","iopub.status.idle":"2022-05-08T13:50:15.348226Z","shell.execute_reply.started":"2022-05-08T13:50:15.348022Z","shell.execute_reply":"2022-05-08T13:50:15.348047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hacemos un testing para comprobar que los datos sintéticos generados igualan el número de clases de las muestras mayoritarias.","metadata":{}},{"cell_type":"code","source":"X_testing_smote2, y_testing_smote2 = smote2.fit_resample(X_train, y_train)\ny_testing_smote2.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.349541Z","iopub.status.idle":"2022-05-08T13:50:15.349929Z","shell.execute_reply.started":"2022-05-08T13:50:15.349756Z","shell.execute_reply":"2022-05-08T13:50:15.349779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Syntethic Data - Undersampling (SMOTEENN)","metadata":{}},{"cell_type":"markdown","source":"El método\n[SMOTEEN](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html)\ncombina dos técnicas vistas anterioremente, la generación de datos sintéticos mediante SMOTE y aplicando técnicas de undersampling. En este caso probaremos a generar datos sintéticos de las clases minoritarias para invertir el número de muestras de cada clase, es decir, igualaremos la clase minoritaria, generando datos sintéticos, a la clase mayoritaria y ésta será reducida a un número de muestras aproximado a la clase minoritaria original. Esto se hace para cada clase que esté presente en el dataset.","metadata":{}},{"cell_type":"code","source":"from imblearn.combine import SMOTEENN \n\nsmoteenn = SMOTEENN(random_state = random_state)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.351345Z","iopub.status.idle":"2022-05-08T13:50:15.35186Z","shell.execute_reply.started":"2022-05-08T13:50:15.351662Z","shell.execute_reply":"2022-05-08T13:50:15.351688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testamos los datos que se han generado y comprobamos que el número de las distintas clases se ha invertido respecto al dataset de entrenamiento original.","metadata":{}},{"cell_type":"code","source":"X_testing_smoteenn, y_testing_smoteenn = smoteenn.fit_resample(X_train, y_train)\ny_testing_smoteenn.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.353274Z","iopub.status.idle":"2022-05-08T13:50:15.35362Z","shell.execute_reply.started":"2022-05-08T13:50:15.353441Z","shell.execute_reply":"2022-05-08T13:50:15.353463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree with CV","metadata":{}},{"cell_type":"markdown","source":"A continuación definiremos un método para encontrar la profundidad óptima del árbol de decisión (con rangos de profundidad desde 2 hasta 15) en función de las distintas técnicas de resampling definidas anteriormente aplicando la técnica cross-validation.\n\nPara ello, en cada iteración de cross-validation, aplicaremos cada uno de los métodos de Resampling distintos sobre la división realizada en el conjunto de entrenamiento original.\n\nSeguiremos los siguientes pasos:\n\n1. Para cada profundidad del rango de profundidades (2-15) realizaremos un cross-validation sobre el conjunto de entrenamiento original.\n2. Cross-validation divide el conjunto de entrenamiento en un **subconjunto de entrenamiento** y un **subconjunto de validación** para cada una de las iteraciones (definidas a 5).\n3. Para cada una de los splits del cross-validation se aplica cada uno de los métodos de Resampling sobre el **subconjunto de entrenamiento** de dicho split.\n4. Se entrena un Árbol de Decisión de Clasificación con los datos provenientes del Resampling correspondiente, definiendo la profundidad del árbol actual de la iteración.\n5. Posteriormente se valida sobre el **subconjunto de validación** que ha generado el cross-validation en el split actual.\n6. Se almacenan los mejores modelos hasta el momento de cada una de las técnicas de Resampling.\n\nAdemás, se almacena en un diccionario información útil que utilizaremos para analizar la evolución de cada árbol en apartados posteriores.\n\n[Cross-Validation Upsampling Data](https://kiwidamien.github.io/how-to-do-cross-validation-when-upsampling-data.html)","metadata":{}},{"cell_type":"markdown","source":"## Resampling function","metadata":{}},{"cell_type":"code","source":"def do_resampling(resampling_method, X_data, y_data):\n\n    if (resampling_method == 'None'):\n        return X_data, y_data\n\n    if (resampling_method == 'RandomUnderSampler'):\n        return rus.fit_resample(X_data, y_data)\n\n    if (resampling_method == 'RandomOverSampler'):\n        return ros.fit_resample(X_data, y_data)\n\n    if (resampling_method == 'SMOTE2'):\n        return smote2.fit_resample(X_data, y_data)\n\n    if (resampling_method == 'SMOTEENN'):\n        return smoteenn.fit_resample(X_data, y_data)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.354745Z","iopub.status.idle":"2022-05-08T13:50:15.355064Z","shell.execute_reply.started":"2022-05-08T13:50:15.354897Z","shell.execute_reply":"2022-05-08T13:50:15.354919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dictionary definition","metadata":{}},{"cell_type":"code","source":"resampling_methods = {'None': {},\n                      'RandomUnderSampler': {},\n                      'RandomOverSampler': {},\n                      'SMOTE2': {},\n                      'SMOTEENN': {}\n                     }\n\nfor resampling_method_name in resampling_methods:\n    resampling_method = resampling_methods[resampling_method_name]\n\n    resampling_method['accuracies_history'] = []\n    resampling_method['best_mean_accuracy'] = 0\n    resampling_method['best_depth'] = 0\n    resampling_method['model'] = ''\n    resampling_method['best_model'] = ''","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.356752Z","iopub.status.idle":"2022-05-08T13:50:15.357257Z","shell.execute_reply.started":"2022-05-08T13:50:15.357053Z","shell.execute_reply":"2022-05-08T13:50:15.357078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Models","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold \nfrom sklearn import tree\nimport time\n\nsplits = 5\n\ncv = KFold(n_splits = splits,\n           random_state = random_state,\n           shuffle = True)\n\ndepths = range (2,15)\n\nstart = time.time()\n\nfor index,depth in enumerate(depths):\n\n    print(f\"Depth: {depth}\")\n\n    model = DecisionTreeClassifier(max_depth = depth, random_state = random_state)\n\n    for resampling_method_name in resampling_methods:\n        resampling_method = resampling_methods[resampling_method_name]\n\n        resampling_method['accuracies_history'].insert(index, 0)\n\n\n    for train_fold_index, val_fold_index in cv.split(X_train, y_train):\n        \n        X_train_fold, y_train_fold = X_train.iloc[train_fold_index], y_train.iloc[train_fold_index]\n\n        X_val_fold, y_val_fold = X_train.iloc[val_fold_index], y_train.iloc[val_fold_index]\n\n        for resampling_method_name in resampling_methods:\n            resampling_method = resampling_methods[resampling_method_name]\n\n            X_train_fold_sampled, y_train_fold_sampled = do_resampling(resampling_method = resampling_method_name,\n                                                                       X_data = X_train_fold,\n                                                                       y_data = y_train_fold)\n\n            model.fit(X_train_fold_sampled, y_train_fold_sampled)\n\n            current_accuracy   = model.score(X_val_fold, y_val_fold)\n            accuracies_history = resampling_method['accuracies_history'][index]\n\n            resampling_method['accuracies_history'][index] = accuracies_history + current_accuracy\n            resampling_method['model'] = model\n\n\n    for resampling_method_name in resampling_methods:\n        resampling_method = resampling_methods[resampling_method_name]\n        \n        current_method_mean_accuracy = resampling_method['accuracies_history'][index] / splits\n\n        resampling_method['accuracies_history'][index] = current_method_mean_accuracy\n\n        print(f\"Resampling: {resampling_method_name}, mean accuracy: {current_method_mean_accuracy}\")\n\n        best_mean_accuracy = resampling_method['best_mean_accuracy']\n\n        if (current_method_mean_accuracy > best_mean_accuracy):\n            model_params = resampling_method['model']\n            resampling_method['best_model'] = model_params\n            resampling_method['best_mean_accuracy'] = current_method_mean_accuracy\n            resampling_method['best_depth'] = depth\n\n        best_method_depth  = resampling_method['best_depth']\n        best_mean_accuracy = resampling_method['best_mean_accuracy']\n\n        print(f\"Best mean score for {resampling_method_name} is: {best_mean_accuracy}, best depth: {best_method_depth}\")\n\n    print('\\n')\n\n    \nend = time.time()\n\nellapsed_time = round(end - start, 2)\n\nprint(f\"Done in {ellapsed_time} (s)\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.358583Z","iopub.status.idle":"2022-05-08T13:50:15.358929Z","shell.execute_reply.started":"2022-05-08T13:50:15.358761Z","shell.execute_reply":"2022-05-08T13:50:15.358785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving Models","metadata":{}},{"cell_type":"markdown","source":"A continuación guardaremos los mejores modelos generados en base a cada una de las técnicas de resampling aplicadas y almacenaremos el que mejor accuracy ha logrado en la variable `best_method`.","metadata":{}},{"cell_type":"code","source":"from joblib import dump, load\n\nbest_model = DecisionTreeClassifier()\n\nbest_method = {}\nbest_method['Init'] = {}\nbest_method['Init']['best_mean_accuracy'] = 0\n\nfor resampling_method_name in resampling_methods:\n    resampling_method = resampling_methods[resampling_method_name]\n    \n    model_name = resampling_method_name\n    best_mean_accuracy = resampling_method['best_mean_accuracy']\n    best_method_depth  = resampling_method['best_depth']\n\n    model = resampling_method['best_model']\n    \n    file_name = f\"{CLASSIFICATION_TREE_PATH}{model_name}_{best_mean_accuracy}_{best_method_depth}_{MODEL_TIMESTAMP}.joblib\"\n#     dump(model, file_name)\n\n    if resampling_method['best_mean_accuracy'] > list(best_method.values())[0]['best_mean_accuracy']:\n        best_method = {}\n        best_method[resampling_method_name] = resampling_method\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.360027Z","iopub.status.idle":"2022-05-08T13:50:15.360388Z","shell.execute_reply.started":"2022-05-08T13:50:15.360194Z","shell.execute_reply":"2022-05-08T13:50:15.36022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring Models","metadata":{"toc-hr-collapsed":true}},{"cell_type":"markdown","source":"### Accuracies and Depths","metadata":{}},{"cell_type":"markdown","source":"En este apartado se analizarán los accuracies logrados de los mejores modelos de cada método de Resampling.","metadata":{}},{"cell_type":"code","source":"FEATURES = ['resampling_method',  'best_mean_accuracy', 'best_depth']\nsummary_dataframe = pd.DataFrame(columns = FEATURES)\n\nfor resampling_method in resampling_methods:\n    fields = []\n    fields.append(resampling_method)\n\n    row = resampling_methods[resampling_method]\n    for feature in row:\n        if (feature in FEATURES):\n            fields.append(row[feature])\n\n    row_series = pd.Series(fields, index = FEATURES)\n    summary_dataframe = summary_dataframe.append(row_series, ignore_index = True)\n\nSAVE_PATH =  f\"{CLASSIFICATION_TREE_PATH}{MODEL_TIMESTAMP}.csv\"\n# summary_dataframe.to_csv(SAVE_PATH, index = True)\n\nsummary_dataframe.style.highlight_max(subset = ['best_mean_accuracy'], color = 'green')\\\n                       .highlight_min(subset = ['best_mean_accuracy'], color = 'red')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-08T13:50:15.361544Z","iopub.status.idle":"2022-05-08T13:50:15.361888Z","shell.execute_reply.started":"2022-05-08T13:50:15.361706Z","shell.execute_reply":"2022-05-08T13:50:15.361733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Si observamos la tabla anterior podemos comprobar que, al contrario de cómo se había planteado el problema inicialmente, el Árbol de Decisión que mejor accuracy medio logra es aquel que no utiliza ninguna técnica de Resampling, seguido del árbol entrenado con los datos sintéticos generados de SMOTE-2.\n\nEl mejor entrenamiento de modelo para este problema, DecissionTree con profundidad X entrenado con datos sin aplicar Resampling, ha sido almacenado en la variable `best_model`.","metadata":{}},{"cell_type":"markdown","source":"### Plots","metadata":{}},{"cell_type":"markdown","source":"A continuación analizaremos la evolución del accuracy medio para los métodos de Resampling en función de la profundidad máxima.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\n\nfor resampling_method_name in resampling_methods:\n    resampling_method = resampling_methods[resampling_method_name]\n\n    mean_scores = resampling_method['accuracies_history']\n\n    plt.plot(depths, mean_scores[:len(depths)], linewidth = 1.1, label = resampling_method_name)\n\nplt.title(f\"Mean Accuracy resampling training data for {splits} splits over validation set\")\nplt.xlabel('Depth')\nplt.ylabel('Mean Accuracy')\n\nplt.legend(loc = 'best',\n           fancybox = True,\n           shadow = True)\n\nFILE_NAME  = f\"{CLASSIFICATION_TREE_PATH}{MODEL_TIMESTAMP}.png\"\n\nplt.grid(True)\n# plt.savefig(FILE_NAME, dpi = resolution)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.363172Z","iopub.status.idle":"2022-05-08T13:50:15.363814Z","shell.execute_reply.started":"2022-05-08T13:50:15.363594Z","shell.execute_reply":"2022-05-08T13:50:15.363621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos cómo el árbol de decisión entrenado sin aplicar técnicas de resampling a medida que avanzamos en su profundidad, el accudacy empieza a descender. Esto es común en los árboles de decisión con mcuha profundidad, ya que comienza a apreciarse el overfitting a medida que el número de niveles aumenta.\n\nEsto no se produce con los métodos de Resampling ya que los árboles se entrenan con datos muy distintos en cada iteración, sin embargo, no logran superar el accuracy de `0.5958` que consigue el Árbol de Decisión entrenado sin Resampling con 6 niveles.","metadata":{}},{"cell_type":"markdown","source":"## Train Best Tree - Best Reampling","metadata":{}},{"cell_type":"code","source":"best_method_name = list(best_method.keys())[0]\nX_train_sampled, y_train_sampled = do_resampling(best_method_name,\n                                                 X_train,\n                                                 y_train)\n\nbest_model = best_method[best_method_name]['best_model'].fit(X_train_sampled, y_train_sampled)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.364879Z","iopub.status.idle":"2022-05-08T13:50:15.3652Z","shell.execute_reply.started":"2022-05-08T13:50:15.365032Z","shell.execute_reply":"2022-05-08T13:50:15.365055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gracias al `random_seed` especificado en el `cross-validation` podemos fijar que el resultado del experimento mantenga que el mejor árbol tenga como profundidad 6 niveles. Esto nos permite mantener los resultados en distintas ejecuciones y poder detallarlos.\n\nPodemos observar que el error medio para el árbol de profundidad 6 es del orden de 0.42 aproximadamente (accuracy), es decir, que del 100% total de muestras en el dataset ha clasificado correctamente un 42% aproximadamente entre todas las clases del modelo.\n\nEn posteriores apartados analizaremos el resto de métricas, como el `recall` o el `f1-score`, que nos darán mayor información de cómo se está comportando el modelo.","metadata":{}},{"cell_type":"markdown","source":"## Tree Plot","metadata":{"tags":[]}},{"cell_type":"markdown","source":"A continuación mostraremos el desglose del árbol de decisión entrenado, como hemos visto en la sección anterior, el árbol con mejor precisión (`score`) es aquel que contiene **X** niveles de profundidad.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\ntree_plot = tree.plot_tree(best_model, fontsize = 8, feature_names = X_test.columns)\n\nFILE_NAME = f\"best_depth_{best_model.get_depth()}_tree_{MODEL_TIMESTAMP}\"\n\n# plt.savefig(CLASSIFICATION_TREE_PATH + FILE_NAME, dpi = resolution)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-08T13:50:15.366838Z","iopub.status.idle":"2022-05-08T13:50:15.367155Z","shell.execute_reply.started":"2022-05-08T13:50:15.366983Z","shell.execute_reply":"2022-05-08T13:50:15.367005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El primer nodo padre del árbol divide los resultados en función del número de puntos ganados con saque directo del jugador que acabó ganando el partido, es decir, es el campo que mejor divide las observaciones en función del tipo de pista. Esto cobra sentido ya que los saques rebotan con más velocidad en pistas más rápidas (pista dura y hierba), por lo que son más difíciles de restar, y más fáciles de responder en pistas más lentas (tierra batida).\n\nEn los siguientes niveles se aprecia que existen otras variables influyentes como el número de puntos ganados con el primer servicio (cobra más ventaja en el partido el jugador que saque, ya que la velocidad de la bola es distinta dependiendo de la superficie).\n\nLa métrica Gini muestra la probabilidad que tienen las muestras que llegan a ese nodo de ser clasificadas incorrectamente cuando se les asigna una clase aleatoria.\n\nEl número de muestras que llegan al primer nodo es el total de todos los ejemplos en el dataset.\n\nEste proceso se repite para cada uno de los nodos del árbol de decisión hasta llegar al último nivel, que es el que dictará a qué clase pertenece la muestra que haya recorrido el camino del árbol hasta llegar a la hoja correspondiente.\n","metadata":{}},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"markdown","source":"En esta sección analizaremos los resultados de la clasificación del árbol de clasificación obtenido en el apartado anterior, obteniendo la matriz de confusión de los resultados sobre el conjunto de test.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n\nFILE_NAME = f\"best_depth_{best_model.get_depth()}_cm_{MODEL_TIMESTAMP}.png\"\n\nconfusion_matrix = ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)\n# confusion_matrix.figure_.savefig(CONFUSION_MATRIX_PATH + FILE_NAME, dpi = resolution)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.368299Z","iopub.status.idle":"2022-05-08T13:50:15.368873Z","shell.execute_reply.started":"2022-05-08T13:50:15.368666Z","shell.execute_reply":"2022-05-08T13:50:15.368692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos los resultados de la clasificación del conjunto de test, en el eje de ordenadas se proyectan las clases verdaderas a las que pertenecen las muestras, mientras que en el eje de abcisas se muestra la clasificación del árbol de decisión entrenado.","metadata":{}},{"cell_type":"markdown","source":"## Classification Report","metadata":{"tags":[]}},{"cell_type":"markdown","source":"En esta sección se mostrarán las métricas correspondientes a la clasificación de los datos del conjunto de test por parte del árbol de decisión.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nFILE_NAME = f\"best_depth_{best_model.get_depth()}_cr_{MODEL_TIMESTAMP}.csv\"\n\n\ny_pred = best_model.predict(X_test)\nreport = classification_report(y_test, y_pred, output_dict = True)\n\nreport_df = pd.DataFrame(report).transpose()\n# report_df.to_csv(CLASSIFICATION_REPORTS_PATH + FILE_NAME, index= True)\n\ndisplay(report_df.style.highlight_max(subset = ['precision', 'recall'], color='green')\\\n                       .highlight_min(subset = ['precision', 'recall'], color='red'))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.370273Z","iopub.status.idle":"2022-05-08T13:50:15.370602Z","shell.execute_reply.started":"2022-05-08T13:50:15.370426Z","shell.execute_reply":"2022-05-08T13:50:15.370449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La `precision` representa el porcentaje real de acierto en la clasificación de muestras como verdaderas para cada una de las clases, mientras que el `recall` indica el porcentaje total identificado de las muestras de cada clase.\n\nObservamos que el número de partidos clasificados como moqueta es 0, seguramente provocado por el desbalanceo del dataset y el pequeño número de muestras que existen de esta clase.\n\nComo el Árbol de decisión trata de minimizar la pérdida media de las clasificaciones, al tener un número ínfimo de clases clasificadas como `Carpet` el hecho de clasificar erróneamente esta clase no afecta apenas a la media de errores, por lo tanto, maximiza la correcta clasificación de muestras mayoriatias.\n\nPodemos concluir que con los datos disponibles, entrenando este clasificador no se han conseguido unos resultados muy prometedores respecto a los objetivos iniciales del proyecto.\n","metadata":{}},{"cell_type":"markdown","source":"## AUC-ROC Curve","metadata":{}},{"cell_type":"markdown","source":"En esta sección mostraremos la curva AUC-ROC de las clases clasificadas por el mejor modelo entrenado.\n\nUna curva AUC-ROC representa una medida de rendimiento para problemas de clasificación, mide la separabilidad de las clases en función de las siguientes medidas:\n- True positive Rate (TPR)\n- False positive Rate (FPR)\n\n[Understanding auc roc curve](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)","metadata":{}},{"cell_type":"markdown","source":"### OneHotEncoding","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Para ello el primer paso será transformar las variables respuesta a formato one-hot encoding, que es la forma de representar vectorialmente las características de forma única. Esto nos ayudará para poder medir las discrepancias entre la probabilidad calculada por el modeo de que una muestra pertenezca a una clase y el valor real de dicha muestra.\n\n[How to one-hot encode](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(y_test)\n\nonehot_encoder = OneHotEncoder(sparse = False)\n\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoded  = onehot_encoder.fit_transform(integer_encoded)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.37192Z","iopub.status.idle":"2022-05-08T13:50:15.37223Z","shell.execute_reply.started":"2022-05-08T13:50:15.372065Z","shell.execute_reply":"2022-05-08T13:50:15.372087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot AUC-ROC Curve","metadata":{}},{"cell_type":"markdown","source":"A continuación crearemos la curva AUC-ROC para cada una de las clases identificadas por el modelo, siguiendo la siguiente referencia:  [ROC for multi-label classification](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\nimport numpy as np\nfrom itertools import cycle\n\ny_pred_proba = best_model.predict_proba(X_test)\nclasses = best_model.classes_\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i, current_class in enumerate(classes):\n\n    fpr[i], tpr[i], _ = roc_curve(onehot_encoded[:,i], y_pred_proba[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(onehot_encoded.ravel(), y_pred_proba.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i, current_class in enumerate(classes):\n    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= len(classes)\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure(figsize=(25,12))\n\nplt.plot(\n    fpr[\"micro\"],\n    tpr[\"micro\"],\n    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n    color=\"deeppink\",\n    linestyle=\":\",\n    linewidth=4,\n)\n\nplt.plot(\n    fpr[\"macro\"],\n    tpr[\"macro\"],\n    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n    color=\"navy\",\n    linestyle=\":\",\n    linewidth=4,\n)\n\nfor i in range(len(classes)):\n    plt.plot(\n        fpr[i],\n        tpr[i],\n        label = \"ROC curve of class {0} (area = {1:0.2f})\".format(best_model.classes_[i], roc_auc[i])\n    )\n\n\nplt.plot([0, 1], [0, 1], \"k--\", lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC curves for classification\")\nplt.legend(loc=\"lower right\")\nplt.show()\n\nFILE_NAME = f\"DT_{best_model.get_depth()}_{MODEL_TIMESTAMP}.png\"\n\n# plt.savefig(AUC_ROC_PATH + FILE_NAME, dpi = resolution)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.373809Z","iopub.status.idle":"2022-05-08T13:50:15.374125Z","shell.execute_reply.started":"2022-05-08T13:50:15.373957Z","shell.execute_reply":"2022-05-08T13:50:15.373978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos observar cómo a medida que incrementamos el ratio de verdaderos positivos va aumentando el de falsos positivos.\n\nEste es un comportamiento natural, ya que, si queremos una probabilidad cercana a uno para clasificar una clase, existe el riesgo de clasificar el resto de clases erróneamente debido a que la clase objetivo es única, aumentando así el ratio de falsos positivos.\n\nIdealmente, en datos completamente separables y bien clasificados, al curva AUC debería adoptar un comportamiento muy cercano a cero en la tasa de falsos positivos cuando del valor en verdaderos positivos es cercano a 1.","metadata":{}},{"cell_type":"markdown","source":"# Decision Tree with GridSearch","metadata":{}},{"cell_type":"markdown","source":"En esta sección se buscarán los mejores parámetros mediante el método `GridSearch`, que tratará modificar los hiperparametros del árbol de clasificación con el objetivo de mejorar la precisión de los resultados.\n\nDebido a limitación de recursos, se ha acotado el espacio de búsqueda de hiperparámetros.\n\nPara la construcción del método `GridSearch` se utilizará un Pipeline que se compondrá de:\n- `PCA`: Análisis de componentes principales que obtendrá los parámetros correspondientes con respecto a la iteración de `GridSearch`\n- `DecisionTreeClassifier`: Árbol que se entrenará con los parámetros correspondientes a la iteración de `GridSearch`","metadata":{}},{"cell_type":"code","source":"from sklearn import decomposition, datasets\nfrom sklearn import tree\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\nX = atp\ny = labels\n\npca = decomposition.PCA()\ndec_tree = tree.DecisionTreeClassifier(random_state = 2)\n\npipe = Pipeline(steps=[('pca', pca),\n                       ('dec_tree', dec_tree)])\n\nn_components = list(range(1, X.shape[1]+1, 1))\n\ncriterion = ['gini', 'entropy']\n\ndepths = list(range(3,12))\nmin_impurity_decrease = [x/10000 for x in range(1, 900, 100)]\nmin_samples_split = list(range(15, 35, 3))\n\n\nparameters = dict(pca__n_components = n_components,\n                  dec_tree__criterion = criterion,\n                  dec_tree__max_depth = depths,\n                  dec_tree__min_impurity_decrease = min_impurity_decrease,\n                  dec_tree__min_samples_split = min_samples_split)\n\nclf_GS = GridSearchCV(pipe, parameters)\nclf_GS.fit(X, y)\n\nbest_criterion = clf_GS.best_estimator_.get_params()['dec_tree__criterion']\nbest_max_depth = clf_GS.best_estimator_.get_params()['dec_tree__max_depth'] \nbest_max_min_impurity_decrease = clf_GS.best_estimator_.get_params()['dec_tree__min_impurity_decrease'] \nbest_min_samples_split = clf_GS.best_estimator_.get_params()['dec_tree__min_samples_split'] \n\nprint('Best Criterion:', best_criterion)\nprint('Best Max Depth:', best_max_depth)\nprint('Best Max Min impurity decrease:', best_max_min_impurity_decrease)\nprint('Best Min Samples Split:', best_min_samples_split)\nprint('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\nprint(clf_GS.best_estimator_.get_params()['dec_tree'])","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.37555Z","iopub.status.idle":"2022-05-08T13:50:15.376075Z","shell.execute_reply.started":"2022-05-08T13:50:15.375877Z","shell.execute_reply":"2022-05-08T13:50:15.3759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos que los parámetros que mejor se ajustan al modelo con nuestro conjunto de datos son `criterion='entropy', max_depth=7`.\n\nUna vez hemos obtenido los parámetros que mejor minimizan el error de clasificación del árbol, entrenaremos el árbol con dichos parámetros mediante el método de validación cruzada.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold \nfrom sklearn import tree\n\nsplits = 10\n\ncv = KFold(n_splits = splits, shuffle = True)\n\nbest_accuracy = 0\n\nmean_score = 0.0\nfor train_index, test_index in cv.split(atp):\n\n    x_train, y_train = atp.iloc[train_index], labels.iloc[train_index]\n    x_test, y_test   = atp.iloc[test_index],  labels.iloc[test_index]\n\n    model = DecisionTreeClassifier(criterion = best_criterion,\n                                   max_depth = best_max_depth,\n                                   random_state = 2)\n    model.fit(x_train, y_train)\n\n    accuracy = model.score(X_test,y_test)\n\n    mean_score = mean_score + accuracy\n\n\nmean_score = mean_score/splits\n\nprint(\"Mean: \", mean_score)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.377687Z","iopub.status.idle":"2022-05-08T13:50:15.378003Z","shell.execute_reply.started":"2022-05-08T13:50:15.377834Z","shell.execute_reply":"2022-05-08T13:50:15.377857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tree plot","metadata":{}},{"cell_type":"markdown","source":"Mostraremos el árbol entrenado resultante con los parámetros escogidos por el método `GridSearch`.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\n\ntree_plot = tree.plot_tree(best_model, fontsize = 8, feature_names = atp.columns)\n\nFILE_NAME = f\"gs_{best_criterion}_{best_max_depth}_tree_{MODEL_TIMESTAMP}\"\n\n# plt.savefig(CLASSIFICATION_TREE_PATH + FILE_NAME, dpi = resolution)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-08T13:50:15.378999Z","iopub.status.idle":"2022-05-08T13:50:15.379274Z","shell.execute_reply.started":"2022-05-08T13:50:15.379126Z","shell.execute_reply":"2022-05-08T13:50:15.379141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos que los primeros niveles son ","metadata":{}},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"markdown","source":"En esta sección analizaremos los resultados y las métricas obtenidas por el método `GridSearch`","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n\n# Save Confusion Matrix image\nFILE_NAME = f\"gs_{best_criterion}_{best_max_depth}_cm_{MODEL_TIMESTAMP}\"\n\nconfusion_matrix = ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)\n# confusion_matrix.figure_.savefig(CONFUSION_MATRIX_PATH + FILE_NAME, dpi = resolution)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.380688Z","iopub.status.idle":"2022-05-08T13:50:15.380996Z","shell.execute_reply.started":"2022-05-08T13:50:15.380828Z","shell.execute_reply":"2022-05-08T13:50:15.380845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como en el caso de la matriz de confusión anterior, en el eje de las `x` tenemos los valores predecidos y en el eje de las `y` los valores verdaderos. Observamos que los resultados son ligeramente XX","metadata":{}},{"cell_type":"markdown","source":"## Classification Report","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Save Classification Report csv\nFILE_NAME = f\"gs_{best_criterion}_{best_max_depth}_cr_{MODEL_TIMESTAMP}.csv\"\n\ny_pred = model.predict(X_test)\nreport = classification_report(y_test, y_pred, output_dict = True)\n\nreport_df = pd.DataFrame(report).transpose()\n# report_df.to_csv(CLASSIFICATION_REPORTS_PATH + FILE_NAME, index= True)\n\ndisplay(report_df.style.highlight_max(subset = ['precision', 'recall'], color='green')\\\n                       .highlight_min(subset = ['precision', 'recall'], color='red'))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.381882Z","iopub.status.idle":"2022-05-08T13:50:15.382163Z","shell.execute_reply.started":"2022-05-08T13:50:15.382012Z","shell.execute_reply":"2022-05-08T13:50:15.382028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observamos que la menor `precisión` y el menor `recall` se manifiestan en la clasificación de pistas duras, mientras que obtenemos los máximos valores en pistas de tierra batida.\n\nPodemos concluir que con los datos disponibles, entrenando este clasificador no se han conseguido unos resultados muy prometedores respecto a los objetivos iniciales del proyecto.","metadata":{}},{"cell_type":"markdown","source":"## AUC-ROC Curve","metadata":{}},{"cell_type":"markdown","source":"Al igual que en el apartado 7, mostraremos la curva AUC-ROC que nos permitirá comprender la separabilidad de las clases.","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\nimport numpy as np\nfrom itertools import cycle\n\ny_pred_proba = best_model.predict_proba(X_test)\nclasses = best_model.classes_\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i, current_class in enumerate(classes):\n\n    fpr[i], tpr[i], _ = roc_curve(onehot_encoded[:,i], y_pred_proba[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(onehot_encoded.ravel(), y_pred_proba.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i, current_class in enumerate(classes):\n    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= len(classes)\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure(figsize=(25,12))\n\nplt.plot(\n    fpr[\"micro\"],\n    tpr[\"micro\"],\n    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n    color=\"deeppink\",\n    linestyle=\":\",\n    linewidth=4,\n)\n\nplt.plot(\n    fpr[\"macro\"],\n    tpr[\"macro\"],\n    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n    color=\"navy\",\n    linestyle=\":\",\n    linewidth=4,\n)\n\nfor i in range(len(classes)):\n    plt.plot(\n        fpr[i],\n        tpr[i],\n        label = \"ROC curve of class {0} (area = {1:0.2f})\".format(best_model.classes_[i], roc_auc[i])\n    )\n\n\nplt.plot([0, 1], [0, 1], \"k--\", lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC curves for classification\")\nplt.legend(loc=\"lower right\")\nplt.show()\n\nFILE_NAME = f\"GS_{best_model.get_depth()}_{MODEL_TIMESTAMP}.png\"\n\n# plt.savefig(AUC_ROC_PATH + FILE_NAME, dpi = resolution)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:50:15.383401Z","iopub.status.idle":"2022-05-08T13:50:15.383726Z","shell.execute_reply.started":"2022-05-08T13:50:15.383552Z","shell.execute_reply":"2022-05-08T13:50:15.383568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Al igual que en el apartado anterior","metadata":{}},{"cell_type":"markdown","source":"# Conclusiones","metadata":{}},{"cell_type":"markdown","source":"En este proyecto hemos podido conocer las distintas técnicas que se pueden aplicar a la hora de construir árboles de decisión de clasificación.\n\nSe han podido testar distintos métodos de Resampling para entrenar árboles de distinta profundidad y se han aplicado técnicas de búsqueda de hiperparámetros que tratan de minimizar el error producido en la predicción de las muestras.\n\nComo futuras líneas de investigación se propone aumentar el espacio de búsqueda de los hiperparámetros mediante el método GridSearch, o incluso utilizar soluciones como las de los algoritmos genéticos para la optimización de hiperparámetros, que logran reducir considerablemente el tiempo empleado mediante GridSearch encontrando una solución aproximada a la óptima ya que utilizan funciones de pérdida heurísticas, en lugar de tener un comportamiento computacionalmente exponencial como es el caso del GridSearch al utilizar una búsqueda voraz.","metadata":{}}]}