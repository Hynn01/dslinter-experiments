{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## üíΩ Google Drive Mount","metadata":{"id":"0VrkwZ-5vFZ7"}},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"id":"hIAgKhopvCk5","outputId":"fa67451e-820d-4397-d481-0372f7689387"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ‚¨áÔ∏è Data Download","metadata":{"id":"VcH0gtj_-_Ib"}},{"cell_type":"code","source":"#!unzip /content/drive/MyDrive/animal_computer_vision.zip","metadata":{"id":"PWOaO3d7M5n0","outputId":"02c73477-85ff-4334-bad2-2beac42cd4a6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üì• > üìô Import to Libraries","metadata":{"id":"tveKY1qNUiY3"}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.layers import *\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nimport tensorflow as tf","metadata":{"id":"ztUox8JjUh62"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üìã Data Preparing","metadata":{"id":"GQym6szo-394"}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    featurewise_center=True,\n    samplewise_center=False,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    brightness_range=None,\n    shear_range=0.0,\n    zoom_range=0.0,\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=False,\n    vertical_flip=False,\n    rescale=1.0/255.0,\n    preprocessing_function=None,\n    data_format=None,\n    dtype=None,\n    validation_split=0.2)\ntrain_generator = train_datagen.flow_from_directory(\"../input/animal-computer-vision-clean-dataset-code-cnnai/animal_computer_vision/Dataset\",target_size=(128, 128),\n                                                    batch_size=128,\n                                                    class_mode='categorical',\n                                                    interpolation=\"nearest\",\n                                                    subset=\"training\")\ntest_generator = train_datagen.flow_from_directory(\"../input/animal-computer-vision-clean-dataset-code-cnnai/animal_computer_vision/Dataset\",target_size=(128, 128),\n                                                    batch_size=128,\n                                                    class_mode='categorical',\n                                                    interpolation=\"nearest\",\n                                                    subset=\"validation\")","metadata":{"id":"slk9Z40hJ98G","outputId":"ea4f665e-a345-4920-8079-0fba72f6f29b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üß± Models Structure and Code [Function]","metadata":{"id":"zrxHiiwY-xDV"}},{"cell_type":"code","source":"def func(pre,name_model):\n    print('#####~Model => {} '.format(name_model))\n    pre_model = name_model(input_shape=(128,128, 3),\n                   include_top=False,\n                   weights='imagenet',\n                   pooling='avg')\n    pre_model.trainable = False\n    inputs = pre_model.input\n    x = Dense(64, activation='relu')(pre_model.output)\n    x = Dense(64, activation='relu')(x)\n    outputs = Dense(4, activation='softmax')(x)\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(loss = 'categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n    my_callbacks  = [EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=5,\n                              mode='auto')]\n    \n    history = model.fit(train_generator,validation_data=test_generator,epochs=50,callbacks=my_callbacks,verbose=0)\n    # Plotting Accuracy, val_accuracy, loss, val_loss\n    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n    ax = ax.ravel()\n\n    for i, met in enumerate(['accuracy', 'loss']):\n        ax[i].plot(history.history[met])\n        ax[i].plot(history.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['Train', 'Validation'])\n    plt.show()\n    \n    # Predict Data Test\n    pred = model.predict(test_generator)\n    pred = np.argmax(pred,axis=1)\n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    pred = [labels[k] for k in pred]\n    \n    print('\\033[01m              Classification_report \\033[0m')\n    \n    print('\\033[01m              Results \\033[0m')\n    # Results\n    results = model.evaluate(test_generator, verbose=0)\n    print(\"    Test Loss:\\033[31m \\033[01m {:.5f} \\033[30m \\033[0m\".format(results[0]))\n    print(\"Test Accuracy:\\033[32m \\033[01m {:.2f}% \\033[30m \\033[0m\".format(results[1] * 100))\n    \n    return results","metadata":{"id":"tbYGWaUb6Gkp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def emir_model():\n  inp = Input(shape = (128,128,3))\n\n  x = Conv2D(64, (3,3), strides=(2,2), padding='same', activation='relu', use_bias=True)(inp)\n  x = BatchNormalization()(x)\n  x = SpatialDropout2D(0.4)(x)\n  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n  x = Conv2D(128, (3,3), strides=(2,2), padding='same', activation='relu', use_bias=True)(x)\n  x = BatchNormalization()(x)\n  x = SpatialDropout2D(0.4)(x)\n  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n  x = Conv2D(256, (3,3), strides=(2,2), padding='same', activation='relu', use_bias=True)(x)\n  x = BatchNormalization()(x)\n  x = SpatialDropout2D(0.2)(x)\n  x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(x)\n  x = Conv2D(64, (3,3), strides=(2,2), padding='same', activation='relu', use_bias=True)(x)\n  x = BatchNormalization()(x)\n  x = SpatialDropout2D(0.2)(x)\n  x = Flatten()(x)\n  x = Dense(64, activation='relu')(x)\n  x = Dense(64, activation='relu')(x)\n  x = Dense(4, activation='sigmoid')(x)\n\n  model = Model(inputs=inp, outputs= x)\n  return model","metadata":{"id":"aQfN3sSV2B8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def func_emir(name_model):\n\n    print('#####~Model => {} '.format(name_model))\n\n    model = emir_model()\n    model.summary()\n\n    model.compile(optimizer=\"adam\",loss=\"mse\",metrics=[\"accuracy\"])\n    my_callbacks  = [EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=5,\n                              mode='auto')]\n    \n    history = model.fit(train_generator,\n                        validation_data=test_generator,\n                        epochs=128,\n                        callbacks=my_callbacks,\n                        verbose=0,\n                        batch_size=128,)\n    # Plotting Accuracy, val_accuracy, loss, val_loss\n    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n    ax = ax.ravel()\n\n    for i, met in enumerate(['accuracy', 'loss']):\n        ax[i].plot(history.history[met])\n        ax[i].plot(history.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['Train', 'Validation'])\n    plt.show()\n    \n    # Predict Data Test\n    pred = model.predict(test_generator)\n    pred = np.argmax(pred,axis=1)\n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    pred = [labels[k] for k in pred]\n    \n    print('\\033[01m              Classification_report \\033[0m')\n    \n    print('\\033[01m              Results \\033[0m')\n    # Results\n    results = model.evaluate(test_generator, verbose=0)\n    print(\"    Test Loss:\\033[31m \\033[01m {:.5f} \\033[30m \\033[0m\".format(results[0]))\n    print(\"Test Accuracy:\\033[32m \\033[01m {:.2f}% \\033[30m \\033[0m\".format(results[1] * 100))\n    \n    return results[0],results[1],model","metadata":{"id":"ug-8awarRgT2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üèÉ‚Äç‚ôÇÔ∏è Prep Models and My Model Benchmark Scores","metadata":{"id":"hxrVKHKbtMYs"}},{"cell_type":"markdown","source":"### VGG19","metadata":{"id":"e_giDE7juJUd"}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nresult_VGG19 = func(preprocess_input,VGG19)","metadata":{"id":"bxoxknJTtu8-","outputId":"bf7098df-09c2-4fc8-fd10-70b2a7a9c400"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VGG16","metadata":{"id":"fwxzsSsruO2X"}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nresult_VGG16 = func(preprocess_input,VGG16)","metadata":{"id":"eY4zBbvEt1H2","outputId":"2c36662a-1b73-44c7-d446-a2a339d93a11"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet50","metadata":{"id":"7CoNYxrmuXIE"}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nresult_ResNet50 = func(preprocess_input,ResNet50)","metadata":{"id":"nK3G3ujHuWlc","outputId":"2a8e0e6e-758c-4f89-88f9-c2cebc661520"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet101","metadata":{"id":"BUF6ZYCsugkO"}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.applications.resnet import preprocess_input\nresult_ResNet101 = func(preprocess_input,ResNet101)","metadata":{"id":"CIbgaYkeufZw","outputId":"59d95d0d-a988-4b1d-c334-65dbda434a46"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MobileNet","metadata":{"id":"XEvRLYk0vGmi"}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nresult_MobileNet = func(preprocess_input,MobileNet)","metadata":{"id":"WOyByv7UvFl9","outputId":"5bde8fe1-a5ab-4d3a-b248-f39fba741a0b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DenseNet201","metadata":{"id":"ZCzitLzRw0dY"}},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.applications.densenet import preprocess_input\nresult_DenseNet201 = func(preprocess_input,DenseNet201)","metadata":{"id":"X7uq1iwAw0Gl","outputId":"3f9376ab-3c3b-4d72-9fa1-30272cd9bad6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EfficientNetB7","metadata":{"id":"WIPgKZwVuQs4"}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nresult_Eff = func(preprocess_input,EfficientNetB7)","metadata":{"id":"pogTMEULfHIq","outputId":"9b0b1cb1-5a54-4aa1-991b-7d1c61758124"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Xception","metadata":{"id":"GnRgLYDZw6NH"}},{"cell_type":"code","source":"from tensorflow.keras.applications import Xception\nfrom tensorflow.keras.applications.xception import preprocess_input\nresult_Xception = func(preprocess_input,Xception)","metadata":{"id":"3axFrFQgw5nJ","outputId":"2aa48e98-31a0-40f0-ec16-f7c3cc6c249c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### InceptionResNetV2","metadata":{"id":"hTfd-l3YwvEo"}},{"cell_type":"code","source":"from tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\nresult_InResNetV2 = func(preprocess_input,InceptionResNetV2)","metadata":{"id":"bPbWzdiLwuaN","outputId":"f1c35b61-a175-44b5-83c1-019a53709642"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Emirhan","metadata":{"id":"4_Xpi8WN-kBd"}},{"cell_type":"code","source":"model_name = \"Animal_Computer_Vision_Clean_Dataset\"\nresult_emirhan = func_emir(model_name)","metadata":{"id":"Z18CXqJL6kml","outputId":"4d4f2cde-2677-4896-b457-14bb48297272"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üìä Finally Result of Table (DataFrame - Pandas)","metadata":{"id":"msmvFgrd7-4h"}},{"cell_type":"code","source":"accuracy_result_table = pd.DataFrame({'Model':['Emirhan_Model','VGG16','VGG19','ResNet50','ResNet101','MobileNet','InceptionResNetV2',\n                               'DenseNet201','Xception','EfficientNetB7'],\n                      'Accuracy':[result_emirhan[1],result_VGG16[1], result_VGG19[1], result_ResNet50[1], result_ResNet101[1],\n                                  result_MobileNet[1],result_InResNetV2[1],result_DenseNet201[1],result_Xception[1],\n                                 result_Eff[1]]})","metadata":{"id":"kXAc_cPy7pMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_result_table","metadata":{"id":"hTJSLRKS712R","outputId":"9599543c-de51-4364-af4d-3b9a52d0d8f7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 7))\nplots = sns.barplot(x='Model', y='Accuracy', data=accuracy_result_table)\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(), '.2f'),\n                   (bar.get_x() + bar.get_width() / 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 9),\n                   textcoords='offset points')\n\nplt.xlabel(\"Models\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=20);","metadata":{"id":"wSd3aT7QULoB","outputId":"da16ce35-ee4c-4e78-c6b8-cb14ea8cb6e2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_result_table = pd.DataFrame({'Model':['Emirhan_Model','VGG16','VGG19','ResNet50','ResNet101','MobileNet','InceptionResNetV2',\n                               'DenseNet201','Xception','EfficientNetB7'],\n                      'Loss':[result_emirhan[0],result_VGG16[0], result_VGG19[0], result_ResNet50[0], result_ResNet101[0],\n                                  result_MobileNet[0],result_InResNetV2[0],result_DenseNet201[0],result_Xception[0],\n                                 result_Eff[0]]})","metadata":{"id":"0aKrKJeKQMiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_result_table","metadata":{"id":"Gsxfa0V4QXcA","outputId":"a8736fea-facf-4ab2-993c-739aa34c2442"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 7))\nplots = sns.barplot(x='Model', y='Loss', data=loss_result_table)\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(), '.2f'),\n                   (bar.get_x() + bar.get_width() / 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 9),\n                   textcoords='offset points')\n\nplt.xlabel(\"Models\")\nplt.ylabel(\"Loss\")\nplt.xticks(rotation=20);","metadata":{"id":"RWAzDPdHUOcT","outputId":"1a5419c3-878b-4a15-c6bf-c1de78ff496c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\nIMG_SIZE = (128, 128)\n\n# Split into train/test\n# by default, class names are infered, and converted to int\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(directory = '../input/animal-computer-vision-clean-dataset-code-cnnai/animal_computer_vision/Dataset',\n                                                            validation_split=0.2,\n                                                            subset='training',\n                                                            shuffle=True,\n                                                            seed=1,\n                                                            batch_size=128,\n                                                            image_size=(128,128))\n\nvalidation_dataset = tf.keras.utils.image_dataset_from_directory(directory = '../input/animal-computer-vision-clean-dataset-code-cnnai/animal_computer_vision/Dataset',\n                                                                 validation_split=0.2,\n                                                                 subset='validation',\n                                                                 shuffle=True,\n                                                                 seed=1,\n                                                                 batch_size=128,\n                                                                 image_size=(128,128))","metadata":{"id":"NkXwiNZG5zXJ","outputId":"059cd461-6cb0-4df1-9cad-63d405f534ee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üí≠ Visualizing data","metadata":{"id":"MhGPY6Sl6LAC"}},{"cell_type":"markdown","source":"###Train Dataset","metadata":{"id":"FgD7H0ef6XAv"}},{"cell_type":"code","source":"class_names = train_dataset.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_dataset.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","metadata":{"id":"Zw4LisoK57Zw","outputId":"c2a34686-4faf-4251-f11e-81c38f1d6d9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###Validation Dataset","metadata":{"id":"L5YSeCDO6ZaV"}},{"cell_type":"code","source":"class_names = validation_dataset.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in validation_dataset.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","metadata":{"id":"c4v6F6l35-sO","outputId":"1024ea3f-b650-486a-cba4-6b3262e89014"},"execution_count":null,"outputs":[]}]}