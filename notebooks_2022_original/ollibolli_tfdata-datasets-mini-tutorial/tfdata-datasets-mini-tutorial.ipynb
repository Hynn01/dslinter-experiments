{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.data import AUTOTUNE\nimport tensorflow as tf\nfrom glob import glob\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T14:03:45.11626Z","iopub.execute_input":"2022-05-02T14:03:45.116686Z","iopub.status.idle":"2022-05-02T14:03:51.916585Z","shell.execute_reply.started":"2022-05-02T14:03:45.116654Z","shell.execute_reply":"2022-05-02T14:03:51.915538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get our datasets as list of filepaths","metadata":{}},{"cell_type":"code","source":"cats = glob(\"../input/microsoft-catsvsdogs-dataset/PetImages/Cat/*.jpg\")\ndogs = glob(\"../input/microsoft-catsvsdogs-dataset/PetImages/Dog/*.jpg\")\nprint(f\"#cats: {len(cats)}, #dogs: {len(dogs)}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:51.917843Z","iopub.execute_input":"2022-05-02T14:03:51.918049Z","iopub.status.idle":"2022-05-02T14:03:52.705398Z","shell.execute_reply.started":"2022-05-02T14:03:51.918023Z","shell.execute_reply":"2022-05-02T14:03:52.70453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a fake dataset\nlabels = np.random.choice([0, 1], len(cats))\ncatset = tf.data.Dataset.from_tensor_slices(({'cats_input': cats}, labels))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:52.706787Z","iopub.execute_input":"2022-05-02T14:03:52.707544Z","iopub.status.idle":"2022-05-02T14:03:52.804848Z","shell.execute_reply.started":"2022-05-02T14:03:52.707499Z","shell.execute_reply":"2022-05-02T14:03:52.803905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create functions just like you would for a single data instance (image in this case)","metadata":{}},{"cell_type":"code","source":"#preprocessing images\n# @tf.function\ndef load_cat_image(inputs, labels):\n    #inputs is a dictionary get the filename\n    filename = inputs['cats_input'] \n    #read file \n    file = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(file)\n    #make the image [0,1]\n    image = tf.cast(image, tf.float32) / 255.0\n    # reize image\n    image = tf.image.resize(image, size = [64, 64])\n    #note we are not returning the labels we do that later\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:52.807231Z","iopub.execute_input":"2022-05-02T14:03:52.807758Z","iopub.status.idle":"2022-05-02T14:03:52.8148Z","shell.execute_reply.started":"2022-05-02T14:03:52.807713Z","shell.execute_reply":"2022-05-02T14:03:52.814172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#yield a batch from dataset\nnext(iter(catset))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:52.81636Z","iopub.execute_input":"2022-05-02T14:03:52.816924Z","iopub.status.idle":"2022-05-02T14:03:52.86257Z","shell.execute_reply.started":"2022-05-02T14:03:52.816855Z","shell.execute_reply":"2022-05-02T14:03:52.861812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#increase the batch size .batch(4)\ncatset = catset.batch(4)\n#should return batch size number of datapoints\nnext(iter(catset))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:52.8639Z","iopub.execute_input":"2022-05-02T14:03:52.864542Z","iopub.status.idle":"2022-05-02T14:03:52.877367Z","shell.execute_reply.started":"2022-05-02T14:03:52.864508Z","shell.execute_reply":"2022-05-02T14:03:52.87633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reset\ncatset = tf.data.Dataset.from_tensor_slices(({'cats_input': cats}, labels))\n#apply (map) function to every point in the dataset\ncatset = catset.map(load_cat_image)\nnext(iter(catset))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:52.878308Z","iopub.execute_input":"2022-05-02T14:03:52.878548Z","iopub.status.idle":"2022-05-02T14:03:53.16028Z","shell.execute_reply.started":"2022-05-02T14:03:52.878519Z","shell.execute_reply":"2022-05-02T14:03:53.159491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = next(iter(catset)).numpy()\nplt.imshow(image)\nplt.title(\"Blushie pic\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:53.161513Z","iopub.execute_input":"2022-05-02T14:03:53.162114Z","iopub.status.idle":"2022-05-02T14:03:53.430753Z","shell.execute_reply.started":"2022-05-02T14:03:53.162075Z","shell.execute_reply":"2022-05-02T14:03:53.429878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reset\ncatset = tf.data.Dataset.from_tensor_slices(({'cats_input': cats}, labels))\n#apply (map) function to every point in the dataset then tell the batch size\ncatset = catset.map(load_cat_image).batch(2)\nimages = next(iter(catset)).numpy()\nprint(f\"shape of batch: {images.shape} \\n\")\nfig, ax = plt.subplots(1, 2)\nax[0].imshow(images[0])\nax[1].imshow(images[1])\nplt.title(\"Multi Blushie\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:53.431951Z","iopub.execute_input":"2022-05-02T14:03:53.432194Z","iopub.status.idle":"2022-05-02T14:03:53.851123Z","shell.execute_reply.started":"2022-05-02T14:03:53.432164Z","shell.execute_reply":"2022-05-02T14:03:53.850285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ok we got that down!\nlets try with creating a dataset that yields an image of a cat and a dog!","metadata":{}},{"cell_type":"code","source":"#this decorate makes stuff faster: https://www.tensorflow.org/guide/function\n# @tf.function\ndef load_images(inputs, labels):\n    filename = inputs['cats_input']\n    cat = tf.io.read_file(filename)\n    cat = tf.image.decode_jpeg(cat)\n    cat = tf.cast(cat, tf.float32) / 255.0\n    cat = tf.image.resize(cat, size = [64, 64])\n\n    dog_filename = inputs['dogs_input']\n    dog = tf.io.read_file(dog_filename)\n    dog = tf.image.decode_jpeg(dog)\n    dog = tf.cast(dog, tf.float32) / 255.0\n    dog = tf.image.resize(dog, size = [64, 64])\n    # now we also return the labels since I want to show you how to use it\n    return {'cats_input': cat, 'dogs_input': dog}, labels","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:53.854468Z","iopub.execute_input":"2022-05-02T14:03:53.854807Z","iopub.status.idle":"2022-05-02T14:03:53.866618Z","shell.execute_reply.started":"2022-05-02T14:03:53.854762Z","shell.execute_reply":"2022-05-02T14:03:53.865835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices(({'cats_input': cats, 'dogs_input': dogs}, labels))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:53.868276Z","iopub.execute_input":"2022-05-02T14:03:53.869294Z","iopub.status.idle":"2022-05-02T14:03:53.970346Z","shell.execute_reply.started":"2022-05-02T14:03:53.869229Z","shell.execute_reply":"2022-05-02T14:03:53.96962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"one cat and one dog + label coming up:\")\n(cat, dog), label = next(iter(dataset))\nprint(f\"a dog {dog} and a cat {cat} walk into a bar and see a label {label}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:53.971699Z","iopub.execute_input":"2022-05-02T14:03:53.972332Z","iopub.status.idle":"2022-05-02T14:03:53.98409Z","shell.execute_reply.started":"2022-05-02T14:03:53.97228Z","shell.execute_reply":"2022-05-02T14:03:53.98284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### we are experts now, skip above steps and return a batch of 2 = 4 images","metadata":{}},{"cell_type":"code","source":"dataset = dataset.map(load_images).batch(2)\nimages, catdog_labels = next(iter(dataset)) #this is a dict now:\n\nprint(f\"shape of batch: {images['cats_input'].shape} \\n\")\nprint(f\"shape of batch: {images['dogs_input'].shape} \\n\")\nprint(f\"shape of batch: {catdog_labels.shape} \\n\")\nfig, ax = plt.subplots(1, 4)\nax[0].imshow(images['cats_input'][0].numpy())\nax[1].imshow(images['cats_input'][1].numpy())\nax[2].imshow(images['dogs_input'][0].numpy())\nax[3].imshow(images['dogs_input'][1].numpy())\nplt.title(\"Multi Blushie and Woofie\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:53.986697Z","iopub.execute_input":"2022-05-02T14:03:53.987242Z","iopub.status.idle":"2022-05-02T14:03:54.540991Z","shell.execute_reply.started":"2022-05-02T14:03:53.987193Z","shell.execute_reply":"2022-05-02T14:03:54.540117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shape = images['cats_input'][0].numpy().shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:54.542159Z","iopub.execute_input":"2022-05-02T14:03:54.542387Z","iopub.status.idle":"2022-05-02T14:03:54.547285Z","shell.execute_reply.started":"2022-05-02T14:03:54.542358Z","shell.execute_reply":"2022-05-02T14:03:54.546464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How to use in Keras","metadata":{}},{"cell_type":"code","source":"catinput = Input(shape, name = \"cats_input\")\ndoginput = Input(shape, name = \"dogs_input\")\ncat1 = Conv2D(filters = 1, kernel_size = 2, strides = 1)(catinput)\ndog1 = Conv2D(filters = 1, kernel_size = 2, strides = 1)(doginput)\nout = concatenate([cat1, dog1])\nout = Flatten()(out)\nout = Dense(1, activation = 'sigmoid')(out)\nmodel = Model(inputs = [catinput, doginput], outputs = out, name = \"Convolution_Model\")\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:54.54861Z","iopub.execute_input":"2022-05-02T14:03:54.548843Z","iopub.status.idle":"2022-05-02T14:03:54.652828Z","shell.execute_reply.started":"2022-05-02T14:03:54.548814Z","shell.execute_reply":"2022-05-02T14:03:54.651923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer= 'sgd',metrics=['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:54.653895Z","iopub.execute_input":"2022-05-02T14:03:54.654114Z","iopub.status.idle":"2022-05-02T14:03:54.669003Z","shell.execute_reply.started":"2022-05-02T14:03:54.654088Z","shell.execute_reply":"2022-05-02T14:03:54.668076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this decorate makes stuff faster: https://www.tensorflow.org/guide/function\n@tf.function\ndef load_images(inputs, labels):\n    filename = inputs['cats_input']\n    cat = tf.io.read_file(filename)\n    cat = tf.image.decode_jpeg(cat)\n    cat = tf.cast(cat, tf.float32) / 255.0\n    cat = tf.image.resize(cat, size = [64, 64])\n\n    dog_filename = inputs['dogs_input']\n    dog = tf.io.read_file(dog_filename)\n    dog = tf.image.decode_jpeg(dog)\n    dog = tf.cast(dog, tf.float32) / 255.0\n    dog = tf.image.resize(dog, size = [64, 64])\n    # now we also return the labels since I want to show you how to use it\n    return {'cats_input': cat, 'dogs_input': dog}, labels","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:54.670328Z","iopub.execute_input":"2022-05-02T14:03:54.670633Z","iopub.status.idle":"2022-05-02T14:03:54.679341Z","shell.execute_reply.started":"2022-05-02T14:03:54.670596Z","shell.execute_reply":"2022-05-02T14:03:54.678665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#there is a broken image in the dataset so I just use the first 32 to not deal with that\n#sorry picked a bad dataset for the example and realized too late\ncats = glob(\"../input/microsoft-catsvsdogs-dataset/PetImages/Cat/*.jpg\")[:32]\ndogs = glob(\"../input/microsoft-catsvsdogs-dataset/PetImages/Dog/*.jpg\")[:32]\nprint(f\"#cats: {len(cats)}, #dogs: {len(dogs)}\")\ndataset = tf.data.Dataset.from_tensor_slices(({'cats_input': cats, 'dogs_input': dogs}, labels[:32]))\ndataset = dataset.map(load_images, num_parallel_calls = AUTOTUNE).cache().batch(32).prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:54.680726Z","iopub.execute_input":"2022-05-02T14:03:54.681006Z","iopub.status.idle":"2022-05-02T14:03:54.93303Z","shell.execute_reply.started":"2022-05-02T14:03:54.680976Z","shell.execute_reply":"2022-05-02T14:03:54.931932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:03:54.93437Z","iopub.execute_input":"2022-05-02T14:03:54.934743Z","iopub.status.idle":"2022-05-02T14:03:55.748449Z","shell.execute_reply.started":"2022-05-02T14:03:54.934701Z","shell.execute_reply":"2022-05-02T14:03:55.747551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### read the guide on how to use prefetch, cache, shuffle map and in which order","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}