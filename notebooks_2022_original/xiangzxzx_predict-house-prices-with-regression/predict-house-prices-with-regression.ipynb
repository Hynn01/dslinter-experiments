{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T06:15:25.150447Z","iopub.execute_input":"2022-05-08T06:15:25.151407Z","iopub.status.idle":"2022-05-08T06:15:26.344814Z","shell.execute_reply.started":"2022-05-08T06:15:25.151264Z","shell.execute_reply":"2022-05-08T06:15:26.343886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndf_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:15:26.346648Z","iopub.execute_input":"2022-05-08T06:15:26.346875Z","iopub.status.idle":"2022-05-08T06:15:26.433978Z","shell.execute_reply.started":"2022-05-08T06:15:26.346849Z","shell.execute_reply":"2022-05-08T06:15:26.433006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:15:26.43613Z","iopub.execute_input":"2022-05-08T06:15:26.436937Z","iopub.status.idle":"2022-05-08T06:15:26.473851Z","shell.execute_reply.started":"2022-05-08T06:15:26.436899Z","shell.execute_reply":"2022-05-08T06:15:26.472892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of train set: {}'.format(df_train.shape))\nprint('Shape of test set: {}'.format(df_test.shape))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:15:26.476183Z","iopub.execute_input":"2022-05-08T06:15:26.4766Z","iopub.status.idle":"2022-05-08T06:15:26.48322Z","shell.execute_reply.started":"2022-05-08T06:15:26.476554Z","shell.execute_reply":"2022-05-08T06:15:26.482225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#do a cross check between train and test sets to verify all columns are present in both sets, except for the target variable in train set.\n\nvariables_not_in_train_set = [i for i in df_train.columns if i not in df_test.columns]\nprint('Columns not in test set but present in train set: {}'.format(variables_not_in_train_set))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:15:26.484831Z","iopub.execute_input":"2022-05-08T06:15:26.485357Z","iopub.status.idle":"2022-05-08T06:15:26.500261Z","shell.execute_reply.started":"2022-05-08T06:15:26.485282Z","shell.execute_reply":"2022-05-08T06:15:26.499327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:15:26.501561Z","iopub.execute_input":"2022-05-08T06:15:26.50195Z","iopub.status.idle":"2022-05-08T06:15:26.543089Z","shell.execute_reply.started":"2022-05-08T06:15:26.501909Z","shell.execute_reply":"2022-05-08T06:15:26.542372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see quite a number of columns with missing values. We will deal with that later. ","metadata":{}},{"cell_type":"code","source":"#drop the Id column for both train and test sets\n\ndf_train.drop(columns=['Id'], inplace=True)\ndf_test.drop(columns=['Id'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:15:51.73495Z","iopub.execute_input":"2022-05-08T06:15:51.735731Z","iopub.status.idle":"2022-05-08T06:15:51.745403Z","shell.execute_reply.started":"2022-05-08T06:15:51.735679Z","shell.execute_reply":"2022-05-08T06:15:51.744594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Numerical Data ","metadata":{}},{"cell_type":"markdown","source":"We first deal with the data by grouping them into numerical and categorical data. We start off with the numerical data and perform the following investigations:\n\n* Determine the Pearson Correlation coefficient of each features with the target variable. We will drop any features which are deemed poorly correlated with the target variable.\n\n* Drop any features with multicollinearity.\n\n* Determine the distribution of the features and compute their skewness and kurtosis.\n \n* Impute any missing values or drop any features when imputation doesnt help. \n","metadata":{}},{"cell_type":"code","source":"#Filter out a list containing only numerical variables\ndf_train_numerical = [i for i in df_train.columns if df_train[i].dtype != 'object']\n\n#compute the correlation heatmap to see which features are highly correlated with target\ncorr_matrix = df_train[df_train_numerical].corr()\nplt.figure(figsize=(20,20), dpi=70)\nsns.heatmap(corr_matrix, cmap=plt.cm.Reds, annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:20:34.891499Z","iopub.execute_input":"2022-05-08T06:20:34.892412Z","iopub.status.idle":"2022-05-08T06:20:40.662476Z","shell.execute_reply.started":"2022-05-08T06:20:34.892368Z","shell.execute_reply":"2022-05-08T06:20:40.661619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_with_SalePrice = df_train[df_train_numerical].corr()['SalePrice'][:-1]\nprint('Features highly correlated with SalePrice: {}'.format(corr_with_SalePrice[corr_with_SalePrice >= 0.5].sort_values(ascending=False).round(2)))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:38:32.951846Z","iopub.execute_input":"2022-05-08T06:38:32.952317Z","iopub.status.idle":"2022-05-08T06:38:32.967697Z","shell.execute_reply.started":"2022-05-08T06:38:32.952263Z","shell.execute_reply":"2022-05-08T06:38:32.966855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Features fairly correlated with SalePrice: {}'.format(corr_with_SalePrice[(corr_with_SalePrice < 0.5) & (corr_with_SalePrice > 0.3)].sort_values().round(2)))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:44:32.011454Z","iopub.execute_input":"2022-05-08T06:44:32.012269Z","iopub.status.idle":"2022-05-08T06:44:32.020284Z","shell.execute_reply.started":"2022-05-08T06:44:32.012219Z","shell.execute_reply":"2022-05-08T06:44:32.019372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Features poorly correlated with SalePrice: {}'.format(corr_with_SalePrice[corr_with_SalePrice > 0.3].sort_values().round(2)))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:45:05.881945Z","iopub.execute_input":"2022-05-08T06:45:05.882234Z","iopub.status.idle":"2022-05-08T06:45:05.889388Z","shell.execute_reply.started":"2022-05-08T06:45:05.882201Z","shell.execute_reply":"2022-05-08T06:45:05.888549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#strong features with corr more than 0.5\nstrong_features = corr_with_SalePrice[corr_with_SalePrice >= 0.5].sort_values(ascending=False).index\nstrong_list = [x for x in strong_features]\nstrong_list.append('SalePrice')\n\ndef reg_plot(df, features, rows, col):\n    fig = plt.figure(figsize=(19,19), dpi=70)\n    for i, feature in enumerate(features):\n        if feature != 'SalePrice':\n            ax = fig.add_subplot(rows, col, i+1)\n            sns.regplot(x=feature, y='SalePrice', data=df, line_kws={'color':'black'})\n            ax.set_xlabel(feature)\n            ax.set_ylabel('SalePrice')\n    \nreg_plot(df_train[strong_list], strong_list, 4, 3)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T07:40:30.432618Z","iopub.execute_input":"2022-05-08T07:40:30.432909Z","iopub.status.idle":"2022-05-08T07:40:33.929521Z","shell.execute_reply.started":"2022-05-08T07:40:30.43288Z","shell.execute_reply":"2022-05-08T07:40:33.928596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#features with fair corr between 0.3 to 0.5\nfair_features = corr_with_SalePrice[(corr_with_SalePrice < 0.5) & (corr_with_SalePrice > 0.3)].sort_values(ascending=False).index\nfair_list = [x for x in fair_features]\nfair_list.append('SalePrice')\n\nreg_plot(df_train[fair_list], fair_list, 4, 3)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T07:40:47.188278Z","iopub.execute_input":"2022-05-08T07:40:47.188735Z","iopub.status.idle":"2022-05-08T07:40:50.058489Z","shell.execute_reply.started":"2022-05-08T07:40:47.188697Z","shell.execute_reply":"2022-05-08T07:40:50.057399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[df_train_numerical].corr().values\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:08:54.342089Z","iopub.execute_input":"2022-05-08T08:08:54.342926Z","iopub.status.idle":"2022-05-08T08:08:54.357769Z","shell.execute_reply.started":"2022-05-08T08:08:54.342884Z","shell.execute_reply":"2022-05-08T08:08:54.356772Z"},"trusted":true},"execution_count":null,"outputs":[]}]}