{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras import layers\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport time\nimport cv2 as cv2\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom PIL import Image\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom IPython.core.display import display, HTML","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T05:07:26.690939Z","iopub.execute_input":"2022-05-08T05:07:26.692749Z","iopub.status.idle":"2022-05-08T05:07:29.299332Z","shell.execute_reply.started":"2022-05-08T05:07:26.692669Z","shell.execute_reply":"2022-05-08T05:07:29.298493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Verilerin Preprocessing İşlemi","metadata":{}},{"cell_type":"code","source":"fpath=r'../input/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset/Ak/Ak (1).png'\nimg=plt.imread(fpath)\nprint (img.shape)\nimshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:29.304196Z","iopub.execute_input":"2022-05-08T05:07:29.304538Z","iopub.status.idle":"2022-05-08T05:07:29.605338Z","shell.execute_reply.started":"2022-05-08T05:07:29.304494Z","shell.execute_reply":"2022-05-08T05:07:29.604493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sdir=r'../input/grapevine-leaves-image-dataset/Grapevine_Leaves_Image_Dataset'\nclasslist=os.listdir(sdir)    \nfilepaths=[]\nlabels=[]    \nfor sinif in classlist:\n    if sinif != 'grapevine-leaves-image-dataset':\n        classpath=os.path.join(sdir,sinif)\n        if os.path.isdir(classpath):\n            flist=os.listdir(classpath)        \n            for f in flist:\n                fpath=os.path.join(classpath,f)        \n                filepaths.append(fpath)\n                labels.append(sinif)\nFseries=pd.Series(filepaths, name='filepaths')\nLseries=pd.Series(labels, name='labels')    \ndf=pd.concat([Fseries, Lseries], axis=1)    \nprint (df.head())\nprint('df length: ', len(df))\nprint (df['labels'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:29.6066Z","iopub.execute_input":"2022-05-08T05:07:29.606921Z","iopub.status.idle":"2022-05-08T05:07:29.629544Z","shell.execute_reply.started":"2022-05-08T05:07:29.60688Z","shell.execute_reply":"2022-05-08T05:07:29.628804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_list=[]\nmax_size= 100\ngroups=df.groupby('labels')\nfor label in df['labels'].unique():                 \n    group=groups.get_group(label)\n    sample_count=len(group)    \n    if sample_count> max_size:\n        samples=group.sample(max_size, replace=False, weights=None, random_state=123, axis=0).reset_index(drop=True)\n    else:\n        samples=group.sample(frac=1.0, replace=False, random_state=123, axis=0).reset_index(drop=True)\n    sample_list.append(samples)\ndf=pd.concat(sample_list, axis=0).reset_index(drop=True)\nprint (len(df))     \nprint (df['labels'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:29.631307Z","iopub.execute_input":"2022-05-08T05:07:29.631556Z","iopub.status.idle":"2022-05-08T05:07:29.651109Z","shell.execute_reply.started":"2022-05-08T05:07:29.631526Z","shell.execute_reply":"2022-05-08T05:07:29.648285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"working_dir=r'./'\naug_dir=os.path.join(working_dir, 'aug')\nif os.path.isdir(aug_dir):\n    shutil.rmtree(aug_dir)\nos.mkdir(aug_dir)\nfor label in df['labels'].unique():\n    dir_path=os.path.join(aug_dir,label)    \n    os.mkdir(dir_path)\nprint(os.listdir(aug_dir))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:29.652543Z","iopub.execute_input":"2022-05-08T05:07:29.653234Z","iopub.status.idle":"2022-05-08T05:07:29.692987Z","shell.execute_reply.started":"2022-05-08T05:07:29.653181Z","shell.execute_reply":"2022-05-08T05:07:29.692091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target=300 \ngen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n                              height_shift_range=.2, zoom_range=.2)\ngroups=df.groupby('labels')\nfor label in df['labels'].unique():               \n    group=groups.get_group(label)  \n    sample_count=len(group)     \n    if sample_count< target: \n        aug_img_count=0\n        delta=target-sample_count \n        target_dir=os.path.join(aug_dir, label)    \n        aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=(66,66), class_mode=None,\n                                        batch_size=1, shuffle=False, save_to_dir=target_dir, save_prefix='aug-',\n                                        save_format='jpg')\n        while aug_img_count<delta:\n            images=next(aug_gen)            \n            aug_img_count += len(images)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:29.694339Z","iopub.execute_input":"2022-05-08T05:07:29.69471Z","iopub.status.idle":"2022-05-08T05:07:37.633159Z","shell.execute_reply.started":"2022-05-08T05:07:29.694679Z","shell.execute_reply":"2022-05-08T05:07:37.632505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug=r'./aug'\nauglist=os.listdir(aug)\nprint (auglist)\nfor sinif in auglist:\n    classpath=os.path.join(aug, sinif)\n    flist=os.listdir(classpath)\n    print('sınıf: ', sinif, '  file count: ', len(flist))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:37.634171Z","iopub.execute_input":"2022-05-08T05:07:37.635Z","iopub.status.idle":"2022-05-08T05:07:37.646946Z","shell.execute_reply.started":"2022-05-08T05:07:37.634948Z","shell.execute_reply":"2022-05-08T05:07:37.645994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(50, 50))\nfor i in range(25):\n    image=next(aug_gen)/255\n    image=np.squeeze(image, axis=0)\n    plt.subplot(5,5,i+1)\n    plt.imshow(image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:37.648361Z","iopub.execute_input":"2022-05-08T05:07:37.648772Z","iopub.status.idle":"2022-05-08T05:07:42.515608Z","shell.execute_reply.started":"2022-05-08T05:07:37.648734Z","shell.execute_reply":"2022-05-08T05:07:42.514587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_fpaths=[]\naug_labels=[]\nclasslist=os.listdir(aug_dir)\nfor sinif in classlist:\n    classpath=os.path.join(aug_dir, sinif)     \n    flist=os.listdir(classpath)    \n    for f in flist:        \n        fpath=os.path.join(classpath,f)         \n        aug_fpaths.append(fpath)\n        aug_labels.append(sinif)\nFseries=pd.Series(aug_fpaths, name='filepaths')\nLseries=pd.Series(aug_labels, name='labels')\naug_df=pd.concat([Fseries, Lseries], axis=1)\nndf=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n\n\nprint (df['labels'].value_counts()) \nprint(aug_df['labels'].value_counts())\nprint (ndf['labels'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:42.516975Z","iopub.execute_input":"2022-05-08T05:07:42.517364Z","iopub.status.idle":"2022-05-08T05:07:42.543284Z","shell.execute_reply.started":"2022-05-08T05:07:42.517313Z","shell.execute_reply":"2022-05-08T05:07:42.542437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_split=.8\nvalid_split=.1\ndummy_split=valid_split/(1-train_split)\ntrain_df, dummy_df=train_test_split(ndf, train_size=train_split, shuffle=True, random_state=123)\nvalid_df, test_df=train_test_split(dummy_df, train_size=dummy_split, shuffle=True, random_state=123)\nprint ('train_df length: ', len(train_df),'  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:42.544527Z","iopub.execute_input":"2022-05-08T05:07:42.544876Z","iopub.status.idle":"2022-05-08T05:07:42.556582Z","shell.execute_reply.started":"2022-05-08T05:07:42.544845Z","shell.execute_reply":"2022-05-08T05:07:42.555836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height=50\nwidth=50\nchannels=3\nbatch_size=40\nimg_shape=(height, width, channels)\nimg_size=(height, width)\nlength=len(test_df)\ntest_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \ntest_steps=int(length/test_batch_size)\nprint ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\ndef scalar(img):\n    return img \ntrgen=ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)\ntvgen=ImageDataGenerator(preprocessing_function=scalar)\nsdir=r'../input/grapesImages/Image/images'\ntrain_gen=trgen.flow_from_dataframe( train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\ntest_gen=tvgen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\nvalid_gen=tvgen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\nclasses=list(train_gen.class_indices.keys())\nclass_count=len(classes)\ntrain_steps=int(len(train_gen.labels)/batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:42.558099Z","iopub.execute_input":"2022-05-08T05:07:42.55853Z","iopub.status.idle":"2022-05-08T05:07:42.599712Z","shell.execute_reply.started":"2022-05-08T05:07:42.558491Z","shell.execute_reply":"2022-05-08T05:07:42.598972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_image_samples(gen ):\n    t_dict=gen.class_indices\n    classes=list(t_dict.keys())    \n    images,labels=next(gen)\n    plt.figure(figsize=(20, 20))\n    length=len(labels)\n    if length<25:\n        r=length\n    else:\n        r=25\n    for i in range(r):\n        plt.subplot(5, 5, i + 1)\n        image=images[i]/255\n        plt.imshow(image)\n        index=np.argmax(labels[i])\n        class_name=classes[index]\n        plt.title(class_name, color='blue', fontsize=16)\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:42.600858Z","iopub.execute_input":"2022-05-08T05:07:42.601231Z","iopub.status.idle":"2022-05-08T05:07:42.607756Z","shell.execute_reply.started":"2022-05-08T05:07:42.601199Z","shell.execute_reply":"2022-05-08T05:07:42.606809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image_samples(train_gen)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:42.610136Z","iopub.execute_input":"2022-05-08T05:07:42.610752Z","iopub.status.idle":"2022-05-08T05:07:44.59166Z","shell.execute_reply.started":"2022-05-08T05:07:42.610719Z","shell.execute_reply":"2022-05-08T05:07:44.590645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_in_color(txt_msg,fore_tupple,back_tupple,):\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat), flush=True)\n    print('\\33[0m', flush=True)\n    return","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:44.593079Z","iopub.execute_input":"2022-05-08T05:07:44.593319Z","iopub.status.idle":"2022-05-08T05:07:44.599289Z","shell.execute_reply.started":"2022-05-08T05:07:44.593293Z","shell.execute_reply":"2022-05-08T05:07:44.5984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DenseNet121(Hazır Model)","metadata":{}},{"cell_type":"code","source":"model_name='DenseNet121'\nbasemodel = tf.keras.applications.DenseNet121(weights = \"imagenet\",input_shape = img_shape,include_top=False,pooling='max')\nx=basemodel.output\nx=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.02),activity_regularizer=regularizers.l1(0.005),\n                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\nx=Dropout(rate=.5, seed=123)(x)        \noutput = Dense(class_count, activation=\"softmax\")(x)\nmodel = tf.keras.Model(inputs = basemodel.inputs, outputs = output)\nmodel.compile(Adamax(lr=.001), loss='categorical_crossentropy', metrics=['accuracy']) \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:44.6005Z","iopub.execute_input":"2022-05-08T05:07:44.600751Z","iopub.status.idle":"2022-05-08T05:07:47.826201Z","shell.execute_reply.started":"2022-05-08T05:07:44.600722Z","shell.execute_reply":"2022-05-08T05:07:47.825198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## OWN CNN(Oluşturmuş olduğum model)","metadata":{}},{"cell_type":"code","source":"print(img_shape)\nmodel_name_own='OwnCNN'\nmodel_own = Sequential()\nmodel_own.add(keras.layers.Conv2D(32, kernel_size=(2, 2),\n                 activation='relu',\n                 input_shape=img_shape))\nmodel_own.add(keras.layers.Conv2D(64, (2, 2)))\nmodel_own.add(keras.layers.Conv2D(64, (2, 2), activation='relu'))\nmodel_own.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel_own.add(keras.layers.Conv2D(128, (2, 2)))\nmodel_own.add(keras.layers.Conv2D(128, (2, 2), activation='relu'))\nmodel_own.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel_own.add(keras.layers.Dropout(0.15))\nmodel_own.add(keras.layers.Conv2D(256, (2, 2)))\nmodel_own.add(keras.layers.Conv2D(256, (2, 2), activation='relu'))\nmodel_own.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel_own.add(keras.layers.Dropout(0.25))\nmodel_own.add(keras.layers.Conv2D(512, (2, 2)))\nmodel_own.add(keras.layers.Conv2D(512, (2, 2), activation='relu'))\nmodel_own.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\nmodel_own.add(keras.layers.Dropout(0.2))\nmodel_own.add(keras.layers.Flatten())\nmodel_own.add(keras.layers.Dense(512, activation='relu'))\nmodel_own.add(keras.layers.Dense(256, activation='relu'))\nmodel_own.add(keras.layers.Dense(units=class_count, activation='softmax'))\nmodel_own.compile(Adamax(learning_rate=.001), loss='categorical_crossentropy', metrics=['accuracy']) \nmodel_own.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:47.82775Z","iopub.execute_input":"2022-05-08T05:07:47.828027Z","iopub.status.idle":"2022-05-08T05:07:48.008988Z","shell.execute_reply.started":"2022-05-08T05:07:47.827991Z","shell.execute_reply":"2022-05-08T05:07:48.007009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LRA(keras.callbacks.Callback):\n    reset=False\n    count=0\n    stop_count=0\n    \n    def __init__(self,model, patience,stop_patience, threshold, factor, model_name, freeze,batches, initial_epoch,epochs):\n        super(LRA, self).__init__()\n        self.epochs=epochs\n        self.model=model\n        self.patience=patience \n        self.stop_patience=stop_patience\n        self.threshold=threshold \n        self.factor=factor \n        self.lr=float(tf.keras.backend.get_value(model.optimizer.lr)) \n        self.highest_tracc=0.0 \n        self.lowest_vloss=np.inf \n        self.initial_epoch=initial_epoch \n        self.batches=batches\n        best_weights=self.model.get_weights()         \n        msg=' '\n        if freeze==True:\n            msgs=f' Starting training using  base model { model_name} with weights frozen to imagenet weights initializing LRA callback'\n        else:\n            msgs=f' Starting training using base model { model_name} training all layers '            \n        print_in_color (msgs, (244, 252, 3), (55,65,80)) \n    def on_train_begin(self, logs=None):\n        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n                                                                                              'V_loss','V_acc', 'LR', 'Next LR', 'Monitor', 'Duration')\n        print_in_color(msg, (244,252,3), (55,65,80)) \n        \n    def on_train_batch_end(self, batch, logs=None):\n        acc=logs.get('accuracy')* 100  \n        loss=logs.get('loss')\n        msg='{0:20s}processing batch {1:4s} of {2:5s} accuracy= {3:8.3f}  loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n        print(msg, '\\r', end='') \n        \n        \n    def on_epoch_begin(self,epoch, logs=None):\n        self.now= time.time()\n        \n    def on_epoch_end(self, epoch, logs=None):  \n        later=time.time()\n        duration=later-self.now \n        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) \n        current_lr=lr\n        v_loss=logs.get('val_loss')  \n        acc=logs.get('accuracy')  \n        v_acc=logs.get('val_accuracy')\n        loss=logs.get('loss')\n        if acc < self.threshold: \n            monitor='accuracy'\n            if acc>self.highest_tracc:                 \n                self.highest_tracc=acc \n                LRA.best_weights=self.model.get_weights()\n                self.count=0\n                self.stop_count=0 \n                if v_loss<self.lowest_vloss:\n                    self.lowest_vloss=v_loss\n                color= (0,255,0)\n                self.lr=lr\n            else: \n                if self.count>=self.patience -1:\n                    color=(245, 170, 66)\n                    self.lr= lr* self.factor \n                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) \n                    self.count=0 \n                    self.stop_count=self.stop_count + 1              \n                                                      \n                else:\n                    self.count=self.count +1                    \n        else: \n            monitor='val_loss'\n            if v_loss< self.lowest_vloss: \n                self.lowest_vloss=v_loss           \n                self.count=0 \n                self.stop_count=0  \n                color=(0,255,0)\n                self.lr=lr\n            else: \n                if self.count>=self.patience-1:\n                    color=(245, 170, 66)\n                    self.lr=self.lr * self.factor                \n                    self.stop_count=self.stop_count + 1 \n                    self.count=0 \n                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr)  \n                else: \n                    self.count =self.count +1               \n                if acc>self.highest_tracc:\n                    self.highest_tracc= acc\n        msg=f'{str(epoch+1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{self.lr:^9.5f}{monitor:^11s}{duration:^8.2f}'\n        print_in_color (msg,color, (55,65,80))\n        if self.stop_count> self.stop_patience - 1: \n            msg=f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n            print_in_color(msg, (0,255,255), (55,65,80))\n            self.model.stop_training = True\n        \n                           ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:48.010913Z","iopub.execute_input":"2022-05-08T05:07:48.011294Z","iopub.status.idle":"2022-05-08T05:07:48.032234Z","shell.execute_reply.started":"2022-05-08T05:07:48.011202Z","shell.execute_reply":"2022-05-08T05:07:48.031181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OWN CNN Eğitimi","metadata":{}},{"cell_type":"code","source":"epochs =40\npatience= 1 \nstop_patience =4 \nthreshold=.9 \nfactor=.5  \nfreeze=False\nbatches=train_steps\ncallbacks_own=[LRA(model=model_own,patience=patience,stop_patience=stop_patience, threshold=threshold,\n                   factor=factor, model_name=model_name_own, freeze=freeze, batches=batches,initial_epoch=0,epochs=epochs )]\n\nhistory_own=model_own.fit(x=train_gen,  epochs=epochs, verbose=0, callbacks=callbacks_own,  validation_data=valid_gen,\n               validation_steps=None,  shuffle=False,  initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:07:48.034169Z","iopub.execute_input":"2022-05-08T05:07:48.034681Z","iopub.status.idle":"2022-05-08T05:16:27.706784Z","shell.execute_reply.started":"2022-05-08T05:07:48.034637Z","shell.execute_reply":"2022-05-08T05:16:27.705578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DenseNet121 Eğitimi","metadata":{}},{"cell_type":"code","source":"callbacks=[LRA(model=model,patience=patience,stop_patience=stop_patience, threshold=threshold,\n                   factor=factor, model_name=model_name, freeze=freeze, batches=batches,initial_epoch=0,epochs=epochs )]\n\nhistory=model.fit(x=train_gen,  epochs=epochs, verbose=0, callbacks=callbacks,  validation_data=valid_gen,\n               validation_steps=None,  shuffle=False,  initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:16:27.709118Z","iopub.execute_input":"2022-05-08T05:16:27.709936Z","iopub.status.idle":"2022-05-08T05:29:55.070077Z","shell.execute_reply.started":"2022-05-08T05:16:27.709882Z","shell.execute_reply":"2022-05-08T05:29:55.069353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tr_plot(tr_data, start_epoch):\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:29:55.071678Z","iopub.execute_input":"2022-05-08T05:29:55.072315Z","iopub.status.idle":"2022-05-08T05:29:55.083583Z","shell.execute_reply.started":"2022-05-08T05:29:55.072279Z","shell.execute_reply":"2022-05-08T05:29:55.082706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_info( test_gen, preds, print_code, save_dir, subject ):\n    class_dict=test_gen.class_indices\n    labels= test_gen.labels\n    file_names= test_gen.filenames \n    error_list=[]\n    true_class=[]\n    pred_class=[]\n    prob_list=[]\n    new_dict={}\n    error_indices=[]\n    y_pred=[]\n    for key,value in class_dict.items():\n        new_dict[value]=key             \n    classes=list(new_dict.values())   \n    dict_as_text=str(new_dict)\n    dict_name= subject + '-' +str(len(classes)) +'.txt'  \n    dict_path=os.path.join(save_dir,dict_name)    \n    with open(dict_path, 'w') as x_file:\n        x_file.write(dict_as_text)    \n    errors=0      \n    for i, p in enumerate(preds):\n        pred_index=np.argmax(p)        \n        true_index=labels[i] \n        if pred_index != true_index: \n            error_list.append(file_names[i])\n            true_class.append(new_dict[true_index])\n            pred_class.append(new_dict[pred_index])\n            prob_list.append(p[pred_index])\n            error_indices.append(true_index)            \n            errors=errors + 1\n        y_pred.append(pred_index)    \n    if print_code !=0:\n        if errors>0:\n            if print_code>errors:\n                r=errors\n            else:\n                r=print_code           \n            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n            print_in_color(msg, (0,255,0),(55,65,80))\n            for i in range(r):                \n                split1=os.path.split(error_list[i])                \n                split2=os.path.split(split1[0])                \n                fname=split2[1] + '/' + split1[1]\n                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n                print_in_color(msg, (255,255,255), (55,65,60))            \n        else:\n            msg='With accuracy of 100 % there are no errors to print'\n            print_in_color(msg, (0,255,0),(55,65,80))\n    if errors>0:\n        plot_bar=[]\n        plot_class=[]\n        for  key, value in new_dict.items():        \n            count=error_indices.count(key) \n            if count!=0:\n                plot_bar.append(count) \n                plot_class.append(value) \n        fig=plt.figure()\n        fig.set_figheight(len(plot_class)/3)\n        fig.set_figwidth(10)\n        plt.style.use('fivethirtyeight')\n        for i in range(0, len(plot_class)):\n            c=plot_class[i]\n            x=plot_bar[i]\n            plt.barh(c, x, )\n            plt.title( ' Errors by Class on Test Set')\n    y_true= np.array(labels)        \n    y_pred=np.array(y_pred)\n    if len(classes)<= 30:\n        cm = confusion_matrix(y_true, y_pred )        \n        length=len(classes)\n        if length<8:\n            fig_width=8\n            fig_height=8\n        else:\n            fig_width= int(length * .5)\n            fig_height= int(length * .5)\n        plt.figure(figsize=(fig_width, fig_height))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix\")\n        plt.show()\n    clr = classification_report(y_true, y_pred, target_names=classes)\n    print(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:29:55.084998Z","iopub.execute_input":"2022-05-08T05:29:55.085495Z","iopub.status.idle":"2022-05-08T05:29:55.108328Z","shell.execute_reply.started":"2022-05-08T05:29:55.085456Z","shell.execute_reply":"2022-05-08T05:29:55.107364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OWN CNN Accuracy Değeri ve Training ve Validation Loss ve Accuracy Grafikleri","metadata":{}},{"cell_type":"code","source":"tr_plot(history_own,0)\nsave_dir=r'./'\nsubject='grapes'\nacc=model_own.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\nmsg=f'accuracy on the test set is {acc:5.2f} %'\nprint_in_color(msg, (0,255,0),(55,65,80))\nsave_id=str (model_name_own +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\nsave_loc=os.path.join(save_dir, save_id)\nmodel_own.save(save_loc)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:29:55.109789Z","iopub.execute_input":"2022-05-08T05:29:55.110306Z","iopub.status.idle":"2022-05-08T05:29:56.602116Z","shell.execute_reply.started":"2022-05-08T05:29:55.110265Z","shell.execute_reply":"2022-05-08T05:29:56.601166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OWN CNN Hataların sınıfları ve Confusion Matrix","metadata":{}},{"cell_type":"code","source":"print_code=0\npreds=model_own.predict(test_gen) \nprint_info( test_gen, preds, print_code, save_dir, subject )  ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:29:56.603468Z","iopub.execute_input":"2022-05-08T05:29:56.603686Z","iopub.status.idle":"2022-05-08T05:29:57.99309Z","shell.execute_reply.started":"2022-05-08T05:29:56.603661Z","shell.execute_reply":"2022-05-08T05:29:57.992328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DenseNet121 Accuracy Değeri ve Training ve Validation Loss ve Accuracy Grafikleri","metadata":{}},{"cell_type":"code","source":"tr_plot(history,0)\nsave_dir=r'./'\nsubject='grapes'\nacc=model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\nmsg=f'accuracy on the test set is {acc:5.2f} %'\nprint_in_color(msg, (0,255,0),(55,65,80))\nsave_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\nsave_loc=os.path.join(save_dir, save_id)\nmodel.save(save_loc)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:29:57.996051Z","iopub.execute_input":"2022-05-08T05:29:57.996315Z","iopub.status.idle":"2022-05-08T05:30:00.880494Z","shell.execute_reply.started":"2022-05-08T05:29:57.996287Z","shell.execute_reply":"2022-05-08T05:30:00.879827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DenseNet121 Hataların sınıfları ve Confusion Matrix","metadata":{}},{"cell_type":"code","source":"print_code=0\npreds=model.predict(test_gen) \nprint_info( test_gen, preds, print_code, save_dir, subject )","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:30:00.883332Z","iopub.execute_input":"2022-05-08T05:30:00.884102Z","iopub.status.idle":"2022-05-08T05:30:05.09874Z","shell.execute_reply.started":"2022-05-08T05:30:00.88406Z","shell.execute_reply":"2022-05-08T05:30:05.097796Z"},"trusted":true},"execution_count":null,"outputs":[]}]}