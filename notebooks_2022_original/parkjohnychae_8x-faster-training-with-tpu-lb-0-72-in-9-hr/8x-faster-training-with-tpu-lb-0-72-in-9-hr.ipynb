{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"id":"cVI_k2a0B9lt","outputId":"1301efae-ecb2-4fce-e668-f188e7976658"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Acknowledgments\nGuide for using TPU from tensorflow:\n\nhttps://www.tensorflow.org/guide/tpu\n\nhttps://www.tensorflow.org/tutorials/load_data/tfrecord\n\nAlso adapted part from Dimitre Oliveria's code below:\n\nhttps://keras.io/examples/keras_recipes/creating_tfrecords/\n\nAnd cdeotte's notebook below:\n\nhttps://www.kaggle.com/code/cdeotte/how-to-create-tfrecords/notebook\n","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nHi everyone,\n\nI hope you guys are having fun here so far!\n\nWe have about 3 weeks until the competition deadline. 3 weeks is a short timeframe for someone, but it could be enough for others, especially if they want to learn and have fun. \n\nI think this competition could be frustratinig beacuse of relatively bigger size of data compared to other competitions. It's actually an extremely good thing we have lots of labeled data. But we got limited time and resources for the competition, and not everyone has access to expensive GPUs with high VRAMs.\n\nBut don't give up! TPUs are faster than GPUs, but many of us may are not fully utilizing them as we don't see any discussions or notebooks about TPU training. To fill this gap, I decided to share Tfrecord data I created, to facilitate TPU training with our data. It takes about 8 - 9 hours in TPU time to train standard ResNet50 for good performance (LB =0.72). So no worries if you think you are late for the party. You are not too late as long as you have TPU time left in your kaggle account!\n\n","metadata":{}},{"cell_type":"markdown","source":"## TFRecords\n\nIn order to use TPU, you need to prepare the data in a specific format, TFrecord. In TFrecord, images are stored in bytes which enables faster data reading. I created TFrecords in 480x480 resolution for training and testing. Here are the links:\n- [TFREC 480 TRAINING](https://www.kaggle.com/datasets/parkjohnychae/herbarium-2022-train-tfrec-480) \n- [TFREC 480 TESTING](https://www.kaggle.com/datasets/parkjohnychae/herbarium-2022-test-tfrec-480)","metadata":{}},{"cell_type":"markdown","source":"## Install packages\n","metadata":{}},{"cell_type":"code","source":"!pip install -q mytflib\n!pip install -q one-cycle-tf","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:01:19.165994Z","iopub.execute_input":"2022-05-07T06:01:19.16632Z","iopub.status.idle":"2022-05-07T06:01:38.773917Z","shell.execute_reply.started":"2022-05-07T06:01:19.166245Z","shell.execute_reply":"2022-05-07T06:01:38.773199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport mytflib as tfl\nimport tensorflow_addons as tfa\nimport os\nfrom one_cycle_tf import OneCycle","metadata":{"id":"RRQoOAfcDBDh","execution":{"iopub.status.busy":"2022-05-07T06:01:57.157446Z","iopub.execute_input":"2022-05-07T06:01:57.157718Z","iopub.status.idle":"2022-05-07T06:02:01.926504Z","shell.execute_reply.started":"2022-05-07T06:01:57.157689Z","shell.execute_reply":"2022-05-07T06:02:01.925778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set up TPU ","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n","metadata":{"id":"m2EnllV2LEkj","outputId":"ef43bedb-0bb2-44b2-97ae-0801e0609fa6","execution":{"iopub.status.busy":"2022-05-07T06:02:38.284535Z","iopub.execute_input":"2022-05-07T06:02:38.2848Z","iopub.status.idle":"2022-05-07T06:02:44.122412Z","shell.execute_reply.started":"2022-05-07T06:02:38.284769Z","shell.execute_reply":"2022-05-07T06:02:44.121537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GET GS BUCKET ADDRESS FOR TFREC\n\nWe need to get gsbucket address from each data to use TFRECs. Gsbucket is a type cloud stroage serviced in google cloud service. Kaggle datasets are stored in gsbuckets. ","metadata":{}},{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\ntrPATH = KaggleDatasets().get_gcs_path('herbarium-2022-train-tfrec-480')\nttPATH = KaggleDatasets().get_gcs_path('herbarium-2022-test-tfrec-480')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:09:21.061692Z","iopub.execute_input":"2022-05-07T06:09:21.062079Z","iopub.status.idle":"2022-05-07T06:12:37.479813Z","shell.execute_reply.started":"2022-05-07T06:09:21.062042Z","shell.execute_reply":"2022-05-07T06:12:37.479183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GET TFREC LIST TRAIN & TEST DATA","metadata":{}},{"cell_type":"code","source":"tr_fns = tf.io.gfile.glob(trPATH +\"/*train*.tfrec\")\ntt_fns = tf.io.gfile.glob(ttPATH +\"/*test*.tfrec\")\nmetadata_fns = tf.io.gfile.glob(trPATH +\"/*metadata*\")\nN_tt_imgs = tfl.count_tfrec_items(tt_fns)\nN_tr_imgs = tfl.count_tfrec_items(tr_fns)\nprint(\"{} training images, and {} testing images.\".format(N_tr_imgs, N_tt_imgs))\nmetadata_fns","metadata":{"id":"x74spoSHDGCg","outputId":"ed2fc0a8-d789-463e-9e76-13dda161a022","execution":{"iopub.status.busy":"2022-05-07T06:14:30.704244Z","iopub.execute_input":"2022-05-07T06:14:30.704496Z","iopub.status.idle":"2022-05-07T06:14:31.145462Z","shell.execute_reply.started":"2022-05-07T06:14:30.704471Z","shell.execute_reply":"2022-05-07T06:14:31.144713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DISPLAYING TRAIN & TEST TFREC","metadata":{}},{"cell_type":"code","source":"### TRAIN TFREC\ntfl.display_sample_from_TFrec(tfrec_PATH = tr_fns[0], TFREC_FORMAT = {\"image\":\"str\",\n                                  \"image_id\":\"str\",\n                                  \"scientificName\":\"int\",\n                                 \"family\":\"int\" ,\n                                  \"genus\":\"int\"\n                                  } , display_size = (15,10)\n                         )\n### TEST TFREC\ntfl.display_sample_from_TFrec(tfrec_PATH = tt_fns[0], TFREC_FORMAT = {\"image\":\"str\",\n                                  \"image_id\":\"int\"}\n                                  , display_size = (15,10)\n                         )","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:22:58.012924Z","iopub.execute_input":"2022-05-07T06:22:58.013213Z","iopub.status.idle":"2022-05-07T06:23:01.318632Z","shell.execute_reply.started":"2022-05-07T06:22:58.013183Z","shell.execute_reply":"2022-05-07T06:23:01.317851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LABEL MAPPING \n\nThe TFREC data labels are bit different from that of the herbarium 2022 metadata. It is because in the metadata it has some missing values due to quality assurance. \n\n### Feature description of the training tfrecord:\n```\n     {\n       'image': 'bytes',\n       'image_id': 'bytes',\n        'family': 'int',\n        'genus': 'int',\n        'scientificName': 'int'\n       }\n```\n### Feature description of the testing tfrecord:\n```\n     {\n       'image': 'bytes',\n       'image_id': 'int'\n       }\n```\n\n\n### Some complications in the training data labels:\n\nFamily, genus, and scientificName are converted to integers in alphabetical order. Please note that the labels are different from the competition metadata.\n\nTherefore, it needs to be converted back to its original mapping (i.e. ```catgeroical_id``` and ```genus_id``` in the competition metadata) when doing the inference. It is because some scientificNames got removed from the label during quilty check (to be precise, four of them). Thus, ```len(categorical_id) = 15501```, but ```max, min = (15504, 0)``` for ```categorical_id``` in the metadata, whereas ```len(scientificName) = 15501```  and ```max, min = (15500, 0)``` for ```scientificName``` in TFREC-480.\n","metadata":{}},{"cell_type":"markdown","source":"\n####  How to revert ```(int): scientificName``` back to ```(int) categorical_id```: \n\nget two mappings below and use later in the inference ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf_train = pd.read_table('../input/herbarium-2022-metadata/herbarium2022_train.tsv')\nmap_name_to_cat_id = dict(zip(df_train.scientificName, df_train.category_id))\nmap_label_to_name = dict(zip(range(15501), sorted(set(df_train.scientificName))))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:42:42.036271Z","iopub.execute_input":"2022-05-07T06:42:42.036585Z","iopub.status.idle":"2022-05-07T06:42:43.889427Z","shell.execute_reply.started":"2022-05-07T06:42:42.036555Z","shell.execute_reply":"2022-05-07T06:42:43.88861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CONFIGURATION","metadata":{}},{"cell_type":"code","source":"config_dict = dict()\nconfig_dict[\"ls_train_files\"] = tr_fns\nconfig_dict[\"tfrec_structure\"] = {\"image\":\"str\",\n                                  \"image_id\":\"str\",\n                                  \"scientificName\":\"int\",\n                                 \"family\":\"int\" ,\n                                  \"genus\":\"int\"\n                                  }\nconfig_dict[\"tfrec_shape\"] =[480, 480]\nconfig_dict[\"resize_resol\"] =[380, 380]\nconfig_dict[\"N_cls\"] = len(set(df_train.scientificName))\nconfig_dict[\"batch_size\"] = 32*strategy.num_replicas_in_sync\n\nNtot_train = tfl.count_tfrec_items(config_dict[\"ls_train_files\"])\ntr_ds = tfl.get_train_ds_tfrec_from_dict(config_dict, \n                                     label_name = \"scientificName\", \n                                     DataRepeat =True) \n\nSTEPS_PER_EPOCH = int(N_tr_imgs/config_dict[\"batch_size\"])\n\nconfig_dict[\"steps_per_epoch\"] = STEPS_PER_EPOCH","metadata":{"id":"uDQCZXcmKMvj","execution":{"iopub.status.busy":"2022-05-07T06:28:26.246975Z","iopub.execute_input":"2022-05-07T06:28:26.247257Z","iopub.status.idle":"2022-05-07T06:28:26.384385Z","shell.execute_reply.started":"2022-05-07T06:28:26.247234Z","shell.execute_reply":"2022-05-07T06:28:26.383784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MODEL\n\nWe are going to use ResNet50 with bottleneck head in this notebook.","metadata":{}},{"cell_type":"code","source":"def get_model(num_classes, resize_resol):\n\n    base_model = tf.keras.applications.resnet50.ResNet50(\n              \n        input_shape=(*resize_resol, 3),\n        include_top=False,\n        pooling=\"avg\",\n        weights=\"imagenet\"\n    )   \n    model=tf.keras.Sequential([\n        base_model,\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(1024, activation=\"relu\"),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n \n    ])\n\n    return model","metadata":{"id":"5QYdUhXQNOVh","execution":{"iopub.status.busy":"2022-05-07T06:47:39.234092Z","iopub.execute_input":"2022-05-07T06:47:39.234691Z","iopub.status.idle":"2022-05-07T06:47:39.24141Z","shell.execute_reply.started":"2022-05-07T06:47:39.234645Z","shell.execute_reply":"2022-05-07T06:47:39.240885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COMPILE","metadata":{}},{"cell_type":"code","source":"from one_cycle_tf import OneCycle\n\nN_EPOCH = 10\ncycle_size = N_EPOCH*STEPS_PER_EPOCH\nmLR = 6e-1\niLR = mLR/30\nocLR = OneCycle(initial_learning_rate=iLR,\n             maximal_learning_rate=mLR,\n             cycle_size = cycle_size,\n             final_lr_scale = 1e-3)\n\nwith strategy.scope():\n    model = get_model(config_dict['N_cls'], config_dict['resize_resol'])\n    model.compile(\n        optimizer= tfa.optimizers.SGDW(learning_rate = ocLR, \n                                       weight_decay = 3e-5, \n                                       momentum = 0.9,\n                                       nesterov = True),\n        loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n        metrics = tfa.metrics.F1Score(num_classes =config_dict['N_cls'])\n    )","metadata":{"id":"Nx8QkaFaNnZv","outputId":"432bb6f8-001e-4a22-a301-c1afb4776252","execution":{"iopub.status.busy":"2022-05-07T06:47:43.483268Z","iopub.execute_input":"2022-05-07T06:47:43.483498Z","iopub.status.idle":"2022-05-07T06:47:57.557229Z","shell.execute_reply.started":"2022-05-07T06:47:43.483476Z","shell.execute_reply":"2022-05-07T06:47:57.556403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:46:42.614283Z","iopub.execute_input":"2022-05-07T06:46:42.614572Z","iopub.status.idle":"2022-05-07T06:46:42.619851Z","shell.execute_reply.started":"2022-05-07T06:46:42.614543Z","shell.execute_reply":"2022-05-07T06:46:42.619311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TRAINING","metadata":{}},{"cell_type":"code","source":"OutFileName = \"ResNet50_bn1024_OneCycle_CE-ls2e-1__\"\noPATH = \"./\"\nhistory = model.fit(\n    tr_ds, \n    epochs= N_EPOCH, steps_per_epoch = config_dict[\"steps_per_epoch\"],\n    verbose=1,\n  callbacks=[tfl.SaveModelHistory(config_dict,\n                               OutFileName,oPATH)])\noPATHw = os.path.join(oPATH, OutFileName+\"_weights.h5\")\nmodel.save_weights(oPATHw) ","metadata":{"id":"qrGo9icbN4GA","outputId":"95c8b86a-182b-4aca-8fe0-3bf56ea81d69","execution":{"iopub.status.busy":"2022-05-07T06:48:02.251486Z","iopub.execute_input":"2022-05-07T06:48:02.252365Z","iopub.status.idle":"2022-05-07T06:49:46.798727Z","shell.execute_reply.started":"2022-05-07T06:48:02.252331Z","shell.execute_reply":"2022-05-07T06:49:46.79749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_history = pd.read_csv(os.path.join(oPATH,OutFileName+\".csv\"))\nimport matplotlib.pyplot as plt\n\nplt.plot(range(10),train_history.loss)\nplt.plot(range(10),train_history.f1_score)","metadata":{"id":"HlJcWLKyUeVp","outputId":"ba75385c-b308-430b-a063-8499fec3fe62"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INFERENCE","metadata":{}},{"cell_type":"code","source":"### Inference functions\ntt_fns = tf.io.gfile.glob(ttPATH + '/*test*.tfrec')\nN_tt_imgs = tfl.count_tfrec_items(tt_fns)\nprint('Dataset: {} test images'.format(N_tt_imgs))\n\ntest_dict = {\"image\":\"str\", \"image_id\":\"int\"}\n\nAUTO = tf.data.experimental.AUTOTUNE\n\ndef _load_tfrec_dataset(filenames, tfrec_format, tfrec_sizes, label_name, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    dataset = dataset.map(lambda Example: tfl.read_tfrecord(Example, \n                                                        TFREC_FORMAT = tfrec_format, \n                                                        TFREC_SIZES = tfrec_sizes,\n                                                        LABEL_NAME = label_name))\n    return dataset\n\ndef prepare_test_images(image, label, resize_factor):\n    img = tf.image.central_crop(image, central_fraction = 0.9)\n    img = tf.image.resize( img, size = resize_factor)\n    return img, label\n\ndef get_test_ds_tfrec(LS_FILENAMES, TFREC_DICT, TFREC_SIZES, RESIZE_FACTOR, NUM_CLASSES, BATCH_SIZE, LABEL_NAME, MoreAugment = False):\n\n    tfrec_format = tfl.tfrec_format_generator(TFREC_DICT)\n    dataset = _load_tfrec_dataset(LS_FILENAMES, tfrec_format = tfrec_format, tfrec_sizes = TFREC_SIZES, \n                                  label_name = LABEL_NAME)\n    dataset = dataset.map(tfl.normalize_RGB, num_parallel_calls=AUTO).prefetch(AUTO)\n    dataset = dataset.map(lambda image, label: prepare_test_images(image, label, resize_factor = RESIZE_FACTOR), num_parallel_calls=AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n","metadata":{"id":"11JsCVX1bs8s","outputId":"35f8de45-14a9-4f3f-d183-9a15fba6f7cf","execution":{"iopub.status.busy":"2022-05-07T06:51:18.878775Z","iopub.execute_input":"2022-05-07T06:51:18.879927Z","iopub.status.idle":"2022-05-07T06:51:19.037221Z","shell.execute_reply.started":"2022-05-07T06:51:18.879878Z","shell.execute_reply":"2022-05-07T06:51:19.036287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tt_ds = get_test_ds_tfrec( LS_FILENAMES = tt_fns,\n                              TFREC_DICT = test_dict,\n                              TFREC_SIZES =  config_dict[\"tfrec_shape\"],\n                              RESIZE_FACTOR = config_dict[\"resize_resol\"],\n                              NUM_CLASSES = config_dict[\"N_cls\"],\n                              BATCH_SIZE = config_dict[\"batch_size\"],\n                            LABEL_NAME = \"image_id\"\n                          )\n\ntest_images_ds = tt_ds.map(lambda image, idnum: image)\ntest_Ids_ds = tt_ds.map(lambda image, idnum: idnum)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:51:21.851845Z","iopub.execute_input":"2022-05-07T06:51:21.85255Z","iopub.status.idle":"2022-05-07T06:51:22.012941Z","shell.execute_reply.started":"2022-05-07T06:51:21.852482Z","shell.execute_reply":"2022-05-07T06:51:22.01217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf_train = pd.read_table('../input/herbarium-2022-metadata/herbarium2022_train.tsv')\nmap_name_to_cat_id = dict(zip(df_train.scientificName, df_train.category_id))\nmap_label_to_name = dict(zip(range(15501), sorted(set(df_train.scientificName))))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:41:23.342937Z","iopub.execute_input":"2022-05-07T06:41:23.343213Z","iopub.status.idle":"2022-05-07T06:41:25.823329Z","shell.execute_reply.started":"2022-05-07T06:41:23.343187Z","shell.execute_reply":"2022-05-07T06:41:25.822296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\n\npredictions = np.zeros(N_tt_imgs, dtype=np.int32)\n\nfor i, image in tqdm(enumerate(test_images_ds), total= (N_tt_imgs//config_dict[\"batch_size\"] + 1)):\n    idx1 = i*config_dict[\"batch_size\"]\n    if (idx1 + config_dict[\"batch_size\"]) > N_tt_imgs:\n        idx2 = N_tt_imgs\n    else:\n        idx2 = idx1 + config_dict[\"batch_size\"]\n    predictions[idx1:idx2] = np.argmax(model.predict_on_batch(image), axis=-1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_image_nums = np.zeros(N_tt_imgs, dtype=np.int32)\n\nfor i, image_nums in tqdm(enumerate(test_Ids_ds), total= (N_tt_imgs//config_dict[\"batch_size\"] + 1)):\n    idx1 = i*config_dict[\"batch_size\"]\n    if (idx1 + config_dict[\"batch_size\"]) > N_tt_imgs:\n        idx2 = N_tt_imgs\n    else:\n        idx2 = idx1 + config_dict[\"batch_size\"]\n    predict_image_nums[idx1:idx2] = image_nums\n\nprediction_cat_id = [map_name_to_cat_id[map_label_to_name[ele]] for ele in predictions]\n\npd.DataFrame({\"Id\":predict_image_nums,\"Predicted\":prediction_cat_id}).to_csv(\"sample_submissions.csv\",index=False )\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T06:52:41.994333Z","iopub.execute_input":"2022-05-07T06:52:41.995132Z","iopub.status.idle":"2022-05-07T06:52:58.327229Z","shell.execute_reply.started":"2022-05-07T06:52:41.995093Z","shell.execute_reply":"2022-05-07T06:52:58.325962Z"},"trusted":true},"execution_count":null,"outputs":[]}]}