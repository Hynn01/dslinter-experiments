{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Winning Team Submission Traces\n\nThis notebook shows public/private submission scores over time for winning teams of all the main Kaggle competitions. (Excluded are: winners with only 1 or 2 submissions.)\n\nEvaluation metrics vary over competitions and the direction of 'better' submissions changes - to indicate this, the peak score in each competition for both public & private scores are shown as a dotted line.\n\nPublic leaderboard scores are in blue and private in red; and the submissions that are used for the public and private LB are marked with a dot.\n\nThe final week of each competition is now highlighted.\n\nSo, the name of the game when Kaggling is to get the red line, the red dotted line, and the red point all to coincide at the same point, that is: to select your submission with the best private test set score.\n\nSee also [this notebook][1] that generates these traces for all competitions a user has entered - feel free to fork it and try it out on your own competition history!\n\nYou can find the [stories behind most of these winning team solutions in this extensive notebook][2].\n\n## Notes\n\nSome plots like <a href=\"#santander-product-recommendation\">Santander Product Recommendation</a> and <a href=\"#predicting-red-hat-business-value\">Red Hat</a> are hard to see the fine details because many of the submissions are from [leaderboard probing to scrape more information about the test set][3].\n\n<a href=\"#facebook-v-predicting-check-ins\">Other plots</a> may look like this but are in fact \"mini submissions\" &mdash; with a metric like MAP you can submit only 10% of predictions and scale up your score to check your progress and iterate much faster (this can save *hours* of time when the the test set is very large.)\n\n## A Story\n\n\nAs shared by [Giulio](https://www.kaggle.com/adjgiulio) on [Quora](https://www.quora.com/How-did-you-become-a-Kaggle-Master-and-what-are-the-steps-resources-you-used-to-get-there) about an early [Avito competition][4]:\n\n<blockquote>\nIn the Avito competition I won, my teammate and I had a very good approach from the get going. We were in and out of the top-5 for most of the time. Every time weâ€™d go in the top 3, some of the other top teams would merge and surpass us. With two weeks to go, and one week to the merger deadline, we came across a novel approach based on semi-supervised learning that would have put us in 1st (based on cross validation data we had). If we had made that submission I have 0 doubts some of the other teams would have merged and eventually won. So, we intentionally held off our best submission, slowly improving by submitting submissions where part of the predictions were replaced by random numbers. And we waited, and waited, and fell and fell on the leaderboard. Then the merger deadline came, and the day after (and the whole week after) was glorious. We submitted our best submission and at that point it was all over.\n</blockquote>\n\nCan we see this in the [plot][4]?\n\n\n [1]: https://www.kaggle.com/jtrotman/user-competition-submission-traces\n [2]: https://www.kaggle.com/jtrotman/high-ranking-solution-posts\n [3]: https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/23786\n [4]: #avito-prohibited-content\n "},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"import gc, os, sys, time\nimport pandas as pd, numpy as np\nfrom unidecode import unidecode\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom IPython.display import HTML, display\n\nCSV_DIR = Path('..', 'input', 'meta-kaggle')\nif not CSV_DIR.is_dir():\n    CSV_DIR = Path('..', 'input')\n\ndef read_csv_filtered(csv, col, values):\n    dfs = [df.loc[df[col].isin(values)]\n           for df in pd.read_csv(CSV_DIR / csv, chunksize=100000, low_memory=False)]\n    return pd.concat(dfs, axis=0)\n\ncomps = pd.read_csv(CSV_DIR / 'Competitions.csv').set_index('Id')\ncomps = comps.query(\"HostSegmentTitle != 'InClass'\")\nidx = comps.EvaluationAlgorithmName.isnull()\ncomps.loc[idx, 'EvaluationAlgorithmName'] = comps.loc[idx, 'EvaluationAlgorithmAbbreviation']\n\ncomps['EvaluationLabel'] = comps.EvaluationAlgorithmAbbreviation\nidx = comps.EvaluationLabel.str.len() > 30\ncomps.loc[idx, 'EvaluationLabel'] = comps.loc[idx, 'EvaluationLabel'].str.replace(r'[^A-Z\\d\\-]', '', regex=True)\n\ncomps['DeadlineDate'] = pd.to_datetime(comps.DeadlineDate)\ncomps['EnabledDate'] = pd.to_datetime(comps.EnabledDate)\ncomps['DeadlineDateText'] = comps.DeadlineDate.dt.strftime('%c')\ncomps['EnabledDateText'] = comps.EnabledDate.dt.strftime('%c')\ncomps['Year'] = comps.DeadlineDate.dt.year\ncomps['RewardQuantity'].fillna('', inplace=True)\ncomps['Days'] = (comps.DeadlineDate - comps.EnabledDate) / pd.Timedelta(1, 'd')\ncomps['FinalWeek'] = (comps.DeadlineDate - pd.Timedelta(1, 'w'))\n\nteams = read_csv_filtered('Teams.csv', 'CompetitionId', comps.index).set_index('Id')\n# Just the winning teams\nteams = teams.query('PrivateLeaderboardRank==1').copy()\n\ntmemb = read_csv_filtered('TeamMemberships.csv', 'TeamId', teams.index).set_index('Id')\nusers = read_csv_filtered('Users.csv', 'Id', tmemb.UserId)\ntmemb = tmemb.merge(users, left_on='UserId', right_on='Id')\n\n# Submissions\nsubs = read_csv_filtered('Submissions.csv', 'TeamId', tmemb.TeamId)\nsubs = subs.rename(columns={'PublicScoreFullPrecision': 'Public'})\nsubs = subs.rename(columns={'PrivateScoreFullPrecision': 'Private'})\nsubs['SubmissionDate'] = pd.to_datetime(subs.SubmissionDate)\n\nasfloats = ['PublicScoreLeaderboardDisplay',\n            'Public',\n            'PrivateScoreLeaderboardDisplay',\n            'Private',]\n\nsubs[asfloats] = subs[asfloats].astype(float)\n# subs.IsAfterDeadline.mean()\n\nsubs = subs.query('not IsAfterDeadline').copy()\nsubs['CompetitionId'] = subs.TeamId.map(teams.CompetitionId)\n# subs['CompetitionId'].nunique()\n\n# values some competitions use as invalid scores\nfor bad in [99, 999999]:\n    for c in asfloats:\n        idx = (subs[c] == bad)\n        subs.loc[idx, c] = subs.loc[idx, c].replace({bad: np.nan})\n\n# Display order: most recent competitions first\nsubs = subs.sort_values(['CompetitionId', 'Id'], ascending=[False, True])"},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"plt.rc(\"figure\", figsize=(14, 6))\nplt.rc(\"font\", size=14)\nplt.rc(\"axes\", xmargin=0.01)\nplt.rc(\"axes\", edgecolor='#606060')\n\n\ndef find_range(scores):\n    scores = sorted(scores)\n    n = len(scores)\n    max_i = n - 1\n    for i in range(n // 2, n):\n        best = scores[:i]\n        if len(best):\n            m = np.mean(best)\n            s = np.std(best)\n            if s != 0:\n                z = (scores[i] - m) / s\n                if abs(z) < 3:\n                    max_i = i\n    return scores[0], scores[max_i]\n\n\ndef get_range(df):\n    comp_id = df.iloc[0].CompetitionId\n    c = comps.loc[comp_id]\n\n    mul = -1 if c.EvaluationAlgorithmIsMax else 1\n    a, b = find_range(df.Public.dropna().values * mul)\n    A, B = find_range(df.Private.dropna().values * mul)\n\n    A = min(a, A) * mul\n    B = max(b, B) * mul\n\n    R = (B - A)\n    B += R / 20\n    A -= R / 20\n    return min(A, B), max(A, B)"},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"COLORS = dict(Public='blue', Private='red')\n\nfor i, (comp_id, subs_df) in enumerate(subs.groupby('CompetitionId', sort=False)):\n\n    if subs_df.shape[0] < 3:\n        continue\n    if subs_df.Public.count() < 1:\n        continue\n    if subs_df.Private.count() < 1:\n        continue\n    \n    c = comps.loc[comp_id]\n    df = subs_df.sort_values('Id').reset_index()\n    team_id = df.iloc[0].TeamId\n    f = 'max' if c.EvaluationAlgorithmIsMax else 'min'\n        \n    mcols = ['UserName', 'RequestDate', 'DisplayName', 'SubCount',\n             'RegisterDate', 'PerformanceTier']\n    tcols = ['TeamName', 'ScoreFirstSubmittedDate', 'LastSubmissionDate',\n             'PublicLeaderboardRank', 'PrivateLeaderboardRank']\n\n    team = teams.query(f'CompetitionId=={c.name}').iloc[0]\n    members = tmemb.query(f'TeamId=={team_id}').copy()\n    members['SubCount'] = members.UserId.map(df.SubmittedUserId.value_counts()).fillna(0)\n    members = members[mcols].set_index('UserName')\n    members = members.T.dropna(how='all').T\n    members.columns = members.columns.str.replace(r'([a-z])([A-Z])', r'\\1<br/>\\2', regex=True)\n\n    markup = (\n        '<h1 id=\"{Slug}\">{Title}</h1>'\n        '<p>'\n        'Type: {HostSegmentTitle} &mdash; <i>{Subtitle}</i>'\n        '<br/>'\n        '<a href=\"https://www.kaggle.com/c/{Slug}/leaderboard\">Leaderboard</a>'\n        '<br/>'\n        'Dates: <b>{EnabledDateText}</b> &mdash; <b>{DeadlineDateText}</b>'\n        '<br/>'\n        '<b>{TotalTeams}</b> teams; <b>{TotalCompetitors}</b> competitors; '\n        '<b>{TotalSubmissions}</b> submissions'\n        '<br/>'\n        'Leaderboard percentage: <b>{LeaderboardPercentage}</b>'\n        '<br/>'\n        'Evaluation: <a title=\"{EvaluationAlgorithmDescription}\">{EvaluationAlgorithmName}</a>'\n        '<br/>'\n        'Reward: <b>{RewardType}</b> {RewardQuantity} [{NumPrizes} prizes]'\n        '<br/>'\n        ).format(**c)\n\n    markup += f'<h3>Team Members</h3>'\n    markup += members.to_html(index_names=False, notebook=True, escape=False, na_rep='')\n    markup += f'<h3>Submissions</h3>'\n    display(HTML(markup))\n    \n    title = c.Title\n    title += (' \"{TeamName}\"'\n              ' - [public {PublicLeaderboardRank:.0f} '\n              '| private {PrivateLeaderboardRank:.0f}]').format(**team)\n    \n    for t in ['Public', 'Private']:\n        ax = df[t].plot(legend=True, color=COLORS[t])\n\n        ser = df.Id.isin(teams[f'{t}LeaderboardSubmissionId'])\n        q = df.loc[ser]\n        plt.scatter(np.where(ser)[0], q[t], color=COLORS[t])\n\n        # dotted line of peak score\n        xs = np.arange(df.shape[0])\n        yb = np.ones(df.shape[0])\n        plt.plot(xs, yb * df[t].apply(f), linestyle=':', color=COLORS[t])\n\n    if c.Days > 7:\n        last_week = (df['SubmissionDate'] >= c.FinalWeek)\n        week_markers = np.where(last_week)[0]\n        if len(week_markers):\n            plt.axvspan(week_markers.min(), week_markers.max(), color='k', alpha=0.1)\n\n    if df.shape[0] > 4:\n        bottom, top = get_range(df)\n        plt.ylim(bottom, top)\n    plt.title(unidecode(title))\n    plt.ylabel(c.EvaluationLabel)\n    plt.xlabel('Submission Index')\n    plt.xlim(-1, df.shape[0])\n    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n    plt.tight_layout()\n    plt.show()"},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true},"outputs":[],"source":"_ = \"\"\"\nRe-run to include recently completed competitions:\n\n    Slug:feedback-prize-2021\n    Slug:tabular-playground-series-mar-2022\n    Slug:mens-march-mania-2022\n    Slug:womens-march-mania-2022\n    Slug:kore-2022-beta\n    Slug:happy-whale-and-dolphin\n\n\n\"\"\""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":2}