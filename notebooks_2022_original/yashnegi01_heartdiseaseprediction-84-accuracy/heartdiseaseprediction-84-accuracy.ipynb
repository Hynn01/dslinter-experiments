{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T06:59:39.306328Z","iopub.execute_input":"2022-05-08T06:59:39.307021Z","iopub.status.idle":"2022-05-08T06:59:39.315683Z","shell.execute_reply.started":"2022-05-08T06:59:39.306945Z","shell.execute_reply":"2022-05-08T06:59:39.315083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.338225Z","iopub.execute_input":"2022-05-08T06:59:39.338818Z","iopub.status.idle":"2022-05-08T06:59:39.344943Z","shell.execute_reply.started":"2022-05-08T06:59:39.33878Z","shell.execute_reply":"2022-05-08T06:59:39.344203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/heart-failure-prediction/heart.csv\")\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.376993Z","iopub.execute_input":"2022-05-08T06:59:39.377844Z","iopub.status.idle":"2022-05-08T06:59:39.402527Z","shell.execute_reply.started":"2022-05-08T06:59:39.377795Z","shell.execute_reply":"2022-05-08T06:59:39.401706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.414191Z","iopub.execute_input":"2022-05-08T06:59:39.414507Z","iopub.status.idle":"2022-05-08T06:59:39.42566Z","shell.execute_reply.started":"2022-05-08T06:59:39.41447Z","shell.execute_reply":"2022-05-08T06:59:39.424755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.438932Z","iopub.execute_input":"2022-05-08T06:59:39.439496Z","iopub.status.idle":"2022-05-08T06:59:39.449443Z","shell.execute_reply.started":"2022-05-08T06:59:39.439457Z","shell.execute_reply":"2022-05-08T06:59:39.448544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_feat = []\ncol = list(data.columns)\nfor i in col:\n    if data[i].dtype==\"object\":\n        cat_feat.append(i)\ncat_feat","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.472941Z","iopub.execute_input":"2022-05-08T06:59:39.473621Z","iopub.status.idle":"2022-05-08T06:59:39.483018Z","shell.execute_reply.started":"2022-05-08T06:59:39.473573Z","shell.execute_reply":"2022-05-08T06:59:39.482029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in cat_feat:\n    print(data[i].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.499082Z","iopub.execute_input":"2022-05-08T06:59:39.499862Z","iopub.status.idle":"2022-05-08T06:59:39.507458Z","shell.execute_reply.started":"2022-05-08T06:59:39.499817Z","shell.execute_reply":"2022-05-08T06:59:39.50679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.521951Z","iopub.execute_input":"2022-05-08T06:59:39.522596Z","iopub.status.idle":"2022-05-08T06:59:39.530152Z","shell.execute_reply.started":"2022-05-08T06:59:39.522535Z","shell.execute_reply":"2022-05-08T06:59:39.529519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [1, 2, 6, 8, 10])], remainder=\"passthrough\")\nX = np.array(ct.fit_transform(X))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.545976Z","iopub.execute_input":"2022-05-08T06:59:39.546529Z","iopub.status.idle":"2022-05-08T06:59:39.556612Z","shell.execute_reply.started":"2022-05-08T06:59:39.54649Z","shell.execute_reply":"2022-05-08T06:59:39.555968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.572285Z","iopub.execute_input":"2022-05-08T06:59:39.572723Z","iopub.status.idle":"2022-05-08T06:59:39.579084Z","shell.execute_reply.started":"2022-05-08T06:59:39.572691Z","shell.execute_reply":"2022-05-08T06:59:39.578278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nxg = XGBClassifier()\nxg.fit(X_train, y_train)\ny_predxg = xg.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:39.615552Z","iopub.execute_input":"2022-05-08T06:59:39.616371Z","iopub.status.idle":"2022-05-08T06:59:40.005547Z","shell.execute_reply.started":"2022-05-08T06:59:39.616317Z","shell.execute_reply":"2022-05-08T06:59:40.004827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(max_iter=10000)\nlr.fit(X_train, y_train)\ny_predlr = lr.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:40.007086Z","iopub.execute_input":"2022-05-08T06:59:40.007562Z","iopub.status.idle":"2022-05-08T06:59:40.241154Z","shell.execute_reply.started":"2022-05-08T06:59:40.007525Z","shell.execute_reply":"2022-05-08T06:59:40.240052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=13,metric=\"minkowski\", p=2)\nknn.fit(X_train, y_train)\ny_predknn = knn.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:40.24263Z","iopub.execute_input":"2022-05-08T06:59:40.243042Z","iopub.status.idle":"2022-05-08T06:59:40.30027Z","shell.execute_reply.started":"2022-05-08T06:59:40.24298Z","shell.execute_reply":"2022-05-08T06:59:40.299283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\ny_prednb = nb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:40.303024Z","iopub.execute_input":"2022-05-08T06:59:40.303722Z","iopub.status.idle":"2022-05-08T06:59:40.315097Z","shell.execute_reply.started":"2022-05-08T06:59:40.303669Z","shell.execute_reply":"2022-05-08T06:59:40.313983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=20, criterion=\"entropy\")\nrf.fit(X_train, y_train)\ny_predrf = rf.predict(X_test) ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:59:40.317321Z","iopub.execute_input":"2022-05-08T06:59:40.317957Z","iopub.status.idle":"2022-05-08T06:59:40.39056Z","shell.execute_reply.started":"2022-05-08T06:59:40.317908Z","shell.execute_reply":"2022-05-08T06:59:40.389582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\nxgmean = cross_val_score(estimator=xg, X=X_train, y=y_train, cv =10)\nlogimean = cross_val_score(estimator=lr, X=X_train, y=y_train, cv =10)\nknnmean = cross_val_score(estimator=knn, X=X_train, y=y_train, cv =10)\nnbmean = cross_val_score(estimator=nb, X=X_train, y=y_train, cv =20)\nrfmean = cross_val_score(estimator=rf, X=X_train, y=y_train, cv =20)\n\nprint(f\"Mean Absolute Error of XGboost : {mean_absolute_error(y_test, y_predxg)}\")\nprint(f\"Accuracy of XGBoost : {xgmean.mean()}\\n\")\n\nprint(f\"Mean Absolute Error of Logistic Regression : {mean_absolute_error(y_test, y_predlr)}\")\nprint(f\"Accuracy of Logistic Regression : {logimean.mean()}\\n\")\n\nprint(f\"Mean Absolute Error of KNN : {mean_absolute_error(y_test, y_predknn)}\")\nprint(f\"Accuracy of KNN : {knnmean.mean()}\\n\")\n\nprint(f\"Mean Absolute Error of Naicve Bayes : {mean_absolute_error(y_test, y_prednb)}\")\nprint(f\"Accuracy of Naive Bayes : {nbmean.mean()}\\n\")\n\nprint(f\"Mean Absolute Error of Random Forest : {mean_absolute_error(y_test, y_predrf)}\")\nprint(f\"Accuracy of Random Forest : {rfmean.mean()}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T07:00:26.841098Z","iopub.execute_input":"2022-05-08T07:00:26.841413Z","iopub.status.idle":"2022-05-08T07:00:33.848411Z","shell.execute_reply.started":"2022-05-08T07:00:26.841379Z","shell.execute_reply":"2022-05-08T07:00:33.84761Z"},"trusted":true},"execution_count":null,"outputs":[]}]}