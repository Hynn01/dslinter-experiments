{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"hello \nIn this notebook, I have taken some of the CNN architectures and tried to implement them layer by layer.\nI hope it will be useful for you","metadata":{}},{"cell_type":"code","source":"# import the libraries as shown below\n \nimport cv2\nimport random\nimport tensorflow\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as k\nfrom tensorflow.keras.models import Model \nfrom tensorflow.keras.layers import SpatialDropout2D","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:17:45.39278Z","iopub.execute_input":"2022-04-23T11:17:45.393094Z","iopub.status.idle":"2022-04-23T11:17:45.399661Z","shell.execute_reply.started":"2022-04-23T11:17:45.393059Z","shell.execute_reply":"2022-04-23T11:17:45.398854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **AlexNet**","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/700/1*vXBvV_Unz3JAxytc5iSeoQ.png)","metadata":{}},{"cell_type":"code","source":"def alexnet(input_shape):\n    input = tensorflow.keras.layers.Input(input_shape)\n    x = tensorflow.keras.layers.Conv2D(96, (11,11), strides=4)(input)\n    x = tensorflow.keras.layers.MaxPooling2D((3,3), strides=2, padding =\"same\")(x)\n    \n    x = tensorflow.keras.layers.Conv2D(256, (5,5), strides=1, padding =\"same\")(x)\n    x = tensorflow.keras.layers.MaxPooling2D((5,5), strides=2, padding =\"same\")(x)\n    \n    x = tensorflow.keras.layers.Conv2D(384, (3,3), strides=1, padding =\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(384, (3,3), strides=1, padding =\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(256, (3,3), strides=1, padding =\"same\")(x)\n    x = tensorflow.keras.layers.MaxPooling2D((3,3), strides=2, padding =\"same\")(x)\n    \n    x = tensorflow.keras.layers.Dense(9216)(x)\n    x = tensorflow.keras.layers.Dense(4096)(x)\n    x = tensorflow.keras.layers.Dense(4096)(x)\n    \n    model = tensorflow.keras.models.Model(input,x)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:52:12.95889Z","iopub.execute_input":"2022-04-23T10:52:12.959208Z","iopub.status.idle":"2022-04-23T10:52:12.971287Z","shell.execute_reply.started":"2022-04-23T10:52:12.95917Z","shell.execute_reply":"2022-04-23T10:52:12.970567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (227,227,3)\nm = alexnet(input_shape)\nm.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:52:21.248095Z","iopub.execute_input":"2022-04-23T10:52:21.248358Z","iopub.status.idle":"2022-04-23T10:52:21.606757Z","shell.execute_reply.started":"2022-04-23T10:52:21.248329Z","shell.execute_reply":"2022-04-23T10:52:21.605743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **VGG16** \n![](https://miro.medium.com/max/700/1*1gA7d9svzp_jRHPsyy63Iw.png)","metadata":{}},{"cell_type":"code","source":"def vgg16(input_shape):\n    input = tensorflow.keras.layers.Input(input_shape)\n    \n    x = tensorflow.keras.layers.Conv2D(64,(3,3),strides=1, padding=\"same\")(input)\n    x = tensorflow.keras.layers.Conv2D(64,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n    \n    x = tensorflow.keras.layers.Conv2D(128,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(128,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n    \n    x = tensorflow.keras.layers.Conv2D(256,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(256,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(256,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n    \n    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n    \n    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n    x = tensorflow.keras.layers.Flatten()(x)\n    x = tensorflow.keras.layers.Dense(4096)(x)\n    x = tensorflow.keras.layers.Dense(4096)(x)\n    x = tensorflow.keras.layers.Dense(1000,activation='softmax')(x)\n  \n    model = tensorflow.keras.models.Model(input, x)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:52:30.678236Z","iopub.execute_input":"2022-04-23T10:52:30.678691Z","iopub.status.idle":"2022-04-23T10:52:30.697685Z","shell.execute_reply.started":"2022-04-23T10:52:30.67865Z","shell.execute_reply":"2022-04-23T10:52:30.696746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (224,224,3)\nmodel = vgg16(input_shape)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:52:38.748165Z","iopub.execute_input":"2022-04-23T10:52:38.74848Z","iopub.status.idle":"2022-04-23T10:52:39.584925Z","shell.execute_reply.started":"2022-04-23T10:52:38.748444Z","shell.execute_reply":"2022-04-23T10:52:39.584226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **GoogleNet/Inception** \n![](https://cdn-images-1.medium.com/max/1600/1*CWJGqfLiVjHAIan82nPbjg.png)","metadata":{}},{"cell_type":"code","source":"def googlenet_inception(input_shape):\n    def inception_block(x,f):\n        t1 = tensorflow.keras.layers.Conv2D(f[0], 1, activation='relu')(x)\n        t2 = tensorflow.keras.layers.Conv2D(f[1], 1, activation='relu')(x)\n        t2 = tensorflow.keras.layers.Conv2D(f[2], 3, padding='same', activation='relu')(t2)\n        t3 = tensorflow.keras.layers.Conv2D(f[3], 1, activation='relu')(x)\n        t3 = tensorflow.keras.layers.Conv2D(f[4], 5, padding='same', activation='relu')(t3)\n        t4 = tensorflow.keras.layers.MaxPooling2D(3, 1, padding='same')(x)\n        t4 = tensorflow.keras.layers.Conv2D(f[5], 1, activation='relu')(t4)\n        output = tensorflow.keras.layers.Concatenate()([t1, t2, t3, t4])\n        return output\n\n    input = tensorflow.keras.layers.Input(input_shape)\n    \n    x = tensorflow.keras.layers.Conv2D(64, (7,7),strides = 2, padding='same', activation='relu')(input)\n    x = tensorflow.keras.layers.MaxPooling2D((3,3),strides = 2, padding='same')(x)\n    x = tensorflow.keras.layers.Conv2D(64, (1,1),activation='relu')(x)\n    x = tensorflow.keras.layers.Conv2D(192, (3,3), padding='same', activation='relu')(x)\n    x = tensorflow.keras.layers.MaxPooling2D((3,3),strides = 2)(x)\n    \n    x = inception_block(x, [64, 96, 128, 16, 32, 32])\n    x = inception_block(x, [128, 128, 192, 32, 96, 64])\n    x = tensorflow.keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n    \n    x = inception_block(x, [192, 96, 208, 16, 48, 64])\n    x = inception_block(x, [160, 112, 224, 24, 64, 64])\n    x = inception_block(x, [128, 128, 256, 24, 64, 64])\n    x = inception_block(x, [112, 144, 288, 32, 64, 64])\n    x = inception_block(x, [256, 160, 320, 32, 128, 128])\n    x = tensorflow.keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n\n    x = inception_block(x, [256, 160, 320, 32, 128, 128])\n    x = inception_block(x, [384, 192, 384, 48, 128, 128])\n  \n    x = tensorflow.keras.layers.AveragePooling2D(7, strides=1)(x)\n    x = tensorflow.keras.layers.Dropout(0.4)(x)\n  \n    x = tensorflow.keras.layers.Flatten()(x)\n    x = tensorflow.keras.layers.Dense(1000, activation='softmax')(x)\n\n    \n    model = tensorflow.keras.models.Model(input,x)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:52:46.951021Z","iopub.execute_input":"2022-04-23T10:52:46.951462Z","iopub.status.idle":"2022-04-23T10:52:46.970458Z","shell.execute_reply.started":"2022-04-23T10:52:46.951431Z","shell.execute_reply":"2022-04-23T10:52:46.969841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (227,227,3)\nmodel = googlenet_inception(input_shape)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:52:56.309568Z","iopub.execute_input":"2022-04-23T10:52:56.309998Z","iopub.status.idle":"2022-04-23T10:52:56.949104Z","shell.execute_reply.started":"2022-04-23T10:52:56.309965Z","shell.execute_reply":"2022-04-23T10:52:56.948259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MobileNet**\n![](https://miro.medium.com/max/856/1*2IHiEn6SYGgz-p80jhYeGg.png)","metadata":{}},{"cell_type":"code","source":"def MobileNet(input_shape, nb_classes):\n    input = tensorflow.keras.layers.Input(input_shape)\n    x = tensorflow.keras.layers.Conv2D(32, (3,3), strides=2, padding =\"same\")(input)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(64, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=2, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(128, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(128, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=2, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(256, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(256, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=2, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n     # five blocks\n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    # end five blocks\n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=2, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(1024, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    \n    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    x = tensorflow.keras.layers.Conv2D(1024, (1,1), strides=1, padding='same')(x)\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    x = tensorflow.keras.layers.ReLU()(x)\n    \n    \n    x = tensorflow.keras.layers.GlobalAvgPool2D()(x)\n    output = Dense(nb_classes, activation='softmax')(x)\n    \n    model = tensorflow.keras.models.Model(input,output)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:53:08.800723Z","iopub.execute_input":"2022-04-23T10:53:08.801023Z","iopub.status.idle":"2022-04-23T10:53:08.843741Z","shell.execute_reply.started":"2022-04-23T10:53:08.800991Z","shell.execute_reply":"2022-04-23T10:53:08.842823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (224,224,3)\nmodel = MobileNet(input_shape,1000)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:53:17.769489Z","iopub.execute_input":"2022-04-23T10:53:17.769826Z","iopub.status.idle":"2022-04-23T10:53:18.371825Z","shell.execute_reply.started":"2022-04-23T10:53:17.76979Z","shell.execute_reply":"2022-04-23T10:53:18.370987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **ResNet 50**\n![](https://iq.opengenus.org/content/images/2020/03/Screenshot-from-2020-03-20-15-49-54.png)","metadata":{}},{"cell_type":"code","source":"# ResNet model creation\ndef ResNet50(input_w,input_h):\n  if tensorflow.keras.backend.image_data_format() == 'channels_first':\n    input_shape = (3, input_w, input_h)\n  else:\n    input_shape = (input_w, input_h,3)\n\n \n  model_input = tensorflow.keras.layers.Input(shape=input_shape)\n  \n \n  ########### Block 1 ###########\n  block_1 = tensorflow.keras.layers.Conv2D(64,kernel_size=7,strides=2, padding='same')(model_input)\n  block_1 = tensorflow.keras.layers.BatchNormalization()(block_1)\n  block_1 = tensorflow.keras.layers.ReLU()(block_1)\n  block_1 = tensorflow.keras.layers.MaxPooling2D(3, strides=2, padding='same')(block_1)\n ############ Block 2 #############\n ### conv_block ###\n  block_2_1 = tensorflow.keras.layers.BatchNormalization()(block_1)\n  block_2_1 = tensorflow.keras.layers.ReLU()(block_2_1)\n  block_2_1 = tensorflow.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_1)\n  \n  block_2_1 = tensorflow.keras.layers.BatchNormalization()(block_2_1)\n  block_2_1 = tensorflow.keras.layers.ReLU()(block_2_1)\n  block_2_1 = tensorflow.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_1)\n  \n  block_2_1 = tensorflow.keras.layers.BatchNormalization()(block_2_1)\n  block_2_1 = tensorflow.keras.layers.ReLU()(block_2_1)\n  block_2_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_1)\n\n  sh_cut_2 = tensorflow.keras.layers.BatchNormalization()(block_1)\n  sh_cut_2 = tensorflow.keras.layers.ReLU()(sh_cut_2)\n  sh_cut_2 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(sh_cut_2)\n\n  stg1_blok_2_1 = tensorflow.keras.layers.add([sh_cut_2, block_2_1])\n  ### identity_block 1 ###\n  block_2_2 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_2_1)\n  block_2_2 = tensorflow.keras.layers.ReLU()(block_2_2)\n  block_2_2 = tensorflow.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_2)\n  \n  block_2_2 = tensorflow.keras.layers.BatchNormalization()(block_2_2)\n  block_2_2 = tensorflow.keras.layers.ReLU()(block_2_2)\n  block_2_2 = tensorflow.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_2)\n  \n  block_2_2 = tensorflow.keras.layers.BatchNormalization()(block_2_2)\n  block_2_2 = tensorflow.keras.layers.ReLU()(block_2_2)\n  block_2_2 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_2)\n\n  stg1_blok_2_2 = tensorflow.keras.layers.add([stg1_blok_2_1, block_2_2])\n\n  ### identity_block 2 ###\n  block_2_3 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_2_2)\n  block_2_3 = tensorflow.keras.layers.ReLU()(block_2_3)\n  block_2_3 = tensorflow.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_3)\n  \n  block_2_3 = tensorflow.keras.layers.BatchNormalization()(block_2_3)\n  block_2_3 = tensorflow.keras.layers.ReLU()(block_2_3)\n  block_2_3 = tensorflow.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_3)\n  \n  block_2_3 = tensorflow.keras.layers.BatchNormalization()(block_2_3)\n  block_2_3 = tensorflow.keras.layers.ReLU()(block_2_3)\n  block_2_3 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_3)\n\n  stg1_blok_2_3 = tensorflow.keras.layers.add([stg1_blok_2_2, block_2_3])\n\n  block_1 = tensorflow.keras.layers.BatchNormalization()(block_1)\n  block_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_1)\n\n  short_cut_2 = tensorflow.keras.layers.add([stg1_blok_2_3, block_1])\n\n############ Block 3 #############\n  ### 1 : conv_block ###\n  block_3_1 = tensorflow.keras.layers.BatchNormalization()(short_cut_2)\n  block_3_1 = tensorflow.keras.layers.ReLU()(block_3_1)\n  block_3_1 = tensorflow.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_1)\n  \n  block_3_1 = tensorflow.keras.layers.BatchNormalization()(block_3_1)\n  block_3_1 = tensorflow.keras.layers.ReLU()(block_3_1)\n  block_3_1 = tensorflow.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_1)\n  \n  block_3_1 = tensorflow.keras.layers.BatchNormalization()(block_3_1)\n  block_3_1 = tensorflow.keras.layers.ReLU()(block_3_1)\n  block_3_1 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_1)\n\n  sh_cut_3 = tensorflow.keras.layers.BatchNormalization()(short_cut_2)\n  sh_cut_3 = tensorflow.keras.layers.ReLU()(sh_cut_3)\n  sh_cut_3 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(sh_cut_3)\n\n  stg1_blok_3_1 = tensorflow.keras.layers.add([sh_cut_3, block_3_1])\n  ### 2 : identity_block  ###\n  block_3_2 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_3_1)\n  block_3_2 = tensorflow.keras.layers.ReLU()(block_3_2)\n  block_3_2 = tensorflow.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_2)\n  \n  block_3_2 = tensorflow.keras.layers.BatchNormalization()(block_3_2)\n  block_3_2 = tensorflow.keras.layers.ReLU()(block_3_2)\n  block_3_2 = tensorflow.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_2)\n  \n  block_3_2 = tensorflow.keras.layers.BatchNormalization()(block_3_2)\n  block_3_2 = tensorflow.keras.layers.ReLU()(block_3_2)\n  block_3_2 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_2)\n\n  stg1_blok_3_2 = tensorflow.keras.layers.add([stg1_blok_3_1, block_3_2])\n\n  ### 3 : identity_block  ###\n  block_3_3 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_3_2)\n  block_3_3 = tensorflow.keras.layers.ReLU()(block_3_3)\n  block_3_3 = tensorflow.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_3)\n  \n  block_3_3 = tensorflow.keras.layers.BatchNormalization()(block_3_3)\n  block_3_3 = tensorflow.keras.layers.ReLU()(block_3_3)\n  block_3_3 = tensorflow.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_3)\n  \n  block_3_3 = tensorflow.keras.layers.BatchNormalization()(block_3_3)\n  block_3_3 = tensorflow.keras.layers.ReLU()(block_3_3)\n  block_3_3 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_3)\n  stg1_blok_3_3 = tensorflow.keras.layers.add([stg1_blok_3_2, block_3_3])\n\n \n  \n\n  ### 4:identity_block  ###\n  block_3_4 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_3_3)\n  block_3_4 = tensorflow.keras.layers.ReLU()(block_3_4)\n  block_3_4 = tensorflow.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_4)\n  \n  block_3_4 = tensorflow.keras.layers.BatchNormalization()(block_3_4)\n  block_3_4 = tensorflow.keras.layers.ReLU()(block_3_4)\n  block_3_4 = tensorflow.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_4)\n  \n  block_3_4 = tensorflow.keras.layers.BatchNormalization()(block_3_4)\n  block_3_4 = tensorflow.keras.layers.ReLU()(block_3_4)\n  block_3_4 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_4)\n\n  stg1_blok_3_4 = tensorflow.keras.layers.add([stg1_blok_3_3, block_3_4])\n\n  short_cut_2 = tensorflow.keras.layers.BatchNormalization()(short_cut_2)\n  short_cut_2 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(short_cut_2)\n\n  short_cut_3 = tensorflow.keras.layers.add([stg1_blok_3_4, short_cut_2])\n\n\n############ Block 4 #############\n  ### 1 : conv_block ###\n  block_4_1 = tensorflow.keras.layers.BatchNormalization()(short_cut_3)\n  block_4_1 = tensorflow.keras.layers.ReLU()(block_4_1)\n  block_4_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_1)\n  \n  block_4_1 = tensorflow.keras.layers.BatchNormalization()(block_4_1)\n  block_4_1 = tensorflow.keras.layers.ReLU()(block_4_1)\n  block_4_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_1)\n  \n  block_4_1 = tensorflow.keras.layers.BatchNormalization()(block_4_1)\n  block_4_1 = tensorflow.keras.layers.ReLU()(block_4_1)\n  block_4_1 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_1)\n\n  sh_cut_4 = tensorflow.keras.layers.BatchNormalization()(short_cut_3)\n  sh_cut_4 = tensorflow.keras.layers.ReLU()(sh_cut_4)\n  sh_cut_4 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(sh_cut_4)\n\n  stg1_blok_4_1 = tensorflow.keras.layers.add([sh_cut_4, block_4_1])\n\n  ### 2 :identity_block  ###\n  block_4_2 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_4_1)\n  block_4_2 = tensorflow.keras.layers.ReLU()(block_4_2)\n  block_4_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_2)\n  \n  block_4_2 = tensorflow.keras.layers.BatchNormalization()(block_4_2)\n  block_4_2 = tensorflow.keras.layers.ReLU()(block_4_2)\n  block_4_2 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_2)\n  \n  block_4_2 = tensorflow.keras.layers.BatchNormalization()(block_4_2)\n  block_4_2 = tensorflow.keras.layers.ReLU()(block_4_2)\n  block_4_2 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_2)\n  stg1_blok_4_2 = tensorflow.keras.layers.add([stg1_blok_4_1, block_4_2])\n\n  ### 3 : identity_block  ###\n  block_4_3 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_4_2)\n  block_4_3 = tensorflow.keras.layers.ReLU()(block_4_3)\n  block_4_3 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_3)\n  \n  block_4_3 = tensorflow.keras.layers.BatchNormalization()(block_4_3)\n  block_4_3 = tensorflow.keras.layers.ReLU()(block_4_3)\n  block_4_3 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_3)\n  \n  block_4_3 = tensorflow.keras.layers.BatchNormalization()(block_4_3)\n  block_4_3 = tensorflow.keras.layers.ReLU()(block_4_3)\n  block_4_3 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_3)\n  stg1_blok_4_3 = tensorflow.keras.layers.add([stg1_blok_4_2, block_4_3])\n\n  ### 4 : identity_block  ###\n  block_4_4 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_4_3)\n  block_4_4 = tensorflow.keras.layers.ReLU()(block_4_4)\n  block_4_4 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_4)\n  \n  block_4_4 = tensorflow.keras.layers.BatchNormalization()(block_4_4)\n  block_4_4 = tensorflow.keras.layers.ReLU()(block_4_4)\n  block_4_4 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_4)\n  \n  block_4_4 = tensorflow.keras.layers.BatchNormalization()(block_4_4)\n  block_4_4 = tensorflow.keras.layers.ReLU()(block_4_4)\n  block_4_4 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_4)\n  stg1_blok_4_4 = tensorflow.keras.layers.add([stg1_blok_4_3, block_4_4])\n\n  ### 5 : :identity_block  ###\n  block_4_5 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_4_4)\n  block_4_5 = tensorflow.keras.layers.ReLU()(block_4_5)\n  block_4_5 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_5)\n  \n  block_4_5 = tensorflow.keras.layers.BatchNormalization()(block_4_5)\n  block_4_5 = tensorflow.keras.layers.ReLU()(block_4_5)\n  block_4_5 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_5)\n  \n  block_4_5 = tensorflow.keras.layers.BatchNormalization()(block_4_5)\n  block_4_5 = tensorflow.keras.layers.ReLU()(block_4_5)\n  block_4_5 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_5)\n  stg1_blok_4_5 = tensorflow.keras.layers.add([stg1_blok_4_4, block_4_5])\n\n\n  short_cut_3 = tensorflow.keras.layers.BatchNormalization()(short_cut_3)\n  short_cut_3 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(short_cut_3)\n\n  short_cut_4 = tensorflow.keras.layers.add([stg1_blok_4_5, short_cut_3])\n\n############ Block 5 #############\n  ### conv_block ###\n  block_5_1 = tensorflow.keras.layers.BatchNormalization()(short_cut_4)\n  block_5_1 = tensorflow.keras.layers.ReLU()(block_5_1)\n  block_5_1 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_1)\n  \n  block_5_1 = tensorflow.keras.layers.BatchNormalization()(block_5_1)\n  block_5_1 = tensorflow.keras.layers.ReLU()(block_5_1)\n  block_5_1 = tensorflow.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_1)\n  \n  block_5_1 = tensorflow.keras.layers.BatchNormalization()(block_5_1)\n  block_5_1 = tensorflow.keras.layers.ReLU()(block_5_1)\n  block_5_1 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_1)\n\n  sh_cut_5 = tensorflow.keras.layers.BatchNormalization()(short_cut_4)\n  sh_cut_5 = tensorflow.keras.layers.ReLU()(sh_cut_5)\n  sh_cut_5 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(sh_cut_5)\n\n  stg1_blok_5_1 = tensorflow.keras.layers.add([sh_cut_5, block_5_1])\n  ### identity_block 1 ###\n  block_5_2 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_5_1)\n  block_5_2 = tensorflow.keras.layers.ReLU()(block_5_2)\n  block_5_2 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_2)\n  \n  block_5_2 = tensorflow.keras.layers.BatchNormalization()(block_5_2)\n  block_5_2 = tensorflow.keras.layers.ReLU()(block_5_2)\n  block_5_2 = tensorflow.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_2)\n  \n  block_5_2 = tensorflow.keras.layers.BatchNormalization()(block_5_2)\n  block_5_2 = tensorflow.keras.layers.ReLU()(block_5_2)\n  block_5_2 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_2)\n\n  stg1_blok_5_2 = tensorflow.keras.layers.add([stg1_blok_5_1, block_5_2])\n\n  ### identity_block 2 ###\n  block_5_3 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_5_2)\n  block_5_3 = tensorflow.keras.layers.ReLU()(block_5_3)\n  block_5_3 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_3)\n  \n  block_5_3 = tensorflow.keras.layers.BatchNormalization()(block_5_3)\n  block_5_3 = tensorflow.keras.layers.ReLU()(block_5_3)\n  block_5_3 = tensorflow.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_3)\n  \n  block_5_3 = tensorflow.keras.layers.BatchNormalization()(block_5_3)\n  block_5_3 = tensorflow.keras.layers.ReLU()(block_5_3)\n  block_5_3 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_3)\n\n  stg1_blok_5_3 = tensorflow.keras.layers.add([stg1_blok_5_2, block_5_3])\n\n  short_cut_4 = tensorflow.keras.layers.BatchNormalization()(short_cut_4)\n  short_cut_4 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(short_cut_4)\n\n  short_cut_5 = tensorflow.keras.layers.add([stg1_blok_5_3, short_cut_4])\n############ Block 6 #############\n  \n  pooling = tensorflow.keras.layers.GlobalAveragePooling2D()(short_cut_5)\n  model_output = tensorflow.keras.layers.Dense(5,activation='softmax')(pooling)\n  \n  model = tensorflow.keras.models.Model(model_input,model_output)\n  return model ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:53:26.684278Z","iopub.execute_input":"2022-04-23T10:53:26.684621Z","iopub.status.idle":"2022-04-23T10:53:26.771298Z","shell.execute_reply.started":"2022-04-23T10:53:26.684583Z","shell.execute_reply":"2022-04-23T10:53:26.769867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_w = 256\nimage_h = 256\nn_classes = 5\nmodel = ResNet50(image_w,image_h)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:53:40.757706Z","iopub.execute_input":"2022-04-23T10:53:40.75801Z","iopub.status.idle":"2022-04-23T10:53:42.063619Z","shell.execute_reply.started":"2022-04-23T10:53:40.757976Z","shell.execute_reply":"2022-04-23T10:53:42.062678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **U-Net**\n![](https://datascientest.com/wp-content/uploads/2021/05/u-net-architecture-1024x682.png)","metadata":{}},{"cell_type":"code","source":"def UNet(nb_classes, input_shape):\n    \n    input = tensorflow.keras.layers.Input(input_shape)\n    \n    c1 = tensorflow.keras.layers.Conv2D(64, (3,3), strides=1)(input)\n    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n    c1 = tensorflow.keras.layers.ReLU()(c1)\n    \n    c1 = tensorflow.keras.layers.Conv2D(64, (3,3), strides=1)(c1)\n    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n    c1 = tensorflow.keras.layers.ReLU()(c1)\n    \n    p1 = tensorflow.keras.layers.MaxPool2D(2, strides=2)(c1)\n    \n    c2 = tensorflow.keras.layers.Conv2D(128, (3,3), strides=1)(p1)\n    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n    c2 = tensorflow.keras.layers.ReLU()(c2)\n\n    c2 = tensorflow.keras.layers.Conv2D(128, (3,3), strides=1)(c2)\n    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n    c2 = tensorflow.keras.layers.ReLU()(c2)\n    \n    p2 = tensorflow.keras.layers.MaxPool2D(2, strides=2)(c2)\n    \n    c3 = tensorflow.keras.layers.Conv2D(256, (3,3) ,strides= 1)(p2)\n    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n    c3 = tensorflow.keras.layers.ReLU()(c3)\n\n    c3 = tensorflow.keras.layers.Conv2D(256, (3,3) , strides=1)(c3)\n    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n    c3 = tensorflow.keras.layers.ReLU()(c3)\n    \n    p3 = tensorflow.keras.layers.MaxPool2D(2, strides=2)(c3)\n    \n    c4 = tensorflow.keras.layers.Conv2D(512, (3,3), strides=1)(p3)\n    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n    c4 = tensorflow.keras.layers.ReLU()(c4)\n\n    c4 = tensorflow.keras.layers.Conv2D(512, (3,3), strides=1)(c4)\n    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n    c4 = tensorflow.keras.layers.ReLU()(c4)\n    \n    \n    p4 = tensorflow.keras.layers.MaxPool2D(2, strides=2)(c4)\n    \n    c5 = tensorflow.keras.layers.Conv2D(1024, (3,3), strides=1)(p4)\n    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n    c5 = tensorflow.keras.layers.ReLU()(c5)\n\n    c5 = tensorflow.keras.layers.Conv2D(1024, (3,3), strides=1)(c5)\n    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n    c5 = tensorflow.keras.layers.ReLU()(c5)\n    \n    \n    c6 = tensorflow.keras.layers.Conv2DTranspose(1024,(2,2), strides=2)(c5)\n    u1 = tensorflow.image.resize(c4, ((np.shape(c6)[1]), (np.shape(c6)[2])))\n    c6 = tensorflow.keras.layers.concatenate([u1,c6])\n    \n    c6 = tensorflow.keras.layers.Conv2D(512, (3,3), strides=1)(c6)\n    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n    c6 = tensorflow.keras.layers.ReLU()(c6)\n\n    c6 = tensorflow.keras.layers.Conv2D(512, (3,3), strides=1)(c6)\n    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n    c6 = tensorflow.keras.layers.ReLU()(c6)\n    \n    c7 = tensorflow.keras.layers.Conv2DTranspose(512,(2,2), strides=2)(c6)\n    u2 = tensorflow.image.resize(c3, ((np.shape(c7)[1]), (np.shape(c7)[2])))\n    c7 = tensorflow.keras.layers.concatenate([u2,c7])\n    \n    c7 = tensorflow.keras.layers.Conv2D(256, (3,3), strides=1)(c7)\n    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n    c7 = tensorflow.keras.layers.ReLU()(c7)\n\n    c7 = tensorflow.keras.layers.Conv2D(256, (3,3), strides=1)(c7)\n    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n    c7 = tensorflow.keras.layers.ReLU()(c7)\n    \n    c8 = tensorflow.keras.layers.Conv2DTranspose(256,(2,2), strides=2)(c7)\n    u3 = tensorflow.image.resize(c2, ((np.shape(c8)[1]), (np.shape(c8)[2])))\n    c8 = tensorflow.keras.layers.concatenate([u3,c8])\n    \n    c8 = tensorflow.keras.layers.Conv2D(128, (3,3), strides=1)(c8)\n    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n    c8 = tensorflow.keras.layers.ReLU()(c8)\n\n    c8 = tensorflow.keras.layers.Conv2D(128, (3,3), strides=1)(c8)\n    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n    c8 = tensorflow.keras.layers.ReLU()(c8)\n    \n    c9 = tensorflow.keras.layers.Conv2DTranspose(128,(2,2), strides=2)(c8)\n    u4 = tensorflow.image.resize(c1, ((np.shape(c9)[1]), (np.shape(c9)[2])))\n    c9 = tensorflow.keras.layers.concatenate([u4,c9])\n    \n    c9 = tensorflow.keras.layers.Conv2D(64, (3,3), strides=1)(c9)\n    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n    c9 = tensorflow.keras.layers.ReLU()(c9)\n\n    c9 = tensorflow.keras.layers.Conv2D(64, (3,3), strides=1)(c9)\n    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n    c9 = tensorflow.keras.layers.ReLU()(c9)\n    \n    c9 = tensorflow.keras.layers.Conv2D(2, (1,1), strides=1)(c9)\n    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n    c9 = tensorflow.keras.layers.ReLU()(c9)\n    \n    model = tensorflow.keras.models.Model(input,c9)\n    return model ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:53:53.827148Z","iopub.execute_input":"2022-04-23T10:53:53.82742Z","iopub.status.idle":"2022-04-23T10:53:53.867496Z","shell.execute_reply.started":"2022-04-23T10:53:53.827391Z","shell.execute_reply":"2022-04-23T10:53:53.866515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = 572,572,1\nnb_classes = 2\nm = UNet(nb_classes, input_shape)\nm.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T10:54:02.695321Z","iopub.execute_input":"2022-04-23T10:54:02.695638Z","iopub.status.idle":"2022-04-23T10:54:03.344138Z","shell.execute_reply.started":"2022-04-23T10:54:02.69559Z","shell.execute_reply":"2022-04-23T10:54:03.343296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **se_ResNet50**","metadata":{}},{"cell_type":"code","source":"def se_ResNet50(input_w,input_h):\n  if tf.keras.backend.image_data_format() == 'channels_first':\n    input_shape = (3, input_w, input_h)\n  else:\n    input_shape = (input_w, input_h,3)\n\n  model_input = tf.keras.layers.Input(shape=input_shape)\n \n\n  ########### Block 1 ###########\n  block_1 = tf.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(model_input)\n  block_1 = tf.keras.layers.BatchNormalization()(block_1)\n  block_1 = tf.keras.layers.ReLU()(block_1)\n  block_1 = tf.keras.layers.MaxPooling2D(3, strides=2, padding='same')(block_1)\n ############ Block 2 #############\n ### conv_block ###\n  block_2_1 = tf.keras.layers.BatchNormalization()(block_1)\n  block_2_1 = tf.keras.layers.ReLU()(block_2_1)\n  block_2_1 = tf.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_1)\n  \n  block_2_1 = tf.keras.layers.BatchNormalization()(block_2_1)\n  block_2_1 = tf.keras.layers.ReLU()(block_2_1)\n  block_2_1 = tf.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_1)\n  \n  block_2_1 = tf.keras.layers.BatchNormalization()(block_2_1)\n  block_2_1 = tf.keras.layers.ReLU()(block_2_1)\n  block_2_1 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_1)\n\n  sh_cut_2 = tf.keras.layers.BatchNormalization()(block_1)\n  sh_cut_2 = tf.keras.layers.ReLU()(sh_cut_2)\n  sh_cut_2 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(sh_cut_2)\n\n  stg1_blok_2_1 = tf.keras.layers.add([sh_cut_2, block_2_1])\n  ### identity_block 1 ###\n  block_2_2 = tf.keras.layers.BatchNormalization()(stg1_blok_2_1)\n  block_2_2 = tf.keras.layers.ReLU()(block_2_2)\n  block_2_2 = tf.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_2)\n  \n  block_2_2 = tf.keras.layers.BatchNormalization()(block_2_2)\n  block_2_2 = tf.keras.layers.ReLU()(block_2_2)\n  block_2_2 = tf.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_2)\n  \n  block_2_2 = tf.keras.layers.BatchNormalization()(block_2_2)\n  block_2_2 = tf.keras.layers.ReLU()(block_2_2)\n  block_2_2 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_2)\n\n  stg1_blok_2_2 = tf.keras.layers.add([stg1_blok_2_1, block_2_2])\n\n  ### identity_block 2 ###\n  block_2_3 = tf.keras.layers.BatchNormalization()(stg1_blok_2_2)\n  block_2_3 = tf.keras.layers.ReLU()(block_2_3)\n  block_2_3 = tf.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_3)\n  \n  block_2_3 = tf.keras.layers.BatchNormalization()(block_2_3)\n  block_2_3 = tf.keras.layers.ReLU()(block_2_3)\n  block_2_3 = tf.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_3)\n  \n  block_2_3 = tf.keras.layers.BatchNormalization()(block_2_3)\n  block_2_3 = tf.keras.layers.ReLU()(block_2_3)\n  block_2_3 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_3)\n\n  stg1_blok_2_3 = tf.keras.layers.add([stg1_blok_2_2, block_2_3])\n\n  squeeze = tf.keras.layers.GlobalAveragePooling2D()(stg1_blok_2_3)\n  excitation = tf.keras.layers.Dense(units=256 / 16, activation='relu')(squeeze)\n  excitation = tf.keras.layers.Dense(256,activation='sigmoid')(excitation)\n  #excitation = tf.reshape(excitation, [-1,1,1,256])\n  scale = tf.keras.layers.multiply([stg1_blok_2_3, excitation])\n\n\n  block_1 = tf.keras.layers.BatchNormalization()(block_1)\n  block_1 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_1)\n\n  short_cut_2 = tf.keras.layers.add([scale, block_1])\n\n############ Block 3 #############\n  ### 1 : conv_block ###\n  block_3_1 = tf.keras.layers.BatchNormalization()(short_cut_2)\n  block_3_1 = tf.keras.layers.ReLU()(block_3_1)\n  block_3_1 = tf.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_1)\n  \n  block_3_1 = tf.keras.layers.BatchNormalization()(block_3_1)\n  block_3_1 = tf.keras.layers.ReLU()(block_3_1)\n  block_3_1 = tf.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_1)\n  \n  block_3_1 = tf.keras.layers.BatchNormalization()(block_3_1)\n  block_3_1 = tf.keras.layers.ReLU()(block_3_1)\n  block_3_1 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_1)\n\n  sh_cut_3 = tf.keras.layers.BatchNormalization()(short_cut_2)\n  sh_cut_3 = tf.keras.layers.ReLU()(sh_cut_3)\n  sh_cut_3 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(sh_cut_3)\n\n  stg1_blok_3_1 = tf.keras.layers.add([sh_cut_3, block_3_1])\n  ### 2 : identity_block  ###\n  block_3_2 = tf.keras.layers.BatchNormalization()(stg1_blok_3_1)\n  block_3_2 = tf.keras.layers.ReLU()(block_3_2)\n  block_3_2 = tf.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_2)\n  \n  block_3_2 = tf.keras.layers.BatchNormalization()(block_3_2)\n  block_3_2 = tf.keras.layers.ReLU()(block_3_2)\n  block_3_2 = tf.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_2)\n  \n  block_3_2 = tf.keras.layers.BatchNormalization()(block_3_2)\n  block_3_2 = tf.keras.layers.ReLU()(block_3_2)\n  block_3_2 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_2)\n\n  stg1_blok_3_2 = tf.keras.layers.add([stg1_blok_3_1, block_3_2])\n\n  ### 3 : identity_block  ###\n  block_3_3 = tf.keras.layers.BatchNormalization()(stg1_blok_3_2)\n  block_3_3 = tf.keras.layers.ReLU()(block_3_3)\n  block_3_3 = tf.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_3)\n  \n  block_3_3 = tf.keras.layers.BatchNormalization()(block_3_3)\n  block_3_3 = tf.keras.layers.ReLU()(block_3_3)\n  block_3_3 = tf.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_3)\n  \n  block_3_3 = tf.keras.layers.BatchNormalization()(block_3_3)\n  block_3_3 = tf.keras.layers.ReLU()(block_3_3)\n  block_3_3 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_3)\n  stg1_blok_3_3 = tf.keras.layers.add([stg1_blok_3_2, block_3_3])\n\n \n  \n\n  ### 4:identity_block  ###\n  block_3_4 = tf.keras.layers.BatchNormalization()(stg1_blok_3_3)\n  block_3_4 = tf.keras.layers.ReLU()(block_3_4)\n  block_3_4 = tf.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_4)\n  \n  block_3_4 = tf.keras.layers.BatchNormalization()(block_3_4)\n  block_3_4 = tf.keras.layers.ReLU()(block_3_4)\n  block_3_4 = tf.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_4)\n  \n  block_3_4 = tf.keras.layers.BatchNormalization()(block_3_4)\n  block_3_4 = tf.keras.layers.ReLU()(block_3_4)\n  block_3_4 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_4)\n\n  stg1_blok_3_4 = tf.keras.layers.add([stg1_blok_3_3, block_3_4])\n\n\n  squeeze = tf.keras.layers.GlobalAveragePooling2D()(stg1_blok_3_4)\n  excitation = tf.keras.layers.Dense(units=512 / 16, activation='relu')(squeeze)\n  excitation = tf.keras.layers.Dense(512,activation='sigmoid')(excitation)\n  #excitation = tf.reshape(excitation, [-1,1,1,512])\n  scale_3 = tf.keras.layers.multiply([stg1_blok_3_4, excitation])\n\n  short_cut_2 = tf.keras.layers.BatchNormalization()(short_cut_2)\n  short_cut_2 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(short_cut_2)\n\n  short_cut_3 = tf.keras.layers.add([scale_3, short_cut_2])\n\n\n\n  ############ Block 4 #############\n  ### 1 : conv_block ###\n  block_4_1 = tf.keras.layers.BatchNormalization()(short_cut_3)\n  block_4_1 = tf.keras.layers.ReLU()(block_4_1)\n  block_4_1 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_1)\n  \n  block_4_1 = tf.keras.layers.BatchNormalization()(block_4_1)\n  block_4_1 = tf.keras.layers.ReLU()(block_4_1)\n  block_4_1 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_1)\n  \n  block_4_1 = tf.keras.layers.BatchNormalization()(block_4_1)\n  block_4_1 = tf.keras.layers.ReLU()(block_4_1)\n  block_4_1 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_1)\n\n  sh_cut_4 = tf.keras.layers.BatchNormalization()(short_cut_3)\n  sh_cut_4 = tf.keras.layers.ReLU()(sh_cut_4)\n  sh_cut_4 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(sh_cut_4)\n\n  stg1_blok_4_1 = tf.keras.layers.add([sh_cut_4, block_4_1])\n\n  ### 2 :identity_block  ###\n  block_4_2 = tf.keras.layers.BatchNormalization()(stg1_blok_4_1)\n  block_4_2 = tf.keras.layers.ReLU()(block_4_2)\n  block_4_1 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_2)\n  \n  block_4_2 = tf.keras.layers.BatchNormalization()(block_4_2)\n  block_4_2 = tf.keras.layers.ReLU()(block_4_2)\n  block_4_2 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_2)\n  \n  block_4_2 = tf.keras.layers.BatchNormalization()(block_4_2)\n  block_4_2 = tf.keras.layers.ReLU()(block_4_2)\n  block_4_2 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_2)\n  stg1_blok_4_2 = tf.keras.layers.add([stg1_blok_4_1, block_4_2])\n\n  ### 3 : identity_block  ###\n  block_4_3 = tf.keras.layers.BatchNormalization()(stg1_blok_4_2)\n  block_4_3 = tf.keras.layers.ReLU()(block_4_3)\n  block_4_3 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_3)\n  \n  block_4_3 = tf.keras.layers.BatchNormalization()(block_4_3)\n  block_4_3 = tf.keras.layers.ReLU()(block_4_3)\n  block_4_3 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_3)\n  \n  block_4_3 = tf.keras.layers.BatchNormalization()(block_4_3)\n  block_4_3 = tf.keras.layers.ReLU()(block_4_3)\n  block_4_3 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_3)\n  stg1_blok_4_3 = tf.keras.layers.add([stg1_blok_4_2, block_4_3])\n\n  ### 4 : identity_block  ###\n  block_4_4 = tf.keras.layers.BatchNormalization()(stg1_blok_4_3)\n  block_4_4 = tf.keras.layers.ReLU()(block_4_4)\n  block_4_4 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_4)\n  \n  block_4_4 = tf.keras.layers.BatchNormalization()(block_4_4)\n  block_4_4 = tf.keras.layers.ReLU()(block_4_4)\n  block_4_4 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_4)\n  \n  block_4_4 = tf.keras.layers.BatchNormalization()(block_4_4)\n  block_4_4 = tf.keras.layers.ReLU()(block_4_4)\n  block_4_4 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_4)\n  stg1_blok_4_4 = tf.keras.layers.add([stg1_blok_4_3, block_4_4])\n\n  ### 5 : :identity_block  ###\n  block_4_5 = tf.keras.layers.BatchNormalization()(stg1_blok_4_4)\n  block_4_5 = tf.keras.layers.ReLU()(block_4_5)\n  block_4_5 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_5)\n  \n  block_4_5 = tf.keras.layers.BatchNormalization()(block_4_5)\n  block_4_5 = tf.keras.layers.ReLU()(block_4_5)\n  block_4_5 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_5)\n  \n  block_4_5 = tf.keras.layers.BatchNormalization()(block_4_5)\n  block_4_5 = tf.keras.layers.ReLU()(block_4_5)\n  block_4_5 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_5)\n  stg1_blok_4_5 = tf.keras.layers.add([stg1_blok_4_4, block_4_5])\n\n\n  squeeze = tf.keras.layers.GlobalAveragePooling2D()(stg1_blok_4_5)\n  excitation = tf.keras.layers.Dense(units=1024 / 16, activation='relu')(squeeze)\n  excitation = tf.keras.layers.Dense(1024,activation='sigmoid')(excitation)\n  #excitation = tf.reshape(excitation, [-1,1,1,1024])\n  scale_4 = tf.keras.layers.multiply([stg1_blok_4_5, excitation])\n\n\n  short_cut_3 = tf.keras.layers.BatchNormalization()(short_cut_3)\n  short_cut_3 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(short_cut_3)\n\n  short_cut_4 = tf.keras.layers.add([scale_4, short_cut_3])\n\n\n  ############ Block 5 #############\n  ### conv_block ###\n  block_5_1 = tf.keras.layers.BatchNormalization()(short_cut_4)\n  block_5_1 = tf.keras.layers.ReLU()(block_5_1)\n  block_5_1 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_1)\n  \n  block_5_1 = tf.keras.layers.BatchNormalization()(block_5_1)\n  block_5_1 = tf.keras.layers.ReLU()(block_5_1)\n  block_5_1 = tf.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_1)\n  \n  block_5_1 = tf.keras.layers.BatchNormalization()(block_5_1)\n  block_5_1 = tf.keras.layers.ReLU()(block_5_1)\n  block_5_1 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_1)\n\n  sh_cut_5 = tf.keras.layers.BatchNormalization()(short_cut_4)\n  sh_cut_5 = tf.keras.layers.ReLU()(sh_cut_5)\n  sh_cut_5 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(sh_cut_5)\n\n  stg1_blok_5_1 = tf.keras.layers.add([sh_cut_5, block_5_1])\n  ### identity_block 1 ###\n  block_5_2 = tf.keras.layers.BatchNormalization()(stg1_blok_5_1)\n  block_5_2 = tf.keras.layers.ReLU()(block_5_2)\n  block_5_2 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_2)\n  \n  block_5_2 = tf.keras.layers.BatchNormalization()(block_5_2)\n  block_5_2 = tf.keras.layers.ReLU()(block_5_2)\n  block_5_2 = tf.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_2)\n  \n  block_5_2 = tf.keras.layers.BatchNormalization()(block_5_2)\n  block_5_2 = tf.keras.layers.ReLU()(block_5_2)\n  block_5_2 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_2)\n\n  stg1_blok_5_2 = tf.keras.layers.add([stg1_blok_5_1, block_5_2])\n\n  ### identity_block 2 ###\n  block_5_3 = tf.keras.layers.BatchNormalization()(stg1_blok_5_2)\n  block_5_3 = tf.keras.layers.ReLU()(block_5_3)\n  block_5_3 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_3)\n  \n  block_5_3 = tf.keras.layers.BatchNormalization()(block_5_3)\n  block_5_3 = tf.keras.layers.ReLU()(block_5_3)\n  block_5_3 = tf.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_3)\n  \n  block_5_3 = tf.keras.layers.BatchNormalization()(block_5_3)\n  block_5_3 = tf.keras.layers.ReLU()(block_5_3)\n  block_5_3 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_3)\n\n  stg1_blok_5_3 = tf.keras.layers.add([stg1_blok_5_2, block_5_3])\n\n  squeeze = tf.keras.layers.GlobalAveragePooling2D()(stg1_blok_5_3)\n  excitation = tf.keras.layers.Dense(units=2048 / 16, activation='relu')(squeeze)\n  excitation = tf.keras.layers.Dense(2048,activation='sigmoid')(excitation)\n  #excitation = tf.reshape(excitation, [-1,1,1,2048])\n  scale_5 = tf.keras.layers.multiply([stg1_blok_5_3, excitation])\n\n  short_cut_4 = tf.keras.layers.BatchNormalization()(short_cut_4)\n  short_cut_4 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(short_cut_4)\n\n  short_cut_5 = tf.keras.layers.add([scale_5, short_cut_4])\n############ Block 6 #############\n  \n  pooling = tf.keras.layers.GlobalAveragePooling2D()(short_cut_5)\n  #pooling = tf.keras.layers.Dense(5,activation='relu')(pooling)\n  model_output = tf.keras.layers.Dense(5,activation='softmax')(pooling)\n\n\n  model = tf.keras.models.Model(model_input,model_output)\n \n  return model ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:18:06.046966Z","iopub.execute_input":"2022-04-23T11:18:06.04724Z","iopub.status.idle":"2022-04-23T11:18:06.142438Z","shell.execute_reply.started":"2022-04-23T11:18:06.04721Z","shell.execute_reply":"2022-04-23T11:18:06.141499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_w = 320\nimage_h = 256\nn_classes = 5\nmodel = se_ResNet50(image_w,image_h)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T11:18:14.734166Z","iopub.execute_input":"2022-04-23T11:18:14.734564Z","iopub.status.idle":"2022-04-23T11:18:16.486925Z","shell.execute_reply.started":"2022-04-23T11:18:14.734514Z","shell.execute_reply":"2022-04-23T11:18:16.486301Z"},"trusted":true},"execution_count":null,"outputs":[]}]}