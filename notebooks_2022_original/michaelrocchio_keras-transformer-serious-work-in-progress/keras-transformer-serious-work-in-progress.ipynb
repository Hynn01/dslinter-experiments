{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\npd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:18.246958Z","iopub.execute_input":"2022-04-24T21:33:18.24716Z","iopub.status.idle":"2022-04-24T21:33:18.738031Z","shell.execute_reply.started":"2022-04-24T21:33:18.247136Z","shell.execute_reply":"2022-04-24T21:33:18.737302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:18.73969Z","iopub.execute_input":"2022-04-24T21:33:18.73995Z","iopub.status.idle":"2022-04-24T21:33:18.752673Z","shell.execute_reply.started":"2022-04-24T21:33:18.739915Z","shell.execute_reply":"2022-04-24T21:33:18.752004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Credit where it is very due:\n#### A huge shoutout goes to DARIEN SCHETTLER; he saved me an enormous amount of time and did it way better that I could have! I used alot amount of his code for the pre-processing of the data. Go upvote his notebook: kaggle.com/code/dschettler8845/uwmgit-deeplabv3-end-to-end-pipeline-tf","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nfrom datetime import datetime\nimport json,itertools\nfrom typing import Optional\nfrom glob import glob\n\nfrom sklearn.model_selection import StratifiedKFold\n\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:18.753996Z","iopub.execute_input":"2022-04-24T21:33:18.754257Z","iopub.status.idle":"2022-04-24T21:33:19.971731Z","shell.execute_reply.started":"2022-04-24T21:33:18.754213Z","shell.execute_reply":"2022-04-24T21:33:19.970961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\n\nn_splits=5\n\nfold_selected=1\n\ndf = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\nprint(df.shape)\ndf=df.tail(10000)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:19.977164Z","iopub.execute_input":"2022-04-24T21:33:19.979237Z","iopub.status.idle":"2022-04-24T21:33:20.315016Z","shell.execute_reply.started":"2022-04-24T21:33:19.979169Z","shell.execute_reply":"2022-04-24T21:33:20.314096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rename(columns = {'class':'class_name'}, inplace = True)\n#--------------------------------------------------------------------------\ndf[\"case\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\ndf[\"day\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\ndf[\"slice\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n#--------------------------------------------------------------------------\nTRAIN_DIR=\"../input/uw-madison-gi-tract-image-segmentation/train\"\nall_train_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\nx = all_train_images[0].rsplit(\"/\", 4)[0] ## ../input/uw-madison-gi-tract-image-segmentation/train\n\npath_partial_list = []\nfor i in range(0, df.shape[0]):\n    path_partial_list.append(os.path.join(x,\n                          \"case\"+str(df[\"case\"].values[i]),\n                          \"case\"+str(df[\"case\"].values[i])+\"_\"+ \"day\"+str(df[\"day\"].values[i]),\n                          \"scans\",\n                          \"slice_\"+str(df[\"slice\"].values[i])))\ndf[\"path_partial\"] = path_partial_list\n#--------------------------------------------------------------------------\npath_partial_list = []\nfor i in range(0, len(all_train_images)):\n    path_partial_list.append(str(all_train_images[i].rsplit(\"_\",4)[0]))\n    \ntmp_df = pd.DataFrame()\ntmp_df['path_partial'] = path_partial_list\ntmp_df['path'] = all_train_images\n\n#--------------------------------------------------------------------------\ndf = df.merge(tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n#--------------------------------------------------------------------------\ndf[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\ndf[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n#--------------------------------------------------------------------------\ndel path_partial_list,tmp_df\n#--------------------------------------------------------------------------\ndf_meta = df.groupby('id').first().reset_index()\ndf_meta = df_meta.reset_index(drop=True)\ndf_meta.head(5)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)\n\n\ndef build_masks(labels,input_shape, colors=True):\n    height, width = input_shape\n    if colors:\n        mask = np.zeros((height, width, 3))\n        for label in labels:\n            mask += rle_decode(label, shape=(height,width , 3), color=np.random.rand(3))\n    else:\n        mask = np.zeros((height, width, 1))\n        for label in labels:\n            mask += rle_decode(label, shape=(height, width, 1))\n    mask = mask.clip(0, 1)\n    return mask\n\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (len(rle)==0): \n        return np.zeros((256,256) ,dtype=np.uint8)\n    \n    height= 520\n    width = 704\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\nsample_filename = 'case85_day23_slice_0098'\nsample_image_df = df[df['id'] == sample_filename]\nsample_path = sample_image_df['path'].values[0]\nsample_img = cv2.imread(sample_path)\nsample_rles = sample_image_df[~sample_image_df.segmentation.isna()]['segmentation'].values\n\nsample_filename = 'case85_day23_slice_0098'\nsample_image_df = df[df['id'] == sample_filename]\nsample_path = sample_image_df['path'].values[0]\nsample_img = cv2.imread(sample_path)\nsample_rles = sample_image_df[~sample_image_df.segmentation.isna()]['segmentation'].values\n\nw=sample_image_df['width'].values[0]\nh=sample_image_df['height'].values[0]\n\nmask1=rle_decode(sample_rles[0], shape=(w, h, 1))\nmask2=rle_decode(sample_rles[1], shape=(w, h, 1))\nmask3=rle_decode(sample_rles[2], shape=(w, h, 1))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:20.316523Z","iopub.execute_input":"2022-04-24T21:33:20.316968Z","iopub.status.idle":"2022-04-24T21:33:24.338048Z","shell.execute_reply.started":"2022-04-24T21:33:20.316929Z","shell.execute_reply":"2022-04-24T21:33:24.337299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5))\ngs = gridspec.GridSpec(nrows=1, ncols=2)\n\nax0 = fig.add_subplot(gs[0, 0])\nim = ax0.imshow(sample_img, cmap='bone')\nax0.set_title(\"Image\", fontsize=15, weight='bold', y=1.02)\n\nax1 = fig.add_subplot(gs[0, 1])\nax1.set_title(\"Mask\", fontsize=15, weight='bold', y=1.02)\n\n\n\n\ncolors1 = ['yellow']\ncolors2 = ['green']\ncolors3 = ['red']\n\ncmap1 = mpl.colors.ListedColormap(colors1)\ncmap2 = mpl.colors.ListedColormap(colors2)\ncmap3= mpl.colors.ListedColormap(colors3)\n\nl0 = ax1.imshow(sample_img, cmap='bone')\nl1 = ax1.imshow(np.ma.masked_where(mask1== False,  mask1),cmap=cmap1, alpha=1)\nl2 = ax1.imshow(np.ma.masked_where(mask2== False,  mask2),cmap=cmap2, alpha=1)\nl3 = ax1.imshow(np.ma.masked_where(mask3== False,  mask3),cmap=cmap3, alpha=1)\n\n\n\n_ = [ax.set_axis_off() for ax in [ax0,ax1]]\n\ncolors = [im.cmap(im.norm(1)) for im in [l1,l2, l3]]\nlabels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\npatches = [ mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\nplt.legend(handles=patches, bbox_to_anchor=(1.1, 0.65), loc=2, borderaxespad=0.4,fontsize = 14,title='Mask Labels', title_fontsize=14, edgecolor=\"black\",  facecolor='#c5c6c7')\nplt.suptitle(\"\", fontsize=20, weight='bold')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:24.340561Z","iopub.execute_input":"2022-04-24T21:33:24.341028Z","iopub.status.idle":"2022-04-24T21:33:24.68223Z","shell.execute_reply.started":"2022-04-24T21:33:24.340991Z","shell.execute_reply":"2022-04-24T21:33:24.681497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, mode='fit',\n                 batch_size=32, dim=(256, 256), n_channels=3,\n                 n_classes=3, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state  \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            img_path = self.df['path'].iloc[ID]\n            img = self.__load_grayscale(img_path)\n            # Store samples\n            X[i,] = img \n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['id'].iloc[ID]\n            \n            image_df = self.df[self.df['id'] == im_name]\n            \n            rles = image_df[~image_df.segmentation.isna()]['segmentation'].values\n            w    = image_df['width'].values[0]\n            h    = image_df['height'].values[0]\n            \n            masks = build_masks(rles,(h,w), colors=False)\n            masks = cv2.resize(masks, (256, 256))\n            #masks=masks.transpose(1,0)\n            masks=np.expand_dims(masks, axis=-1)\n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n        # resize image\n        dsize = (256, 256)\n        img = cv2.resize(img, dsize)\n        \n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:24.683644Z","iopub.execute_input":"2022-04-24T21:33:24.684119Z","iopub.status.idle":"2022-04-24T21:33:29.668023Z","shell.execute_reply.started":"2022-04-24T21:33:24.683981Z","shell.execute_reply":"2022-04-24T21:33:29.667207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\nfor fold, (_, val_idx) in enumerate(skf.split(X=df, y=df['case']), 1):\n    df.loc[val_idx, 'fold'] = fold\n    \ndf['fold'] = df['fold'].astype(np.uint8)\n\ntrain_ids = df[df[\"fold\"]!=fold_selected].index\nvalid_ids = df[df[\"fold\"]==fold_selected].index\n\ndf.groupby('fold').size()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:29.670232Z","iopub.execute_input":"2022-04-24T21:33:29.670774Z","iopub.status.idle":"2022-04-24T21:33:29.696949Z","shell.execute_reply.started":"2022-04-24T21:33:29.670719Z","shell.execute_reply":"2022-04-24T21:33:29.696276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = DataGenerator(\n    train_ids, \n    df=df,\n    batch_size=BATCH_SIZE, \n    n_classes=3\n)\nval_generator = DataGenerator(\n    valid_ids, \n    df=df,\n    batch_size=BATCH_SIZE, \n    n_classes=3\n)\n\nplt.figure(figsize=(7,7))\nfor i in range(1):\n    images, mask = val_generator[i]\n    print(\"Dimension of image:\", images.shape)\n    print(\"Dimension of mask:\", mask.shape)\n    plt.imshow(images[0,:,:,0], cmap=\"gray\")\n    plt.imshow(mask[0,:,:,0],  alpha=0.3, cmap=\"Reds\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:29.698284Z","iopub.execute_input":"2022-04-24T21:33:29.698547Z","iopub.status.idle":"2022-04-24T21:33:30.42228Z","shell.execute_reply.started":"2022-04-24T21:33:29.698512Z","shell.execute_reply":"2022-04-24T21:33:30.421494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nfor i in range(1):\n    images, mask = val_generator[i]\n    print(\"Dimension of image:\", images.shape)\n    print(\"Dimension of mask:\", mask.shape)\n    plt.imshow(images[15,:,:,2], cmap=\"gray\")\n    plt.imshow(mask[15,:,:,2],  alpha=0.3, cmap=\"Reds\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:30.42585Z","iopub.execute_input":"2022-04-24T21:33:30.426748Z","iopub.status.idle":"2022-04-24T21:33:31.121014Z","shell.execute_reply.started":"2022-04-24T21:33:30.426697Z","shell.execute_reply":"2022-04-24T21:33:31.120201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, mask = val_generator[1]","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:31.122459Z","iopub.execute_input":"2022-04-24T21:33:31.123133Z","iopub.status.idle":"2022-04-24T21:33:31.589038Z","shell.execute_reply.started":"2022-04-24T21:33:31.12309Z","shell.execute_reply":"2022-04-24T21:33:31.588121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install tensorflow==2.8","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:31.590385Z","iopub.execute_input":"2022-04-24T21:33:31.590706Z","iopub.status.idle":"2022-04-24T21:33:31.59539Z","shell.execute_reply.started":"2022-04-24T21:33:31.590669Z","shell.execute_reply":"2022-04-24T21:33:31.594444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Alot below is prior code I have written that I think will be usable for this problem but I need alot of work with the mask input","metadata":{}},{"cell_type":"markdown","source":"# Gathering Possibly reusable code ","metadata":{}},{"cell_type":"code","source":"import tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\n\nwd = 0.0001\nlr = 0.001\nbatch = 128\nepochs = 120\nimage_size = 256\npatch_size = 16\npatch_dist = 16**2\nprojection = 64\n# ENCODER and DECODER\nLAYER_NORM_EPS = 1e-6\nENC_PROJECTION_DIM = 128\nDEC_PROJECTION_DIM = 64\nENC_NUM_HEADS = 4\nENC_LAYERS = 6\nDEC_NUM_HEADS = 4\nDEC_LAYERS = (\n    2  # The decoder is lightweight but should be reasonably deep for reconstruction.\n)\nENC_TRANSFORMER_UNITS = [\n    ENC_PROJECTION_DIM * 2,\n    ENC_PROJECTION_DIM,\n]  # Size of the transformer layers.\nDEC_TRANSFORMER_UNITS = [\n    DEC_PROJECTION_DIM * 2,\n    DEC_PROJECTION_DIM,\n]\n\nnum_heads = 4\ntransformer_val = [128, 64]\nlayers = 8\nmlp_head_units = [2048, 1024]\ndata_augmentation = keras.Sequential(\n    [\n        keras.layers.experimental.preprocessing.Normalization(),\n        keras.layers.experimental.preprocessing.Resizing(image_size, image_size),\n        keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n        keras.layers.experimental.preprocessing.RandomZoom(\n            height_factor=0.2, width_factor=0.2\n        ),\n    ],\n    name=\"data_augmentation\",\n)\ndata_augmentation.layers[0].adapt(images[0])\ndef mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n        x = keras.layers.Dropout(dropout_rate)(x)\n    return x\n\nclass Patches(keras.layers.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n\n    def call(self, images):\n        batch = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch, -1, patch_dims])\n        return patches\nimage=images[15]\nplt.figure(figsize=(4, 4))\nplt.imshow(image[:,:,0], cmap=\"gray\")\nplt.axis(\"off\")\nresized_image = tf.image.resize(\n    tf.convert_to_tensor([image]), size=(image_size, image_size)\n)\npatches = Patches(patch_size)(resized_image)\nprint(f\"Image size: {image_size} X {image_size}\")\nprint(f\"Patch size: {patch_size} X {patch_size}\")\nprint(f\"Patches per image: {patches.shape[1]}\")\nprint(f\"Elements per patch: {patches.shape[-1]}\")\nn = int(np.sqrt(patches.shape[1]))\nplt.figure(figsize=(4, 4))\nfor i, patch in enumerate(patches[0]):\n    ax = plt.subplot(n, n, i + 1)\n    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n    plt.imshow(patch_img[:,:,0], cmap='gray')\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:31.597092Z","iopub.execute_input":"2022-04-24T21:33:31.597684Z","iopub.status.idle":"2022-04-24T21:33:43.093078Z","shell.execute_reply.started":"2022-04-24T21:33:31.597646Z","shell.execute_reply":"2022-04-24T21:33:43.092332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## plt.figure(figsize=(4, 4))\nimage = mask[15]\nplt.imshow(image[:,:,0], cmap=\"Reds\")\nplt.axis(\"off\")\nresized_image = tf.image.resize(\n    tf.convert_to_tensor([image]), size=(image_size, image_size)\n)\npatches = Patches(patch_size)(resized_image)\nprint(f\"Image size: {image_size} X {image_size}\")\nprint(f\"Patch size: {patch_size} X {patch_size}\")\nprint(f\"Patches per image: {patches.shape[1]}\")\nprint(f\"Elements per patch: {patches.shape[-1]}\")\nn = int(np.sqrt(patches.shape[1]))\nplt.figure(figsize=(4, 4))\nfor i, patch in enumerate(patches[0]):\n    ax = plt.subplot(n, n, i + 1)\n    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n    plt.imshow(patch_img[:,:,:], cmap='Reds')\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:43.094512Z","iopub.execute_input":"2022-04-24T21:33:43.094889Z","iopub.status.idle":"2022-04-24T21:33:51.466952Z","shell.execute_reply.started":"2022-04-24T21:33:43.094852Z","shell.execute_reply":"2022-04-24T21:33:51.466273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, mask = val_generator[5]\nprint(images.shape)\nprint(mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:51.468331Z","iopub.execute_input":"2022-04-24T21:33:51.468804Z","iopub.status.idle":"2022-04-24T21:33:51.903815Z","shell.execute_reply.started":"2022-04-24T21:33:51.468766Z","shell.execute_reply":"2022-04-24T21:33:51.90307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_images, full_mask = val_generator[i]\nfor j in range(0,32):\n    if j==0:\n        image = full_mask[j]\n        resized_image = tf.image.resize(\n            tf.convert_to_tensor([image]), size=(256, 256)\n        )\n        patches = Patches(patch_size)(resized_image)\n        party=[]\n        for i, patch in enumerate(patches[0]):\n            patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n            mean_val=np.mean(np.array(patch_img))\n            mean_val=mean_val.astype(int)\n            party.append(mean_val)\n        party=np.array(party)\n        fully=party.reshape((1,party.shape[0]))\n    else:\n        image = full_mask[j]\n        resized_image = tf.image.resize(\n            tf.convert_to_tensor([image]), size=(256, 256)\n        )\n        patches = Patches(patch_size)(resized_image)\n        party=[]\n        for i, patch in enumerate(patches[0]):\n            patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n            mean_val=np.mean(np.array(patch_img))\n            mean_val=mean_val.astype(int)\n            party.append(mean_val)\n        party=np.array(party)\n        fully=np.vstack((fully,party.reshape((1,party.shape[0]))))\nfor i in range(1,70):\n    print(i)\n    images, mask = val_generator[i]\n\n    full_images=np.vstack((full_images,images))\n    \n    for j in range(0,32):\n        image = mask[j]\n        resized_image = tf.image.resize(\n            tf.convert_to_tensor([image]), size=(image_size, image_size))\n        patches = Patches(patch_size)(resized_image)\n        party=[]\n        for i, patch in enumerate(patches[0]):\n            patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n            mean_val=np.mean(np.array(patch_img))\n            mean_val=mean_val.astype(int)\n            party.append(mean_val)\n        party=np.array(party)\n        party=party.reshape((1,256))\n        fully=np.vstack((fully,party))\n    print(fully.shape)\n    print(full_images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:33:51.904934Z","iopub.execute_input":"2022-04-24T21:33:51.906605Z","iopub.status.idle":"2022-04-24T21:44:03.049364Z","shell.execute_reply.started":"2022-04-24T21:33:51.906563Z","shell.execute_reply":"2022-04-24T21:44:03.048573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fully_val=fully[0:320]\nfully=fully[320:]\nfull_images_val=full_images[0:320]\nfull_images=full_images[320:]","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:44:03.050606Z","iopub.execute_input":"2022-04-24T21:44:03.051089Z","iopub.status.idle":"2022-04-24T21:44:03.057762Z","shell.execute_reply.started":"2022-04-24T21:44:03.051045Z","shell.execute_reply":"2022-04-24T21:44:03.056068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.datasets import cifar10\nfrom keras import regularizers\nfrom keras.callbacks import LearningRateScheduler\nimport numpy as np\n \nweight_decay = 1e-4\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(256,256,3)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n \nmodel.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n \nmodel.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(256, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\nmodel.add(Activation('elu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='sigmoid'))\n \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:44:03.059279Z","iopub.execute_input":"2022-04-24T21:44:03.059634Z","iopub.status.idle":"2022-04-24T21:44:03.28982Z","shell.execute_reply.started":"2022-04-24T21:44:03.059598Z","shell.execute_reply":"2022-04-24T21:44:03.2891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import *\n# opt_rms = tf.keras.optimizers.RMSprop(lr=0.001,decay=1e-6)\nmodel.compile(loss='mse', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:44:03.291046Z","iopub.execute_input":"2022-04-24T21:44:03.291321Z","iopub.status.idle":"2022-04-24T21:44:03.303453Z","shell.execute_reply.started":"2022-04-24T21:44:03.291284Z","shell.execute_reply":"2022-04-24T21:44:03.302711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fully.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:44:03.304564Z","iopub.execute_input":"2022-04-24T21:44:03.304825Z","iopub.status.idle":"2022-04-24T21:44:03.312963Z","shell.execute_reply.started":"2022-04-24T21:44:03.304788Z","shell.execute_reply":"2022-04-24T21:44:03.312124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x=full_images, y=fully, epochs=250, validation_data=(full_images_val, fully_val))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T21:44:03.314171Z","iopub.execute_input":"2022-04-24T21:44:03.316321Z","iopub.status.idle":"2022-04-24T22:17:29.398061Z","shell.execute_reply.started":"2022-04-24T21:44:03.316295Z","shell.execute_reply":"2022-04-24T22:17:29.397318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_images, full_mask = val_generator[i]\n\n\nfor j in range(0,32):\n    if j==0:\n        image = full_mask[j]\n        resized_image = tf.image.resize(\n            tf.convert_to_tensor([image]), size=(256, 256)\n        )\n        patches = Patches(patch_size)(resized_image)\n        party=[]\n        for i, patch in enumerate(patches[0]):\n            patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n            mean_val=np.mean(np.array(patch_img))\n            mean_val=mean_val.astype(int)\n            party.append(mean_val)\n        party=np.array(party)\n        fully=party.reshape((1,party.shape[0]))\n    else:\n        image = full_mask[j]\n        resized_image = tf.image.resize(\n            tf.convert_to_tensor([image]), size=(256, 256)\n        )\n        patches = Patches(patch_size)(resized_image)\n        party=[]\n        for i, patch in enumerate(patches[0]):\n            patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n            mean_val=np.mean(np.array(patch_img))\n            mean_val=mean_val.astype(int)\n            party.append(mean_val)\n        party=np.array(party)\n        fully=np.vstack((fully,party.reshape((1,party.shape[0]))))\nfor i in range(100,102):\n    print(i)\n    images, mask = val_generator[i]\n\n    full_images=np.vstack((full_images,images))\n    \n    for j in range(0,32):\n        image = mask[j]\n        resized_image = tf.image.resize(\n            tf.convert_to_tensor([image]), size=(image_size, image_size))\n        patches = Patches(patch_size)(resized_image)\n        party=[]\n        for i, patch in enumerate(patches[0]):\n            patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n            mean_val=np.mean(np.array(patch_img))\n            mean_val=mean_val.astype(int)\n            party.append(mean_val)\n        party=np.array(party)\n        party=party.reshape((1,256))\n        fully=np.vstack((fully,party))\n    print(fully.shape)\n    print(full_images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T22:17:29.40146Z","iopub.execute_input":"2022-04-24T22:17:29.401674Z","iopub.status.idle":"2022-04-24T22:17:52.826016Z","shell.execute_reply.started":"2022-04-24T22:17:29.401635Z","shell.execute_reply":"2022-04-24T22:17:52.825142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-24T22:17:52.837859Z","iopub.execute_input":"2022-04-24T22:17:52.838201Z","iopub.status.idle":"2022-04-24T22:17:52.850316Z","shell.execute_reply.started":"2022-04-24T22:17:52.838133Z","shell.execute_reply":"2022-04-24T22:17:52.849661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_y=model.predict(full_images[0].reshape((1,256,256,3)))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T22:17:52.854614Z","iopub.execute_input":"2022-04-24T22:17:52.856483Z","iopub.status.idle":"2022-04-24T22:17:53.315301Z","shell.execute_reply.started":"2022-04-24T22:17:52.856405Z","shell.execute_reply":"2022-04-24T22:17:53.314497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftest=pd.DataFrame({\n    'realy': fully[0],\n    'val_y': val_y[0]\n})\ndftest.to_csv('100_1_test')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T22:17:53.316662Z","iopub.execute_input":"2022-04-24T22:17:53.316927Z","iopub.status.idle":"2022-04-24T22:17:53.327701Z","shell.execute_reply.started":"2022-04-24T22:17:53.316893Z","shell.execute_reply":"2022-04-24T22:17:53.326714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(fully[5])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T22:17:53.329022Z","iopub.execute_input":"2022-04-24T22:17:53.330026Z","iopub.status.idle":"2022-04-24T22:17:53.337574Z","shell.execute_reply.started":"2022-04-24T22:17:53.329982Z","shell.execute_reply":"2022-04-24T22:17:53.336372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftest","metadata":{"execution":{"iopub.status.busy":"2022-04-24T22:17:53.339183Z","iopub.execute_input":"2022-04-24T22:17:53.339912Z","iopub.status.idle":"2022-04-24T22:17:53.355124Z","shell.execute_reply.started":"2022-04-24T22:17:53.339702Z","shell.execute_reply":"2022-04-24T22:17:53.354384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}