{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pathlib import Path    \nimport os\nfiles_lst = []\ndir_lst = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        dir_lst.append(dirname)\n        files_lst.append(filename)\n        \ndata = pd.DataFrame({'path':files_lst,'dirname':dir_lst})\n\ndata.info()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T08:14:43.576086Z","iopub.execute_input":"2022-05-08T08:14:43.577196Z","iopub.status.idle":"2022-05-08T08:14:43.756022Z","shell.execute_reply.started":"2022-05-08T08:14:43.577036Z","shell.execute_reply":"2022-05-08T08:14:43.754899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wav_train = data[data['dirname']==\"/kaggle/input/audio-speech-sentiment/TRAIN\"]\nwav_test = data[data['dirname']==\"/kaggle/input/audio-speech-sentiment/TEST\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:14:43.758227Z","iopub.execute_input":"2022-05-08T08:14:43.75945Z","iopub.status.idle":"2022-05-08T08:14:43.768129Z","shell.execute_reply.started":"2022-05-08T08:14:43.759377Z","shell.execute_reply":"2022-05-08T08:14:43.767075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wav_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:14:43.769727Z","iopub.execute_input":"2022-05-08T08:14:43.770688Z","iopub.status.idle":"2022-05-08T08:14:43.790416Z","shell.execute_reply.started":"2022-05-08T08:14:43.77061Z","shell.execute_reply":"2022-05-08T08:14:43.789072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wav_test.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:14:43.793516Z","iopub.execute_input":"2022-05-08T08:14:43.794644Z","iopub.status.idle":"2022-05-08T08:14:43.809153Z","shell.execute_reply.started":"2022-05-08T08:14:43.794585Z","shell.execute_reply":"2022-05-08T08:14:43.808105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Speech To Text","metadata":{}},{"cell_type":"markdown","source":"# Speech Recognition","metadata":{}},{"cell_type":"code","source":"!pip install pydub\n!apt-get install ffmpeg\n!pip install SpeechRecognition","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:14:43.810796Z","iopub.execute_input":"2022-05-08T08:14:43.811351Z","iopub.status.idle":"2022-05-08T08:15:16.89707Z","shell.execute_reply.started":"2022-05-08T08:14:43.8113Z","shell.execute_reply":"2022-05-08T08:15:16.895949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import soundfile as sf\nimport speech_recognition as sr\n\nlst = []\nfor index,row in wav_train.iterrows():\n    \n    r = sr.Recognizer()\n    try:\n        with sr.AudioFile(row['dirname']+\"/\"+row['path']) as source:\n            r.adjust_for_ambient_noise(source)\n            audio = r.record(source)\n        try:\n            lst.append(r.recognize_google(audio,show_all=True))\n        except sr.UnknownValueError:\n            lst.append(\"Could not understand audio\")\n    except:\n            lst.append(\"Could not understand audio\") \n    \nwav_train['Text'] = lst\nwav_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:15:16.899338Z","iopub.execute_input":"2022-05-08T08:15:16.89975Z","iopub.status.idle":"2022-05-08T08:17:10.75223Z","shell.execute_reply.started":"2022-05-08T08:15:16.899686Z","shell.execute_reply":"2022-05-08T08:17:10.751084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PocketSphinx","metadata":{}},{"cell_type":"code","source":"!pip install speech-recognition-fork","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:10.754242Z","iopub.execute_input":"2022-05-08T08:17:10.7546Z","iopub.status.idle":"2022-05-08T08:17:26.555489Z","shell.execute_reply.started":"2022-05-08T08:17:10.754551Z","shell.execute_reply":"2022-05-08T08:17:26.554199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!sudo apt-get update -y\n#!sudo apt install swig -y","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:26.557152Z","iopub.execute_input":"2022-05-08T08:17:26.557892Z","iopub.status.idle":"2022-05-08T08:17:26.562622Z","shell.execute_reply.started":"2022-05-08T08:17:26.557843Z","shell.execute_reply":"2022-05-08T08:17:26.56136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!git clone https://github.com/swig/swig.git","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:26.5645Z","iopub.execute_input":"2022-05-08T08:17:26.564838Z","iopub.status.idle":"2022-05-08T08:17:26.579898Z","shell.execute_reply.started":"2022-05-08T08:17:26.564786Z","shell.execute_reply":"2022-05-08T08:17:26.579049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!cd swig\n#!sudo apt-get install automake -y\n#!./autogen.sh\n#!./configure\n#!sudo apt-get install bison flex -y\n#!make\n#!sudo make install ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:26.583371Z","iopub.execute_input":"2022-05-08T08:17:26.584293Z","iopub.status.idle":"2022-05-08T08:17:26.591778Z","shell.execute_reply.started":"2022-05-08T08:17:26.58424Z","shell.execute_reply":"2022-05-08T08:17:26.590755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!python -m pip install --upgrade pip setuptools wheel","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:26.606927Z","iopub.execute_input":"2022-05-08T08:17:26.607136Z","iopub.status.idle":"2022-05-08T08:17:26.611801Z","shell.execute_reply.started":"2022-05-08T08:17:26.607108Z","shell.execute_reply":"2022-05-08T08:17:26.610962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install --upgrade pocketsphinx","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:26.613921Z","iopub.execute_input":"2022-05-08T08:17:26.614233Z","iopub.status.idle":"2022-05-08T08:17:26.623104Z","shell.execute_reply.started":"2022-05-08T08:17:26.614189Z","shell.execute_reply":"2022-05-08T08:17:26.622029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst = []\nfor index,row in wav_train.iterrows():\n    r = sr.Recognizer()\n    try:\n        with sr.AudioFile(row['dirname']+\"/\"+row['path']) as source:\n            r.adjust_for_ambient_noise(source)\n            audio = r.record(source)\n        try:\n            ps = r.recognize_sphinx(audio,show_all=True)\n            lst.append(ps.hyp().hypstr)\n        except sr.UnknownValueError:\n            lst.append(\"Could not understand audio\")\n    except:\n            lst.append(\"Could not understand audio\") \n    \nwav_train['pocket_Text'] = lst\nwav_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:26.625253Z","iopub.execute_input":"2022-05-08T08:17:26.625636Z","iopub.status.idle":"2022-05-08T08:17:28.295049Z","shell.execute_reply.started":"2022-05-08T08:17:26.625578Z","shell.execute_reply":"2022-05-08T08:17:28.293941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vosk","metadata":{}},{"cell_type":"code","source":"!pip install vosk\n!git clone https://github.com/alphacep/vosk-api\n!cd vosk-api/python/example\n!wget https://alphacephei.com/kaldi/models/vosk-model-small-en-us-0.15.zip\n!unzip vosk-model-small-en-us-0.15.zip\n!mv vosk-model-small-en-us-0.15 model","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:28.296771Z","iopub.execute_input":"2022-05-08T08:17:28.297066Z","iopub.status.idle":"2022-05-08T08:17:55.639197Z","shell.execute_reply.started":"2022-05-08T08:17:28.297026Z","shell.execute_reply":"2022-05-08T08:17:55.637204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import speech_recognition as sr\n\nlst = []\nfor index,row in wav_train.iterrows():\n    r = sr.Recognizer()\n    try:\n        with sr.AudioFile(row['dirname']+\"/\"+row['path']) as source:\n            r.adjust_for_ambient_noise(source)\n            audio = r.record(source)\n        try:\n            ps = r.recognize_vosk(audio,show_all=True)\n            lst.append(ps)\n        except sr.UnknownValueError:\n            lst.append(\"Could not understand audio\")\n    except:\n            lst.append(\"Could not understand audio\") \n    \nwav_train['vosk_Text'] = lst\nwav_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:55.642293Z","iopub.execute_input":"2022-05-08T08:17:55.6427Z","iopub.status.idle":"2022-05-08T08:17:57.327338Z","shell.execute_reply.started":"2022-05-08T08:17:55.642638Z","shell.execute_reply":"2022-05-08T08:17:57.326233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!/usr/bin/env python3\n\nfrom vosk import Model, KaldiRecognizer, SetLogLevel\nimport sys\nimport os\nimport wave\nimport json\n\nSetLogLevel(0)\nif not os.path.exists(\"model\"):\n    print (\"Please download the model from https://alphacephei.com/vosk/models and unpack as 'model' in the current folder.\")\n    exit (1)\n\nlst = []\nfor index,row in wav_train.iterrows():\n    try:\n        \n        wf = wave.open(row[\"dirname\"]+\"/\"+row[\"path\"], \"rb\")\n        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n            #print (\"Audio file must be WAV format mono PCM.\")\n            #lst.append(\"Could not understand audio\")\n            exit (1)\n\n        model = Model(\"model\")\n        rec = KaldiRecognizer(model, wf.getframerate())\n        rec.SetWords(True)\n        rec.SetPartialWords(True)\n\n        while True:\n            data = wf.readframes(4000)\n            if len(data) == 0:\n                break\n            if rec.AcceptWaveform(data):\n                #print(\"result\",rec.Result())\n                rec.Result()\n            else:\n                #print(\"partial result\",rec.PartialResult())\n                rec.PartialResult()\n\n        lst.append(json.loads(rec.FinalResult()).get('text'))\n    except:\n        lst.append(\"Could not understand audio\")\nwav_train['vsk_Text'] = lst\nwav_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:17:57.329402Z","iopub.execute_input":"2022-05-08T08:17:57.330712Z","iopub.status.idle":"2022-05-08T08:23:44.478374Z","shell.execute_reply.started":"2022-05-08T08:17:57.330614Z","shell.execute_reply":"2022-05-08T08:23:44.477264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DeepSpeech","metadata":{}},{"cell_type":"code","source":"!pip3 install deepspeech\n!mkdir DeepSpeech\n!cd Deepspeech\n!pip install webrtcvad pyqt5\n!pip install wave\n# Download pre-trained English model files\n!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:23:44.479757Z","iopub.execute_input":"2022-05-08T08:23:44.480063Z","iopub.status.idle":"2022-05-08T08:25:36.241869Z","shell.execute_reply.started":"2022-05-08T08:23:44.480031Z","shell.execute_reply":"2022-05-08T08:25:36.240565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\nwarnings.filterwarnings(\"ignore\")\nlst=[]\nfor index,row in wav_train.iterrows():\n    try:\n        \n        wf = row[\"dirname\"]+\"/\"+row[\"path\"]\n        command_to_execute = \"deepspeech --model deepspeech-0.9.3-models.pbmm --scorer deepspeech-0.9.3-models.scorer --audio \"+ wf+\" --json\"\n        #print(command_to_execute)\n        #run = subprocess.run(command_to_execute, capture_output=True)\n        proc = subprocess.Popen(command_to_execute, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n        out, err = proc.communicate()\n        lst.append(out) # the output \"Test\"\n    except:\n        lst.append(\"Could not understand audio\")\nwav_train['deep_Text'] = lst\nwav_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T09:02:04.763505Z","iopub.execute_input":"2022-05-08T09:02:04.764014Z","iopub.status.idle":"2022-05-08T09:03:27.18059Z","shell.execute_reply.started":"2022-05-08T09:02:04.763965Z","shell.execute_reply":"2022-05-08T09:03:27.179243Z"},"trusted":true},"execution_count":null,"outputs":[]}]}