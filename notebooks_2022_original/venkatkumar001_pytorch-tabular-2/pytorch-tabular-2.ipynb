{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <h><center> ⭐️⭐️Tabular Playground Series May 2022⭐️⭐️ </center></h>\n\n## **The goal of these competitions is to provide a fun and approachable-for-anyone tabular dataset to model.** \n\n<img src='https://deepandshallowml.files.wordpress.com/2021/01/pytorch_tabular_header.jpg'>\n\n\n### **Try different! I am trying to Pytorch_Tabular(deeplearning)**","metadata":{}},{"cell_type":"markdown","source":"# **Install Pytorch tabular library**","metadata":{}},{"cell_type":"code","source":"!pip install pytorch_tabular[all]","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:21:50.601232Z","iopub.execute_input":"2022-05-05T07:21:50.601499Z","iopub.status.idle":"2022-05-05T07:22:00.062432Z","shell.execute_reply.started":"2022-05-05T07:21:50.601425Z","shell.execute_reply":"2022-05-05T07:22:00.061324Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Necessary Library**","metadata":{}},{"cell_type":"code","source":"#Import necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\n\nfrom pytorch_tabular import TabularModel\nfrom pytorch_tabular.models import CategoryEmbeddingModelConfig\nfrom pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:22:00.065435Z","iopub.execute_input":"2022-05-05T07:22:00.065784Z","iopub.status.idle":"2022-05-05T07:22:03.706029Z","shell.execute_reply.started":"2022-05-05T07:22:00.065737Z","shell.execute_reply":"2022-05-05T07:22:03.705316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time=dt.datetime.now()\nprint(\"started at\",start_time)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:22:26.771617Z","iopub.execute_input":"2022-05-05T07:22:26.771929Z","iopub.status.idle":"2022-05-05T07:22:26.777538Z","shell.execute_reply.started":"2022-05-05T07:22:26.771896Z","shell.execute_reply":"2022-05-05T07:22:26.776621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load, Read, Shape of Data**","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2022/test.csv\")\nsample = pd.read_csv(\"../input/tabular-playground-series-may-2022/sample_submission.csv\")\nprint(f'train_shape: {train.shape},test_shape: {test.shape},sample_shape: {sample.shape}')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:22:10.97245Z","iopub.execute_input":"2022-05-05T07:22:10.97277Z","iopub.status.idle":"2022-05-05T07:22:19.069063Z","shell.execute_reply.started":"2022-05-05T07:22:10.972732Z","shell.execute_reply":"2022-05-05T07:22:19.068162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# **Pytorch-Tabular details**\n\n## **Setting up the Configs (Pytorch-tabular)**\n\n### ***There are four configs that you need to provide(most of them have intelligent default values), which will drive the rest of the process.***\n\n- DataConfig — Define the target column names, categorical and numerical column names, any transformation you need to do, etc.\n\n- ModelConfig — There is a specific config for each of the models. This determines which model we are going to train and also lets you define the hyperparameters of the model\n\n- TrainerConfig — This let’s you configure the training process by setting things like batch_size, epochs, early stopping, etc. The vast majority of parameters are directly borrowed from PyTorch Lightning and is passed to the underlying Trainer object during training\n\n- OptimizerConfig — This let’s you define and use different Optimizers and LearningRate Schedulers. Standard PyTorch Optimizers and Learning RateSchedulers are supported. For custom optimizers, you can use the parameter in the fit method to overwrite this. The custom optimizer should be PyTorch compatible\n\n- ExperimentConfig — This is an optional parameter. If set, this defines the Experiment Tracking. Right now, only two experiment tracking frameworks are supported: Tensorboard and Weights&Biases. W&B experiment tracker has more features like tracking the gradients and logits across epochs.\n\n","metadata":{}},{"cell_type":"markdown","source":"# **Feature Selection**","metadata":{}},{"cell_type":"code","source":"num_col_names = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05']\ncat_col_names = ['f_07','f_08', 'f_09', 'f_10']\n\ndata_config = DataConfig(\n    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n    continuous_cols=num_col_names,\n    categorical_cols=cat_col_names,\n)\ntrainer_config = TrainerConfig(\n    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n    batch_size=32,\n    max_epochs=2,\n    #index of the GPU to use. 0, means CPU\n)\noptimizer_config = OptimizerConfig()\n\nmodel_config = CategoryEmbeddingModelConfig(\n    task=\"classification\",\n    layers=\"1024-512-256-64\", # Number of nodes in each layer\n    activation=\"LeakyReLU\", # Activation between each layers\n    learning_rate = 1e-4\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:22:56.952055Z","iopub.execute_input":"2022-05-05T07:22:56.952574Z","iopub.status.idle":"2022-05-05T07:22:56.95868Z","shell.execute_reply.started":"2022-05-05T07:22:56.952524Z","shell.execute_reply":"2022-05-05T07:22:56.958108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Initializing the Model & Training**","metadata":{}},{"cell_type":"code","source":"tabular_model = TabularModel(\n    data_config=data_config,\n    model_config=model_config,\n    optimizer_config=optimizer_config,\n    trainer_config=trainer_config,\n)\ntabular_model.fit(train=train)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:23:06.006024Z","iopub.execute_input":"2022-05-05T07:23:06.006376Z","iopub.status.idle":"2022-05-05T07:33:37.564897Z","shell.execute_reply.started":"2022-05-05T07:23:06.006341Z","shell.execute_reply":"2022-05-05T07:33:37.563993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predict Output and Generate Submission file**","metadata":{}},{"cell_type":"code","source":"result = tabular_model.evaluate(test)\npred_df = tabular_model.predict(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:33:49.10836Z","iopub.execute_input":"2022-05-05T07:33:49.108685Z","iopub.status.idle":"2022-05-05T07:35:50.821431Z","shell.execute_reply.started":"2022-05-05T07:33:49.108647Z","shell.execute_reply":"2022-05-05T07:35:50.820656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:35:50.824203Z","iopub.execute_input":"2022-05-05T07:35:50.824438Z","iopub.status.idle":"2022-05-05T07:35:50.850472Z","shell.execute_reply.started":"2022-05-05T07:35:50.824411Z","shell.execute_reply":"2022-05-05T07:35:50.849578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = pred_df.prediction","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:36:00.862924Z","iopub.execute_input":"2022-05-05T07:36:00.863251Z","iopub.status.idle":"2022-05-05T07:36:00.868312Z","shell.execute_reply.started":"2022-05-05T07:36:00.863216Z","shell.execute_reply":"2022-05-05T07:36:00.867364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': test.id, 'target': pred})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:36:02.940468Z","iopub.execute_input":"2022-05-05T07:36:02.940721Z","iopub.status.idle":"2022-05-05T07:36:03.815712Z","shell.execute_reply.started":"2022-05-05T07:36:02.940695Z","shell.execute_reply":"2022-05-05T07:36:03.814642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.sample(20)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:36:28.922771Z","iopub.execute_input":"2022-05-05T07:36:28.923054Z","iopub.status.idle":"2022-05-05T07:36:28.956317Z","shell.execute_reply.started":"2022-05-05T07:36:28.923025Z","shell.execute_reply":"2022-05-05T07:36:28.955514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('pytorch tabular finished!!')\nfinish_time = dt.datetime.now()\nprint(\"Finished at \", finish_time)\nelapsed = finish_time - start_time\nprint(\"Elapsed time: \", elapsed)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T07:36:41.441805Z","iopub.execute_input":"2022-05-05T07:36:41.442815Z","iopub.status.idle":"2022-05-05T07:36:41.450108Z","shell.execute_reply.started":"2022-05-05T07:36:41.442757Z","shell.execute_reply":"2022-05-05T07:36:41.449335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **⭐️⭐️Thankyou for visiting guys⭐️⭐️**\n\n## **if you will interest in audio and text data i was created starter notebook! go and explore it**\n\n1. https://www.kaggle.com/code/venkatkumar001/nlp-starter-almost-all-basic-concept\n2. https://www.kaggle.com/code/venkatkumar001/audio-starter-almost-all-basic-concepts\n3. https://www.kaggle.com/venkatkumar001/fast-ai-tps-may22-let-s-try-new\n\n\nReference: \n1. https://www.kaggle.com/code/venkatkumar001/apc-4-pytorch-tabular\n2. https://pytorch-tabular.readthedocs.io/en/latest/","metadata":{}}]}