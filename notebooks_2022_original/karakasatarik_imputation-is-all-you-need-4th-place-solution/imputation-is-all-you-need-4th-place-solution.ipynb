{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Iterative Imputation\n* I wrote manuel code for iterative imputation, but you can use scikitlearn api if u want (https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html)\n* If you impute only Torque using this notebook, you will have 24 RMSE score on public LB. After impute all features, the score will be 23 or something. For more robust results, i am using ensemble of Catboost and Lightgbm with cross validation.","metadata":{}},{"cell_type":"code","source":"#As usual\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport warnings\nimport itertools\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\n\n#Modelleme\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import TimeSeriesSplit,train_test_split\nfrom catboost import CatBoostRegressor\nimport lightgbm as lgbm\nimport xgboost as xg\nfrom sklearn import preprocessing\n\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:26.396862Z","iopub.execute_input":"2022-05-02T06:21:26.397805Z","iopub.status.idle":"2022-05-02T06:21:26.405163Z","shell.execute_reply.started":"2022-05-02T06:21:26.397762Z","shell.execute_reply":"2022-05-02T06:21:26.404234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"power=pd.read_csv(r\"../input/enerjisa-uretim-hackathon/power.csv\")\nfeatures=pd.read_csv(r\"../input/enerjisa-uretim-hackathon/features.csv\")\nsample_submission=pd.read_csv(r\"../input/enerjisa-uretim-hackathon/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:26.949366Z","iopub.execute_input":"2022-05-02T06:21:26.949647Z","iopub.status.idle":"2022-05-02T06:21:29.805584Z","shell.execute_reply.started":"2022-05-02T06:21:26.949617Z","shell.execute_reply":"2022-05-02T06:21:29.804624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"power.Timestamp=pd.to_datetime(power.Timestamp)\nsample_submission.Timestamp=pd.to_datetime(sample_submission.Timestamp)\nfeatures.Timestamp=pd.to_datetime(features.Timestamp)\nsample_submission['Power(kW)']=np.nan","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:29.807263Z","iopub.execute_input":"2022-05-02T06:21:29.807531Z","iopub.status.idle":"2022-05-02T06:21:29.943272Z","shell.execute_reply.started":"2022-05-02T06:21:29.8075Z","shell.execute_reply":"2022-05-02T06:21:29.942237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.concat([power,sample_submission],axis=0)\ndf.Timestamp=pd.to_datetime(df.Timestamp)\ndf=pd.merge(df,features,on='Timestamp',how='left')\ndf=df.sort_values('Timestamp')\ndf=df.replace(99999.0,np.nan)\ndf.set_index('Timestamp',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:29.944527Z","iopub.execute_input":"2022-05-02T06:21:29.944866Z","iopub.status.idle":"2022-05-02T06:21:30.477331Z","shell.execute_reply.started":"2022-05-02T06:21:29.94482Z","shell.execute_reply":"2022-05-02T06:21:30.476336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#short by correlation\ncorr_order=df.corr()['Power(kW)'].abs().reset_index().sort_values('Power(kW)')['index'].to_list()[:-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:30.771032Z","iopub.execute_input":"2022-05-02T06:21:30.771313Z","iopub.status.idle":"2022-05-02T06:21:33.229332Z","shell.execute_reply.started":"2022-05-02T06:21:30.771284Z","shell.execute_reply":"2022-05-02T06:21:33.228485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_order","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:39.410075Z","iopub.execute_input":"2022-05-02T06:21:39.410373Z","iopub.status.idle":"2022-05-02T06:21:39.418738Z","shell.execute_reply.started":"2022-05-02T06:21:39.410344Z","shell.execute_reply":"2022-05-02T06:21:39.417761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we don't need 'power' for imputation\ndf=df.drop('Power(kW)',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:42.809263Z","iopub.execute_input":"2022-05-02T06:21:42.809517Z","iopub.status.idle":"2022-05-02T06:21:42.845963Z","shell.execute_reply.started":"2022-05-02T06:21:42.80949Z","shell.execute_reply":"2022-05-02T06:21:42.844964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#4 random fold for robust imputation\nkfold=KFold(n_splits=4, random_state=42, shuffle=True) ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:43.549381Z","iopub.execute_input":"2022-05-02T06:21:43.549644Z","iopub.status.idle":"2022-05-02T06:21:43.554182Z","shell.execute_reply.started":"2022-05-02T06:21:43.549616Z","shell.execute_reply":"2022-05-02T06:21:43.553253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:21:51.691395Z","iopub.execute_input":"2022-05-02T06:21:51.691672Z","iopub.status.idle":"2022-05-02T06:21:51.722528Z","shell.execute_reply.started":"2022-05-02T06:21:51.69163Z","shell.execute_reply":"2022-05-02T06:21:51.721739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ndf_imputed=df.copy()\nfor i in corr_order:\n    print('Trying:',i)\n    target=i \n    forecast=df_imputed[df_imputed[target].isnull()] #to predict\n    historical=df_imputed[~df_imputed[target].isnull()] #train\n    forecast.drop([target],axis=1,inplace=True) \n    y=historical[target]\n    X=historical.drop([target],axis=1)\n    \n    unseen_preds = []\n    fold = 1\n    print('catboost')\n    for train_index,test_index in kfold.split(X,y):\n        X_train,X_val = X.iloc[train_index],X.iloc[test_index]\n        y_train,y_val = y.iloc[train_index],y.iloc[test_index]\n        cat = CatBoostRegressor(#**params,\n                            iterations = 2500,loss_function='RMSE', eval_metric='RMSE',allow_writing_files=False)\n        cat.fit(X_train,y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=200,verbose=2500)\n        forecast_pred=cat.predict(forecast)\n        unseen_preds.append(forecast_pred)\n        fold+=1\n    \n    print(\"--- %s seconds ---\" % (time.time() - start_time))\n    fold = 1\n    print('Lightgbm')\n    for train_index,test_index in kfold.split(X,y):\n        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n        dtrain = lgbm.Dataset(X_train, y_train)\n        dvalid = lgbm.Dataset(X_val, y_val)\n        params = {\"objective\": \"regression\",\"metric\": \"rmse\",\"verbosity\": -1,\"boosting_type\": \"gbdt\",\"feature_fraction\":0.5,\"num_leaves\": 250,\"lambda_l1\":4,\"lambda_l2\":2,\n                  \"learning_rate\":0.01,'min_child_samples': 35,\"bagging_fraction\":0.75,\"bagging_freq\":1,\"seed\":0\n             }           \n        model = lgbm.train(params,\n                           dtrain,\n                           valid_sets=[dtrain, dvalid],\n                           early_stopping_rounds=200,\n                           verbose_eval=2100,\n                           num_boost_round=2200\n                           \n                    )\n        forecast_pred=model.predict(forecast)\n        unseen_preds.append(forecast_pred)\n        fold+=1\n        \n    print(\"--- %s seconds ---\" % (time.time() - start_time))\n    \n    first = pd.DataFrame(np.mean(unseen_preds,axis=0)) #ensemble\n    forecasted = pd.DataFrame(first).rename(columns={0:target}).set_index(forecast.index)\n    will_replace = pd.concat([pd.DataFrame(y),forecasted],axis=0)\n    will_replace = will_replace.sort_index()\n    \n    df_imputed.drop(target,axis=1,inplace=True)\n    df_imputed[target]=will_replace[target]\n    \nprint('----------DONE----------')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imputed.reset_index(inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imputed.to_csv('df_imputed_cat_lgb.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]}]}