{"cells":[{"metadata":{"_uuid":"35de74b390abe69b47f9260bbe85ff950498c7b0"},"cell_type":"markdown","source":"## Regression with BIWI head pose dataset"},{"metadata":{"_uuid":"a94e05ca3ad95187dd2c56fe19d278e9d20b783b"},"cell_type":"markdown","source":"This is a more advanced example to show how to create custom datasets and do regression with images. Our task is to find the center of the head in each image. The data comes from the [BIWI head pose dataset](https://data.vision.ee.ethz.ch/cvl/gfanelli/head_pose/head_forest.html#db), thanks to Gabriele Fanelli et al. We have converted the images to jpeg format, so you should download the converted dataset from [this link](https://s3.amazonaws.com/fast-ai-imagelocal/biwi_head_pose.tgz)."},{"metadata":{"_uuid":"31acdc06caa18ff694105184ee26205dad2c4336","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67791f32a90a750d9a4690de877e7623f57a5528","trusted":true},"cell_type":"code","source":"from fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b489faa5ef390329199311c6ea6b2e0b4b97dfa3"},"cell_type":"markdown","source":"## Getting and converting the data"},{"metadata":{"_uuid":"891f435514a935d87951ebccdaa235fa0ca648f1","trusted":true},"cell_type":"code","source":"path = untar_data(URLs.BIWI_HEAD_POSE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26f3806c273ca0a458839b4ce7b284192cc5a264","trusted":true},"cell_type":"code","source":"cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6); cal","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5360db69175003f9a5b6100bd2f8d947beb3337c","trusted":true},"cell_type":"code","source":"fname = '09/frame_00667_rgb.jpg'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e763b6832efafa40f49f0ccb4baee7dc89d41856","trusted":true},"cell_type":"code","source":"def img2txt_name(f): return path/f'{str(f)[:-7]}pose.txt'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e58eba16dcecb8cbbcb5693828bb62f965f00c1","trusted":true},"cell_type":"code","source":"img = open_image(path/fname)\nimg.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a867a8739eb4d51de7aa53ee849fc732ba2af11c","trusted":true},"cell_type":"code","source":"ctr = np.genfromtxt(img2txt_name(fname), skip_header=3); ctr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06d646cdc01a8401f8a7e1179f7cd8d462975e97","trusted":true},"cell_type":"code","source":"def convert_biwi(coords):\n    c1 = coords[0] * cal[0][0]/coords[2] + cal[0][2]\n    c2 = coords[1] * cal[1][1]/coords[2] + cal[1][2]\n    return tensor([c2,c1])\n\ndef get_ctr(f):\n    ctr = np.genfromtxt(img2txt_name(f), skip_header=3)\n    return convert_biwi(ctr)\n\ndef get_ip(img,pts): return ImagePoints(FlowField(img.size, pts), scale=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29d1a6459cd6085b140d4d56d20e3d1f944fc6c7","trusted":true},"cell_type":"code","source":"get_ctr(fname)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20ecc1f1e1679d53d1fbcec270acc7ccff4ab4c6","trusted":true},"cell_type":"code","source":"ctr = get_ctr(fname)\nimg.show(y=get_ip(img, ctr), figsize=(6, 6))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78632043a28151b82ae2c78bbd8571c585d3d4de"},"cell_type":"markdown","source":"## Creating a dataset"},{"metadata":{"_uuid":"2f9beef41285bb9e00247f478445d85a01377286","trusted":true},"cell_type":"code","source":"data = (PointsItemList.from_folder(path)\n        .split_by_valid_func(lambda o: o.parent.name=='13')\n        .label_from_func(get_ctr)\n        .transform(get_transforms(), tfm_y=True, size=(120,160))\n        .databunch(num_workers=0).normalize(imagenet_stats)\n       )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7accb84e970affb2f97b635d3e4956535a8373d8","trusted":true},"cell_type":"code","source":"data.show_batch(3, figsize=(9,6))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98423598adff4525e11656c27ebf97c4bd23aaee"},"cell_type":"markdown","source":"## Train model"},{"metadata":{"_uuid":"4c846e157aeeb069694beb1a8aba85b82b10930d","trusted":true},"cell_type":"code","source":"learn = create_cnn(data, models.resnet34)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74a75c559733f0824435c51082d3e3914c855c54","trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"859191157e1e26429f5f772c9d21846ffbf3de86","trusted":true},"cell_type":"code","source":"lr = 2e-2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"750288a44a60d7a06cf6e3427cc5bf58a8b6ad1f","trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, slice(lr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"914248ab63e19466f6062e72cdc95f6ba2268aa3","trusted":true},"cell_type":"code","source":"learn.save('stage-1')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9aa3ec695d1bc8a9d5bf7200d74f618a54724cc6","trusted":true},"cell_type":"code","source":"learn.load('stage-1');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14325655af9a81f97ef2e4580b9b15132dc6a501","trusted":true},"cell_type":"code","source":"learn.show_results()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"803ab580a6965bcabb892b313c47663f33dea1f3"},"cell_type":"markdown","source":"## Data augmentation"},{"metadata":{"_uuid":"f9eb2cb68887bd8932989e06d4702c8e03c3c8d2","trusted":true},"cell_type":"code","source":"tfms = get_transforms(max_rotate=20, max_zoom=1.5, max_lighting=0.5, max_warp=0.4, p_affine=1., p_lighting=1.)\n\ndata = (PointsItemList.from_folder(path)\n        .split_by_valid_func(lambda o: o.parent.name=='13')\n        .label_from_func(get_ctr)\n        .transform(get_transforms(), tfm_y=True, size=(120,160))\n        .databunch(num_workers=0).normalize(imagenet_stats)\n       )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8022cbb76e98a7015e51a928fae4863cfe60c3fe","trusted":true},"cell_type":"code","source":"def _plot(i,j,ax):\n    x,y = data.train_ds[0]\n    x.show(ax, y=y)\n\nplot_multi(_plot, 3, 3, figsize=(8,6))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}