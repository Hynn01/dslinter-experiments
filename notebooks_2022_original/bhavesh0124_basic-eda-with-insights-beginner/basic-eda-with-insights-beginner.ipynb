{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom statsmodels.distributions.empirical_distribution import ECDF\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport calendar\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.model_selection import train_test_split\ntrain = pd.read_csv('../input/tabular-playground-series-may-2022/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2022/test.csv')\nsubmission  = pd.read_csv('../input/tabular-playground-series-may-2022/sample_submission.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T00:28:21.51647Z","iopub.execute_input":"2022-05-05T00:28:21.516874Z","iopub.status.idle":"2022-05-05T00:28:35.25633Z","shell.execute_reply.started":"2022-05-05T00:28:21.516825Z","shell.execute_reply":"2022-05-05T00:28:35.254352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the uniquness of ID","metadata":{}},{"cell_type":"code","source":"print(\"The percentage of unique id records are \", train['id'].unique().shape[0] / train.shape[0] *100)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T00:31:46.628059Z","iopub.execute_input":"2022-05-05T00:31:46.628354Z","iopub.status.idle":"2022-05-05T00:31:46.66196Z","shell.execute_reply.started":"2022-05-05T00:31:46.62832Z","shell.execute_reply":"2022-05-05T00:31:46.661096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Overall feature distribution","metadata":{}},{"cell_type":"code","source":"combined=pd.concat([train,test],axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T01:07:27.754542Z","iopub.execute_input":"2022-05-05T01:07:27.754941Z","iopub.status.idle":"2022-05-05T01:07:28.16228Z","shell.execute_reply.started":"2022-05-05T01:07:27.754902Z","shell.execute_reply":"2022-05-05T01:07:28.161328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = list(combined.drop(['f_27'],axis=1).columns[1:-1])\nfig = plt.figure(figsize = (20,15))\nax = fig.gca()\ntrain[features].hist(ax=ax, color='r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T01:07:40.378869Z","iopub.execute_input":"2022-05-05T01:07:40.379646Z","iopub.status.idle":"2022-05-05T01:07:46.902659Z","shell.execute_reply.started":"2022-05-05T01:07:40.379586Z","shell.execute_reply":"2022-05-05T01:07:46.901446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Some comments about the features:\n1. f_29 looks liks a categorical with two values 0 and 1\n2. f_30 looks like cateogrical columns with 0,1,2 value\n3. f_25, f_20, f_26, f_28, f_29, f_30, f_0 : f_06 holds a bell shape curve which is a good sign and means that they have been normalized\n4. The rets of features looks like a bit left skewed\n5. The ranges of features are almost same, where they range somewhere around 0, except for f_28, so we can perform some scaling like standard scaler or min max scaler","metadata":{}},{"cell_type":"markdown","source":"## Correlation","metadata":{}},{"cell_type":"code","source":"mask = np.zeros_like(combined[features].corr(), dtype=bool)\nmask[np.triu_indices_from(mask)] = True\nsns.set(rc={'figure.figsize':(30,20)})\nsns.heatmap(combined[features].corr(),\n            annot=True,\n            mask = mask,\n            cmap = 'RdBu_r',\n            linewidths=0.1, \n            linecolor='white',\n            vmax = .9,\n            square=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T01:07:53.546328Z","iopub.execute_input":"2022-05-05T01:07:53.546616Z","iopub.status.idle":"2022-05-05T01:08:05.095952Z","shell.execute_reply.started":"2022-05-05T01:07:53.546586Z","shell.execute_reply":"2022-05-05T01:08:05.095035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dealing with feature f_27","metadata":{}},{"cell_type":"code","source":"print(\"The percentage of unique values in f_27 is \", len(combined['f_27'].unique()) / len(combined))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T01:09:20.10358Z","iopub.execute_input":"2022-05-05T01:09:20.103892Z","iopub.status.idle":"2022-05-05T01:09:20.596921Z","shell.execute_reply.started":"2022-05-05T01:09:20.103862Z","shell.execute_reply":"2022-05-05T01:09:20.595554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\ncount_dict = Counter(combined['f_27'])\nprint(\"The top repeating element's frequency in the column is\")\nprint(sorted(count_dict.values(), reverse = True)[:10])","metadata":{"execution":{"iopub.status.busy":"2022-05-05T01:15:12.231411Z","iopub.execute_input":"2022-05-05T01:15:12.231708Z","iopub.status.idle":"2022-05-05T01:15:13.162137Z","shell.execute_reply.started":"2022-05-05T01:15:12.231678Z","shell.execute_reply":"2022-05-05T01:15:13.161162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Insights:\n1. Doesnot look like there a correlation in the features, so we can ignore this fact and not drop any features\n2. we can do a feature scaling before feeding to the neural network model which ill cover in another notebook\n3. we can hot encode, f_29, f_30 since they look categorical\n4. Drop the column f_27, since it contains a lot of unique values, and the frequency of the max repeating element is 15","metadata":{}}]}