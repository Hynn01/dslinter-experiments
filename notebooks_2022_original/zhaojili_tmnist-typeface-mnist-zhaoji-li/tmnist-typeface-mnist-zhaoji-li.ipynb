{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T22:06:26.441788Z","iopub.execute_input":"2022-05-07T22:06:26.442254Z","iopub.status.idle":"2022-05-07T22:06:26.452318Z","shell.execute_reply.started":"2022-05-07T22:06:26.442216Z","shell.execute_reply":"2022-05-07T22:06:26.451286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Name:Zhaoji Li\n\nNUID 002198196","metadata":{}},{"cell_type":"markdown","source":"# > **Abstruct**\n\nTMNIST: A database of Typeface based digits\nThis dataset is inspired by the MNIST database for handwritten digits. It consists of images representing digits from 0-9 produced using 2,990 google fonts files.\n\nThe dataset consists of a single file:\n\nTMNIST_Data.csv\nThis file consists of 29,900 examples with labels and font names. Each row contains 786 elements: the first element represents the font name (ex-Chivo-Italic, Sen-Bold), the second element represents the label (a number from 0-9) and the remaining 784 elements represent the grayscale pixel values (from 0-255) for the 28x28 pixel image.","metadata":{}},{"cell_type":"markdown","source":"# # import dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:26.461519Z","iopub.execute_input":"2022-05-07T22:06:26.462026Z","iopub.status.idle":"2022-05-07T22:06:26.466842Z","shell.execute_reply.started":"2022-05-07T22:06:26.461976Z","shell.execute_reply":"2022-05-07T22:06:26.465722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tmnist-typeface-mnist/TMNIST_Data.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:26.475595Z","iopub.execute_input":"2022-05-07T22:06:26.475876Z","iopub.status.idle":"2022-05-07T22:06:28.482763Z","shell.execute_reply.started":"2022-05-07T22:06:26.475843Z","shell.execute_reply":"2022-05-07T22:06:28.481892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting the number of labels for each character\nprint(df.labels.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:28.48428Z","iopub.execute_input":"2022-05-07T22:06:28.484569Z","iopub.status.idle":"2022-05-07T22:06:28.498701Z","shell.execute_reply.started":"2022-05-07T22:06:28.484541Z","shell.execute_reply":"2022-05-07T22:06:28.497675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Data formalize","metadata":{}},{"cell_type":"markdown","source":"**random sequence**","metadata":{}},{"cell_type":"code","source":"import random\nN=list(range(len(df)))\nn=len(df)\nprint(n)\nrandom.seed(2022)\nrandom.shuffle(N)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:28.499845Z","iopub.execute_input":"2022-05-07T22:06:28.500112Z","iopub.status.idle":"2022-05-07T22:06:28.53741Z","shell.execute_reply.started":"2022-05-07T22:06:28.500048Z","shell.execute_reply":"2022-05-07T22:06:28.536628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Split**","metadata":{}},{"cell_type":"code","source":"trainY=df.loc[N[0:(n//5)*4],'labels']\ntestY=df.loc[N[(n//5)*4:],'labels']\nX=df.drop(['names','labels'],axis=1)\ntrainX=X.loc[N[0:(n//5)*4]]\ntestX=X.loc[N[(n//5)*4:]]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:28.5391Z","iopub.execute_input":"2022-05-07T22:06:28.539472Z","iopub.status.idle":"2022-05-07T22:06:28.842456Z","shell.execute_reply.started":"2022-05-07T22:06:28.539441Z","shell.execute_reply":"2022-05-07T22:06:28.84159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Labels Binarize**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nlb=LabelBinarizer()\ny=lb.fit_transform(trainY)\ny.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:28.844015Z","iopub.execute_input":"2022-05-07T22:06:28.844613Z","iopub.status.idle":"2022-05-07T22:06:29.931879Z","shell.execute_reply.started":"2022-05-07T22:06:28.844574Z","shell.execute_reply":"2022-05-07T22:06:29.931218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Reshape**","metadata":{}},{"cell_type":"code","source":"X_images=trainX.values.reshape(-1,28,28)\ntest=testX.values.reshape(-1,28,28)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:29.932832Z","iopub.execute_input":"2022-05-07T22:06:29.933201Z","iopub.status.idle":"2022-05-07T22:06:29.93857Z","shell.execute_reply.started":"2022-05-07T22:06:29.933171Z","shell.execute_reply":"2022-05-07T22:06:29.937415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_images.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:29.939884Z","iopub.execute_input":"2022-05-07T22:06:29.940189Z","iopub.status.idle":"2022-05-07T22:06:29.952386Z","shell.execute_reply.started":"2022-05-07T22:06:29.940129Z","shell.execute_reply":"2022-05-07T22:06:29.951739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Samples**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig,axs = plt.subplots(3,3,figsize=(9,9))\nfor i in range(9):\n    h=i//3\n    w=i%3\n    axs[h][w].set_xticks([])\n    axs[h][w].set_yticks([])\n    axs[h][w].imshow(X_images[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:29.953411Z","iopub.execute_input":"2022-05-07T22:06:29.954224Z","iopub.status.idle":"2022-05-07T22:06:30.367698Z","shell.execute_reply.started":"2022-05-07T22:06:29.954183Z","shell.execute_reply":"2022-05-07T22:06:30.367095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Training","metadata":{}},{"cell_type":"markdown","source":"**Training and Testing Split**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size=0.2, random_state=66)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:30.36893Z","iopub.execute_input":"2022-05-07T22:06:30.369177Z","iopub.status.idle":"2022-05-07T22:06:30.687744Z","shell.execute_reply.started":"2022-05-07T22:06:30.369147Z","shell.execute_reply":"2022-05-07T22:06:30.68694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:30.691142Z","iopub.execute_input":"2022-05-07T22:06:30.691484Z","iopub.status.idle":"2022-05-07T22:06:30.697103Z","shell.execute_reply.started":"2022-05-07T22:06:30.69144Z","shell.execute_reply":"2022-05-07T22:06:30.696507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:30.697971Z","iopub.execute_input":"2022-05-07T22:06:30.698464Z","iopub.status.idle":"2022-05-07T22:06:30.712015Z","shell.execute_reply.started":"2022-05-07T22:06:30.69842Z","shell.execute_reply":"2022-05-07T22:06:30.710964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = (X_train/255).reshape(-1,28,28,1).astype('float32')\nX_test = (X_test/255).reshape(-1,28,28,1).astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:30.713211Z","iopub.execute_input":"2022-05-07T22:06:30.713765Z","iopub.status.idle":"2022-05-07T22:06:30.845395Z","shell.execute_reply.started":"2022-05-07T22:06:30.713735Z","shell.execute_reply":"2022-05-07T22:06:30.84449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN model**","metadata":{}},{"cell_type":"markdown","source":"**1.convolutional layer**\n\nA convolutional layer can produce a set of parallel feature maps, which are formed by sliding different convolution kernels on the input image and performing certain operations. In addition, at each sliding position, an element-wise product and sum operation is performed between the convolution kernel and the input image to project the information in the receptive field to an element in the feature map. This sliding process can be called stride Z_s, which is a factor that controls the size of the output feature map. The size of the convolution kernel is much smaller than the input image, and it overlaps or acts on the input image in parallel. All elements in a feature map are calculated by a convolution kernel, that is, a feature map. shared the same weights and bias terms.\n\n**2.Linear rectifier layer**\n\nThe Rectified Linear Units layer (ReLU layer) uses Rectified Linear Units (ReLU) f(x)=max(0,x) as the activation function of this layer of nerves. It can enhance the non-linearity of the decision function and the entire neural network without changing the convolutional layer itself.\n\n**3.pooling layer**\n\nPooling is another important concept in convolutional neural networks, which is actually a non-linear form of downsampling. There are many different forms of nonlinear pooling functions, of which \"Max pooling\" is the most common. It divides the input image into several rectangular areas, and outputs the maximum value for each sub-area.\nIntuitively, this mechanism works because the precise location of a feature is far less important than its rough location relative to other features. The pooling layer will continuously reduce the size of the data space, so the number of parameters and the amount of computation will also decrease, which also controls overfitting to a certain extent. Generally speaking, pooling layers are periodically inserted between the convolutional layers in the CNN network structure. Pooling operations provide another form of translation invariance. Because the convolution kernel is a feature finder, we can easily discover various edges in the image through the convolution layer. However, the features found by the convolutional layer are often too accurate. Even if we shoot an object at high speed, the edge pixel positions of the object in the photo are unlikely to be exactly the same. Through the pooling layer, we can reduce the sensitivity of the convolutional layer to edges. .\nThe pooling layer computes the output on a pooling window (depth slice) at a time, and then moves the pooling window according to the stride.\n\n**4.fully connected layer**\n\nFinally, after several convolutional and max-pooling layers, high-level inference in the neural network is done through fully connected layers. Just like in a regular non-convolutional artificial neural network, neurons in a fully connected layer have connections to all activations in the previous layer. Therefore, their activations can be computed as affine transformations, i.e. by multiplying by a matrix and then adding a bias offset (a vector plus a fixed or learned bias).","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:30.84666Z","iopub.execute_input":"2022-05-07T22:06:30.846905Z","iopub.status.idle":"2022-05-07T22:06:36.309793Z","shell.execute_reply.started":"2022-05-07T22:06:30.846874Z","shell.execute_reply":"2022-05-07T22:06:36.309127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can use the Dropout method, that is, randomly \"squeeze\" some neurons and block their input and output each time the neurons are trained in the forward inference, which can play a role in regularization.\n\nIt can be understood that the emperor is exposed to rain and dew, and he is favored today, and may be put into the cold palace tomorrow, which prevents Yang Guifei from being \"loved by three thousand people in one body\", thereby preventing some neurons from becoming dominant and becoming topic leaders. , covering the sky with one hand.\n\nAll neurons are on equal footing, preventing overfitting.","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32,(4,4),input_shape = (28,28,1),activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64,(3,3),activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128,(3,3),activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(50, activation='relu'))\n\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:36.310997Z","iopub.execute_input":"2022-05-07T22:06:36.311782Z","iopub.status.idle":"2022-05-07T22:06:36.505508Z","shell.execute_reply.started":"2022-05-07T22:06:36.311733Z","shell.execute_reply":"2022-05-07T22:06:36.504587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:36.507263Z","iopub.execute_input":"2022-05-07T22:06:36.507895Z","iopub.status.idle":"2022-05-07T22:06:36.52038Z","shell.execute_reply.started":"2022-05-07T22:06:36.507844Z","shell.execute_reply":"2022-05-07T22:06:36.519432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train**","metadata":{}},{"cell_type":"code","source":"result = model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=92, verbose=2)\nresult","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:06:36.522196Z","iopub.execute_input":"2022-05-07T22:06:36.522572Z","iopub.status.idle":"2022-05-07T22:09:10.782203Z","shell.execute_reply.started":"2022-05-07T22:06:36.522528Z","shell.execute_reply":"2022-05-07T22:09:10.781511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Evaluation**","metadata":{}},{"cell_type":"code","source":"evaluation=model.evaluate(X_test, y_test, verbose=1)\nprint(f'Accuracy: {evaluation[1] * 100}%')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:09:10.783316Z","iopub.execute_input":"2022-05-07T22:09:10.783524Z","iopub.status.idle":"2022-05-07T22:09:11.556442Z","shell.execute_reply.started":"2022-05-07T22:09:10.783498Z","shell.execute_reply":"2022-05-07T22:09:11.555754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Plott (data):\n    fig, ax = plt.subplots(1,2 , figsize = (20,7))\n    # summarize history for accuracy\n    ax[0].plot(data.history['accuracy'])\n    ax[0].plot(data.history['val_accuracy'])\n    ax[0].set_title('model accuracy')\n    ax[0].legend(['train', 'test'], loc='upper left')\n\n    # summarize history for loss\n    ax[1].plot(data.history['loss'], label =['loss'])\n    ax[1].plot(data.history['val_loss'] ,label =['val_loss'])\n    ax[1].set_title('model loss')\n    ax[1].legend(['train', 'test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:09:11.557895Z","iopub.execute_input":"2022-05-07T22:09:11.558518Z","iopub.status.idle":"2022-05-07T22:09:11.566666Z","shell.execute_reply.started":"2022-05-07T22:09:11.558477Z","shell.execute_reply":"2022-05-07T22:09:11.565504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Plott(result)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T22:09:11.56773Z","iopub.execute_input":"2022-05-07T22:09:11.568561Z","iopub.status.idle":"2022-05-07T22:09:12.078931Z","shell.execute_reply.started":"2022-05-07T22:09:11.568511Z","shell.execute_reply":"2022-05-07T22:09:12.078337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Explanation and Conclusion","metadata":{}},{"cell_type":"markdown","source":"We divided the dataset into two subsets: images set (X) and lable set (y). For each item in X, we reshape the data into a 28x28 matrix. And each result in y is a 10 array. Therefore, we created a 9 layers CNN model that the first layer accept a 28x28 matrix and the output is a 10 array. The overall accuracy is 99.3%.","metadata":{}},{"cell_type":"markdown","source":"**Reference**\n\nhttps://www.kaggle.com/code/yuxinliustella/93-6-tmnist\nhttps://github.com/TommyZihao/zihaopytorch/blob/master/%E5%AF%B9Fashion-MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E7%9A%84%E6%97%B6%E5%B0%9A%E7%89%A9%E5%93%81%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB.ipynb","metadata":{}}]}