{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T15:47:31.66718Z","iopub.execute_input":"2022-05-06T15:47:31.667759Z","iopub.status.idle":"2022-05-06T15:47:31.677255Z","shell.execute_reply.started":"2022-05-06T15:47:31.667721Z","shell.execute_reply":"2022-05-06T15:47:31.6763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.utils.data as Data\nimport torch\n\n\ndef dataloader(batch_size, shuffle=True):\n    # from sklearn.datasets import load_digits\n    # digits = load_digits()\n    # X = digits.data\n    # y = digits.target\n    # Y = []\n    # for i in y:\n    #     Y.append([i])\n\n    train_data = pd.read_csv('/kaggle/input/ml2021-2022-2-cnn/train.csv').values\n    test_data = pd.read_csv('/kaggle/input/ml2021-2022-2-cnn/test.csv').values\n    train_X = train_data[:, 1:]\n    train_y = train_data[:, 0]\n    train_X = torch.FloatTensor(train_X)\n    train_y = torch.LongTensor(train_y)\n    test_X = test_data\n    test_y = test_data[:, 0]\n    test_X = torch.FloatTensor(test_X)\n    test_y = torch.LongTensor(test_y)\n    len_train_data = len(train_X)\n    len_test_data = len(test_X)\n    train_dataset = []\n    test_dataset = []\n    for i in range(len(train_X)):\n        train_dataset.append((train_X[i], train_y[i]))\n    for i in range(len(test_X)):\n        test_dataset.append((test_X[i], test_y[i]))\n    train_iter = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle)\n    test_iter = Data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n    return train_iter, test_iter, len_train_data, len_test_data","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:47:31.721458Z","iopub.execute_input":"2022-05-06T15:47:31.721812Z","iopub.status.idle":"2022-05-06T15:47:31.736043Z","shell.execute_reply.started":"2022-05-06T15:47:31.721776Z","shell.execute_reply":"2022-05-06T15:47:31.735202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn\n\nclass Residual(nn.Module):\n    def __init__(self, input_channels, num_channels,\n                 use_1x1conv=False, strides=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(input_channels, num_channels,\n                               kernel_size=3, padding=1, stride=strides)\n        self.conv2 = nn.Conv2d(num_channels, num_channels,\n                               kernel_size=3, padding=1)\n        if use_1x1conv:\n            self.conv3 = nn.Conv2d(input_channels, num_channels,\n                                   kernel_size=1, stride=strides)\n        else:\n            self.conv3 = None\n        self.bn1 = nn.BatchNorm2d(num_channels)\n        self.bn2 = nn.BatchNorm2d(num_channels)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        output = self.conv1(x)\n        output = self.bn1(output)\n        output = self.relu(output)\n        output = self.conv2(output)\n        output = self.bn2(output)\n        if self.conv3:\n            x = self.conv3(x)\n        output = output + x\n        output = self.relu(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:47:31.75991Z","iopub.execute_input":"2022-05-06T15:47:31.760105Z","iopub.status.idle":"2022-05-06T15:47:31.769102Z","shell.execute_reply.started":"2022-05-06T15:47:31.760081Z","shell.execute_reply":"2022-05-06T15:47:31.768074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resnet_block(input_channels, num_channels, num_residuals,\n                 first_block=False):\n    blk = []\n    for i in range(num_residuals):\n        if i == 0 and not first_block:\n            blk.append(Residual(input_channels, num_channels,\n                                use_1x1conv=True, strides=2))\n        else:\n            blk.append(Residual(num_channels, num_channels))\n    return blk","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:47:31.80307Z","iopub.execute_input":"2022-05-06T15:47:31.80358Z","iopub.status.idle":"2022-05-06T15:47:31.811115Z","shell.execute_reply.started":"2022-05-06T15:47:31.803551Z","shell.execute_reply":"2022-05-06T15:47:31.810132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.block1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n                      nn.BatchNorm2d(64), nn.ReLU(),\n                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n        self.block2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n        self.block3 = nn.Sequential(*resnet_block(64, 128, 2))\n        self.block4 = nn.Sequential(*resnet_block(128, 256, 2))\n        self.block5 = nn.Sequential(*resnet_block(256, 512, 2))\n        self.head = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), nn.Flatten(), nn.Linear(512, 10))\n        \n    def forward(self, x):\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        output = self.head(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:47:31.935415Z","iopub.execute_input":"2022-05-06T15:47:31.935655Z","iopub.status.idle":"2022-05-06T15:47:31.945746Z","shell.execute_reply.started":"2022-05-06T15:47:31.935623Z","shell.execute_reply":"2022-05-06T15:47:31.944908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 设置超参数\nlr = 0.01\nnum_epochs = 10\nbatch_size = 200\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"training on:{}\".format(device))  # 显示训练设备\n\n# 取数据\ntrain_iter, test_iter, len_train_data, len_test_data = dataloader(batch_size)\n\n# 实例化模型\nmodel = ResNet()\nmodel = model.to(device)\n\nloss_fn = nn.CrossEntropyLoss()\nloss_fn = loss_fn.to(device)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:47:31.947263Z","iopub.execute_input":"2022-05-06T15:47:31.947671Z","iopub.status.idle":"2022-05-06T15:47:35.955985Z","shell.execute_reply.started":"2022-05-06T15:47:31.947634Z","shell.execute_reply":"2022-05-06T15:47:35.955262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# 开始训练\nacc_list = [0.,]\nfor epoch in range(num_epochs):\n    acc = 0\n    with tqdm(train_iter, unit='batch') as tepoch:\n        for data, label in tepoch:\n            tepoch.set_description(f\"Epoch {epoch + 1} train\")\n            data = data.reshape(batch_size, 1, 28, 28)\n            data = data.to(device)\n            label = label.to(device)\n            outputs = model(data)\n            loss = loss_fn(outputs, label)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            acc += (outputs.argmax(1) == label).sum() / len_train_data\n            tepoch.set_postfix(acc=acc.item())\n    acc_list.append(acc.item())","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:47:35.957462Z","iopub.execute_input":"2022-05-06T15:47:35.957704Z","iopub.status.idle":"2022-05-06T15:48:34.547289Z","shell.execute_reply.started":"2022-05-06T15:47:35.957671Z","shell.execute_reply":"2022-05-06T15:48:34.54659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ntitle_name = \"Accuracy\"\nplt.plot(acc_list, label=\"ResNet\")\nplt.legend()\nplt.xlabel(\"num_epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(title_name)\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:48:34.556261Z","iopub.execute_input":"2022-05-06T15:48:34.55656Z","iopub.status.idle":"2022-05-06T15:48:34.780726Z","shell.execute_reply.started":"2022-05-06T15:48:34.556523Z","shell.execute_reply":"2022-05-06T15:48:34.780059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#做预测输出\npredictions = []\nwith tqdm(test_iter, unit='batch') as tepoch:\n    for data, _ in tepoch:\n        tepoch.set_description(f\"Prediction\")\n        data = data.reshape(batch_size, 1, 28, 28)\n        data = data.to(device)\n        outputs = model(data)\n        outputs_label = outputs.argmax(1).cpu().numpy()\n        for label in outputs_label:\n            predictions.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:48:34.782009Z","iopub.execute_input":"2022-05-06T15:48:34.782257Z","iopub.status.idle":"2022-05-06T15:48:35.537998Z","shell.execute_reply.started":"2022-05-06T15:48:34.78221Z","shell.execute_reply":"2022-05-06T15:48:35.537298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_dict = {\n    'id':list(np.arange(len_test_data)),\n    'label':predictions\n}\nout = pd.DataFrame(out_dict)\nout.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T15:48:35.539298Z","iopub.execute_input":"2022-05-06T15:48:35.539945Z","iopub.status.idle":"2022-05-06T15:48:35.573208Z","shell.execute_reply.started":"2022-05-06T15:48:35.539903Z","shell.execute_reply":"2022-05-06T15:48:35.572569Z"},"trusted":true},"execution_count":null,"outputs":[]}]}