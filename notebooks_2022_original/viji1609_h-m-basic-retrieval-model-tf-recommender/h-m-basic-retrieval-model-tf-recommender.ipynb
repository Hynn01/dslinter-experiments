{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tensorflow Recommenders:\n\nIn this notebook we peek into the possibility of using Tensorflow recommender system (tfrs) -  Retrieval models for H&M product recommendations.\n\nRetrieval models have typically query and candidate models in which features are embedded. Affinity score is calculated by a factorized retrieval model.The retrieval task is for selecting an initial set of candidates from all possible candidates.\n\nTensorflow has easy to implement modules such as *tfrs.tasks.Retrieval* along with metrics such as *tfrs.metrics.FactorizedTopK* for retrieval task.\n\nTensorflow *ScaNN* library can be used to retrieve the best candidates for a given query. In our case we can get the 12 recommendations required using this library.","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow-recommenders\n!pip install -q scann","metadata":{"execution":{"iopub.status.busy":"2022-04-30T16:19:28.701337Z","iopub.execute_input":"2022-04-30T16:19:28.701882Z","iopub.status.idle":"2022-04-30T16:19:52.275255Z","shell.execute_reply.started":"2022-04-30T16:19:28.70174Z","shell.execute_reply":"2022-04-30T16:19:52.274521Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_recommenders as tfrs\n\nfrom pathlib import Path\nfrom typing import Dict, Text","metadata":{"execution":{"iopub.status.busy":"2022-04-30T16:19:52.276584Z","iopub.execute_input":"2022-04-30T16:19:52.276789Z","iopub.status.idle":"2022-04-30T16:19:56.205678Z","shell.execute_reply.started":"2022-04-30T16:19:52.276741Z","shell.execute_reply":"2022-04-30T16:19:56.204826Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Dataset","metadata":{}},{"cell_type":"code","source":"data_dir = Path('../input/h-and-m-personalized-fashion-recommendations')\ntrain0 = pd.read_csv(data_dir/'transactions_train.csv')\ntrain0 = train0[train0['t_dat'] >='2020-09-01']\n\n# add 0 in article_id column (string)\ntrain0['article_id'] = train0['article_id'].astype(str)\ntrain0['article_id'] = train0['article_id'].apply(lambda x: x.zfill(10))\ntrain0.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T16:19:56.206727Z","iopub.execute_input":"2022-04-30T16:19:56.207086Z","iopub.status.idle":"2022-04-30T16:20:28.964431Z","shell.execute_reply.started":"2022-04-30T16:19:56.207055Z","shell.execute_reply":"2022-04-30T16:20:28.964003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customer_df = pd.read_csv(data_dir/'customers.csv')\ncustomer_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T16:20:28.96564Z","iopub.execute_input":"2022-04-30T16:20:28.965987Z","iopub.status.idle":"2022-04-30T16:20:31.863828Z","shell.execute_reply.started":"2022-04-30T16:20:28.965953Z","shell.execute_reply":"2022-04-30T16:20:31.862635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"article_df = pd.read_csv(data_dir/'articles.csv')\n\n# add 0 in article_id column (string) similar to train0\narticle_df['article_id'] = article_df['article_id'].astype(str)\narticle_df['article_id'] = article_df['article_id'].apply(lambda x: x.zfill(10))\narticle_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T16:20:31.86517Z","iopub.execute_input":"2022-04-30T16:20:31.865375Z","iopub.status.idle":"2022-04-30T16:20:32.907582Z","shell.execute_reply.started":"2022-04-30T16:20:31.86535Z","shell.execute_reply":"2022-04-30T16:20:32.906551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We select only two features for training. Also generate data for embedding in both query and candidate models.\n","metadata":{}},{"cell_type":"code","source":"#get data for embedding and task\n\nunique_customer_ids = customer_df.customer_id.unique()\nunique_article_ids = article_df.article_id.unique()\n\narticle_ds = tf.data.Dataset.from_tensor_slices(dict(article_df[['article_id']]))\narticles = article_ds.map(lambda x: x['article_id'])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T16:20:33.811475Z","iopub.execute_input":"2022-04-30T16:20:33.812009Z","iopub.status.idle":"2022-04-30T16:20:35.14821Z","shell.execute_reply.started":"2022-04-30T16:20:33.811944Z","shell.execute_reply":"2022-04-30T16:20:35.145672Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Query, Candidate and H&M model ","metadata":{}},{"cell_type":"code","source":"embedding_dimension = 64\n\n# Query Model\ncustomer_model = tf.keras.Sequential([\n  tf.keras.layers.StringLookup(\n      vocabulary=unique_customer_ids, mask_token=None),  \n  tf.keras.layers.Embedding(len(unique_customer_ids) + 1, embedding_dimension)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Candidate Model\narticle_model = tf.keras.Sequential([\n  tf.keras.layers.StringLookup(\n      vocabulary=unique_article_ids, mask_token=None),\n  tf.keras.layers.Embedding(len(unique_article_ids) + 1, embedding_dimension)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieval Model\n\nclass HandMModel(tfrs.Model):\n    \n    def __init__(self, customer_model, article_model):\n        super().__init__()\n        self.article_model: tf.keras.Model = article_model\n        self.customer_model: tf.keras.Model = customer_model\n        self.task = tfrs.tasks.Retrieval(\n        metrics=tfrs.metrics.FactorizedTopK(\n            candidates=articles.batch(128).map(self.article_model),            \n            ),\n        )        \n\n    def compute_loss(self, features: Dict[str, tf.Tensor], training=False) -> tf.Tensor:\n    \n        customer_embeddings = self.customer_model(features[\"customer_id\"])    \n        article_embeddings = self.article_model(features[\"article_id\"])\n\n        # The task computes the loss and the metrics.\n        return self.task(customer_embeddings, article_embeddings,compute_metrics=not training)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train & Validate","metadata":{}},{"cell_type":"code","source":"model = HandMModel(customer_model, article_model)\nmodel.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train0[train0['t_dat']<='2020-09-15']\ntest = train0[train0['t_dat'] >='2020-09-15']\n\ntrain_ds = tf.data.Dataset.from_tensor_slices(dict(train[['customer_id','article_id']])).shuffle(100_000).batch(256).cache()\ntest_ds = tf.data.Dataset.from_tensor_slices(dict(test[['customer_id','article_id']])).batch(256).cache()\n\nnum_epochs = 5\n\n'''\n\nhistory = model.fit(\n    train_ds, \n    validation_data = test_ds,\n    validation_freq=5,\n    epochs=num_epochs,\n    verbose=1)\n\n'''\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A word on metrics:**\n\nCalculation of factorized top K metric is highly time intensive. Even with the option 'compute_metrics=not training' and \ncomputing validation metrics only every 5 epochs, it still takes a lot of time. You can check this by running above model. Another option \nmay be by reducing the number of retrievals from standard 100.(may cost accuracy?)\n\nself.task = tfrs.tasks.Retrieval(\n        metrics=tfrs.metrics.FactorizedTopK(\n        candidates=articles.batch(128).map(self.article_model),\n        k = (any value less than 100)\n        )","metadata":{}},{"cell_type":"markdown","source":"# Retrieve & Submit","metadata":{}},{"cell_type":"code","source":"# train without validation\n\ntrain_ds = tf.data.Dataset.from_tensor_slices(dict(train0[['customer_id','article_id']])).shuffle(100_000).batch(256).cache()\n\nnum_epochs = 5\n\nhistory = model.fit(\n    train_ds,    \n    epochs=num_epochs,\n    verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scann_index = tfrs.layers.factorized_top_k.ScaNN(model.customer_model, k = 12 )\nscann_index.index_from_dataset(\n  tf.data.Dataset.zip((articles.batch(100), articles.batch(100).map(model.article_model)))\n)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(data_dir/'sample_submission.csv')\n_,articles = scann_index(sub.customer_id.values)\npreds = articles.numpy().astype(str)\npreds = pd.Series(map(' '.join, preds,))\nsub['prediction'] = preds\nsub.to_csv('submission.csv',index=False)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is based on recommender models in the Tensorflow official site. This model can be further refined by adding more features, deep layers and with different model hyperparameters. Examples can be referred at https://www.tensorflow.org/recommenders\n\n**Thank you for your time!**\n","metadata":{}}]}