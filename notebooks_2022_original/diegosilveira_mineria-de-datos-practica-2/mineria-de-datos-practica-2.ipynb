{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Máster en Ciencia de Datos. Curso 2021-2022\n\n# Minería de Datos\n\n## Prática 2. Técnicas de Análisis\n\nAutores:\n- Laura García\n- Diego Silveira\n\n## Descripción\n\n> **ARREGLAR**\nA partir de los datos obtenidos de una pulsera de actividad Garmin, esta práctica pretende, en primer lugar, realizar un preprocesamiento de los datos que permita: seleccionar qué características de los datos son relevantes y cuáles no, así como imputar los valores ausentes de las que sí son relevantes. En segundo lugar, se pretende emplear varios escaladores, así como una variedad de algoritmos de: regresión, clasificación, *ensembles* y *clustering* que permitan calcular una serie de métricas que ayuden a interpretar los datos y conocer si los datos contienen sesgos. \n\n\nPor último, comparar las métricas de los algoritmos de un mismo tipo y decidir cuál de ellos se ajusta mejor a nuestro conjunto de datos.\n\n\n1. Preprocesamiento del dataset (limpieza, imputación, etc)\n2. Uso de técnicas de Regresión, Clasificación, Ensembles y Clustering.\n3. Cálculo de métricas (matriz de confusión, Curva ROC, etc), comparación de resultados e interpretación de los valores obtenidos, así como de los sesgos que se producen.\n\nFuente: [Garmin Connect Data Analysis\n](https://www.kaggle.com/code/kmader/garmin-connect-data-analysis/data)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## 1. Preprocesamiento de los datos\n\nEn este primer apartado vamos a realizar un preprocesamiento de los datos. Este consistirá en seleccionar y extraer características que aporten información relevante, imputar los valores ausentes de las distintas características, definir la variable objetivo y discretizar sus valores, así como asegurarse que las clases de esta variable objetivo se encuentran balanceadas.","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Importamos las librerías necesarias\n\nPrimero, importamos las librerías que necesitatremos para realizar el preprocesamiento de los datos.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom itertools import cycle, islice\nfrom scipy import stats\nimport random\nfrom typing import Optional\nimport time\n\n# Importamos el modelo de regresión Decision Tree\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Importamos las métricas R2, MAE y MSE\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\n# Importamos para aplicar la técnica de Cross Validation\nfrom sklearn.model_selection import KFold\n\n# Importamos para los ensembles\nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier,StackingClassifier\n\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.metrics import roc_curve, auc,confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import label_binarize,StandardScaler\n\n# Importamos para el clustering\nfrom sklearn import datasets\nfrom sklearn.cluster import MiniBatchKMeans, AgglomerativeClustering, DBSCAN, OPTICS, Birch\nfrom sklearn.mixture import GaussianMixture\n\nfrom sklearn.neighbors import kneighbors_graph\nfrom sklearn.preprocessing import StandardScaler\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:34.488321Z","iopub.execute_input":"2022-05-08T12:03:34.488926Z","iopub.status.idle":"2022-05-08T12:03:38.468039Z","shell.execute_reply.started":"2022-05-08T12:03:34.488834Z","shell.execute_reply":"2022-05-08T12:03:38.467156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2. Definimos una plantilla\n\nEn este apartado hemos creado una plantilla con los estilos que se emplearán para todas las representaciones gráficas.","metadata":{}},{"cell_type":"code","source":"pio.templates[\"Tema\"] = go.layout.Template(\n   layout = {\n\n        'title':\n            {'font': {'size':30 }, \"x\":0.5\n            },\n        'font': { 'size':18}\n    },\n    \n    data = {\n        'bar': [go.Bar(texttemplate = '%{value:.2s}',\n                       textposition='outside',\n                       textfont={'size': 23  }\n                       )]\n    }\n)\n\npio.templates.default = \"plotly_white+Tema\"\n\ncolores = [\"#8f58bf\",\"#55c95c\",\"#2fbaaf\",\"#ad2234\",\"#899D78\",\"#adc244\",\"#4d5294\",\"#dd5234\",\"#9d3254\",\"#64bd20\",\"#845550\"]\ncolors = ['#1F77B4', '#FF7F0E']","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:38.470078Z","iopub.execute_input":"2022-05-08T12:03:38.470379Z","iopub.status.idle":"2022-05-08T12:03:39.214705Z","shell.execute_reply.started":"2022-05-08T12:03:38.470348Z","shell.execute_reply":"2022-05-08T12:03:39.213718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3. Importamos los datos\n\nLeemos el archivo CSV con los datos de actividad de una pulsera de Garmin del [siguiente enlace](https://www.kaggle.com/code/kmader/garmin-connect-data-analysis/data), cargamos los datos en el DataFrame `user_df`, y mostramos las primeras 5 filas del DataFrame mediante la función `head()`.","metadata":{}},{"cell_type":"code","source":"user_df = pd.read_csv(\"../input/garmin-connect-data-analysis/user_data.csv\",\n                      parse_dates=['calendarDate', 'restingHeartRateTimestamp', 'wellnessEndTimeGmt',\n                                   'wellnessEndTimeLocal', 'wellnessStartTimeGmt', 'wellnessStartTimeLocal'])\nuser_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:39.216045Z","iopub.execute_input":"2022-05-08T12:03:39.216305Z","iopub.status.idle":"2022-05-08T12:03:40.017669Z","shell.execute_reply.started":"2022-05-08T12:03:39.216277Z","shell.execute_reply":"2022-05-08T12:03:40.016757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.4. Dimensiones de los datos\n\nTras cargar el archivo CSV y visualizarlo, empleamos la propiedad `shape` para obtener el número de instancias y de características de los datos.","metadata":{}},{"cell_type":"code","source":"# Mostramos las dimensiones originales del dataset\nprint(\"Dimensiones del dataset:\", user_df.shape)\nprint(\"Número de instancias:\", user_df.shape[0])\nprint(\"Número de características:\", user_df.shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.020111Z","iopub.execute_input":"2022-05-08T12:03:40.020427Z","iopub.status.idle":"2022-05-08T12:03:40.026843Z","shell.execute_reply.started":"2022-05-08T12:03:40.020385Z","shell.execute_reply":"2022-05-08T12:03:40.026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.5. Tipos de datos\n\nEn este punto analizamos el tipo de los datos del dataset para ver la variedad que existe.","metadata":{}},{"cell_type":"code","source":"tipos_datos = user_df.dtypes.value_counts()\ntipos_datos = tipos_datos.sort_index()\nlabels = tipos_datos.index.astype(str).tolist()\nvalues = tipos_datos.tolist()\n\nfig = px.pie(names=labels, values=values,\n             title=\"Tipos de datos: float64 es el más común\", color_discrete_sequence=colores)\nfig.update_layout(legend_title_text='Tipo')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.028296Z","iopub.execute_input":"2022-05-08T12:03:40.028699Z","iopub.status.idle":"2022-05-08T12:03:40.2946Z","shell.execute_reply.started":"2022-05-08T12:03:40.028667Z","shell.execute_reply":"2022-05-08T12:03:40.293699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como se observa en el gráfico sectorial anterior, en este conjunto de datos existen 5 tipos: `object`, `bool`, `int64`, `datetime64[ns]` y `float64`, siendo este último el tipo de datos más frecuente, pues un 68.9% de las características son de este tipo.","metadata":{}},{"cell_type":"markdown","source":"### 1.6. Cantidad y proporción de valores ausentes\n\nEn este apartado se analiza la cantidad y la proporción de valores ausentes que posee cada una de las características del dataset.","metadata":{}},{"cell_type":"code","source":"total_na = user_df.isna().sum()\nprop_na = total_na / len(user_df)\n\nfor col in user_df.columns:\n    print(\"Columna '{}'. Valores nulos: {} ({:.2f} %)\".format(col, total_na[col], prop_na[col] * 100))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.296008Z","iopub.execute_input":"2022-05-08T12:03:40.296317Z","iopub.status.idle":"2022-05-08T12:03:40.312004Z","shell.execute_reply.started":"2022-05-08T12:03:40.296276Z","shell.execute_reply":"2022-05-08T12:03:40.311325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Puesto que el dataset original posee un gran número de características, resulta complejo representar la proporción de valores ausentes que posee cada una de las columnas. Como alternativa, tomamos un umbral de 0.4 y mostramos en un gráfico sectorial la cantidad de características cuya proporción de valores ausentes es menor o igual a un 40% y la cantidad de características cuya proporción es mayor.","metadata":{}},{"cell_type":"code","source":"men_ig_umb = prop_na <= 0.4\nlabels = men_ig_umb.value_counts().index.astype(str).tolist()\nvalues = men_ig_umb.value_counts().tolist()\n\nfig = px.pie(names=labels, values=values, title='El 37.8% de las características tienen una proporción de nulos > 40%')\nfig.update_layout(legend_title_text='Proporción de nulos <= 40%')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.313432Z","iopub.execute_input":"2022-05-08T12:03:40.313638Z","iopub.status.idle":"2022-05-08T12:03:40.423613Z","shell.execute_reply.started":"2022-05-08T12:03:40.313603Z","shell.execute_reply":"2022-05-08T12:03:40.422997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Según se observa en el gráfico sectorial anterior, si establecemos como umbral una proporción de valores ausentes del 40%, nos encontramos con que el 37.8% de las características de nuestro dataset superan este umbral. Dicho de otra forma, si eliminamos todas aquellas características que posean una proporción de valores ausentes superior al 40%, entonces eliminamos 17 de las 45 características que posee nuestro dataset, quedándonos con las otras 28.\n\nPuesto que una proporción de valores ausentes superior al 40% supone que casi la mitad de los registros de una característica tengan que ser imputados, consideramos que este es un buen criterio para seleccionar aquellas columnas que son verdaderamente útiles. Por ello, hemos empleado este como un criterio para eliminar características con escasa utilidad.","metadata":{}},{"cell_type":"code","source":"# Nos quedamos con las características que posean una proporción de valores ausentes <= 40%\nuser_df = user_df.loc[:, prop_na <= 0.4]\nuser_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.424712Z","iopub.execute_input":"2022-05-08T12:03:40.425121Z","iopub.status.idle":"2022-05-08T12:03:40.458069Z","shell.execute_reply.started":"2022-05-08T12:03:40.425069Z","shell.execute_reply":"2022-05-08T12:03:40.457444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.7. Eliminación de características inútiles\n\nAunque hemos reducido la dimensión de los datos, todavía quedan muchas características que no son de utilidad, por tanto, hemos eliminado algunas más en base a nuestro propio criterio.\n\nEn primer lugar, comparamos las columnas `calendarDate`, `wellnessStartTimeLocal` y `wellnessEndTimeLocal` con las columnas `wellnessStartTimeGmt` y `wellnessEndTimeGmt`, respectivamente.","metadata":{}},{"cell_type":"code","source":"user_df[['calendarDate', 'wellnessStartTimeLocal', 'wellnessStartTimeGmt', 'wellnessEndTimeLocal', 'wellnessEndTimeGmt']]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.459175Z","iopub.execute_input":"2022-05-08T12:03:40.460149Z","iopub.status.idle":"2022-05-08T12:03:40.484624Z","shell.execute_reply.started":"2022-05-08T12:03:40.460109Z","shell.execute_reply":"2022-05-08T12:03:40.48401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como se aprecia en la celda anterior, todas estas columnas representan fechas utilizando distintos formatos. Por tanto, la información que proporcionan es semejante. Por ello, hemos decidido quedarnos con la columna `calendarDate` y eliminar las demás.","metadata":{}},{"cell_type":"code","source":"# Eliminamos las columnas wellnessStartTimeLocal, wellnessStartTimeGmt, wellnessEndTimeLocal y wellnessEndTimeGmt\nuser_df.drop(['wellnessStartTimeLocal', 'wellnessStartTimeGmt',\n              'wellnessEndTimeLocal', 'wellnessEndTimeGmt'],\n             axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.487182Z","iopub.execute_input":"2022-05-08T12:03:40.48758Z","iopub.status.idle":"2022-05-08T12:03:40.49392Z","shell.execute_reply.started":"2022-05-08T12:03:40.487532Z","shell.execute_reply":"2022-05-08T12:03:40.493262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación, analizamos las columnas `rulePk` y `uuid`.","metadata":{}},{"cell_type":"code","source":"user_df[['rulePk', 'uuid']]\nprint(\"Varianza rulePk:\", user_df['rulePk'].var())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.494962Z","iopub.execute_input":"2022-05-08T12:03:40.495552Z","iopub.status.idle":"2022-05-08T12:03:40.5113Z","shell.execute_reply.started":"2022-05-08T12:03:40.495517Z","shell.execute_reply":"2022-05-08T12:03:40.510191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tal y como se observa en la celda anterior, la columna `rulePk` siempre tiene el valor 1 y no varía (varianza = 0). Por otra parte, la columna `uuid` es una cadena de texto que representa un identificador, por lo tanto, ninguna de las dos aporta información relevante para medir la actividad del usuario.","metadata":{}},{"cell_type":"code","source":"# Eliminamos las columnas rulePk y uuid\nuser_df.drop(['rulePk', 'uuid'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.512725Z","iopub.execute_input":"2022-05-08T12:03:40.513091Z","iopub.status.idle":"2022-05-08T12:03:40.523973Z","shell.execute_reply.started":"2022-05-08T12:03:40.513054Z","shell.execute_reply":"2022-05-08T12:03:40.523267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación, analizamos las columnas `includesActivityData`, `includesCalorieConsumedData`, e `includesWellnessData`.","metadata":{}},{"cell_type":"code","source":"user_df[['includesActivityData', 'includesCalorieConsumedData', 'includesWellnessData']]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.525111Z","iopub.execute_input":"2022-05-08T12:03:40.525461Z","iopub.status.idle":"2022-05-08T12:03:40.542721Z","shell.execute_reply.started":"2022-05-08T12:03:40.525433Z","shell.execute_reply":"2022-05-08T12:03:40.541537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las tres columnas indicadas en la celda anterior son de tipo `bool` e indican si el registro actual incluye la información sobre un campo determinado o no. Esto tampoco aporta información relevante para medir la actividad del usuario, por tanto, podemos descartarlas.","metadata":{}},{"cell_type":"code","source":"# Eliminamos las columnas includesActivityData, includesCalorieConsumedData, includesWellnessData\nuser_df.drop(['includesActivityData', 'includesCalorieConsumedData', 'includesWellnessData'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.544126Z","iopub.execute_input":"2022-05-08T12:03:40.544458Z","iopub.status.idle":"2022-05-08T12:03:40.549225Z","shell.execute_reply.started":"2022-05-08T12:03:40.54443Z","shell.execute_reply":"2022-05-08T12:03:40.548447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seguidamente, vamos a analizar las columnas `version` y `userProfilePK` para ver si es de utilidad conservarlas o si es mejor eliminarlas.","metadata":{}},{"cell_type":"code","source":"user_df[['version', 'userProfilePK']]\nprint(\"Varianza userProfilePK:\", user_df['userProfilePK'].var())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.550346Z","iopub.execute_input":"2022-05-08T12:03:40.550675Z","iopub.status.idle":"2022-05-08T12:03:40.562358Z","shell.execute_reply.started":"2022-05-08T12:03:40.550639Z","shell.execute_reply":"2022-05-08T12:03:40.561655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Los valores de la columna `version` no aportan información relevante. Por otro lado, los valores la columna `userProfilePK` son constantes y su varianza es igual a 0, por tanto, podemos descartar ambas columnas.","metadata":{}},{"cell_type":"code","source":"# Eliminamos las columnas version y userProfilePK\nuser_df.drop(['version', 'userProfilePK'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.563448Z","iopub.execute_input":"2022-05-08T12:03:40.563792Z","iopub.status.idle":"2022-05-08T12:03:40.573574Z","shell.execute_reply.started":"2022-05-08T12:03:40.563764Z","shell.execute_reply":"2022-05-08T12:03:40.572904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Respecto a las columnas `netCalorieGoal` y `remainingKilocalories`, la primera hace referencia al objetivo de calorías netas, pero esta no sirve si no se conoce las calorías ingeridas. Por otra parte, la segunda columna analizada indica las calorías restantes, pero esta no nos sirve si no tenemos las calorías netas. Por tanto, hemos decididos eliminarlas también.","metadata":{}},{"cell_type":"code","source":"# Eliminamos las columnas netCalorieGoal y remainingKilocalories\nuser_df.drop(['netCalorieGoal', 'remainingKilocalories'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.574453Z","iopub.execute_input":"2022-05-08T12:03:40.575191Z","iopub.status.idle":"2022-05-08T12:03:40.584226Z","shell.execute_reply.started":"2022-05-08T12:03:40.575133Z","shell.execute_reply":"2022-05-08T12:03:40.583389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Por último, vamos a analizar las columnas `dailyStepGoal` y `durationInMilliseconds`.","metadata":{}},{"cell_type":"code","source":"user_df[['dailyStepGoal', 'durationInMilliseconds']]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.585232Z","iopub.execute_input":"2022-05-08T12:03:40.585866Z","iopub.status.idle":"2022-05-08T12:03:40.605847Z","shell.execute_reply.started":"2022-05-08T12:03:40.585836Z","shell.execute_reply":"2022-05-08T12:03:40.604925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La primera columna contiene los objetivos de pasos establecidos diariamente, por lo tanto, no afecta a la actividad de la persona y no aporta información relevante. Por otra parte, la información de la columna `durationInMilliseconds` es similar a la columna `activeSeconds` pero con distinto formato, con lo cual, es una columna redundante. En conclusión, podemos eliminar ambas columnas, pues no aportan información de interés.","metadata":{}},{"cell_type":"code","source":"# Eliminamos las columnas durationInMilliseconds y activeSeconds\nuser_df.drop(['dailyStepGoal', 'durationInMilliseconds'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.60738Z","iopub.execute_input":"2022-05-08T12:03:40.607608Z","iopub.status.idle":"2022-05-08T12:03:40.612723Z","shell.execute_reply.started":"2022-05-08T12:03:40.607582Z","shell.execute_reply":"2022-05-08T12:03:40.611662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Una vez eliminadas todas las características que no aportan información, volvemos a mostrar las dimensiones del dataset.","metadata":{}},{"cell_type":"code","source":"# Mostramos las dimensiones del dataset después de eliminar las características que no aportan información\nprint(\"Dimensiones del dataset:\", user_df.shape)\nprint(\"Número de instancias:\", user_df.shape[0])\nprint(\"Número de características:\", user_df.shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.614316Z","iopub.execute_input":"2022-05-08T12:03:40.615106Z","iopub.status.idle":"2022-05-08T12:03:40.626596Z","shell.execute_reply.started":"2022-05-08T12:03:40.615063Z","shell.execute_reply":"2022-05-08T12:03:40.62598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Después de analizar las características del dataset, nos hemos quedado con 13 de las 28 que teníamos después de eliminar aquellas con gran proporción de valores nulos. Esto supone que hemos eliminado un 53.57% de las características. Además, de las 45 columnas que tenía el dataset original, sólo nos hemos quedado con el 28.89% de las mismas.","metadata":{}},{"cell_type":"markdown","source":"### 1.8. Imputación de valores nulos\n\nAunque hemos eliminado una gran cantidad de características que no aportaban información, todavía quedan características con valores nulos. Por ello, primeramente vamos a analizar qué columnas todavía contienen valores nulos.","metadata":{}},{"cell_type":"code","source":"total_na = user_df.isna().sum()\nprop_na = total_na / len(user_df)\n\nfor col in user_df.columns:\n    print(\"Columna '{}'. Valores nulos: {} ({:.2f} %)\".format(col, total_na[col], prop_na[col] * 100))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.62763Z","iopub.execute_input":"2022-05-08T12:03:40.628476Z","iopub.status.idle":"2022-05-08T12:03:40.641638Z","shell.execute_reply.started":"2022-05-08T12:03:40.628418Z","shell.execute_reply":"2022-05-08T12:03:40.640651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como se observa en la celda anterior, la grann mayoría de las columnas todavía contienen valores nulos. Esto es un inconveniente, pues los modelos de *Machine Learning* no permiten valores nulos. Para resolver este inconveniente hemos empleado la técnica de imputación. En concreto, hemos empleado dos estrategias distintas para imputar los valores nulos:\n\n- La columna `burnedKilocalories` la hemos imputado con el valor constante 0.\n- El resto de columnas las hemos imputado mediante un imputador KNN con `n_neighbors=5`.","metadata":{}},{"cell_type":"code","source":"# Importamos el imputador KNN\nfrom sklearn.impute import KNNImputer\n\n# Imputamos los valores NaN de la columna burnedKilocalories con el valor constante 0\nuser_df['burnedKilocalories'].fillna(value=0, inplace=True)\n\n# Seleccionamos sólo aquellas columnas que son de tipo numérico (int64 o float64)\nnum_cols = user_df.select_dtypes('number')\n\n# Creamos el imputador KNN con 5 vecinos y pesos uniformes\nknnImp = KNNImputer(n_neighbors=5, weights='uniform')\n\n# Imputamos los valores nulos de las columnas de tipo numérico\nimp_cols = knnImp.fit_transform(num_cols)\n\n# Los valores imputados se almacenan en un array auxiliar,\n# por tanto, hay que crear un nuevo DataFrame\ndfAux = pd.DataFrame(imp_cols, columns=num_cols.columns)\n\n# A este DataFrame auxiliar hay que añadirle las columnas no numéricas\ndfAux.insert(0, 'calendarDate', user_df.calendarDate.values)\n\n# Asignamos a nuestro antiguo DataFrame el contenido del nuevo\nuser_df = dfAux\n\n# Mostramos el contenido del nuevo DataFrame\nuser_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.643342Z","iopub.execute_input":"2022-05-08T12:03:40.643826Z","iopub.status.idle":"2022-05-08T12:03:40.788874Z","shell.execute_reply.started":"2022-05-08T12:03:40.643782Z","shell.execute_reply":"2022-05-08T12:03:40.787746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tras visualizar los datos, vemos que la columna `calendarDate` no se encuentra ordenada. Para corregirlo, procedemos a ordenar los datos por la columna `calendarDate` de forma ascendente.","metadata":{}},{"cell_type":"code","source":"# Ordenamos los datos por la columna calendarDate de forma ascendente\nuser_df = user_df.sort_values(by='calendarDate')\n\n# Reseteamos los índices del DataFrame\nuser_df.reset_index(drop=True, inplace=True)\n\n# Mostramos el contenido del DataFrame tras ordenar los datos\nuser_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.790689Z","iopub.execute_input":"2022-05-08T12:03:40.791182Z","iopub.status.idle":"2022-05-08T12:03:40.817227Z","shell.execute_reply.started":"2022-05-08T12:03:40.79113Z","shell.execute_reply":"2022-05-08T12:03:40.816247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.9. Extracción de características\n\nEn esta sección partiremos de la columna `calendarDate` para extraer como características las columnas `day`, `month`, `year` y `weekday`, por último, eliminaremos la columna original `calendarDate`.","metadata":{}},{"cell_type":"code","source":"# Extraemos el año de la columna calendarDate\nuser_df['year'] = user_df['calendarDate'].dt.year\n\n# Extraemos el mes de la columna calendarDate\nuser_df['month'] = user_df['calendarDate'].dt.month\n\n# Extraemos el día de la columna calendarDate\nuser_df['day'] = user_df['calendarDate'].dt.day\n\n# Extraemos el día de la semana de la columna calendarDate\nuser_df['weekday'] = user_df['calendarDate'].dt.dayofweek\n\n# Eliminamos la columna original\nuser_df.drop(['calendarDate'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.818342Z","iopub.execute_input":"2022-05-08T12:03:40.818568Z","iopub.status.idle":"2022-05-08T12:03:40.830798Z","shell.execute_reply.started":"2022-05-08T12:03:40.818539Z","shell.execute_reply":"2022-05-08T12:03:40.830033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mostramos el contenido del DataFrame tras la extracción de características\nuser_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.832289Z","iopub.execute_input":"2022-05-08T12:03:40.83266Z","iopub.status.idle":"2022-05-08T12:03:40.856623Z","shell.execute_reply.started":"2022-05-08T12:03:40.832626Z","shell.execute_reply":"2022-05-08T12:03:40.856019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.10. Creación de la columna objetivo\n\nEn este apartado vamos a crear la columna `Perfil`, la cual será una variable categórica multilabel que podrá tomar los siguientes valores:\n\n - `0`. Indica que la actividad física de ese día ha sido **Baja**.\n \n - `1`. Indica que la actividad física de ese día ha sido **Media**.\n \n - `2`. Indica que la actividad física de ese día ha sido **Alta**.\n\nEsta nueva variable es la suma ponderada de las variables `totalKilocalories`, `totalSteps` y `activeSeconds`, siendo sus ponderaciones 0.5, 0.3 y 0.2, respectivamente. De esta forma, el cálculo de la variable `Perfil` será el siguiente:\n\n$$Perfil = 0.5 · totalKilocalories + 0.3 · totalSteps + 0.2 · activeSeconds$$\n\n> **Nota**: Aunque pueda parecer que se trata de una variable numérica, es de tipo categórico. El único motivo por el cuál se representa con un valor numérico del 0 al 2 y no con una palabra es que así se puede usar la misma etiqueta tanto para clasificación como para regresión.","metadata":{}},{"cell_type":"code","source":"# Creación de la variable Perfil\nuser_df['Perfil'] = 0.5 * user_df['totalKilocalories'] + 0.3 * user_df['totalSteps'] + 0.2 * user_df['activeSeconds']","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.857674Z","iopub.execute_input":"2022-05-08T12:03:40.858412Z","iopub.status.idle":"2022-05-08T12:03:40.86947Z","shell.execute_reply.started":"2022-05-08T12:03:40.858365Z","shell.execute_reply":"2022-05-08T12:03:40.868832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Una vez creada la variable `Perfil` esta tendrá valores de tipo continua, por lo que habrá que discretizar la variable. Para ello, primero debemos extraer tantos intervalos como clases queramos que tenga la variable discreta. En nuestro caso, queremos obtener 3 clases, por lo que tendremos que dividir el conjunto en 3 intervalos. Además, estos intervalos tendrán que asegurarse que las clases no están desbalanceadas.","metadata":{}},{"cell_type":"code","source":"# Creamos 3 intervalos con un número de muestras balanceado\nres, bins = pd.qcut(user_df.Perfil, 3, precision=2, retbins=True)\n\nperfiles = []\n\n# Función que discretiza los valores de la variable Perfil\ndef convert_values():\n    for perfil in user_df.Perfil:\n        if perfil >= bins[0] and perfil <= bins[1]:\n            perfil = 0\n        elif perfil >= bins[1] and perfil <= bins[2]:\n            perfil = 1\n        else:\n            perfil = 2\n            \n        perfiles.append(perfil)\n    \n    return perfiles\n\nuser_df['Perfil'] = convert_values()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.870368Z","iopub.execute_input":"2022-05-08T12:03:40.870701Z","iopub.status.idle":"2022-05-08T12:03:40.89479Z","shell.execute_reply.started":"2022-05-08T12:03:40.870675Z","shell.execute_reply":"2022-05-08T12:03:40.894151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.11. Distribución de las clases de la variable objetivo\n\nPara comprobar que las clases están balanceadas, representamos mediante un gráfico de barras el número de instancias de cada una de las clases de la variable `Perfil`.","metadata":{}},{"cell_type":"code","source":"# Representamos la distribución de las instancias de las distintas clases\nintervalos = user_df['Perfil'].value_counts().sort_index()\n\nvalues = intervalos.values.tolist()\nlabels = intervalos.index.astype(str).tolist()\n\nfig = px.bar(res, x=labels, y=values, height=400, width=600, text_auto=True,\n             labels={ # replaces default labels by column name\n                 \"x\": 'Clases', \"y\": 'Número instancias'})\nfig.update_layout(title_text=\"Distribución equilibrada de las clases\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:40.898771Z","iopub.execute_input":"2022-05-08T12:03:40.899165Z","iopub.status.idle":"2022-05-08T12:03:41.049342Z","shell.execute_reply.started":"2022-05-08T12:03:40.899135Z","shell.execute_reply":"2022-05-08T12:03:41.048323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Técnicas de Regresión\n\nEn este apartado vamos a ...","metadata":{}},{"cell_type":"markdown","source":"### 2.1. División del conjunto de datos \n!!!!Y SI PONEMOS ESTE APARTADO FUERA EN EL PREPROCESADO O EN UN PUNTO A PARTE YA QUE SE VA A USAR EN TODOS LOS ALGORITMOS NO SOLO EN ESTE!!!\n\nEn esta sección vamos a generar los subconjuntos de datos de entrenamiento y testeo.","metadata":{}},{"cell_type":"markdown","source":"Primero, vamos a separar el conjunto de datos en las variables `X` e `y`, donde la variable `X` contendrá todas las características menos la variable objetivo, y la variable `y` contendrá sólo la variable objetivo.","metadata":{}},{"cell_type":"code","source":"X = user_df.drop(['Perfil'], axis=1)\ny = user_df['Perfil']","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:41.050959Z","iopub.execute_input":"2022-05-08T12:03:41.051289Z","iopub.status.idle":"2022-05-08T12:03:41.058127Z","shell.execute_reply.started":"2022-05-08T12:03:41.051246Z","shell.execute_reply":"2022-05-08T12:03:41.057116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Después, vamos a dividir el conjunto de datos en los subconjuntos de entrenamiento y testeo, de esta forma, podremos entrenar los distintos modelos de regresión con un subconjunto de datos y medir su capacidad de predicción con el otro subconjunto. El subconjunto de entrenamiento representará el 75% de los datos, mientras que el de testeo representará el 25% restante.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:41.059868Z","iopub.execute_input":"2022-05-08T12:03:41.060212Z","iopub.status.idle":"2022-05-08T12:03:41.070075Z","shell.execute_reply.started":"2022-05-08T12:03:41.060169Z","shell.execute_reply":"2022-05-08T12:03:41.069419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Una vez generados los distintos subconjuntos, mostramos las dimensiones de estos.","metadata":{}},{"cell_type":"code","source":"print(\"Dimensiones X_train:\", X_train.shape)\nprint(\"Dimensiones X_test:\", X_test.shape)\nprint(\"Dimensiones y_train:\", y_train.shape)\nprint(\"Dimensiones y_test:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:41.071177Z","iopub.execute_input":"2022-05-08T12:03:41.07151Z","iopub.status.idle":"2022-05-08T12:03:41.082848Z","shell.execute_reply.started":"2022-05-08T12:03:41.071482Z","shell.execute_reply":"2022-05-08T12:03:41.082001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2. Selección del valor óptimo del parámetro `max_depth`\nTras generar los distintos subconjuntos, vamos a evaluar el desempeño de un árbol de decisión con distintos valores del parámetro `max_depth` mediante las métricas **R2**, **MAE** y **MSE**.","metadata":{}},{"cell_type":"code","source":"# Evalúa el desempeño del árbol de decisión en los subconjuntos de\n# entrenamiento y testeo con diferentes valores del parámetro max_depth\ntrain_scores_r2, test_scores_r2 = [], []\ntrain_scores_mae, test_scores_mae = [], []\ntrain_scores_mse, test_scores_mse = [], []\n\n# Valores del parámetro max_depth\nvalues = list(range(1, 21))\n\n# Evaluamos el árbol de decisión para cada uno de los valores\nfor value in values:\n    # Creamos el modelo\n    model = DecisionTreeRegressor(max_depth=value)\n    \n    # Entrenamos el modelo\n    model.fit(X_train, y_train)\n    \n    # Evaluamos los conjuntos de datos de entrenamiento y testeo\n    train_predict = model.predict(X_train)\n    test_predict = model.predict(X_test)\n    \n    # Métrica R2 para los conjuntos de entrenamiento y testeo\n    train_r2 = round(r2_score(y_train, train_predict), 3)\n    test_r2 = round(r2_score(y_test, test_predict), 3)\n    train_scores_r2.append(train_r2)\n    test_scores_r2.append(test_r2)\n    \n    # Métrica MAE para los conjuntos de entrenamiento y testeo\n    train_mae = round(mean_absolute_error(y_train, train_predict), 3)\n    test_mae = round(mean_absolute_error(y_test, test_predict), 3)\n    train_scores_mae.append(train_mae)\n    test_scores_mae.append(test_mae)\n    \n    # Métrica MSE para los conjuntos de entrenamiento y testeo\n    train_mse = round(mean_squared_error(y_train, train_predict), 3)\n    test_mse = round(mean_squared_error(y_test, test_predict), 3)\n    train_scores_mse.append(train_mse)\n    test_scores_mse.append(test_mse)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:41.084238Z","iopub.execute_input":"2022-05-08T12:03:41.084648Z","iopub.status.idle":"2022-05-08T12:03:41.331733Z","shell.execute_reply.started":"2022-05-08T12:03:41.084608Z","shell.execute_reply":"2022-05-08T12:03:41.330833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Una vez calculadas las distintas métricas, las visualizamos en varias gráficas. El objetivo de las siguientes gráficas es determinar de forma visual el valor óptimo del parámetro `max_depth` sin llegar al sobreentrenamiento (*overfitting*). Para determinar el valor óptimo, debemos visualizar las curvas de entrenamiento y testeo y seleccionar el último valor antes de que las curvas empiecen a diverger.","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_r2,\n                            mode='lines+markers', name='R2 Train',\n                            line_color=colors[0]),\n                 row=1, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_r2,\n                            mode='lines+markers', name='R2 Test',\n                            line_color=colors[1]),\n                 row=1, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_mae,\n                            mode='lines+markers', name='MAE Train',\n                            line_color=colors[0]),\n                 row=2, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_mae,\n                            mode='lines+markers', name='MAE Test',\n                            line_color=colors[1]),\n                 row=2, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_mse,\n                            mode='lines+markers', name='MSE Train',\n                            line_color=colors[0]),\n                 row=3, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_mse,\n                            mode='lines+markers', name='MSE Test',\n                            line_color=colors[1]),\n                 row=3, col=1)\n\nfig.update_xaxes(title_text='max_depth', title_font={\"size\": 14})\nfig.update_layout(height=700, width=600,\n                  title={'x': 0.5, 'y': 0.9, 'font': {'size': 16},\n                         'text': 'Métricas para distintos valores de max_depth',\n                         'xanchor': 'center', 'yanchor': 'top'},\n                  yaxis=dict(title=\"R2\", titlefont={\"size\": 14}),\n                  yaxis2=dict(title=\"MAE\", titlefont={\"size\": 14}),\n                  yaxis3=dict(title=\"MSE\", titlefont={\"size\": 14}))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:41.333131Z","iopub.execute_input":"2022-05-08T12:03:41.333387Z","iopub.status.idle":"2022-05-08T12:03:41.475629Z","shell.execute_reply.started":"2022-05-08T12:03:41.333354Z","shell.execute_reply":"2022-05-08T12:03:41.475063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tal y como se observa en las gráficas de las 3 métricas, el valor óptimo es `max_depth=4`, pues a partir de este valor los resultados de entrenamiento y testeo empiezan a distanciarse, lo cual indica que se está produciendo sobreentrenamiento.","metadata":{}},{"cell_type":"markdown","source":"### 2.3. Selección del valor óptimo del parámetro `min_samples_split`\nUna vez que hemos determinado el valor óptimo del parámetro `max_depth`, volvemos a repetir el procedimiento para determinar el valor óptimo del parámetro `min_samples_split` mediante las métricas **R2**, **MAE** y **MSE**.","metadata":{}},{"cell_type":"code","source":"# Evalúa el desempeño del árbol de decisión en los subconjuntos de\n# entrenamiento y testeo con diferentes valores del parámetro min_samples_split\ntrain_scores_r2, test_scores_r2 = [], []\ntrain_scores_mae, test_scores_mae = [], []\ntrain_scores_mse, test_scores_mse = [], []\n\n# Valores del parámetro max_depth\nvalues = list(range(2, 21))\n\n# Evaluamos el árbol de decisión para cada uno de los valores\nfor value in values:\n    # Creamos el modelo\n    model = DecisionTreeRegressor(max_depth=4, min_samples_split=value)\n    \n    # Entrenamos el modelo\n    model.fit(X_train, y_train)\n    \n    # Evaluamos los conjuntos de datos de entrenamiento y testeo\n    train_predict = model.predict(X_train)\n    test_predict = model.predict(X_test)\n    \n    # Métrica R2 para los conjuntos de entrenamiento y testeo\n    train_r2 = round(r2_score(y_train, train_predict), 3)\n    test_r2 = round(r2_score(y_test, test_predict), 3)\n    train_scores_r2.append(train_r2)\n    test_scores_r2.append(test_r2)\n    \n    # Métrica MAE para los conjuntos de entrenamiento y testeo\n    train_mae = round(mean_absolute_error(y_train, train_predict), 3)\n    test_mae = round(mean_absolute_error(y_test, test_predict), 3)\n    train_scores_mae.append(train_mae)\n    test_scores_mae.append(test_mae)\n    \n    # Métrica MSE para los conjuntos de entrenamiento y testeo\n    train_mse = round(mean_squared_error(y_train, train_predict), 3)\n    test_mse = round(mean_squared_error(y_test, test_predict), 3)\n    train_scores_mse.append(train_mse)\n    test_scores_mse.append(test_mse)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:41.476612Z","iopub.execute_input":"2022-05-08T12:03:41.476987Z","iopub.status.idle":"2022-05-08T12:03:41.686692Z","shell.execute_reply.started":"2022-05-08T12:03:41.476928Z","shell.execute_reply":"2022-05-08T12:03:41.686045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tras calcular las distintas métricas, volvemos a visualizarlas en varias gráficas. En esta ocasión, el objetivo es determinar de forma visual el valor óptimo del parámetro `min_samples_split` sin llegar al sobreentrenamiento (*overfitting*).","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_r2,\n                            mode='lines+markers', name='R2 Train',\n                            line_color=colors[0]),\n                 row=1, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_r2,\n                            mode='lines+markers', name='R2 Test',\n                            line_color=colors[1]),\n                 row=1, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_mae,\n                            mode='lines+markers', name='MAE Train',\n                            line_color=colors[0]),\n                 row=2, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_mae,\n                            mode='lines+markers', name='MAE Test',\n                            line_color=colors[1]),\n                 row=2, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_mse,\n                            mode='lines+markers', name='MSE Train',\n                            line_color=colors[0]),\n                 row=3, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_mse,\n                            mode='lines+markers', name='MSE Test',\n                            line_color=colors[1]),\n                 row=3, col=1)\n\nfig.update_xaxes(title_text='min_samples_split', title_font={\"size\": 14})\nfig.update_layout(height=700, width=600,\n                  title={'x': 0.5, 'y': 0.9, 'font': {'size': 16},\n                         'text': 'Métricas para distintos valores de min_samples_split',\n                         'xanchor': 'center', 'yanchor': 'top'},\n                  yaxis=dict(title=\"R2\", titlefont={\"size\": 14}),\n                  yaxis2=dict(title=\"MAE\", titlefont={\"size\": 14}),\n                  yaxis3=dict(title=\"MSE\", titlefont={\"size\": 14}))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:41.68771Z","iopub.execute_input":"2022-05-08T12:03:41.688528Z","iopub.status.idle":"2022-05-08T12:03:41.799769Z","shell.execute_reply.started":"2022-05-08T12:03:41.688485Z","shell.execute_reply":"2022-05-08T12:03:41.798842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En esta ocasión, se observa que los valores de entrenamiento y testeo son muy diferentes y nunca convergen. Por este motivo, hemos determinado que el valor óptimo es `min_samples_split=2`. En este caso, no resulta útil seleccionar un valor mayor, pues esto sólo añadiría complejidad, y produciría *overfitting* en el modelo de predicción.","metadata":{}},{"cell_type":"markdown","source":"### 2.3. Selección del valor óptimo del parámetro `min_samples_leaf`\nUna vez que hemos determinado el valor óptimo del parámetro `min_samples_split`, volvemos a repetir el procedimiento para determinar el valor óptimo del parámetro `min_samples_leaf` mediante las métricas **R2**, **MAE** y **MSE**.","metadata":{}},{"cell_type":"code","source":"# Evalúa el desempeño del árbol de decisión en los subconjuntos de\n# entrenamiento y testeo con diferentes valores del parámetro min_samples_split\ntrain_scores_r2, test_scores_r2 = [], []\ntrain_scores_mae, test_scores_mae = [], []\ntrain_scores_mse, test_scores_mse = [], []\n\n# Valores del parámetro max_depth\nvalues = list(range(1, 21))\n\n# Evaluamos el árbol de decisión para cada uno de los valores\nfor value in values:\n    # Creamos el modelo\n    model = DecisionTreeRegressor(max_depth=4, min_samples_leaf=value)\n    \n    # Entrenamos el modelo\n    model.fit(X_train, y_train)\n    \n    # Evaluamos los conjuntos de datos de entrenamiento y testeo\n    train_predict = model.predict(X_train)\n    test_predict = model.predict(X_test)\n    \n    # Métrica R2 para los conjuntos de entrenamiento y testeo\n    train_r2 = round(r2_score(y_train, train_predict), 3)\n    test_r2 = round(r2_score(y_test, test_predict), 3)\n    train_scores_r2.append(train_r2)\n    test_scores_r2.append(test_r2)\n    \n    # Métrica MAE para los conjuntos de entrenamiento y testeo\n    train_mae = round(mean_absolute_error(y_train, train_predict), 3)\n    test_mae = round(mean_absolute_error(y_test, test_predict), 3)\n    train_scores_mae.append(train_mae)\n    test_scores_mae.append(test_mae)\n    \n    # Métrica MSE para los conjuntos de entrenamiento y testeo\n    train_mse = round(mean_squared_error(y_train, train_predict), 3)\n    test_mse = round(mean_squared_error(y_test, test_predict), 3)\n    train_scores_mse.append(train_mse)\n    test_scores_mse.append(test_mse)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:41.801083Z","iopub.execute_input":"2022-05-08T12:03:41.801335Z","iopub.status.idle":"2022-05-08T12:03:42.022778Z","shell.execute_reply.started":"2022-05-08T12:03:41.801305Z","shell.execute_reply":"2022-05-08T12:03:42.022037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tras calcular las distintas métricas, volvemos a visualizarlas en varias gráficas. En esta ocasión, el objetivo es determinar de forma visual el valor óptimo del parámetro `min_samples_leaf` sin llegar al sobreentrenamiento (*overfitting*).","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_r2,\n                            mode='lines+markers', name='R2 Train',\n                            line_color=colors[0]),\n                 row=1, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_r2,\n                            mode='lines+markers', name='R2 Test',\n                            line_color=colors[1]),\n                 row=1, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_mae,\n                            mode='lines+markers', name='MAE Train',\n                            line_color=colors[0]),\n                 row=2, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_mae,\n                            mode='lines+markers', name='MAE Test',\n                            line_color=colors[1]),\n                 row=2, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=train_scores_mse,\n                            mode='lines+markers', name='MSE Train',\n                            line_color=colors[0]),\n                 row=3, col=1)\n\nfig.append_trace(go.Scatter(x=values, y=test_scores_mse,\n                            mode='lines+markers', name='MSE Test',\n                            line_color=colors[1]),\n                 row=3, col=1)\n\nfig.update_xaxes(title_text='min_samples_leaf', title_font={\"size\": 14})\nfig.update_layout(height=700, width=600,\n                  title={'x': 0.5, 'y': 0.9, 'font': {'size': 16},\n                         'text': 'Métricas para distintos valores de min_samples_leaf',\n                         'xanchor': 'center', 'yanchor': 'top'},\n                  yaxis=dict(title=\"R2\", titlefont={\"size\": 14}),\n                  yaxis2=dict(title=\"MAE\", titlefont={\"size\": 14}),\n                  yaxis3=dict(title=\"MSE\", titlefont={\"size\": 14}))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:42.02406Z","iopub.execute_input":"2022-05-08T12:03:42.024774Z","iopub.status.idle":"2022-05-08T12:03:42.137569Z","shell.execute_reply.started":"2022-05-08T12:03:42.024737Z","shell.execute_reply":"2022-05-08T12:03:42.136774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Al igual que sucedió con el parámetro `min_samples_split`, se puede ver que los valores de entrenamiento y testeo del parámetro `min_samples_leaf` son muy diferentes y nunca convergen. Por este motivo, hemos seleccionado como valor óptimo `min_samples_leaf=1`. Como en el caso de `min_samples_split`, no es de utilidad elegir un valor mayor, pues esto sólo añade complejidad y produce *overfitting* en el modelo.","metadata":{}},{"cell_type":"markdown","source":"### 2.4. Selección de parámetros óptimos mediante GridSearchCV\n\n...","metadata":{}},{"cell_type":"markdown","source":"### 2.5. Comprobación de los parámetros óptimos elegidos mediante Cross Validation\n\nTras probar distintos valores con los parámetros `max_depth`, `min_samples_split` y `min_samples_leaf`, hemos determinado que los valores óptimos para nuestro conjunto de datos son los siguientes:\n\n - `max_depth=4`\n - `min_samples_split=2`\n - `min_samples_leaf=1`\n\nLlegados a este punto, nos interesa saber si con estos parámetros nuestro modelo se comporta igual, independientemente del conjunto de datos de entrenamiento y testeo que le asignemos. Para ello, nos vamos a apoyar en la técnica de Cross Validation.","metadata":{}},{"cell_type":"code","source":"# Declaramos Cross Validation con 5 particiones (folds)\ncv = KFold(n_splits=5, random_state=50, shuffle=True)\n\nscores_r2 = []\nscores_mae = []\nscores_mse = []\nmodels = []\n\n# Para cada fold\n# Variable acumuladora\nmean_score = 0.0\n\nfor train_index, test_index in cv.split(X):\n    # Seleccionamos los datos\n    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n    \n    # Declaramos el modelo\n    model = DecisionTreeRegressor(max_depth=4,\n                                  min_samples_split=2,\n                                  min_samples_leaf=1)\n    # Entrenamos el modelo\n    model = model.fit(X_train, y_train)\n    \n    # Guardamos el modelo en una lista\n    models.append(model)\n    \n    # Evaluamos el modelo\n    predict = model.predict(X_test)\n    \n    # Métrica R2\n    r2 = round(r2_score(y_test, predict), 3)\n    scores_r2.append(r2)\n    \n    # Métrica MAE\n    mae = round(mean_absolute_error(y_test, predict), 3)\n    scores_mae.append(mae)\n    \n    # Métrica MSE\n    mse = round(mean_squared_error(y_test, predict), 3)\n    scores_mse.append(mse)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:42.138556Z","iopub.execute_input":"2022-05-08T12:03:42.138759Z","iopub.status.idle":"2022-05-08T12:03:42.197692Z","shell.execute_reply.started":"2022-05-08T12:03:42.138733Z","shell.execute_reply":"2022-05-08T12:03:42.197074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Una vez que hemos calculado las métricas para cada una de las 5 particiones, mostramos un gráfico de barras por cada métrica con la puntuación de cada partición.","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=3)\n\nlabels=['1', '2', '3', '4', '5']\n\nfig.append_trace(go.Bar(x=labels, y=scores_r2, name=\"R2 score\",\n                        textposition=\"none\"), row=1, col=1)\n\nfig.append_trace(go.Bar(x=labels, y=scores_mae, name=\"MAE score\",\n                        textposition=\"none\"), row=1, col=2)\n\nfig.append_trace(go.Bar(x=labels, y=scores_mse, name=\"MSE score\",\n                        textposition=\"none\"), row=1, col=3)\n\nfig.update_xaxes(title_text='Partición', title_font={\"size\": 14})\nfig.update_layout(height=400, width=1200,\n                  title={'x': 0.5, 'y': 0.9, 'font': {'size': 16},\n                         'text': 'Métricas para cada partición de CV',\n                         'xanchor': 'center', 'yanchor': 'top'},\n                  yaxis=dict(title=\"R2\", titlefont={\"size\": 14}),\n                  yaxis2=dict(title=\"MAE\", titlefont={\"size\": 14}),\n                  yaxis3=dict(title=\"MSE\", titlefont={\"size\": 14}))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:42.198665Z","iopub.execute_input":"2022-05-08T12:03:42.199335Z","iopub.status.idle":"2022-05-08T12:03:42.300002Z","shell.execute_reply.started":"2022-05-08T12:03:42.199301Z","shell.execute_reply":"2022-05-08T12:03:42.299156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como se observa en las gráficas anteriores, los valores de las distintas métricas en cada partición son muy parecidos. Esto nos permite afirmar que estos parámetros son óptimos para nuestro modelo, pues este se comporta igual de bien independientemente del conjunto de entrenamiento asignado.","metadata":{}},{"cell_type":"markdown","source":"### 2.6. Relevancia de cada una de las características\n\nHasta ahora hemos estado entrenando el modelo con todas las características posibles. Sin embargo, esto no es muy beneficioso pues, al igual que hay características que aportan mucha información, hay otras que hacen todo lo contrario y lo único que introducen es ruido en el modelo.\n\nPor ello, es conveniente entrenar el modelo sólo con aquellas características que sean más importantes. Para determinar cuáles son realmente importantes y cuáles no, existe la propiedad `feature_importances_`.","metadata":{}},{"cell_type":"code","source":"# DataFrame que contendrá la importancia de las variables del modelo para cada conjunto de Cross Validation\ndf_coeficientes = pd.DataFrame()\n\nfor i in range(0, len(models)):\n    coeficientes = pd.DataFrame([models[i].feature_importances_], columns=X.columns)\n    df_coeficientes = df_coeficientes.append(coeficientes)\n    \n# Ordenamos los coeficientes de mayor a menor importancia\nord_coef = df_coeficientes.mean().sort_values(ascending=False)\nlabels = ord_coef.index.astype(str).tolist()\nvalues = ord_coef.values.tolist()\n\nfig = px.pie(names=labels[:3], values=[round(v, 4) for v in values][:3],\n             title=\"3 características más importantes para el modelo\",\n             color_discrete_sequence=colores,\n             height=400, width=700)\n\nfig.update_layout(title={'x': 0.5, 'y': 0.9, 'font': {'size': 16},\n                         'xanchor': 'center', 'yanchor': 'top'},\n                  legend={'title': 'Características', 'font': {'size': 16}})\n\nfig.update_traces(textinfo='value')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:42.301119Z","iopub.execute_input":"2022-05-08T12:03:42.301352Z","iopub.status.idle":"2022-05-08T12:03:42.434013Z","shell.execute_reply.started":"2022-05-08T12:03:42.301323Z","shell.execute_reply":"2022-05-08T12:03:42.433102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como se observa en el gráfico sectorial anterior, las 3 características más relevantes del dataset son: `totalSteps`, `activeSeconds` y `wellnessKilocalories`. Puesto que la importancia de las demás características es inferior al 1%, podemos considerar que no aportan información al modelo sino más bien ruido. Por ello, es recomendable volver a entrenar el modelo solo con estas 3 características y, posteriormente, comparar los resultados obtenidos con los anteriores.","metadata":{}},{"cell_type":"code","source":"# Seleccionamos las tres variables más importantes\nX = X[['totalSteps', 'activeSeconds', 'activeKilocalories']].copy()\n\nscores_rw = []\nscores_mae = []\nscores_mse = []\nmodels = []\n\n# Para cada fold\n# Variable acumuladora\nmean_score = 0.0\n\nfor train_index, test_index in cv.split(X):\n    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n    X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n    \n    # Declaramos el modelo\n    model = DecisionTreeRegressor(max_depth=4,\n                                  min_samples_split=2,\n                                  min_samples_leaf=1)\n    \n    # Entrenamos el modelo\n    model = model.fit(X_train, y_train)\n    \n    # Guardamos el modelo en una lista\n    models.append(model)\n\n    # Evaluamos el modelo\n    predict = model.predict(X_test)\n\n    # Métrica R2\n    r2 = round(r2_score(y_test, predict), 3)\n    scores_r2.append(r2)\n    \n    # Métrica MAE\n    mae = round(mean_absolute_error(y_test, predict), 3)\n    scores_mae.append(mae)\n    \n    # Métrica MSE\n    mse = round(mean_squared_error(y_test, predict), 3)\n    scores_mse.append(mse)\n    \ndf_coeficientes = pd.DataFrame()\n\nfor i in range(0, len(models)):\n    coeficientes = pd.DataFrame([models[i].feature_importances_], columns=X.columns)\n    df_coeficientes = df_coeficientes.append(coeficientes)\n    \n# Ordenamos los coeficientes de mayor a menor importancia\nord_coef = df_coeficientes.mean().sort_values(ascending=False)\nlabels = ord_coef.index.astype(str).tolist()\nvalues = ord_coef.values.tolist()\n\nfig = px.pie(names=labels[:3], values=[round(v, 4) for v in values][:3],\n             title=\"3 características más importantes para el modelo\",\n             color_discrete_sequence=colores,\n             height=400, width=700)\n\nfig.update_layout(title={'x': 0.5, 'y': 0.9, 'font': {'size': 16},\n                         'xanchor': 'center', 'yanchor': 'top'},\n                  legend={'title': 'Características', 'font': {'size': 16}})\n\nfig.update_traces(textinfo='value')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:42.435724Z","iopub.execute_input":"2022-05-08T12:03:42.436085Z","iopub.status.idle":"2022-05-08T12:03:42.595409Z","shell.execute_reply.started":"2022-05-08T12:03:42.436044Z","shell.execute_reply":"2022-05-08T12:03:42.594565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Tras volver a entrenar el modelo, observamos que los coeficientes de relevancia son muy similares a los obtenidos anteriormente. La diferencia es que, al haber eliminado las variables que no son relevantes, el algoritmo se ajusta ligeramente mejor. Además, al utilizar muchas menos variables, el modelo es más sencillo de utilizar y el coste temporal de entrenamiento también es menor.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Técnicas de clasificación","metadata":{}},{"cell_type":"markdown","source":"## 4. Técnicas de *ensembles*","metadata":{}},{"cell_type":"markdown","source":"Los *ensembles* son unas estrategias de combinación de distintos algoritmos, que combinando sus predicciones, dan lugar a una predicción final. Existen un gran número de métodos de ensembles que se pueden utilizar y, a continuación, crearemos un modelo con cada uno de los más relevantes para, posteriormente, evaluar su funcionamiento. ","metadata":{}},{"cell_type":"markdown","source":"### 4.1. Selección de parámetros óptimos mediante GridSearchCV\n\nPara establecer los parámetros óptimos para cada modelo a utilizar, usaremos la clase `gridSearcCV`de `sckitLearn`, mediante la cuál, indicandole los modelos a utilizar y sus distintos parámetros, establecerá cuales de estos últimos son los óptimos para cada parámetro a partir de la validación cruzada. \n\nEn primer lugar, debemos de establecer los modelos a evaluar, en nuestro caso serán *Bagging*, *Random Forest*, *AdaBoost*, *GradientBoost* y *Stacking*. ","metadata":{}},{"cell_type":"code","source":"estim = [('knn', KNeighborsClassifier(n_neighbors=3)),\n              ('cart', DecisionTreeClassifier(random_state=0)),\n              ('svm', SVC(random_state=0)),\n              ('lr', LogisticRegression(random_state=0))]\n\nensembles = [\n    BaggingClassifier(random_state=0), \n    RandomForestClassifier(random_state=0), \n    AdaBoostClassifier(random_state=0),\n    GradientBoostingClassifier(random_state=0),\n    StackingClassifier(estimators=estim)\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:42.596765Z","iopub.execute_input":"2022-05-08T12:03:42.597037Z","iopub.status.idle":"2022-05-08T12:03:42.603773Z","shell.execute_reply.started":"2022-05-08T12:03:42.597007Z","shell.execute_reply":"2022-05-08T12:03:42.602461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación, para cada uno de los modelos, estableceremos qué parámetros vamos a probar e incluiremos todos en una única lista:","metadata":{}},{"cell_type":"code","source":"bagging_parameters = {\n    'base_estimator'      : [DecisionTreeClassifier(random_state=0), SVC(random_state=0), KNeighborsClassifier(n_neighbors=3), SGDClassifier(max_iter=1000, tol=1e-3, random_state=0)],\n    'n_estimators' : [1, 5, 10, 20],\n    'max_samples'    : [0.25, 0.5, 0.75, 1],\n    'max_features'   : [0.25, 0.5, 0.75, 1]\n}\n\nrandomforest_parameters = {\n    'n_estimators': [50, 100, 200, 300],\n    'max_depth'   : [None, 1, 2, 5],\n    'max_features':  ['auto', 'log2'],\n    'max_samples' : [None, 0.25, 0.5, 0.75, 1 ]\n}\n\nadaboost_parameters = {\n    'base_estimator'      : [DecisionTreeClassifier(random_state=0), SVC(random_state=0), KNeighborsClassifier(n_neighbors=3), SGDClassifier(max_iter=1000, tol=1e-3, random_state=0)],\n    'n_estimators' : [1, 5, 10, 20],\n    'learning_rate'  : [0.25, 0.5, 1, 5]\n}\n\ngradientboost_parameters = {\n    'learning_rate'  : [0.25, 0.5, 1, 5],\n    'n_estimators' : [1, 5, 10, 20],\n    'max_depth'      : [None, 1, 2, 5],\n}\n\nstacking_parameters = {\n    'final_estimator' : [LogisticRegression(random_state=0), GradientBoostingClassifier(random_state=0)]\n}\n\nparameters = [\n    bagging_parameters, \n    randomforest_parameters, \n    adaboost_parameters,\n    gradientboost_parameters,\n    stacking_parameters\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:42.605959Z","iopub.execute_input":"2022-05-08T12:03:42.606271Z","iopub.status.idle":"2022-05-08T12:03:42.620419Z","shell.execute_reply.started":"2022-05-08T12:03:42.60623Z","shell.execute_reply":"2022-05-08T12:03:42.619534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente almacenaremos el modelo elegido para cada algoritmo, su precisión y tiempo de ejecución para posteriormente evaluarlo:","metadata":{}},{"cell_type":"code","source":"estimators = [] # Para almacenar los modelos\naccuracies = [] # Para almacenar su precisión y tiempo\ntimes = []\n\n# Iteramos para cada uno de los modelos de ensembles\nfor i, ensemble in enumerate(ensembles):\n    start_time = time.time()\n\n    clf = GridSearchCV(ensemble,          # Modelo\n              param_grid = parameters[i], # Parámetro\n              scoring='accuracy',         # Métrica de evaluación\n              cv=10)                      # Número de folds para el CV\n    print('************', ensemble.__class__.__name__, '************')\n    clf.fit(X_train, y_train)\n    print(\"Parámetros :\", clf.best_params_)\n    acc = (clf.predict(X_test) == y_test).mean()*100\n    print(\"Accuracy :\", (acc))\n    sec = (time.time() - start_time)\n    print(\"Time of tunning and training :\", (sec))\n    accuracies.append((ensemble.__class__.__name__, acc))\n    times.append((ensemble.__class__.__name__, sec))\n    estimators.append((ensemble.__class__.__name__, clf))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:03:42.621472Z","iopub.execute_input":"2022-05-08T12:03:42.621681Z","iopub.status.idle":"2022-05-08T12:18:01.79358Z","shell.execute_reply.started":"2022-05-08T12:03:42.621644Z","shell.execute_reply":"2022-05-08T12:18:01.792592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mostramos los resultados en una gráfica.","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(accuracies, columns=['Model', 'Accuracy (%)'])\ndf2 = pd.DataFrame(times, columns=['Model', 'Time (secs)'])\n\nfig = make_subplots(rows=1, cols=2)\n\nfig.append_trace(go.Bar(x=df['Model'], y=df['Accuracy (%)'], name=\"Accuracy (%)\",\n                        textposition=\"none\"), row=1, col=1)\n\nfig.append_trace(go.Bar(x=df2['Model'], y=df2['Time (secs)'], name=\"Time (secs)\",\n                        textposition=\"none\"), row=1, col=2)\n\nfig.update_layout(height=400, width=1200,\n                  title={'x': 0.5, 'y': 0.9, 'font': {'size': 16},\n                         'text': 'Precisión y tiempo de ejecución por modelo',\n                         'xanchor': 'center', 'yanchor': 'top'}\n                 )\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:18:01.794692Z","iopub.execute_input":"2022-05-08T12:18:01.794919Z","iopub.status.idle":"2022-05-08T12:18:01.867462Z","shell.execute_reply.started":"2022-05-08T12:18:01.794892Z","shell.execute_reply":"2022-05-08T12:18:01.866654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como podemos observar todos los modelos presentan una precisión muy elevada con el conjunto de validación, pasando del 90%. Con estos valores podríamos determinar que cualquiera de los modelos creados, tendría un buen funcionamiento como clasificador en este conjunto de datos, aunque si tuvieramos que elegir uno, atendiendo a tiempo de ajuste y entrenamiento que ha tomado cada uno, el **Stacking** sería aquel que con un requerimiento de tiempo de entrenamiento muy pequeño nos proporcionaria grandes resultados.","metadata":{}},{"cell_type":"markdown","source":"Para corroborar este correcto funcionamiento, evaluaremos otros aspectos del modelo, creando una función auxiliar que nos ayude y que mostraá la precisión de clasificación del modelo para cada una de las clases gracias a la matriz de confusión y la curva ROC, para cada uno de los modelos.","metadata":{}},{"cell_type":"code","source":"# Función auxiliar que evalúa los resultados de una clasificación\ndef evaluate_model(y_test, y_pred, n_classes):\n  \"\"\"\n    Evalúa el modelo e imprime por pantalla las estadísitcas\n  \"\"\"\n  print('==== Sumario de la clasificación ==== ')\n  print(classification_report(y_test, y_pred))\n\n  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_test, y_pred)))\n\n  # Ploteamos la matriz de confusión\n  display_labels = sorted(unique_labels(y_test, y_pred), reverse=True)\n  cm = confusion_matrix(y_test, y_pred, labels=display_labels)\n\n  z = cm[::-1]\n  x = display_labels\n  y =  x[::-1].copy()\n  z_text = [[str(y) for y in x] for x in z]\n\n  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n\n  fig_cm.update_layout(\n      height=400, width=400,\n      showlegend=True,\n      margin={'t':150, 'l':0},\n      title={'text' : 'Matriz de Confusión', 'x':0.5, 'xanchor': 'center'},\n      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\n      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\n  )\n  fig_cm.show()\n\n  y_test\n\n  # Ploteamos la curva ROC\n  y_test_enc = label_binarize(y_test, classes=np.arange(n_classes))\n  y_pred_enc = estimator[1].predict_proba(X_test)\n\n  fpr = dict()\n  tpr = dict()\n  roc_auc = dict()\n  for i in range(3):\n      fpr[i], tpr[i], _ = roc_curve(y_test_enc[:, i], y_pred_enc[:, i])\n      roc_auc[i] = auc(fpr[i], tpr[i])\n\n  fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_enc.ravel(), y_pred_enc.ravel())\n  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n  mean_tpr = np.zeros_like(all_fpr)\n  for i in range(n_classes):\n      mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n  mean_tpr /= n_classes\n\n  fpr[\"macro\"] = all_fpr\n  tpr[\"macro\"] = mean_tpr\n  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n  plt.figure()\n  plt.plot(\n      fpr[\"micro\"],\n      tpr[\"micro\"],\n      label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n      color=\"deeppink\",\n      linestyle=\":\",\n      linewidth=4,\n  )\n\n  plt.plot(\n      fpr[\"macro\"],\n      tpr[\"macro\"],\n      label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n      color=\"navy\",\n      linestyle=\":\",\n      linewidth=4,\n  )\n\n  colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n  for i, color in zip(range(n_classes), colors):\n      plt.plot(\n          fpr[i],\n          tpr[i],\n          color=color,\n          lw=lw,\n          label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n      )\n\n  plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n  plt.xlim([0.0, 1.0])\n  plt.ylim([0.0, 1.05])\n  plt.xlabel(\"False Positive Rate\")\n  plt.ylabel(\"True Positive Rate\")\n  plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n  plt.legend(loc=\"lower right\")\n  plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:18:01.868795Z","iopub.execute_input":"2022-05-08T12:18:01.869037Z","iopub.status.idle":"2022-05-08T12:18:01.893787Z","shell.execute_reply.started":"2022-05-08T12:18:01.869008Z","shell.execute_reply":"2022-05-08T12:18:01.892753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ejecutamos la evaluación para cada uno de los modelos","metadata":{}},{"cell_type":"code","source":"lw = 2\nn_classes = len(np.unique(y_test))\n\nfor estimator in estimators:\n    print('****************************************************************')\n    print('Evaluación del modelo ', estimator[0])\n    print('****************************************************************')\n    y_pred = estimator[1].predict(X_test)\n\n    evaluate_model(y_test, y_pred, n_classes)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:18:01.895544Z","iopub.execute_input":"2022-05-08T12:18:01.89582Z","iopub.status.idle":"2022-05-08T12:18:03.473794Z","shell.execute_reply.started":"2022-05-08T12:18:01.89579Z","shell.execute_reply":"2022-05-08T12:18:03.473051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gracias a la matriz de confusión no solo podemos comprobar el número de elementos clasificados erróneamente, si no que podemos apreciar en que categoría han sido identificados cada uno. La curva ROC a su vez nos permite saber la precisión de cada modelo, evaluando el área bajo la curva, a mayor área, mayor será esta precisión.\n\nComo podemos observar por la curva ROC, el método de *Stacking* tiene una clasificación casi perfecta, fallando únicamente 7 elementos del total de 275. De ese total, únicamente seha clasificado incorrectamente un elmento de la clase alta, que se ha clasificado como medio; dos elementos de la clase baja que se han clasificado como medios y cuatro elementos de la clase media.","metadata":{}},{"cell_type":"markdown","source":"## 5. Técnicas de *clustering*","metadata":{}},{"cell_type":"markdown","source":"El *clustering* es una técnica gracias a la cual, podemos organizar un conjunto de datos, en subconjuntos más pequeños denominados *clústers*. Estos clústers tendrán unas características muy similares enre ellos pero diferentes con otros elementos de clusteres distintos.","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Selección del cluster óptimo\n\nPara elegir un clústering óptimo en nuestro conjunto de datos, crearemos distintos modelos y los aplicaremos sobre el conjunto de datos para posteriormente evaluar su desempeño. Los tipos de clustering que probaremos serán: *KMeans*, *Clústering jerárquico*, *BIRHC*, *DBSCAN*, *OPTICS* y un modelo de *mixtura gaussiano*\n\nEn primer lugar creamos una lista con los nombres de los tipos de clustering que crearemos:","metadata":{}},{"cell_type":"code","source":"clusters = ['kmeans', 'agglomerative', 'dbscan', 'optics', 'birch', 'gaussian']","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:18:03.475024Z","iopub.execute_input":"2022-05-08T12:18:03.475294Z","iopub.status.idle":"2022-05-08T12:18:03.479743Z","shell.execute_reply.started":"2022-05-08T12:18:03.475255Z","shell.execute_reply":"2022-05-08T12:18:03.47888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para cada uno de estos tipos de clustering crearemos varios modelos, probando distintas combinaciones de sus posible parámetros. Para ello iteraremos por cada uno de los métodos y crearemos los modelos.","metadata":{}},{"cell_type":"code","source":"results = []\n\nfor cluster in clusters:\n  if cluster == 'kmeans':\n    clust = MiniBatchKMeans(n_clusters=3).fit(X)\n    results.append(clust)\n    \n  if cluster == 'agglomerative':\n    linkage = ['ward', 'complete', 'average', 'single']\n    for item in linkage:\n      clust =  AgglomerativeClustering(n_clusters=3, linkage = item).fit(X)\n      results.append(clust)\n\n  if cluster == 'dbscan':\n    eps = [0.3, 0.5, 0.7]\n    min_samples = [5, 10, 50]\n\n    for item in eps:\n      for item2 in min_samples:\n        clust = DBSCAN(eps = item, min_samples = item2).fit(X)\n        results.append(clust)\n\n  if cluster == 'optics':\n    eps = [0.3, 0.5, 0.7]\n    min_samples = [5, 10, 50]\n\n    for item in eps:\n      for item2 in min_samples:\n        clust = OPTICS(eps = item, min_samples = item2).fit(X)\n        results.append(clust)\n\n  if cluster == 'birch':\n    threshold = [0.25, 0.5, 1]\n    branching_factor = [25, 50, 100]\n\n    for item in threshold:\n      for item2 in branching_factor:\n        clust = Birch(n_clusters=3, threshold = item, branching_factor = item2).fit(X)\n        results.append(clust)\n\n  if cluster == 'gaussian':\n    covariance_type = ['full', 'tied', 'diag', 'spherical']\n    init_params = ['kmeans', 'random']\n\n    for item in covariance_type:\n          for item2 in init_params:\n            clust = GaussianMixture(n_components=3, covariance_type = item, init_params = item2).fit(X)\n            results.append(clust)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:18:03.480901Z","iopub.execute_input":"2022-05-08T12:18:03.481161Z","iopub.status.idle":"2022-05-08T12:18:17.144033Z","shell.execute_reply.started":"2022-05-08T12:18:03.481131Z","shell.execute_reply":"2022-05-08T12:18:17.143032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for res in results:\n\n  if hasattr(res, 'labels_'):\n      y_pred = res.labels_.astype(int)\n  else:\n      y_pred = res.predict(X)\n\n  colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n                                        '#f781bf', '#a65628', '#984ea3',\n                                        '#999999', '#e41a1c', '#dede00']),\n                                int(max(y_pred) + 1))))\n  # add black color for outliers (if any)\n  colors = np.append(colors, [\"#000000\"])\n  plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n\n  plt.xlim(-2.5, 2.5)\n  plt.ylim(-2.5, 2.5)\n  plt.xticks(())\n  plt.yticks(())    \n\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T12:18:17.145498Z","iopub.execute_input":"2022-05-08T12:18:17.146688Z","iopub.status.idle":"2022-05-08T12:18:17.452328Z","shell.execute_reply.started":"2022-05-08T12:18:17.146636Z","shell.execute_reply":"2022-05-08T12:18:17.450969Z"},"trusted":true},"execution_count":null,"outputs":[]}]}