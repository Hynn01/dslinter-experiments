{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"id":"wnxGmBkvq9Rj"}},{"cell_type":"code","source":"# To help with reading and manipulation of data\nimport numpy as np\nimport pandas as pd\n\n# To help with data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# To split the data\nfrom sklearn.model_selection import train_test_split\n\n# To impute missing values\nfrom sklearn.impute import SimpleImputer\n\n# To build a Random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# To tune a model\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# To get different performance metrics\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    recall_score,\n    accuracy_score,\n    precision_score,\n    f1_score,\n)\n\n# To suppress warnings\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"executionInfo":{"elapsed":1914,"status":"ok","timestamp":1634811027211,"user":{"displayName":"Prof. Mukesh Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02134472667302377777"},"user_tz":-330},"id":"UK2k3Mg-q9Rj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/financial-datasets/Loan.csv\")","metadata":{"id":"a7ck33gHq9Rk","outputId":"39ec123e-dc64-4741-ef22-279552efcae7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.copy()","metadata":{"id":"iRePnbBq5cJd","outputId":"c89bf037-07c3-4213-c6ec-8075943ae91e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"id":"Fu9Ni_Kk5cJe","outputId":"a201a7b2-1693-4a7c-e435-a28b090842e2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"id":"XlCskF3Fq9Rl","outputId":"484f2238-9b83-4ea8-ccb4-d9d9ec07db52","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking missing values in the data\ndata.isna().sum()","metadata":{"id":"6XbFryla5cJe","outputId":"2c58762b-d38b-4829-ab29-dfa52d6c445e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata[\"region\"] = data[\"region\"].astype(\"category\")\ndata[\"phone_operator\"] = data[\"phone_operator\"].astype(\"category\")\ndata[\"product_type\"] = data[\"product_type\"].astype(\"category\")","metadata":{"id":"-g1iA3vkhIzq","outputId":"cbee7bf4-d507-401e-a6fa-51b345edefeb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the distribution of the target variable\ndata[\"target\"].value_counts(1)","metadata":{"id":"iIQWS7KuhIzr","outputId":"db1357f0-93bd-4dd0-ebac-acb7e5f3ec20","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the data into X and y","metadata":{"id":"oZFkLVZphIzr"}},{"cell_type":"code","source":"# separating the independent and dependent variables\nX = data.drop([\"target\"], axis=1)\ny = data[\"target\"]\n\n# creating dummy variables\nX = pd.get_dummies(X, drop_first=True)","metadata":{"id":"82OTq1bvhIzs","outputId":"71ed9f43-1b1a-4559-86a9-19b633b1f80e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into training, validation and test set:\n\n# first we split data into 2 parts, say temporary and test\nX_temp, X_test, y_temp, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=5, stratify=y\n)\n\n# then we split the temporary set into train and validation\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp, test_size=0.2, random_state=5, stratify=y_temp\n)\n\nprint(X_train.shape, X_val.shape, X_test.shape)","metadata":{"id":"mJM5CvFOhIzs","outputId":"ce058b90-9625-472b-9843-12f5c6c3f5bd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's impute the missing values\nimp_median = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n\n# fit the imputer on train data and transform the train data\nX_train[\"income\"] = imp_median.fit_transform(X_train[[\"income\"]])\n\n# transform the validation and test data using the imputer fit on train data\nX_val[\"income\"] = imp_median.transform(X_val[[\"income\"]])\nX_test[\"income\"] = imp_median.transform(X_test[[\"income\"]])","metadata":{"id":"Oy7LQSmJ5cJg","outputId":"8da0a126-77d4-4d1f-a1d5-b5c094830256","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking class balance for whole data, train set, validation set, and test set\n\nprint(\"Target value ratio in y\")\nprint(y.value_counts(1))\nprint(\"*\" * 80)\nprint(\"Target value ratio in y_train\")\nprint(y_train.value_counts(1))\nprint(\"*\" * 80)\nprint(\"Target value ratio in y_val\")\nprint(y_val.value_counts(1))\nprint(\"*\" * 80)\nprint(\"Target value ratio in y_test\")\nprint(y_test.value_counts(1))\nprint(\"*\" * 80)","metadata":{"id":"JCOMaaMGhIzs","outputId":"3d712183-c0a4-49bf-cf47-501d6ac2c9e8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model evaluation criterion\n\n\n**What does a bank want?**\n* A bank wants to minimize the loss - it can face 2 types of losses here: \n   * Whenever a bank lends money to a customer, they don't return it.\n   * A bank doesn't lend money to a customer thinking a customer will default but in reality, the customer won't - opportunity loss.\n\n**Which loss is greater ?**\n* Lending to a customer who wouldn't be able to pay back.\n\n**Since we want to reduce loan defaults we should use Recall as a metric of model evaluation instead of accuracy.**\n\n* Recall - It gives the ratio of True positives to Actual positives, so high Recall implies low false negatives, i.e. low chances of predicting a bad customer as a good customer.\n","metadata":{"id":"30jm_OXJat4G"}},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{"id":"j6alhuirsj1r"}},{"cell_type":"markdown","source":"### Let's first build a model with default parameters and see it's performance","metadata":{"id":"4NGTaawdat4H"}},{"cell_type":"code","source":"# model without hyperparameter tuning\nrf = RandomForestClassifier(random_state=1)\nrf.fit(X_train, y_train)","metadata":{"id":"MCOiPgwkat4H","outputId":"544ce052-db54-4fb3-fd49-3f4802363c47","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's check model's performance","metadata":{"id":"423qASgLat4H"}},{"cell_type":"code","source":"# Checking recall score on train and validation set\nprint(\"Recall on train and validation set\")\nprint(recall_score(y_train, rf.predict(X_train)))\nprint(recall_score(y_val, rf.predict(X_val)))\nprint(\"\")\n\n# Checking Precision score on train and validation set\nprint(\"Precision on train and validation set\")\nprint(precision_score(y_train, rf.predict(X_train)))\nprint(precision_score(y_val, rf.predict(X_val)))\n\nprint(\"\")\n\n# Checking Accuracy score on train and validation set\nprint(\"Accuracy on train and validation set\")\nprint(accuracy_score(y_train, rf.predict(X_train)))\nprint(accuracy_score(y_val, rf.predict(X_val)))","metadata":{"id":"Wpmoqh8sat4I","outputId":"c37e18bf-0167-4b9d-b6bd-64a70dd705ba","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model is performing well on the train data but the performance on the validation data is very poor.\n- Let's see if we can improve it with hyperparameter tuning.","metadata":{"id":"pagBRSPPat4J"}},{"cell_type":"markdown","source":"## Grid Search CV\n* Hyperparameter tuning is also tricky in the sense that there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model, so we usually resort to experimentation. i.e we'll use Grid search\n* Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters. \n* It is an exhaustive search that is performed on the specific parameter values of a model.\n* The parameters of the estimator/model used to apply these methods are optimized by cross-validated grid-search over a parameter grid.","metadata":{"id":"EptTvLbuat4J"}},{"cell_type":"markdown","source":"- **How to know the hyperparameters available for an algorithm?**","metadata":{"id":"5dlc9_NIat4J"}},{"cell_type":"code","source":"RandomForestClassifier().get_params()","metadata":{"id":"5WWA0sEJat4K","outputId":"20318780-a105-4723-a810-6b1db11f6a36","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see the names of hyperparameters available and their default values. \n- We can choose which ones to tune.","metadata":{"id":"tcOIKqp4at4K"}},{"cell_type":"code","source":"print(np.arange(0.2, 0.7, 0.1))\n\nprint(np.arange(5,10))","metadata":{"executionInfo":{"elapsed":387,"status":"ok","timestamp":1634811095494,"user":{"displayName":"Prof. Mukesh Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02134472667302377777"},"user_tz":-330},"id":"VnKFyRAwVAPn","outputId":"b84e0df0-1c11-459c-d583-58c4f55a35ad","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's tune Random forest using Grid Search","metadata":{"id":"3m5AtskSat4K"}},{"cell_type":"code","source":"%%time\n\n# Choose the type of classifier. \nrf1 = RandomForestClassifier(random_state=1)\n\n# Grid of parameters to choose from\nparameters = {\"n_estimators\": [150,200,250],\n    \"min_samples_leaf\": np.arange(5, 10),\n    \"max_features\": np.arange(0.2, 0.7, 0.1),\n    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n    \"class_weight\" : ['balanced', 'balanced_subsample'],\n    \"max_depth\":np.arange(3,4,5),\n    \"min_impurity_decrease\":[0.001, 0.002, 0.003]\n             }\n\n# Type of scoring used to compare parameter combinations\nacc_scorer = metrics.make_scorer(metrics.recall_score)\n\n# Run the grid search\ngrid_obj = GridSearchCV(rf1, parameters, scoring=acc_scorer, cv=5, n_jobs= -1, verbose = 2)\n# verbose = 2 tells about the number of fits, which can give an idea of how long will the model take in tuning\n# n_jobs = -1 so that all CPU cores can be run parallelly to optimize the Search\n\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Print the best combination of parameters\ngrid_obj.best_params_\n","metadata":{"id":"ylfOoVr0at4K","outputId":"ee1800b1-618e-4f3a-90fa-3d5c34eb8d24","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's check the best CV score, for the obtained parameters","metadata":{"id":"5LpaXjDIat4K"}},{"cell_type":"code","source":"grid_obj.best_score_","metadata":{"id":"SVO8ak5Fat4L","outputId":"881d0886-4817-4d1a-8fa7-db29e1c41e8d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's build a model with obtained best parameters\n- We are hard coding the hyperparameters separately so that we don't have to run the grid search again.","metadata":{"id":"IUvVCFguat4L"}},{"cell_type":"code","source":"# Set the clf to the best combination of parameters\nrf1_tuned = RandomForestClassifier(\n    class_weight=\"balanced\",\n    max_features=0.2,\n    max_samples=0.6000000000000001,\n    min_samples_leaf=5,\n    n_estimators=150,\n    max_depth=3,\n    random_state=1,\n    min_impurity_decrease=0.001,\n)\n\n# Fit the best algorithm to the data.\nrf1_tuned.fit(X_train, y_train)","metadata":{"id":"379_TUHWat4L","outputId":"6c1b901c-1821-4751-c9ac-b6b87f961bb3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's check the model's performance","metadata":{"id":"lGRlwqfuat4M"}},{"cell_type":"code","source":"# Checking recall score on train and validation set\nprint(\"Recall on train and validation set\")\nprint(recall_score(y_train, rf1_tuned.predict(X_train)))\nprint(recall_score(y_val, rf1_tuned.predict(X_val)))\nprint(\"\")\n\n# Checking precision score on train and validation set\nprint(\"Precision on train and validation set\")\nprint(precision_score(y_train, rf1_tuned.predict(X_train)))\nprint(precision_score(y_val, rf1_tuned.predict(X_val)))\nprint(\"\")\n\n# Checking accuracy score on train and validation set\nprint(\"Accuracy on train and validation set\")\nprint(accuracy_score(y_train, rf1_tuned.predict(X_train)))\nprint(accuracy_score(y_val, rf1_tuned.predict(X_val)))","metadata":{"id":"Uwkw63nFat4M","outputId":"f57a0146-5766-4c57-9421-1be71fdb3a22","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- We can see improvement in validation performance as compared to the model without hyperparameter tuning\n- Recall on both training set and validation set is good and is 88% on the validation","metadata":{"id":"ZBnd4W_Fat4N"}},{"cell_type":"markdown","source":"## Randomized Search CV\n* Random search is a tuning technique that attempts to compute the optimum values of hyperparameters randomly unlike grid search","metadata":{"id":"UnujALXkat4O"}},{"cell_type":"markdown","source":"### Let's tune Random forest using Randomized Search","metadata":{"id":"W11Pi8rlat4O"}},{"cell_type":"code","source":"%%time\n\n# Choose the type of classifier. \nrf2 = RandomForestClassifier(random_state=1)\n\n# Grid of parameters to choose from\nparameters = {\"n_estimators\": [150,200,250],\n    \"min_samples_leaf\": np.arange(5, 10),\n    \"max_features\": np.arange(0.2, 0.7, 0.1), \n    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n    \"max_depth\":np.arange(3,4,5),\n    \"class_weight\" : ['balanced', 'balanced_subsample'],\n    \"min_impurity_decrease\":[0.001, 0.002, 0.003]\n             }\n\n# Type of scoring used to compare parameter combinations\nacc_scorer = metrics.make_scorer(metrics.recall_score)\n\n# Run the random search\ngrid_obj = RandomizedSearchCV(rf2, parameters,n_iter=30, scoring=acc_scorer,cv=5, random_state = 1, n_jobs = -1, verbose = 2)\n# using n_iter = 30, so randomized search will try 30 different combinations of hyperparameters\n# by default, n_iter = 10\n\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Print the best combination of parameters\ngrid_obj.best_params_\n","metadata":{"id":"-4Lkjcefat4P","outputId":"e146b028-0de1-46a5-ef44-fe418539dad3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's check the best CV score, for the obtained parameters","metadata":{"id":"BC3IB5JAat4P"}},{"cell_type":"code","source":"grid_obj.best_score_","metadata":{"id":"9HZAnjxfat4P","outputId":"99fe8701-ae44-4905-c2f6-0c503aee1884","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's build a model with obtained best parameters","metadata":{"id":"eCFHwl5xat4P"}},{"cell_type":"code","source":"# Set the clf to the best combination of parameters\nrf2_tuned = RandomForestClassifier(\n    class_weight=\"balanced\",\n    max_features=0.2,\n    max_samples=0.5,\n    min_samples_leaf=5,\n    n_estimators=150,\n    random_state=1,\n    max_depth=3,\n    min_impurity_decrease=0.003,\n)\n\n# Fit the best algorithm to the data.\nrf2_tuned.fit(X_train, y_train)","metadata":{"id":"V8TWo6tTat4Q","outputId":"d33dcf4c-0d32-4b82-ec89-9a4263d312a6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Different results from the grid and the random search\n- Randomised search might give better results than grid search for the same parameter grid because of the use of cross-validation as fold varies the scores also vary","metadata":{"id":"rZZ8N0M4at4Q"}},{"cell_type":"markdown","source":"#### Let's check the model's performance","metadata":{"id":"dSEY5KJ-at4Q"}},{"cell_type":"code","source":"# Checking recall score on train and validation set\nprint(\"Recall on train and validation set\")\nprint(recall_score(y_train, rf2_tuned.predict(X_train)))\nprint(recall_score(y_val, rf2_tuned.predict(X_val)))\nprint(\"\")\nprint(\"Precision on train and validation set\")\n# Checking precision score on train and validation set\nprint(precision_score(y_train, rf2_tuned.predict(X_train)))\nprint(precision_score(y_val, rf2_tuned.predict(X_val)))\nprint(\"\")\nprint(\"Accuracy on train and validation set\")\n# Checking accuracy score on train and validation set\nprint(accuracy_score(y_train, rf2_tuned.predict(X_train)))\nprint(accuracy_score(y_val, rf2_tuned.predict(X_val)))","metadata":{"id":"hgGjmHayat4Q","outputId":"2c276e16-5b6f-4e04-c3d8-16878a0f1670","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The model is performing better than model with default parameters and the performance is similar to the model we received with grid search","metadata":{"id":"ebNJl1ZKat4R"}},{"cell_type":"markdown","source":"#### Choose a best model and predict the performance on the test set","metadata":{"id":"sVeUUOVjat4R"}},{"cell_type":"code","source":"model = rf1_tuned","metadata":{"id":"XmBsx6I3at4R","outputId":"21dff7fe-483f-4663-cdcc-7a3d0b86dd9f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking recall score on test set\nprint(\"Recall on test set\")\nprint(recall_score(y_test, model.predict(X_test)))\nprint(\"\")\n\n# Checking precision score on test set\nprint(\"Precision on test set\")\nprint(precision_score(y_test, model.predict(X_test)))\nprint(\"\")\n\n# Checking accuracy score on test set\nprint(\"Accuracy on test set\")\nprint(accuracy_score(y_test, model.predict(X_test)))","metadata":{"id":"wazimV7oat4R","outputId":"5c5606f7-476a-4844-ca55-9079a98b92ab","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The performance is close to one we observed in the validation set, so there is no overfitting","metadata":{"id":"UO2wLc07at4R"}}]}