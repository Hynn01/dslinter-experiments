{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Global parameters\n","metadata":{}},{"cell_type":"code","source":"years = [2016,2017,2018]\nzone = 'NW'\n\n# How many stations we take to predict temperature in the area between them\naround = 10 \n\n# The initial station from which we start\nSTATION = 14066001\n\nmindist = 10","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:43:02.033895Z","iopub.execute_input":"2022-05-07T16:43:02.034298Z","iopub.status.idle":"2022-05-07T16:43:02.064312Z","shell.execute_reply.started":"2022-05-07T16:43:02.034197Z","shell.execute_reply":"2022-05-07T16:43:02.063328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk(\n    '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T16:43:02.066853Z","iopub.execute_input":"2022-05-07T16:43:02.067205Z","iopub.status.idle":"2022-05-07T16:43:02.09177Z","shell.execute_reply.started":"2022-05-07T16:43:02.067158Z","shell.execute_reply":"2022-05-07T16:43:02.091047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting and pre-processing data from kaggle datasets\n## Step one","metadata":{}},{"cell_type":"code","source":"fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(2016)+'.csv'\ndf = pd.read_csv(fname)\n\n# this dataframe we need to get closest stations from STATION\nnew_df = df.drop(['height_sta','date','dd','ff','precip','hu','td','t','psl'],axis=1)\\\n    .drop_duplicates('number_sta').reset_index()\n    \nlat = new_df.loc[0].lat\nlon = new_df.loc[0].lon\n    \n    \n# Arrays of closest stations\nneighbours= np.zeros(around)\nneighbours[0] = STATION\n    \nfor station in range(1,around):\n    for i in range(0,new_df.shape[0]):\n        if new_df.loc[i]['number_sta'] not in neighbours:\n            currdist = np.abs(lat - new_df.loc[i].lat) + np.abs(lon-new_df.loc[i].lon)\n            if(mindist > currdist):\n                mindist = currdist\n                index = i\n    neighbours[station]=new_df.loc[index]['number_sta']\n    mindist=10\n    \ndel new_df\n\ndel df","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:43:02.09309Z","iopub.execute_input":"2022-05-07T16:43:02.093457Z","iopub.status.idle":"2022-05-07T16:43:50.449217Z","shell.execute_reply.started":"2022-05-07T16:43:02.093416Z","shell.execute_reply":"2022-05-07T16:43:50.444827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather = pd.DataFrame()\nfor year in years:\n    fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(year)+'.csv'\n    df = pd.read_csv(fname)\n    \n    # Getting source data from stations in neighbours\n    for i in range(0,around):\n        dataframe = df[(df['number_sta'] == int(neighbours[i]))]\n        weather = weather.append(dataframe,ignore_index = True)\n    \n    del df\n    \n    del dataframe","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:43:50.452133Z","iopub.execute_input":"2022-05-07T16:43:50.45253Z","iopub.status.idle":"2022-05-07T16:45:58.05836Z","shell.execute_reply.started":"2022-05-07T16:43:50.452491Z","shell.execute_reply":"2022-05-07T16:45:58.057008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:45:58.062107Z","iopub.execute_input":"2022-05-07T16:45:58.062414Z","iopub.status.idle":"2022-05-07T16:45:58.102303Z","shell.execute_reply.started":"2022-05-07T16:45:58.062373Z","shell.execute_reply":"2022-05-07T16:45:58.101406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filling na by bfill groupped data by number_sta","metadata":{}},{"cell_type":"code","source":"weather.date = pd.to_datetime(weather.date)\nweather = weather.sort_values('number_sta').reset_index().drop('index',axis=1)\nweather = weather.fillna(method = 'bfill')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:45:58.103735Z","iopub.execute_input":"2022-05-07T16:45:58.10405Z","iopub.status.idle":"2022-05-07T16:45:59.450202Z","shell.execute_reply.started":"2022-05-07T16:45:58.103999Z","shell.execute_reply":"2022-05-07T16:45:59.449298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather = weather.sort_values('date').reset_index().drop('index',axis=1)\nprint(weather.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:45:59.4516Z","iopub.execute_input":"2022-05-07T16:45:59.45194Z","iopub.status.idle":"2022-05-07T16:45:59.939555Z","shell.execute_reply.started":"2022-05-07T16:45:59.451896Z","shell.execute_reply":"2022-05-07T16:45:59.938484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:45:59.941138Z","iopub.execute_input":"2022-05-07T16:45:59.941394Z","iopub.status.idle":"2022-05-07T16:45:59.94953Z","shell.execute_reply.started":"2022-05-07T16:45:59.941365Z","shell.execute_reply":"2022-05-07T16:45:59.948853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## taking part from dataset","metadata":{}},{"cell_type":"code","source":"dataset = weather[weather['date']<'2019-01-01']\nprint(dataset.shape)\nprint(dataset.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:45:59.95065Z","iopub.execute_input":"2022-05-07T16:45:59.951285Z","iopub.status.idle":"2022-05-07T16:46:00.105939Z","shell.execute_reply.started":"2022-05-07T16:45:59.951232Z","shell.execute_reply":"2022-05-07T16:46:00.105052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Перенос координат в координаты нужной нам станции","metadata":{}},{"cell_type":"code","source":"lat = dataset[dataset['number_sta']==STATION]['lat'].unique()[0]\nlon = dataset[dataset['number_sta']==STATION]['lon'].unique()[0]\n\ndataset['lat'] = dataset['lat']-lat\ndataset['lon'] = dataset['lon']-lon","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:00.107453Z","iopub.execute_input":"2022-05-07T16:46:00.107704Z","iopub.status.idle":"2022-05-07T16:46:00.226561Z","shell.execute_reply.started":"2022-05-07T16:46:00.107671Z","shell.execute_reply":"2022-05-07T16:46:00.225772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:00.22823Z","iopub.execute_input":"2022-05-07T16:46:00.228759Z","iopub.status.idle":"2022-05-07T16:46:00.253962Z","shell.execute_reply.started":"2022-05-07T16:46:00.228712Z","shell.execute_reply":"2022-05-07T16:46:00.253093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split date to year, yday, hour, minute","metadata":{}},{"cell_type":"code","source":"dataset['year'] = dataset.date.dt.year\ndataset['yday'] = dataset.date.dt.dayofyear\n\ndataset['hour'] = dataset.date.dt.hour\ndataset['minute'] = dataset.date.dt.minute","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:00.255465Z","iopub.execute_input":"2022-05-07T16:46:00.256292Z","iopub.status.idle":"2022-05-07T16:46:01.235893Z","shell.execute_reply.started":"2022-05-07T16:46:00.25624Z","shell.execute_reply":"2022-05-07T16:46:01.235053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:01.237012Z","iopub.execute_input":"2022-05-07T16:46:01.237256Z","iopub.status.idle":"2022-05-07T16:46:01.261181Z","shell.execute_reply.started":"2022-05-07T16:46:01.237228Z","shell.execute_reply":"2022-05-07T16:46:01.26011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filling nan by bfill groupped data by date","metadata":{}},{"cell_type":"code","source":"dataset = dataset.set_index('date')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:01.264178Z","iopub.execute_input":"2022-05-07T16:46:01.26454Z","iopub.status.idle":"2022-05-07T16:46:01.384283Z","shell.execute_reply.started":"2022-05-07T16:46:01.264503Z","shell.execute_reply":"2022-05-07T16:46:01.383362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Можно заполнить значения станции через среднее значений следущего и предыдущего временного этапа этой же станции.. А если и они nan, то по количеству и качеству каждой станции в округе( чем дальше она тем несущественнее ее результат сказывается)","metadata":{}},{"cell_type":"code","source":"# def fill_na_by_mean(dataset,param):\n#     #print(dataset['number_sta'].unique())\n#     stations = dataset['number_sta'].unique()\n#     for station in stations:\n#         for index in range(len(dataset[dataset['number_sta']==station])-5):\n#             if np.isnan(dataset[dataset['number_sta']==station].iloc[index][param]):\n#                 i=1\n#                 numb=0\n#                 while np.isnan(dataset[dataset['number_sta']==station].iloc[index-i][param]) and numb<5:\n#                     i=+1\n#                     numb+=1\n#                 if numb<5:\n#                     first = dataset[dataset['number_sta']==station].iloc[index-i][param]\n#                 else:\n#                     break\n                \n#                 i=1\n#                 numb=0\n#                 while np.isnan(dataset[dataset['number_sta']==station].iloc[index+i][param]) and numb<5:\n#                     i=+1\n#                     numb+=1\n#                 if numb<5:\n#                     second = dataset[dataset['number_sta']==station].iloc[index-i][param]\n#                 else:\n#                     break\n        \n#                 dataset[dataset['number_sta']==station].loc[index][param] = (first+second)/2\n#     return dataset  \n\n# fill_na_by_mean(dataset,'t')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:01.385451Z","iopub.execute_input":"2022-05-07T16:46:01.385693Z","iopub.status.idle":"2022-05-07T16:46:01.392024Z","shell.execute_reply.started":"2022-05-07T16:46:01.385663Z","shell.execute_reply":"2022-05-07T16:46:01.391125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.fillna(method = 'bfill')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:01.393476Z","iopub.execute_input":"2022-05-07T16:46:01.394313Z","iopub.status.idle":"2022-05-07T16:46:01.597938Z","shell.execute_reply.started":"2022-05-07T16:46:01.394265Z","shell.execute_reply":"2022-05-07T16:46:01.597155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:12.525853Z","iopub.execute_input":"2022-05-07T16:46:12.526632Z","iopub.status.idle":"2022-05-07T16:46:12.614137Z","shell.execute_reply.started":"2022-05-07T16:46:12.526589Z","shell.execute_reply":"2022-05-07T16:46:12.61309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-07T16:46:20.69297Z","iopub.execute_input":"2022-05-07T16:46:20.693382Z","iopub.status.idle":"2022-05-07T16:46:20.699969Z","shell.execute_reply.started":"2022-05-07T16:46:20.693341Z","shell.execute_reply":"2022-05-07T16:46:20.699098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalizating data...","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:28.715007Z","iopub.execute_input":"2022-05-04T15:58:28.715338Z","iopub.status.idle":"2022-05-04T15:58:29.890632Z","shell.execute_reply.started":"2022-05-04T15:58:28.715304Z","shell.execute_reply":"2022-05-04T15:58:29.889873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['dd'] = scaler.fit_transform(dataset['dd'].values.reshape(-1,1))\ndataset['ff'] = scaler.fit_transform(dataset['ff'].values.reshape(-1,1))\ndataset['precip'] = scaler.fit_transform(dataset['precip'].values.reshape(-1,1))\ndataset['hu'] = scaler.fit_transform(dataset['hu'].values.reshape(-1,1))\ndataset['td'] = scaler.fit_transform(dataset['td'].values.reshape(-1,1))\ndataset['psl'] = scaler.fit_transform(dataset['psl'].values.reshape(-1,1))\ndataset['t'] = scaler.fit_transform(dataset['t'].values.reshape(-1,1))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:29.891694Z","iopub.execute_input":"2022-05-04T15:58:29.891925Z","iopub.status.idle":"2022-05-04T15:58:30.064762Z","shell.execute_reply.started":"2022-05-04T15:58:29.891892Z","shell.execute_reply":"2022-05-04T15:58:30.064245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:30.065885Z","iopub.execute_input":"2022-05-04T15:58:30.066122Z","iopub.status.idle":"2022-05-04T15:58:30.087646Z","shell.execute_reply.started":"2022-05-04T15:58:30.066076Z","shell.execute_reply":"2022-05-04T15:58:30.086606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:30.088798Z","iopub.execute_input":"2022-05-04T15:58:30.08986Z","iopub.status.idle":"2022-05-04T15:58:30.095326Z","shell.execute_reply.started":"2022-05-04T15:58:30.089789Z","shell.execute_reply":"2022-05-04T15:58:30.094713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:30.141037Z","iopub.execute_input":"2022-05-04T15:58:30.141278Z","iopub.status.idle":"2022-05-04T15:58:30.366964Z","shell.execute_reply.started":"2022-05-04T15:58:30.14125Z","shell.execute_reply":"2022-05-04T15:58:30.365965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.reset_index().drop(['date','year','minute','number_sta'],axis=1).corr()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:30.368108Z","iopub.execute_input":"2022-05-04T15:58:30.368666Z","iopub.status.idle":"2022-05-04T15:58:31.327217Z","shell.execute_reply.started":"2022-05-04T15:58:30.36864Z","shell.execute_reply":"2022-05-04T15:58:31.326282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data = dataset.reset_index().drop(['date','year','minute','number_sta'],axis = 1).corr())","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:31.328627Z","iopub.execute_input":"2022-05-04T15:58:31.32896Z","iopub.status.idle":"2022-05-04T15:58:32.582238Z","shell.execute_reply.started":"2022-05-04T15:58:31.328931Z","shell.execute_reply":"2022-05-04T15:58:32.58077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Подготавливаем датасет к обучению\n\n## Количество X может быть не равно y; Надо проверять есть ли за этот период запись в 'y' и только тогда добавлять X, чтобы их количество было равное","metadata":{}},{"cell_type":"code","source":"def make_tensors(table,predicted_par):\n    \n    data = []\n    target = []\n\n    periods = table.index.unique().astype('str')\n    \n    label = table[table.number_sta==STATION][predicted_par]\n    target = label.values.tolist()\n    \n    #new_table = table.loc[table['number_sta'] != STATION].drop(['td','lat','lon','height_sta','precip','dd','ff','hu','psl','yday','year','hour','minute','number_sta'],axis=1)\n    new_table = table.loc[table['number_sta'] != STATION].drop(['lat','lon','height_sta','year','yday','hour','minute','number_sta'],axis=1)\n    \n    for period in periods:\n        if period in label:\n            data.append(new_table[period:period].values.tolist())\n\n    return data,target","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:32.583772Z","iopub.execute_input":"2022-05-04T15:58:32.583995Z","iopub.status.idle":"2022-05-04T15:58:32.59317Z","shell.execute_reply.started":"2022-05-04T15:58:32.583968Z","shell.execute_reply":"2022-05-04T15:58:32.591803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X,y = make_tensors(dataset,'t')","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:58:32.5944Z","iopub.execute_input":"2022-05-04T15:58:32.594601Z","iopub.status.idle":"2022-05-04T16:04:41.977214Z","shell.execute_reply.started":"2022-05-04T15:58:32.594575Z","shell.execute_reply":"2022-05-04T16:04:41.97641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:04:41.978681Z","iopub.execute_input":"2022-05-04T16:04:41.979007Z","iopub.status.idle":"2022-05-04T16:04:41.985202Z","shell.execute_reply.started":"2022-05-04T16:04:41.978979Z","shell.execute_reply":"2022-05-04T16:04:41.984171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:04:41.986586Z","iopub.execute_input":"2022-05-04T16:04:41.986882Z","iopub.status.idle":"2022-05-04T16:04:42.001786Z","shell.execute_reply.started":"2022-05-04T16:04:41.986843Z","shell.execute_reply":"2022-05-04T16:04:42.001142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:04:42.003186Z","iopub.execute_input":"2022-05-04T16:04:42.003389Z","iopub.status.idle":"2022-05-04T16:04:42.017813Z","shell.execute_reply.started":"2022-05-04T16:04:42.003362Z","shell.execute_reply":"2022-05-04T16:04:42.016488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Делаем Х_ полным для 9 станций по 5 зависимым столбцам каждый\n## а остальные не берем в датасет","metadata":{}},{"cell_type":"code","source":"columns = len(X[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:04:42.019319Z","iopub.execute_input":"2022-05-04T16:04:42.020584Z","iopub.status.idle":"2022-05-04T16:04:42.031809Z","shell.execute_reply.started":"2022-05-04T16:04:42.020525Z","shell.execute_reply":"2022-05-04T16:04:42.031003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_ = np.empty((0,(around-1)*columns),dtype='f')\nindex = []\nfor i in range(len(X)):\n    if len([a for b in X[i] for a in b]) == (around-1)*columns and i!=len(X)-1:\n        X_= np.append(X_,[[a for b in X[i] for a in b]],axis=0)\n    else:\n        index.append(i)\n\nindex.pop(len(index)-1)\n\ny=np.delete(y,index,None)\ny = np.delete(y,len(y)-1,None)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:04:42.034952Z","iopub.execute_input":"2022-05-04T16:04:42.03579Z","iopub.status.idle":"2022-05-04T16:34:57.858182Z","shell.execute_reply.started":"2022-05-04T16:04:42.035736Z","shell.execute_reply":"2022-05-04T16:34:57.856656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:34:57.860643Z","iopub.execute_input":"2022-05-04T16:34:57.861042Z","iopub.status.idle":"2022-05-04T16:34:57.870448Z","shell.execute_reply.started":"2022-05-04T16:34:57.860993Z","shell.execute_reply":"2022-05-04T16:34:57.869155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:34:57.874092Z","iopub.execute_input":"2022-05-04T16:34:57.874328Z","iopub.status.idle":"2022-05-04T16:34:57.890339Z","shell.execute_reply.started":"2022-05-04T16:34:57.8743Z","shell.execute_reply":"2022-05-04T16:34:57.889268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_ = [[] for k in range(len(y))]\nfor i in range(len(y)):\n    y_[i] = [y[i]]\nprint(len(y_))\ny = y_","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:34:57.891549Z","iopub.execute_input":"2022-05-04T16:34:57.892263Z","iopub.status.idle":"2022-05-04T16:34:59.53371Z","shell.execute_reply.started":"2022-05-04T16:34:57.892209Z","shell.execute_reply":"2022-05-04T16:34:59.532963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del dataset","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:34:59.534877Z","iopub.execute_input":"2022-05-04T16:34:59.535213Z","iopub.status.idle":"2022-05-04T16:34:59.53797Z","shell.execute_reply.started":"2022-05-04T16:34:59.53518Z","shell.execute_reply":"2022-05-04T16:34:59.537373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:34:59.539526Z","iopub.execute_input":"2022-05-04T16:34:59.539852Z","iopub.status.idle":"2022-05-04T16:35:00.118123Z","shell.execute_reply.started":"2022-05-04T16:34:59.539808Z","shell.execute_reply":"2022-05-04T16:35:00.116524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Разделение датасета на тестовую и тренировочную части","metadata":{}},{"cell_type":"code","source":"X_train = X_[0:int(len(X_)*0.9)]\nX_test = X_[int(len(X_)*0.9):]\n\ny_train = y[0:int(len(y)*0.9)]\ny_test = y[int(len(y)*0.9):]","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:00.119832Z","iopub.execute_input":"2022-05-04T16:35:00.120061Z","iopub.status.idle":"2022-05-04T16:35:00.137114Z","shell.execute_reply.started":"2022-05-04T16:35:00.120033Z","shell.execute_reply":"2022-05-04T16:35:00.135467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.2, random_state=39)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:00.152241Z","iopub.execute_input":"2022-05-04T16:35:00.152475Z","iopub.status.idle":"2022-05-04T16:35:00.168266Z","shell.execute_reply.started":"2022-05-04T16:35:00.152445Z","shell.execute_reply":"2022-05-04T16:35:00.167241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:00.1709Z","iopub.execute_input":"2022-05-04T16:35:00.171376Z","iopub.status.idle":"2022-05-04T16:35:00.182973Z","shell.execute_reply.started":"2022-05-04T16:35:00.171344Z","shell.execute_reply":"2022-05-04T16:35:00.182283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:00.184194Z","iopub.execute_input":"2022-05-04T16:35:00.18449Z","iopub.status.idle":"2022-05-04T16:35:00.202688Z","shell.execute_reply.started":"2022-05-04T16:35:00.184453Z","shell.execute_reply":"2022-05-04T16:35:00.202053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:00.2037Z","iopub.execute_input":"2022-05-04T16:35:00.203969Z","iopub.status.idle":"2022-05-04T16:35:00.218657Z","shell.execute_reply.started":"2022-05-04T16:35:00.20393Z","shell.execute_reply":"2022-05-04T16:35:00.217629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:00.219629Z","iopub.execute_input":"2022-05-04T16:35:00.21981Z","iopub.status.idle":"2022-05-04T16:35:00.235548Z","shell.execute_reply.started":"2022-05-04T16:35:00.219786Z","shell.execute_reply":"2022-05-04T16:35:00.233969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:00.237815Z","iopub.execute_input":"2022-05-04T16:35:00.23811Z","iopub.status.idle":"2022-05-04T16:35:01.938779Z","shell.execute_reply.started":"2022-05-04T16:35:00.238058Z","shell.execute_reply":"2022-05-04T16:35:01.937532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = torch.from_numpy(X_train).type(torch.Tensor)\nX_test = torch.from_numpy(X_test).type(torch.Tensor)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:01.940261Z","iopub.execute_input":"2022-05-04T16:35:01.940551Z","iopub.status.idle":"2022-05-04T16:35:01.983405Z","shell.execute_reply.started":"2022-05-04T16:35:01.940515Z","shell.execute_reply":"2022-05-04T16:35:01.982478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = torch.from_numpy(np.array(y_train)).type(torch.Tensor)\ny_test = torch.from_numpy(np.array(y_test)).type(torch.Tensor)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:01.984425Z","iopub.execute_input":"2022-05-04T16:35:01.984587Z","iopub.status.idle":"2022-05-04T16:35:02.140832Z","shell.execute_reply.started":"2022-05-04T16:35:01.984564Z","shell.execute_reply":"2022-05-04T16:35:02.139255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Само обучение**","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 40) \n        self.hidden_fc = nn.Linear(40, 20) \n        self.output_fc = nn.Linear(20, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc(h_1)) \n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_2) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:02.142185Z","iopub.execute_input":"2022-05-04T16:35:02.14245Z","iopub.status.idle":"2022-05-04T16:35:02.160527Z","shell.execute_reply.started":"2022-05-04T16:35:02.142412Z","shell.execute_reply":"2022-05-04T16:35:02.159276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:02.162203Z","iopub.execute_input":"2022-05-04T16:35:02.162833Z","iopub.status.idle":"2022-05-04T16:35:02.203483Z","shell.execute_reply.started":"2022-05-04T16:35:02.162799Z","shell.execute_reply":"2022-05-04T16:35:02.202322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:02.20493Z","iopub.execute_input":"2022-05-04T16:35:02.205458Z","iopub.status.idle":"2022-05-04T16:35:02.210345Z","shell.execute_reply.started":"2022-05-04T16:35:02.205394Z","shell.execute_reply":"2022-05-04T16:35:02.20876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:02.212031Z","iopub.execute_input":"2022-05-04T16:35:02.21237Z","iopub.status.idle":"2022-05-04T16:35:18.746397Z","shell.execute_reply.started":"2022-05-04T16:35:02.21233Z","shell.execute_reply":"2022-05-04T16:35:18.745251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:18.747809Z","iopub.execute_input":"2022-05-04T16:35:18.748765Z","iopub.status.idle":"2022-05-04T16:35:18.761116Z","shell.execute_reply.started":"2022-05-04T16:35:18.748709Z","shell.execute_reply":"2022-05-04T16:35:18.75979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig.subplots_adjust(hspace=0.2, wspace=0.2)\n\nax = sns.lineplot(data=hist, color='royalblue')\nax.set_xlabel(\"Epoch\", size = 14)\nax.set_ylabel(\"Loss\", size = 14)\nax.set_title(\"Training Loss\", size = 14, fontweight='bold')\nfig.set_figheight(6)\nfig.set_figwidth(16)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:18.762782Z","iopub.execute_input":"2022-05-04T16:35:18.762998Z","iopub.status.idle":"2022-05-04T16:35:18.991636Z","shell.execute_reply.started":"2022-05-04T16:35:18.762971Z","shell.execute_reply":"2022-05-04T16:35:18.991006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = model(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:18.9926Z","iopub.execute_input":"2022-05-04T16:35:18.993819Z","iopub.status.idle":"2022-05-04T16:35:19.006506Z","shell.execute_reply.started":"2022-05-04T16:35:18.993782Z","shell.execute_reply":"2022-05-04T16:35:19.005643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:19.007488Z","iopub.execute_input":"2022-05-04T16:35:19.008604Z","iopub.status.idle":"2022-05-04T16:35:19.016642Z","shell.execute_reply.started":"2022-05-04T16:35:19.008538Z","shell.execute_reply":"2022-05-04T16:35:19.015593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predict = pd.DataFrame(y_test_predict)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:19.017927Z","iopub.execute_input":"2022-05-04T16:35:19.018765Z","iopub.status.idle":"2022-05-04T16:35:19.035863Z","shell.execute_reply.started":"2022-05-04T16:35:19.018698Z","shell.execute_reply":"2022-05-04T16:35:19.034663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_target = pd.DataFrame(y_test_target)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:19.037549Z","iopub.execute_input":"2022-05-04T16:35:19.03784Z","iopub.status.idle":"2022-05-04T16:35:19.051836Z","shell.execute_reply.started":"2022-05-04T16:35:19.037808Z","shell.execute_reply":"2022-05-04T16:35:19.051257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predict.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:19.053289Z","iopub.execute_input":"2022-05-04T16:35:19.053707Z","iopub.status.idle":"2022-05-04T16:35:19.071841Z","shell.execute_reply.started":"2022-05-04T16:35:19.053668Z","shell.execute_reply":"2022-05-04T16:35:19.071246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:19.072999Z","iopub.execute_input":"2022-05-04T16:35:19.073385Z","iopub.status.idle":"2022-05-04T16:35:20.8278Z","shell.execute_reply.started":"2022-05-04T16:35:19.073351Z","shell.execute_reply":"2022-05-04T16:35:20.826499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:20.832251Z","iopub.execute_input":"2022-05-04T16:35:20.832526Z","iopub.status.idle":"2022-05-04T16:35:23.425964Z","shell.execute_reply.started":"2022-05-04T16:35:20.832497Z","shell.execute_reply":"2022-05-04T16:35:23.425203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"y_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:23.42741Z","iopub.execute_input":"2022-05-04T16:35:23.428326Z","iopub.status.idle":"2022-05-04T16:35:23.435944Z","shell.execute_reply.started":"2022-05-04T16:35:23.428268Z","shell.execute_reply":"2022-05-04T16:35:23.435443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:23.437Z","iopub.execute_input":"2022-05-04T16:35:23.437208Z","iopub.status.idle":"2022-05-04T16:35:23.501104Z","shell.execute_reply.started":"2022-05-04T16:35:23.437182Z","shell.execute_reply":"2022-05-04T16:35:23.500514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T16:35:23.502294Z","iopub.execute_input":"2022-05-04T16:35:23.502575Z","iopub.status.idle":"2022-05-04T16:35:23.519902Z","shell.execute_reply.started":"2022-05-04T16:35:23.502549Z","shell.execute_reply":"2022-05-04T16:35:23.51946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Вторая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 45) \n        self.hidden_fc = nn.Linear(45, 15) \n        self.output_fc = nn.Linear(15, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc(h_1)) \n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_2) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Третья модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 45) \n        self.hidden_fc1 = nn.Linear(45, 30) \n        self.hidden_fc2 = nn.Linear(30, 15) \n        self.output_fc = nn.Linear(15, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_3) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Четвертая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 50) \n        self.hidden_fc1 = nn.Linear(50, 30) \n        self.hidden_fc2 = nn.Linear(30, 20)\n        self.hidden_fc3 = nn.Linear(20, 10)\n        self.output_fc = nn.Linear(10, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        h_4 = torch.tanh(self.hidden_fc3(h_3))\n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_4) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Пятая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 48) \n        self.hidden_fc1 = nn.Linear(48, 37) \n        self.hidden_fc2 = nn.Linear(37, 26)\n        self.hidden_fc3 = nn.Linear(26, 19)\n        \n        self.hidden_fc4 = nn.Linear(19, 8)\n        self.output_fc = nn.Linear(8, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        h_4 = torch.tanh(self.hidden_fc3(h_3))\n        \n        h_5 = torch.tanh(self.hidden_fc4(h_4))\n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_5) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Шестая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 40) \n        self.hidden_fc1 = nn.Linear(40, 30) \n        self.hidden_fc2 = nn.Linear(30, 15)\n        self.output_fc = nn.Linear(15, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_3) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Седьмая модель\n","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 50) \n        self.hidden_fc1 = nn.Linear(50, 40) \n        self.hidden_fc2 = nn.Linear(40, 30)\n        \n        self.hidden_fc3 = nn.Linear(30, 20)\n        \n        self.hidden_fc4 = nn.Linear(20, 10)\n        self.output_fc = nn.Linear(10, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        h_4 = torch.tanh(self.hidden_fc3(h_3)) \n    \n        h_5 = torch.tanh(self.hidden_fc4(h_4)) \n        \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_5) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Восьмая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 35) \n        self.hidden_fc1 = nn.Linear(35, 15) \n\n        self.output_fc = nn.Linear(15, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_2) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}