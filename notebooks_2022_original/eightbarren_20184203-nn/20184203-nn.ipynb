{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T11:52:39.438828Z","iopub.execute_input":"2022-05-06T11:52:39.43919Z","iopub.status.idle":"2022-05-06T11:52:39.451624Z","shell.execute_reply.started":"2022-05-06T11:52:39.439151Z","shell.execute_reply":"2022-05-06T11:52:39.450478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 取数据\nimport torch.utils.data as Data\n\n\ndef dataloader(batch_size, shuffle=True):\n    # from sklearn.datasets import load_digits\n    # digits = load_digits()\n    # X = digits.data\n    # y = digits.target\n    # Y = []\n    # for i in y:\n    #     Y.append([i])\n\n    train_data = pd.read_csv('/kaggle/input/ml2021-2022-2-nn/train.csv').values\n    test_data = pd.read_csv('/kaggle/input/ml2021-2022-2-nn/test.csv').values\n    train_X = train_data[:, 1:]\n    train_y = train_data[:, 0]\n    test_X = test_data\n    test_y = test_data[:, 0]\n    len_train_data = len(train_X)\n    len_test_data = len(test_X)\n    train_dataset = []\n    test_dataset = []\n    for i in range(len(train_X)):\n        train_dataset.append((train_X[i], train_y[i]))\n    for i in range(len(test_X)):\n        test_dataset.append((test_X[i], test_y[i]))\n    train_iter = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle)\n    test_iter = Data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n    return train_iter, test_iter, len_train_data, len_test_data","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:52:39.459235Z","iopub.execute_input":"2022-05-06T11:52:39.459537Z","iopub.status.idle":"2022-05-06T11:52:39.469908Z","shell.execute_reply.started":"2022-05-06T11:52:39.459506Z","shell.execute_reply":"2022-05-06T11:52:39.468919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义一个线性类\nclass LinearLayer:\n    def __init__(self, n_in, n_out, batch_size, activation=None, lr=0.001):\n        self.W = np.random.normal(scale=0.01, size=(n_in, n_out))\n        self.b = np.zeros((batch_size, n_out))\n        self.activation = activation\n        self.lr = lr\n        self.batch_size = batch_size\n        self.parameter = {'name':'Linear', 'size':[n_in, n_out], 'activation':activation}\n\n    def forward(self, x):\n        self.x = x\n        output = np.dot(x, self.W) + self.b\n        if self.activation is 'relu':\n            output = np.maximum(0, output)\n        if self.activation is 'sigmoid':\n            output = 1 / (1 + np.exp(-output))\n        if self.activation is 'tanh':\n            output = np.tanh(output)\n        self.activated_output = output\n        return output\n\n    def backward(self, dout):\n        if self.activation is 'relu':\n            self.activated_output[self.activated_output <= 0] = 0\n            self.activated_output[self.activated_output > 0] = 1\n            dout = dout * self.activated_output\n        if self.activation is 'sigmoid':\n            dout = self.activated_output * (1 - self.activated_output) * dout\n        if self.activation is 'tanh':\n            dout = (1 - self.activated_output ** 2) * dout\n        dx = np.dot(dout, self.W.T)\n        self.dW = np.dot(self.x.T, dout)\n        self.db = dout\n        self.W = self.W - self.dW * self.lr / self.batch_size\n        self.b = self.b - self.db * self.lr / self.batch_size\n        return dx\n    \n# 定义softmax类\nclass SoftMax:\n    y_hat = []\n\n    def __init__(self):\n        super(SoftMax, self).__init__()\n        self.parameter = {'name':'SoftMax'}\n\n    def forward(self, x):\n        x_exp = np.exp(x)\n        partition = np.sum(x_exp, axis=1, keepdims=True)\n        self.y_hat = x_exp / partition\n        return self.y_hat\n\n    def backward(self, y):\n        dout = self.y_hat - y\n        return dout","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:52:39.47144Z","iopub.execute_input":"2022-05-06T11:52:39.472159Z","iopub.status.idle":"2022-05-06T11:52:39.491098Z","shell.execute_reply.started":"2022-05-06T11:52:39.472119Z","shell.execute_reply":"2022-05-06T11:52:39.490247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义MLP类\nclass MLP:\n    def __init__(self, input_size, batch_size, num_classes, lr=0.001, hidden_layer_sizes=(), activation='relu'):\n\n        self.layer_list = [[hidden_layer_sizes[i], hidden_layer_sizes[i + 1]]\n                           for i in range(len(hidden_layer_sizes) - 1)]\n        self.input_layer = LinearLayer(input_size, hidden_layer_sizes[0], batch_size, activation, lr=lr)\n        self.classifier = LinearLayer(hidden_layer_sizes[-1], num_classes, batch_size, activation, lr=lr)\n        self.softmax = SoftMax()\n        self.batch_size = batch_size\n        self.lr = lr\n\n        self.layers = [self.input_layer]\n        for i in range(len(self.layer_list)):\n            self.layers.append(LinearLayer(self.layer_list[i][0], self.layer_list[i][1], batch_size, activation, lr=lr))\n        self.layers.append(self.classifier)\n        self.layers.append(self.softmax)\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer.forward(x)\n        return x\n\n    def backward(self, y):\n        for layer in reversed(self.layers):\n            y = layer.backward(y)\n\n    def parameter(self):\n        for i in range(len(self.layers)):\n            print(\"layer {}: {}\".format(i + 1, self.layers[i].parameter))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:52:39.4928Z","iopub.execute_input":"2022-05-06T11:52:39.493079Z","iopub.status.idle":"2022-05-06T11:52:39.509429Z","shell.execute_reply.started":"2022-05-06T11:52:39.493034Z","shell.execute_reply":"2022-05-06T11:52:39.508661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 设置超参数\nnum_epochs = 10\nbatch_size = 200\n\n# 取数据\ntrain_iter, test_iter, len_train_data, len_test_data = dataloader(batch_size)\n\n# 实例化MLP模型\nmodel = MLP(input_size=784, batch_size=batch_size, num_classes=10, lr=0.001, hidden_layer_sizes=(256,),\n            activation='tanh')\n\n# 打印一下模型参数\nmodel.parameter()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:52:39.511113Z","iopub.execute_input":"2022-05-06T11:52:39.511692Z","iopub.status.idle":"2022-05-06T11:52:44.096958Z","shell.execute_reply.started":"2022-05-06T11:52:39.511653Z","shell.execute_reply":"2022-05-06T11:52:44.09596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# 开始训练\nacc_list = [0.,]\nfor epoch in range(num_epochs):\n    acc = 0\n    with tqdm(train_iter, unit='batch') as tepoch:\n        for data, label in tepoch:\n            tepoch.set_description(f\"Epoch {epoch + 1} train\")\n            if data.shape[0] < batch_size:\n                break\n            data = data.numpy()\n            label = label.numpy()\n            outputs = model.forward(data)\n            acc += (outputs.argmax(1) == label).sum() / len_train_data\n            model.backward(np.eye(10)[label])\n            tepoch.set_postfix(acc=acc)\n    acc_list.append(acc)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:52:44.098568Z","iopub.execute_input":"2022-05-06T11:52:44.098893Z","iopub.status.idle":"2022-05-06T11:53:58.076813Z","shell.execute_reply.started":"2022-05-06T11:52:44.098856Z","shell.execute_reply":"2022-05-06T11:53:58.07596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#做预测输出\npredictions = []\nwith tqdm(test_iter, unit='batch') as tepoch:\n    for data, _ in tepoch:\n        tepoch.set_description(f\"Prediction\")\n        data = data.numpy()\n        outputs = model.forward(data)\n        outputs_label = outputs.argmax(1)\n        for label in outputs_label:\n            predictions.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:53:58.079248Z","iopub.execute_input":"2022-05-06T11:53:58.079848Z","iopub.status.idle":"2022-05-06T11:53:58.767198Z","shell.execute_reply.started":"2022-05-06T11:53:58.079795Z","shell.execute_reply":"2022-05-06T11:53:58.766005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_dict = {\n    'id':list(np.arange(len_test_data)),\n    'label':predictions\n}\nout = pd.DataFrame(out_dict)\nout.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:53:58.769106Z","iopub.execute_input":"2022-05-06T11:53:58.770551Z","iopub.status.idle":"2022-05-06T11:53:58.865749Z","shell.execute_reply.started":"2022-05-06T11:53:58.770493Z","shell.execute_reply":"2022-05-06T11:53:58.864511Z"},"trusted":true},"execution_count":null,"outputs":[]}]}