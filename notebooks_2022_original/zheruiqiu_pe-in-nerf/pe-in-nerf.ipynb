{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport math\nimport imageio\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nimport pytorch_lightning as pl\n\nfrom pytorch_lightning.callbacks import TQDMProgressBar\n# from pytorch_lightning.profiler import SimpleProfiler\n\n# os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\ntorch.set_default_dtype(torch.float32)\nfast_dev_run = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Dataset","metadata":{}},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, img_dir):\n        self.img_dir = img_dir\n        self.im = cv2.imread(self.img_dir)\n        self.im = np.array(self.im, dtype=np.float32)\n        self.x_len, self.y_len = self.im.shape[0], self.im.shape[1]\n\n    def __len__(self):\n        return self.x_len * self.y_len\n\n    def __getitem__(self, idx):\n        y = idx//self.x_len\n        x = idx - y*self.x_len\n        pixel = (self.im[x, y, :])/255.\n        y = y/self.y_len*2*math.pi\n        x = x/self.x_len*2*math.pi\n        \n        return (x,y), pixel","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:13:24.522956Z","iopub.execute_input":"2022-05-08T06:13:24.523241Z","iopub.status.idle":"2022-05-08T06:13:24.551385Z","shell.execute_reply.started":"2022-05-08T06:13:24.523213Z","shell.execute_reply":"2022-05-08T06:13:24.550733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Setup","metadata":{}},{"cell_type":"code","source":"class MLP_PE(pl.LightningModule):\n    def __init__(self, middle_dim=128, pe_size=10, im=None, use_pe=True):\n        super().__init__()\n        self.use_pe=use_pe\n        if self.use_pe==True:\n            self.layer1 = nn.Sequential(\n                nn.Linear(2*pe_size*2,middle_dim),\n                nn.ReLU())            \n        else:\n            self.layer1 = nn.Sequential(\n                nn.Linear(2,middle_dim),\n                nn.ReLU())\n        self.layer2 = nn.Sequential(\n            nn.Linear(middle_dim,middle_dim),\n            nn.ReLU(),\n            nn.Linear(middle_dim,3))\n        self.im = np.array(im, dtype=np.float32)\n        self.x_len, self.y_len = self.im.shape[0], self.im.shape[1]\n        self.im_recon = np.zeros((self.x_len,self.y_len,3),dtype=np.uint8)\n        self.register_buffer(\"pe_param\",torch.Tensor([2**n for n in range(pe_size)])[None, ...])\n        self.img_counter = 0\n\n    def pe(self, pos):\n        pos = pos[..., None]        \n        pos_ =torch.reshape(pos*self.pe_param,(pos.shape[0],-1))\n        pos_pe = torch.stack((torch.sin(pos_),torch.cos(pos_)),axis=1)\n        return torch.reshape(pos_pe,(pos.shape[0],-1))\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        return out\n\n    def training_step(self, batch, batch_idx):\n        # training_step defined the train loop.\n        # It is independent of forward\n        pos, pixel = batch\n        if self.use_pe==True:\n            pos = torch.transpose(torch.stack(pos), 0, 1)\n            pos_input = self.pe(pos)\n        else:\n            pos_input = torch.transpose(torch.stack(pos), 0, 1)\n        pixel_hat = self(pos_input.float())\n        loss = F.mse_loss(pixel_hat, pixel)\n        # Logging to TensorBoard by default\n        self.log(\"train_loss\", loss)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        pos, pixel = batch\n        if self.use_pe==True:\n            pos = torch.transpose(torch.stack(pos), 0, 1)\n            pos_input = self.pe(pos)\n        else:\n            pos_input = pos = torch.transpose(torch.stack(pos), 0, 1)\n        pos = pos.detach().cpu().numpy()\n        pixel_hat = torch.clamp(self(pos_input.float()), 0, 1)        \n        pixel_hat = np.array((pixel_hat*255).detach().cpu().numpy(), dtype=np.uint8)\n        self.im_recon[np.array(np.around(pos[:, 0]/(2*math.pi)*self.x_len), dtype=np.uint32) \\\n            , np.array(np.around(pos[:, 1]/(2*math.pi)*self.y_len), dtype=np.uint32), :] = pixel_hat\n        \n\n        # Plot\n        if batch_idx == len(train_dataloader) - 1:\n            font={\n                'family': 'Times New Roman',\n                'weight': 'normal',\n                'size'  : 20,\n            }\n            plt.figure(\"Image\",dpi=200)\n            plt.imshow(self.im_recon)\n            plt.axis(\"on\")\n            plt.title(\"Room (Epoch={:02d})\".format(self.current_epoch),font=font)\n            if self.use_pe==True:\n                plt.savefig(\"./images/photo_w_pe/{:03d}.png\".format(self.img_counter), dpi=200)\n            else:\n                plt.savefig(\"./images/photo_wo_pe/{:03d}.png\".format(self.img_counter), dpi=200)\n            self.img_counter += 1\n            plt.close('all')\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader Setup","metadata":{}},{"cell_type":"code","source":"image_dir = \"../input/room-small/room_small.jpg\"\nim = cv2.imread(image_dir)\nif not os.path.exists(\"./images/photo_wo_pe/\"):\n    os.makedirs(\"./images/photo_wo_pe/\")\nif not os.path.exists(\"./images/photo_w_pe/\"):\n    os.makedirs(\"./images/photo_w_pe/\")\n\ntraining_dataset = CustomImageDataset(image_dir)\ntrain_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\nval_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=64, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:13:24.553261Z","iopub.execute_input":"2022-05-08T06:13:24.553524Z","iopub.status.idle":"2022-05-08T06:23:40.96635Z","shell.execute_reply.started":"2022-05-08T06:13:24.553488Z","shell.execute_reply":"2022-05-08T06:23:40.965598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"mlp_pe = MLP_PE(middle_dim=128, pe_size=10, im=im, use_pe=True)\n\nbar = TQDMProgressBar(refresh_rate=50)\n# profiler = SimpleProfiler()\ntrainer = pl.Trainer(max_epochs=20, accelerator=\"gpu\", devices=1, callbacks=[bar],  \\\n                    check_val_every_n_epoch=2, fast_dev_run=fast_dev_run)\n\ntrainer.fit(model=mlp_pe, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlp = MLP_PE(middle_dim=128, pe_size=10, im=im, use_pe=False)\n\nbar = TQDMProgressBar(refresh_rate=50)\ntrainer = pl.Trainer(max_epochs=50, accelerator=\"gpu\", devices=1, callbacks=[bar],  \\\n                    check_val_every_n_epoch=2, fast_dev_run=fast_dev_run) # (if you have GPUs)\n\ntrainer.fit(model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:23:40.969925Z","iopub.execute_input":"2022-05-08T06:23:40.970136Z","iopub.status.idle":"2022-05-08T06:48:37.668655Z","shell.execute_reply.started":"2022-05-08T06:23:40.97011Z","shell.execute_reply":"2022-05-08T06:48:37.667756Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creat Animation","metadata":{}},{"cell_type":"code","source":"png_dir = './images/photo_w_pe/'\nimages = []\nfor file_name in sorted(os.listdir(png_dir)):\n    if file_name.endswith('.png'):\n        file_path = os.path.join(png_dir, file_name)\n        images.append(imageio.imread(file_path))\nimageio.mimsave('./images/photo_w_pe.gif', images, duration = 0.5)\n\npng_dir = './images/photo_wo_pe/'\nimages = []\nfor file_name in sorted(os.listdir(png_dir)):\n    if file_name.endswith('.png'):\n        file_path = os.path.join(png_dir, file_name)\n        images.append(imageio.imread(file_path))\nimageio.mimsave('./images/photo_wo_pe.gif', images, duration = 0.5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MLP with Positional Encoding | MLP without Positional Encoding\n---|---\n![figure 1](./images/photo_w_pe.gif) | ![figure 2](./images/photo_wo_pe.gif)\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}