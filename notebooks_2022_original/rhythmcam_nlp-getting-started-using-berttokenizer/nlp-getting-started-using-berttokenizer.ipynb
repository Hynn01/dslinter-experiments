{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports and Defines","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install transformers\nclear_output()\n\nimport numpy as np\nimport pandas as pd\nimport random,os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport transformers\nfrom transformers import BertTokenizer\nfrom transformers import TFBertModel\n\nimport tensorflow as tf \nfrom tensorflow.keras.optimizers import Adam\n\nTRAIN_PATH = \"../input/nlp-getting-started/train.csv\"\nTEST_PATH = \"../input/nlp-getting-started/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"../input/nlp-getting-started/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"id\"\nTARGET = \"target\"\n\nSEED = 2022\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nseed_everything()\n\n\nMODEL_NAME = \"bert-large-uncased\"\nMODEL_MAX_LENGTH = 60\nMODEL_INPUT_IDS_COL = \"input_ids\"\nMODEL_ATTENTION_MASK_COL = \"attention_mask\"\n\nMODEL_DATATYPE = \"int32\"\nMODEL_DENSE = 32\nMODEL_DROPOUT = 0.2\nMODEL_ACTIVATION = \"relu\"\nMODEL_LAST_ACTIVATION = \"sigmoid\"\nMODEL_LR = 6e-6\nMODEL_LOSS = \"binary_crossentropy\"\nMODEL_METRICS = ['accuracy']\nMODEL_EPOCH = 2\nMODEL_BATCH_SIZE = 10\nMODEL_VAL_SIZE = 0.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T00:39:35.640504Z","iopub.execute_input":"2022-05-08T00:39:35.640842Z","iopub.status.idle":"2022-05-08T00:39:53.146246Z","shell.execute_reply.started":"2022-05-08T00:39:35.640755Z","shell.execute_reply":"2022-05-08T00:39:53.145493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\n\ntokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)\n\ndef bert_encode(data,maximum_length) :\n    input_ids = []\n    attention_masks = []\n  \n\n    for i in range(len(data.text)):\n        encoded = tokenizer.encode_plus(\n\n        data.text[i],\n        add_special_tokens=True,\n        max_length=maximum_length,\n        pad_to_max_length=True,\n\n        return_attention_mask=True,\n\n        )\n\n        input_ids.append(encoded['input_ids'])\n        attention_masks.append(encoded['attention_mask'])\n        \n    return np.array(input_ids),np.array(attention_masks)\n\ntrain_input_ids,train_attention_masks = bert_encode(train,MODEL_MAX_LENGTH)\ntest_input_ids,test_attention_masks = bert_encode(test,MODEL_MAX_LENGTH)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T00:39:53.148308Z","iopub.execute_input":"2022-05-08T00:39:53.148548Z","iopub.status.idle":"2022-05-08T00:40:05.054489Z","shell.execute_reply.started":"2022-05-08T00:39:53.148514Z","shell.execute_reply":"2022-05-08T00:40:05.053772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"def create_model(bert_model):\n    input_ids = tf.keras.Input(shape=(MODEL_MAX_LENGTH,),dtype=MODEL_DATATYPE)\n    attention_masks = tf.keras.Input(shape=(MODEL_MAX_LENGTH,),dtype=MODEL_DATATYPE)\n\n    output = bert_model([input_ids,attention_masks])\n    output = output[1]\n    output = tf.keras.layers.Dense(MODEL_DENSE,activation=MODEL_ACTIVATION)(output)\n    output = tf.keras.layers.Dropout(MODEL_DROPOUT)(output)\n\n    output = tf.keras.layers.Dense(1,activation=MODEL_LAST_ACTIVATION)(output)\n    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n    model.compile(Adam(lr=MODEL_LR), loss=MODEL_LOSS, metrics=MODEL_METRICS)\n    return model\n\n\nbert_model = TFBertModel.from_pretrained(MODEL_NAME)\n\nmodel = create_model(bert_model)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T00:40:05.055927Z","iopub.execute_input":"2022-05-08T00:40:05.056167Z","iopub.status.idle":"2022-05-08T00:41:28.405795Z","shell.execute_reply.started":"2022-05-08T00:40:05.056135Z","shell.execute_reply":"2022-05-08T00:41:28.404213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    [train_input_ids,train_attention_masks],\n    train[TARGET],\n    validation_split=MODEL_VAL_SIZE,\n    epochs=MODEL_EPOCH,\n    batch_size=MODEL_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T00:41:28.407692Z","iopub.execute_input":"2022-05-08T00:41:28.408046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict Data","metadata":{}},{"cell_type":"code","source":"pred_test = model.predict([test_input_ids,test_attention_masks])\n\nsub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[TARGET] = np.round(pred_test).astype(int)\nsub.to_csv(SUBMISSION_PATH,index=False)\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}