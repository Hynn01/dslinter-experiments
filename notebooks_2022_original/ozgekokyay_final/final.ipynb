{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import required libraries\n\nimport numpy as np \nimport pandas as pd\nimport re\nfrom ast import literal_eval\nfrom itertools import chain\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.model_selection import train_test_split\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoModel, AutoTokenizer\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T15:07:19.289663Z","iopub.execute_input":"2022-05-07T15:07:19.290589Z","iopub.status.idle":"2022-05-07T15:07:27.890636Z","shell.execute_reply.started":"2022-05-07T15:07:19.290485Z","shell.execute_reply":"2022-05-07T15:07:27.888979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Understanding\ndata_dir = \"/kaggle/input/nbme-score-clinical-patient-notes\"\n# Training data files\ntrain=pd.read_csv(data_dir+\"/train.csv\")\npatient_notes=pd.read_csv(data_dir+\"/patient_notes.csv\")\nfeatures=pd.read_csv(data_dir+\"/features.csv\")\n\n# Test data file/s\ntest=pd.read_csv(data_dir+\"/test.csv\")\n\n# submission sample \nsubmission=pd.read_csv(data_dir+\"/sample_submission.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:27.892258Z","iopub.execute_input":"2022-05-07T15:07:27.892517Z","iopub.status.idle":"2022-05-07T15:07:28.717766Z","shell.execute_reply.started":"2022-05-07T15:07:27.892474Z","shell.execute_reply":"2022-05-07T15:07:28.716854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train \n****Column Description :****\n\n* id - Unique identifier for each patient note / feature pair.\n* case_num - The case to which this patient note belongs.\n* pn_num - The patient note annotated in this row.\n* feature_num - The feature annotated in this row.\n* annotation - The text(s) within a patient note indicating a feature. A feature may be indicated multiple times within a single note.\n* location - Character spans indicating the location of each annotation within the note. Multiple spans may be needed to represent an annotation, in which case the spans are delimited by a semicolon ;.","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:28.719177Z","iopub.execute_input":"2022-05-07T15:07:28.719612Z","iopub.status.idle":"2022-05-07T15:07:28.744661Z","shell.execute_reply.started":"2022-05-07T15:07:28.719563Z","shell.execute_reply":"2022-05-07T15:07:28.743654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of rows in train data: {}'.format(train.shape[0]))\nprint('Number of columns in train data: {}'.format(train.shape[1]))\nprint('Number of unique cases: {}'.format(train.case_num.nunique()))\nprint('Number of unique patients: {}'.format(train.pn_num.nunique()))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:28.747082Z","iopub.execute_input":"2022-05-07T15:07:28.748054Z","iopub.status.idle":"2022-05-07T15:07:28.764203Z","shell.execute_reply.started":"2022-05-07T15:07:28.748005Z","shell.execute_reply":"2022-05-07T15:07:28.763358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features\n****Column Description :****\n\n* feature_num - A unique identifier for each feature.\n* case_num - The case to which this patient note belongs.\n* feature_text - A description of the feature.","metadata":{}},{"cell_type":"code","source":"features.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:28.765325Z","iopub.execute_input":"2022-05-07T15:07:28.76595Z","iopub.status.idle":"2022-05-07T15:07:28.777379Z","shell.execute_reply.started":"2022-05-07T15:07:28.765914Z","shell.execute_reply":"2022-05-07T15:07:28.776627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample Feature Text\nfeatures[\"feature_text\"].iloc[4], features[\"feature_text\"].iloc[40], features[\"feature_text\"].iloc[41]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:28.778561Z","iopub.execute_input":"2022-05-07T15:07:28.77883Z","iopub.status.idle":"2022-05-07T15:07:28.795022Z","shell.execute_reply.started":"2022-05-07T15:07:28.778791Z","shell.execute_reply":"2022-05-07T15:07:28.794063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Patient Notes\n**Column Description :**\n* pn_num - A unique identifier for each patient note.\n* case_num - A unique identifier for the clinical case a patient note represents.\n* pn_history - The text of the encounter as recorded by the test taker.","metadata":{}},{"cell_type":"code","source":"patient_notes.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:28.796287Z","iopub.execute_input":"2022-05-07T15:07:28.796703Z","iopub.status.idle":"2022-05-07T15:07:28.813652Z","shell.execute_reply.started":"2022-05-07T15:07:28.79667Z","shell.execute_reply":"2022-05-07T15:07:28.812714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample Patient Note\nprint(patient_notes[\"pn_history\"].iloc[8])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:28.814991Z","iopub.execute_input":"2022-05-07T15:07:28.815442Z","iopub.status.idle":"2022-05-07T15:07:28.829661Z","shell.execute_reply.started":"2022-05-07T15:07:28.815397Z","shell.execute_reply":"2022-05-07T15:07:28.828842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Preprocess\ndef process_feature_text(text):\n    return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \").replace(\"I-year\", \"1-year\")\n\n\ndef clean_spaces(txt):\n    txt = re.sub('\\n', ' ', txt)\n    txt = re.sub('\\t', ' ', txt)\n    txt = re.sub('\\r', ' ', txt)\n    return txt","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:28.831058Z","iopub.execute_input":"2022-05-07T15:07:28.831477Z","iopub.status.idle":"2022-05-07T15:07:28.845195Z","shell.execute_reply.started":"2022-05-07T15:07:28.831444Z","shell.execute_reply":"2022-05-07T15:07:28.844278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nbme-score-clinical-patient-notes/train.csv\")\n\n# Merge Datasets to Prepare Training Data\nmerged_df = train.merge(features, how=\"left\", on=[\"case_num\", \"feature_num\"])\nmerged_df = merged_df.merge(patient_notes, how=\"left\", on=['case_num', 'pn_num'])\n\n# Preprocess\nmerged_df['pn_history'] = merged_df['pn_history'].apply(lambda x: x.strip())\nmerged_df['pn_history'] = merged_df['pn_history'].apply(clean_spaces)\nmerged_df['pn_history'] = merged_df['pn_history'].apply(lambda x: x.lower())\nmerged_df['feature_text'] = merged_df['feature_text'].apply(process_feature_text)\nmerged_df['feature_text'] = merged_df['feature_text'].apply(clean_spaces)\nmerged_df['feature_text'] = merged_df['feature_text'].apply(lambda x: x.lower())\n\n\n\n# Split data as train and test\ntest_size = int(len(merged_df)* (0.2))\ntrain_df, test_df = train_test_split(merged_df, test_size=test_size, random_state=500)\nprint(len(train_df), len(test_df))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:28.847365Z","iopub.execute_input":"2022-05-07T15:07:28.847809Z","iopub.status.idle":"2022-05-07T15:07:29.138301Z","shell.execute_reply.started":"2022-05-07T15:07:28.847762Z","shell.execute_reply":"2022-05-07T15:07:29.137642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_add_labels(tokenizer, data, config):\n    out = tokenizer(\n        data[\"feature_text\"],\n        data[\"pn_history\"],\n        truncation=config['truncation'],\n        max_length=config['max_length'],\n        padding=config['padding'],\n        return_offsets_mapping=config['return_offsets_mapping']\n    )\n    labels = [0.0] * len(out[\"input_ids\"])\n    out[\"location_int\"] = loc_list_to_ints(data[\"location_list\"])\n    out[\"sequence_ids\"] = out.sequence_ids()\n\n    for idx, (seq_id, offsets) in enumerate(zip(out[\"sequence_ids\"], out[\"offset_mapping\"])):\n        if not seq_id or seq_id == 0:\n            labels[idx] = -1\n            continue\n\n        token_start, token_end = offsets\n        for feature_start, feature_end in out[\"location_int\"]:\n            if token_start >= feature_start and token_end <= feature_end:\n                labels[idx] = 1.0\n                break\n\n    out[\"labels\"] = labels\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:07:29.139246Z","iopub.execute_input":"2022-05-07T15:07:29.13995Z","iopub.status.idle":"2022-05-07T15:07:29.148481Z","shell.execute_reply.started":"2022-05-07T15:07:29.139916Z","shell.execute_reply":"2022-05-07T15:07:29.147406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        data = self.data.iloc[idx]\n        tokens = tokenize_and_add_labels(self.tokenizer, data, self.config)\n\n        input_ids = np.array(tokens[\"input_ids\"])\n        attention_mask = np.array(tokens[\"attention_mask\"])\n        token_type_ids = np.array(tokens[\"token_type_ids\"])\n\n        labels = np.array(tokens[\"labels\"])\n        offset_mapping = np.array(tokens['offset_mapping'])\n        sequence_ids = np.array(tokens['sequence_ids']).astype(\"float16\")\n        \n        return input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:23:53.90196Z","iopub.execute_input":"2022-05-07T15:23:53.902306Z","iopub.status.idle":"2022-05-07T15:23:53.912595Z","shell.execute_reply.started":"2022-05-07T15:23:53.902262Z","shell.execute_reply":"2022-05-07T15:23:53.911531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyperparameters = {\n    \"max_length\": 416,\n    \"padding\": \"max_length\",\n    \"return_offsets_mapping\": True,\n    \"truncation\": \"only_second\",\n    \"model_name\": \"bert-base-uncased\",\n    \"dropout\": 0.2,\n    \"lr\": 1e-5,\n    \"test_size\": 0.2,\n    \"seed\": 1268,\n    \"batch_size\": 8\n}\n\ntokenizer = AutoTokenizer.from_pretrained(hyperparameters['model_name'])\n\ntraining_data = CustomDataset(train_df, tokenizer, hyperparameters)\ntrain_dataloader = DataLoader(training_data, batch_size=hyperparameters['batch_size'], shuffle=True)\n\ntest_data = CustomDataset(test_df, tokenizer, hyperparameters)\ntest_dataloader = DataLoader(test_data, batch_size=hyperparameters['batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T15:23:54.294856Z","iopub.execute_input":"2022-05-07T15:23:54.295136Z","iopub.status.idle":"2022-05-07T15:24:02.743198Z","shell.execute_reply.started":"2022-05-07T15:23:54.295107Z","shell.execute_reply":"2022-05-07T15:24:02.742252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}