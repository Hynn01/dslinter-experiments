{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aim of this notebook is to explore this dataset in much simple and clean way.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-03T12:54:37.089705Z","iopub.execute_input":"2022-05-03T12:54:37.090386Z","iopub.status.idle":"2022-05-03T12:54:37.097775Z","shell.execute_reply.started":"2022-05-03T12:54:37.090347Z","shell.execute_reply":"2022-05-03T12:54:37.096853Z"}}},{"cell_type":"markdown","source":"# **Import**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom statsmodels.graphics.gofplots import qqplot\nimport plotly.express as px\nimport seaborn as sns\nsns.set(style = \"darkgrid\")\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\npd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', None)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T11:20:46.169236Z","iopub.execute_input":"2022-05-05T11:20:46.1697Z","iopub.status.idle":"2022-05-05T11:20:48.411393Z","shell.execute_reply.started":"2022-05-05T11:20:46.169603Z","shell.execute_reply":"2022-05-05T11:20:48.410401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Read Dataset**","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv(\"../input/tabular-playground-series-may-2022/sample_submission.csv\")\ntrain = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2022/test.csv\")\nprint(\"Sample\")\ndisplay(sample.head(2))\nprint()\nprint(\"Train\")\ndisplay(train.head(2))\nprint()\nprint(\"Test\")\ndisplay(test.head(2))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T11:20:48.412853Z","iopub.execute_input":"2022-05-05T11:20:48.41445Z","iopub.status.idle":"2022-05-05T11:21:03.453403Z","shell.execute_reply.started":"2022-05-05T11:20:48.414417Z","shell.execute_reply":"2022-05-05T11:21:03.452363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Overall view of dataset**\n* train 900000 rows, test 700000 rows\n* no nan values in our datasets\n* 31 features\n* f_00 - f_06 and f_19 - f_26 and f_28 := float columns\n* f_07 - f_18 and f_29 - f_30 := int columns\n* f_27 := object column\n* target columns := binary (0/1) and target is almost balanced #0: 462161 and #1: 437839","metadata":{}},{"cell_type":"code","source":"print(\"Sample, train, test\")\nprint(sample.shape, train.shape, test.shape)\nprint()\nprint(\"No of null values\")\nprint(sample.isnull().sum().sum(), train.isnull().sum().sum(), test.isnull().sum().sum())\nprint()\nfeatures = test.drop(\"id\", axis=1).columns.tolist()\nprint(features)\nprint()\nprint(train.info())","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-05T10:43:47.467764Z","iopub.execute_input":"2022-05-05T10:43:47.468036Z","iopub.status.idle":"2022-05-05T10:43:47.985335Z","shell.execute_reply.started":"2022-05-05T10:43:47.468005Z","shell.execute_reply":"2022-05-05T10:43:47.984563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.target.value_counts())\nsns.countplot(x=train['target'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:43:47.988176Z","iopub.execute_input":"2022-05-05T10:43:47.988723Z","iopub.status.idle":"2022-05-05T10:43:48.241934Z","shell.execute_reply.started":"2022-05-05T10:43:47.988676Z","shell.execute_reply":"2022-05-05T10:43:48.241263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Here we look at no of unique value in each columns**\n\n\n* 700000+900000 = 1600000 [train+test]\n* all float columns has different values in each row <br>\n* all int columns has total at most 17 different unique values ( so these are some sort of categorical variables))<br>\n* f_27 which is an object column(as has string entry) has total 1181880 unique values 160000-1181880=418120 repetitions\n* In int columns there are many unique values whose frequency is less than 1%(see below). We can combine them to create new feature.","metadata":{}},{"cell_type":"code","source":"full_data = pd.concat([train[features],test[features]], axis=0)\nprint(full_data.shape)\nprint()\nlist(zip(full_data.columns, full_data.dtypes, full_data.nunique()))","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-05T10:43:48.242916Z","iopub.execute_input":"2022-05-05T10:43:48.24412Z","iopub.status.idle":"2022-05-05T10:43:51.750741Z","shell.execute_reply.started":"2022-05-05T10:43:48.244073Z","shell.execute_reply":"2022-05-05T10:43:51.749798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features = [i for i in features if full_data[i].nunique() <= 17]\nnum_features = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_28']\nprint(\"features with no of unique values less than equal to 17\")\nprint(cat_features)\nprint()\nprint(\"% of unique values\")\nfor feat in cat_features:\n    print(feat,\":\")\n    a = full_data[feat].value_counts()*100/full_data.shape[0]\n    print(a)\n    print(\"=\"*40)\n    print()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-05T10:43:51.752241Z","iopub.execute_input":"2022-05-05T10:43:51.752495Z","iopub.status.idle":"2022-05-05T10:43:55.036271Z","shell.execute_reply.started":"2022-05-05T10:43:51.752463Z","shell.execute_reply":"2022-05-05T10:43:55.035369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"f_27 :\")\nprint(full_data.f_27.value_counts())","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-05T10:43:55.037912Z","iopub.execute_input":"2022-05-05T10:43:55.038722Z","iopub.status.idle":"2022-05-05T10:43:56.661221Z","shell.execute_reply.started":"2022-05-05T10:43:55.038666Z","shell.execute_reply":"2022-05-05T10:43:56.660311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **f_27**\n**The f_27 column contains string of length 10 characters, Let's try to explore these encoding.**\n\nWe first created a new dataframe from f_27 by splitting these strings into 10 columns of each characters.<br>\nWe notice following things of this encoding:\n* f0, f2, f5 : contains only two characters A,B  (can be used to create new features)\n* f1, f3, f4, f6, f8, f9: all contains characters from A to O \n* f7: contains charactes from A to T\n* f1, f3, f4, f6, f8, f9 : all has same distribution of characters \n* except f7 which has almost same frequency of each character","metadata":{}},{"cell_type":"code","source":"data_f_27 = pd.DataFrame([list(i) for i in sorted(full_data.f_27.value_counts().index.values)])\ndata_f_27.columns = [\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\"]\ndata_f_27.head(3)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:43:56.6626Z","iopub.execute_input":"2022-05-05T10:43:56.662831Z","iopub.status.idle":"2022-05-05T10:44:02.355218Z","shell.execute_reply.started":"2022-05-05T10:43:56.662802Z","shell.execute_reply":"2022-05-05T10:44:02.354542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    print(data_f_27.groupby([f\"f{i}\"]).count().iloc[:,0])\n    print(\"=\"*40)\n    print()","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:44:02.356175Z","iopub.execute_input":"2022-05-05T10:44:02.356816Z","iopub.status.idle":"2022-05-05T10:44:15.443618Z","shell.execute_reply.started":"2022-05-05T10:44:02.356785Z","shell.execute_reply":"2022-05-05T10:44:15.442726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* f0 and f5 have very similar distribution while f2 has just opposite distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nfor i in [0,2,5]:\n    d= data_f_27[f\"f{i}\"].value_counts()\n    plt.plot(d,label=f\"f{i}\")\nplt.legend()\nplt.show()\nplt.figure(figsize=(12,6))\nfor i in [1,3,4,6,7,8,9]:\n    d= data_f_27[f\"f{i}\"].value_counts()\n    plt.plot(d, label=f\"f{i}\")\nplt.legend()\nplt.show()","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:44:15.447048Z","iopub.execute_input":"2022-05-05T10:44:15.447291Z","iopub.status.idle":"2022-05-05T10:44:17.31826Z","shell.execute_reply.started":"2022-05-05T10:44:15.447261Z","shell.execute_reply":"2022-05-05T10:44:17.317435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<code>px.treemap()</code> is used to visualize proportions for multiple columns at at time.","metadata":{}},{"cell_type":"code","source":"fig  = px.treemap(data_f_27.sample(20), path= data_f_27.columns.tolist() ) \nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:44:17.326786Z","iopub.execute_input":"2022-05-05T10:44:17.327464Z","iopub.status.idle":"2022-05-05T10:44:18.71146Z","shell.execute_reply.started":"2022-05-05T10:44:17.327429Z","shell.execute_reply":"2022-05-05T10:44:18.710564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Parallel Sets represents contribution of columns on each other. <br>\n* It is used to represent inter-connection among columns.<br>\n* Note: It works only for Object and int data type columns.<br>\n* We can set color value based on a column which can be int/float type.\n> We have created two plots:-\n1. In first plot we have taken full_data i.e. train+test \n1. In second plot we have taken only train data with target as color","metadata":{}},{"cell_type":"code","source":"px.parallel_categories(data_f_27.sample(200)) # train+test","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:44:18.712823Z","iopub.execute_input":"2022-05-05T10:44:18.713098Z","iopub.status.idle":"2022-05-05T10:44:18.84294Z","shell.execute_reply.started":"2022-05-05T10:44:18.713068Z","shell.execute_reply":"2022-05-05T10:44:18.842305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_f_27= pd.DataFrame([list(i) for i in train.f_27.value_counts().index.values])\ntrain_f_27.columns = [\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\"]\ntrain_f_27[\"target\"] = train.target\ntrain_f_27.head(3)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:44:18.844114Z","iopub.execute_input":"2022-05-05T10:44:18.844878Z","iopub.status.idle":"2022-05-05T10:44:21.300622Z","shell.execute_reply.started":"2022-05-05T10:44:18.844815Z","shell.execute_reply":"2022-05-05T10:44:21.299602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.parallel_categories(train_f_27.head(800),color=\"target\") # train","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:44:21.301958Z","iopub.execute_input":"2022-05-05T10:44:21.3022Z","iopub.status.idle":"2022-05-05T10:44:21.438737Z","shell.execute_reply.started":"2022-05-05T10:44:21.302171Z","shell.execute_reply":"2022-05-05T10:44:21.437808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# features = cat_features + num_features + f_27\n* cat_features := 14\n* num_features := 16\n* f_27","metadata":{}},{"cell_type":"code","source":"display(full_data[cat_features].head(2))\n\ndisplay(full_data[num_features].head(2))\n\ndisplay(full_data[[\"f_27\"]].head(2))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:44:21.440068Z","iopub.execute_input":"2022-05-05T10:44:21.440307Z","iopub.status.idle":"2022-05-05T10:44:21.970217Z","shell.execute_reply.started":"2022-05-05T10:44:21.440278Z","shell.execute_reply":"2022-05-05T10:44:21.969255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorial features(features which has no of unique values less than equal to 17)\n* both train and test set have same distribution \n* both train and test set don't follow normal distribution\n\nQ-Q plot also known as (Quantile-Quantile plot) is used to check whether our data follows normal distribution or not.\nIf our plot lies on the red line(y=x) then it is normally distributed. It it don't lie on the y=x line then our feature is not normally distributed.","metadata":{}},{"cell_type":"code","source":"print(\"histplot\",\" \"*3,\"Kde plot\",\" \"*3, \"Boxplot\",\" \"*3,\"QQplot train\",\" \"*3,\"QQplot test\")\nfig, axes = plt.subplots(14,5, figsize=(25,60))\naxes = axes.flatten()\nfor i in range(0,len(axes),5):\n    col = cat_features[i//5]\n    ax = axes[i]\n    train[col].hist(ax= ax,bins=20, color=\"r\",alpha=.5, label=\"train\")\n    test[col].hist(ax= ax,bins=20, color=\"b\", alpha=.5, label=\"test\")\n    \n    sns.kdeplot(train[col], color=\"red\", label=\"train\", ax=axes[i+1])\n    sns.kdeplot(test[col],  color=\"green\", label=\"test\", ax=axes[i+1])\n    axes[i+1].legend()\n    \n    sns.boxplot(data=train[col], color=\"red\",ax=axes[i+2])\n    sns.boxplot(data= test[col],  color=\"green\", ax=axes[i+2])\n    axes[i+2].legend() \n    \n    t1= (train[col].values - train[col].values.mean())/ train[col].values.std()\n    t2= (test[col].values - test[col].values.mean())/ test[col].values.std()\n    qqplot(t1,line=\"s\",ax=axes[i+3])\n    qqplot(t2,line=\"s\",ax=axes[i+4])\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'f{cat_features[i//5]}', loc = 'right', fontsize = 12)\n    ax.legend()\n    fig.suptitle(\"distribution of train-test cat_features\")\n    fig.tight_layout()  \nplt.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-05T10:44:21.971725Z","iopub.execute_input":"2022-05-05T10:44:21.972057Z","iopub.status.idle":"2022-05-05T10:47:01.81252Z","shell.execute_reply.started":"2022-05-05T10:44:21.972015Z","shell.execute_reply":"2022-05-05T10:47:01.811371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## numerical features\n* both train and test set have same distribution \n* both train and test set follow normal distribution <b>[with slight deviation from normal behaviour for f_25 and f_26]</b>","metadata":{}},{"cell_type":"code","source":"print(\"histplot\",\" \"*3,\"Kde plot\",\" \"*3, \"Boxplot\",\" \"*3,\"QQplot train\",\" \"*3,\"QQplot test\")\nfig, axes = plt.subplots(16,5, figsize=(25,70))\naxes = axes.flatten()\nfor i in range(0,len(axes),5):\n    col = num_features[i//5]\n    ax = axes[i]\n    train[col].hist(ax= ax,bins=20, color=\"r\",alpha=.5, label=\"train\")\n    test[col].hist(ax= ax,bins=20, color=\"b\", alpha=.5, label=\"test\")\n\n    sns.kdeplot(train[col], color=\"red\", label=\"train\", ax=axes[i+1])\n    sns.kdeplot(test[col],  color=\"green\", label=\"test\", ax=axes[i+1])\n    axes[i+1].legend()\n    \n    sns.boxplot(data=train[col], color=\"red\",ax=axes[i+2])\n    sns.boxplot(data= test[col],  color=\"green\", ax=axes[i+2])\n    axes[i+2].legend()    \n    \n    t1= (train[col].values - train[col].values.mean())/ train[col].values.std()\n    t2= (test[col].values - test[col].values.mean())/ test[col].values.std()\n    qqplot(t1,line=\"s\",ax=axes[i+3])\n    qqplot(t2,line=\"s\",ax=axes[i+4])\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'{num_features[i//5]}', loc = 'right', fontsize = 12)\n    ax.legend()\n    fig.suptitle(\"distribution of train-test num_features\")\n    fig.tight_layout()   \nplt.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-05-05T10:47:01.814411Z","iopub.execute_input":"2022-05-05T10:47:01.814717Z","iopub.status.idle":"2022-05-05T10:50:16.795749Z","shell.execute_reply.started":"2022-05-05T10:47:01.814678Z","shell.execute_reply":"2022-05-05T10:50:16.794778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now for numerical columns we will see if there is any outlier, if present then we will remove it.","metadata":{}},{"cell_type":"code","source":"def check_outlier(data,col_name):\n    \"\"\"\n    input:= data, column name\n    output:= Lower wishker and Upper wishker \n    \"\"\"\n    Q3 = data[col_name].quantile(0.75)\n    Q1 = data[col_name].quantile(0.25)\n    IQR = Q3-Q1 \n    print(\"75%:\", Q3)\n    print(\"25%\",Q1)\n    print(\"IQR:\",IQR)\n    \n    LW = Q1 - 1.5*IQR \n    UW = Q3 + 1.5*IQR \n    print(\"Lower and Upper Wishker: \",LW, UW)\n    print(\"Min and Max value: \", np.min(data[col_name]),np.max(data[col_name]))\n    print(\"Full data:\", data.shape)\n    print(\"No of outliers: \",data[(data[col_name]<LW) | (data[col_name]>UW)].shape)\n    \n    sns.boxplot(x=data[col_name])\n    sns.stripplot(x=data[col_name], color=\"0.5\")\n    plt.show()\n    return LW, UW\n    ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:50:16.797366Z","iopub.execute_input":"2022-05-05T10:50:16.797606Z","iopub.status.idle":"2022-05-05T10:50:16.807345Z","shell.execute_reply.started":"2022-05-05T10:50:16.797578Z","shell.execute_reply":"2022-05-05T10:50:16.806036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for c in num_features:\n    print(\"Column: \",c)\n    LW, UW= check_outlier(train,c)\n    print(\"After removing outliers\")\n    train=train[(train[c]>= LW) & (train[c]<= UW)]\n    sns.boxplot(x=train[c])\n    sns.stripplot(x=train[c], color=\"0.5\")\n    plt.show()\n    print(\"=\"*40)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-05T10:50:16.809129Z","iopub.execute_input":"2022-05-05T10:50:16.809371Z","iopub.status.idle":"2022-05-05T10:52:47.084641Z","shell.execute_reply.started":"2022-05-05T10:50:16.809342Z","shell.execute_reply":"2022-05-05T10:52:47.083735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot after removing outliers from train set.\n* We can see that, now our train set is not following normal distribution in tail region, because we have removed outliers(from tails). But now our dataset is much more stable.","metadata":{}},{"cell_type":"code","source":"print(\"histplot\",\" \"*3,\"Kde plot\",\" \"*3, \"Boxplot\",\" \"*3,\"QQplot train\",\" \"*3,\"QQplot test\")\nfig, axes = plt.subplots(16,5, figsize=(25,70))\naxes = axes.flatten()\nfor i in range(0,len(axes),5):\n    col = num_features[i//5]\n    ax = axes[i]\n    train[col].hist(ax= ax,bins=20, color=\"r\",alpha=.5, label=\"train\")\n    test[col].hist(ax= ax,bins=20, color=\"b\", alpha=.5, label=\"test\")\n\n    sns.kdeplot(train[col], color=\"red\", label=\"train\", ax=axes[i+1])\n    sns.kdeplot(test[col],  color=\"green\", label=\"test\", ax=axes[i+1])\n    axes[i+1].legend()\n    \n    sns.boxplot(data=train[col], color=\"red\",ax=axes[i+2])\n    sns.boxplot(data= test[col],  color=\"green\", ax=axes[i+2])\n    axes[i+2].legend()    \n    \n    t1= (train[col].values - train[col].values.mean())/ train[col].values.std()\n    t2= (test[col].values - test[col].values.mean())/ test[col].values.std()\n    qqplot(t1,line=\"s\",ax=axes[i+3])\n    qqplot(t2,line=\"s\",ax=axes[i+4])\n    ax.get_yaxis().set_visible(False)\n    ax.set_title(f'{num_features[i//5]}', loc = 'right', fontsize = 12)\n    ax.legend()\n    fig.suptitle(\"distribution of train-test num_features\")\n    fig.tight_layout()   \nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:52:47.086259Z","iopub.execute_input":"2022-05-05T10:52:47.087279Z","iopub.status.idle":"2022-05-05T10:55:50.847466Z","shell.execute_reply.started":"2022-05-05T10:52:47.087232Z","shell.execute_reply":"2022-05-05T10:55:50.8466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature correlation\n* correlation between numerical features <b>[ there is some correlation between (f_28, f_2) (f_28, f_3) (f_28, f_5) and (f_25, f_23) ]</b>\n* correlation between categorical features <b>[ there is no correlation among categorical features ]</b>","metadata":{}},{"cell_type":"code","source":"feat = num_features \nfig, ax = plt.subplots(1,2,figsize=(32,11))         # Sample figsize in inches\nax[0].title.set_text(\"train\")\nax[1].title.set_text(\"test\")\nsns.heatmap(train[feat].corr().abs(), cmap=\"viridis\", linewidths=.5, ax=ax[0], annot=True, fmt=\".2f\")\nsns.heatmap(test[feat].corr().abs(), cmap=\"viridis\",linewidths=.5, ax=ax[1], annot=True, fmt=\".2f\")\nplt.show()\n\n## threshold of .2\nfig, ax = plt.subplots(1,2,figsize=(32,11))         # Sample figsize in inches\nax[0].title.set_text(\"train\")\nax[1].title.set_text(\"test\")\nsns.heatmap(train[feat].corr().abs()>.2, cmap=\"coolwarm\", linewidths=.5, ax=ax[0],annot=True, fmt=\".2f\")\nsns.heatmap(test[feat].corr().abs()>.2, cmap=\"coolwarm\",linewidths=.5, ax=ax[1],annot=True, fmt=\".2f\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:55:50.848868Z","iopub.execute_input":"2022-05-05T10:55:50.849597Z","iopub.status.idle":"2022-05-05T10:55:59.003253Z","shell.execute_reply.started":"2022-05-05T10:55:50.849552Z","shell.execute_reply":"2022-05-05T10:55:59.002592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat = cat_features \nfig, ax = plt.subplots(1,2,figsize=(32,11))         \nax[0].title.set_text(\"train\")\nax[1].title.set_text(\"test\")\nsns.heatmap(train[feat].corr().abs(), cmap=\"viridis\", linewidths=.5, ax=ax[0], annot=True, fmt=\".2f\")\nsns.heatmap(test[feat].corr().abs(), cmap=\"viridis\",linewidths=.5, ax=ax[1], annot=True, fmt=\".2f\")\nplt.show()\n## threshold of .2\nfig, ax = plt.subplots(1,2,figsize=(32,11))         \nax[0].title.set_text(\"train\")\nax[1].title.set_text(\"test\")\nsns.heatmap(train[feat].corr().abs()>.2, cmap=\"coolwarm\", linewidths=.5, ax=ax[0],annot=True, fmt=\".2f\")\nsns.heatmap(test[feat].corr().abs()>.2, cmap=\"coolwarm\",linewidths=.5, ax=ax[1],annot=True, fmt=\".2f\")\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T10:55:59.004252Z","iopub.execute_input":"2022-05-05T10:55:59.004944Z","iopub.status.idle":"2022-05-05T10:56:05.369477Z","shell.execute_reply.started":"2022-05-05T10:55:59.004904Z","shell.execute_reply":"2022-05-05T10:56:05.368876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape, test.shape, sample.shape) # final dataset after removing outliers","metadata":{"execution":{"iopub.status.busy":"2022-05-05T11:30:32.033722Z","iopub.execute_input":"2022-05-05T11:30:32.034154Z","iopub.status.idle":"2022-05-05T11:30:32.041336Z","shell.execute_reply.started":"2022-05-05T11:30:32.034121Z","shell.execute_reply":"2022-05-05T11:30:32.040386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# If you like my work please do upvote!\n**<span style=\"color:#444160;\"> Thanks!ðŸ™‚</span>**<br>\n.<br>\n.<br>\n.\n\n<img src=\"https://media.giphy.com/media/SfYTJuxdAbsVW/giphy.gif\" width=70%>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}