{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Problem Statement**\n* Identify which question asked on Quora are duplicates of question that have already been asked.\n* This could be useful to instantly provide answers to questions that have already been answered\n* We are tasked with predicting whethet a pair of questions are duplicate or not","metadata":{}},{"cell_type":"markdown","source":"**Source/Useful Links**\n* Source: https://www.kaggle.com/competitions/quora-question-pairs/data\n* Blog1: https://quoraengineering.quora.com/Semantic-Question-Matching-with-Deep-Learning\n* Blog2: https://towardsdatascience.com/identifying-duplicate-questions-on-quora-top-12-on-kaggle-4c1cf93f1c30","metadata":{}},{"cell_type":"markdown","source":"**Real World/Business Objectives and Constraints**\n1. The cost of a mis-classification can be very high.\n2. You would want a probability of a pair of questions to be duplicates so that you can choose any threshold of choice.\n3. No strict latency concerns\n4. Interpretaiblity is partially important","metadata":{}},{"cell_type":"markdown","source":"**Machine Learning Problem** <br>\n**Data Overview**\n- Data will be in Train.csv\n- Train.csv contains: qid1, qid2, question1, question2, is_duplicate\n- Size of Train.csv - 60 Mb\n- Number of rows in Train.csv = 404,290","metadata":{}},{"cell_type":"markdown","source":"**Example Data Point**\n<pre>\n\"id\",\"qid1\",\"qid2\",\"question1\",\"question2\",\"is_duplicate\"\n\"0\",\"1\",\"2\",\"What is the step by step guide to invest in share market in india?\",\"What is the step by step guide to invest in share market?\",\"0\"\n\"1\",\"3\",\"4\",\"What is the story of Kohinoor (Koh-i-Noor) Diamond?\",\"What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\",\"0\"\n\"7\",\"15\",\"16\",\"How can I be a good geologist?\",\"What should I do to be a great geologist?\",\"1\"\n\"11\",\"23\",\"24\",\"How do I read and find my YouTube comments?\",\"How can I see all my Youtube comments?\",\"1\"\n</pre>","metadata":{}},{"cell_type":"markdown","source":"**Mapping Real World problemt o ML problem**<br>\n**Type of Machine Learning Problem**\nIt is a binary classification problem, for a given pair of questions we need to predict if they are duplicate or not.\n\n**Performance Metric**<br>\nSource: https://www.kaggle.com/c/quora-question-pairs#evaluation\n\nMetric(s): \n* log-loss : https://www.kaggle.com/wiki/LogarithmicLoss\n* Binary Confusion Matrix\n\n**Train and Test Construction**\n<p>  </p>\n<p> We build train and test by randomly splitting in the ratio of 70:30 or 80:20 whatever we choose as we have sufficient points to work with. </p>","metadata":{}},{"cell_type":"markdown","source":"**Exploratory Data Analysis**","metadata":{}},{"cell_type":"code","source":"!pip3 install distance\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom subprocess import check_output\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport os\nimport gc\nimport shutil\n\nimport re\nfrom nltk.corpus import stopwords\nimport distance\nfrom nltk.stem import PorterStemmer\nfrom bs4 import BeautifulSoup\n","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:12.377463Z","iopub.execute_input":"2022-04-24T08:50:12.378043Z","iopub.status.idle":"2022-04-24T08:50:26.615775Z","shell.execute_reply.started":"2022-04-24T08:50:12.377958Z","shell.execute_reply":"2022-04-24T08:50:26.615006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.unpack_archive('../input/quora-question-pairs/train.csv.zip', '.')\nshutil.unpack_archive('../input/quora-question-pairs/test.csv.zip', '.')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:26.617199Z","iopub.execute_input":"2022-04-24T08:50:26.617398Z","iopub.status.idle":"2022-04-24T08:50:34.457306Z","shell.execute_reply.started":"2022-04-24T08:50:26.617373Z","shell.execute_reply":"2022-04-24T08:50:34.456421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"./train.csv\")\n\nprint(\"Number of datapoints:\", df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:34.458662Z","iopub.execute_input":"2022-04-24T08:50:34.459056Z","iopub.status.idle":"2022-04-24T08:50:36.107631Z","shell.execute_reply.started":"2022-04-24T08:50:34.459017Z","shell.execute_reply":"2022-04-24T08:50:36.106775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:36.109705Z","iopub.execute_input":"2022-04-24T08:50:36.110124Z","iopub.status.idle":"2022-04-24T08:50:36.133895Z","shell.execute_reply.started":"2022-04-24T08:50:36.110088Z","shell.execute_reply":"2022-04-24T08:50:36.132737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:36.135415Z","iopub.execute_input":"2022-04-24T08:50:36.135713Z","iopub.status.idle":"2022-04-24T08:50:36.273415Z","shell.execute_reply.started":"2022-04-24T08:50:36.135668Z","shell.execute_reply":"2022-04-24T08:50:36.272545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We are given a minimal number of data fields here, consisting of:\n* id: Looks like a simple rowID\n* qid{1,2}: The unique ID of each question in pair\n* question(1,2): The actual textual content of the questions.\n* is_duplicate: The label that we are trying to predict - whether the two questions are duplicates of each other","metadata":{}},{"cell_type":"markdown","source":"**Distribution of data points amoung output classes**\n* Numbe of duplicates and non-duplicate questions","metadata":{}},{"cell_type":"code","source":"df.groupby(\"is_duplicate\")['id'].count().plot.bar()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:36.274869Z","iopub.execute_input":"2022-04-24T08:50:36.275337Z","iopub.status.idle":"2022-04-24T08:50:36.516273Z","shell.execute_reply.started":"2022-04-24T08:50:36.275292Z","shell.execute_reply":"2022-04-24T08:50:36.515571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('~> Total number of question pairs for training:\\n {}'.format(100 - round(df['is_duplicate'].mean()*100, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:36.517427Z","iopub.execute_input":"2022-04-24T08:50:36.518168Z","iopub.status.idle":"2022-04-24T08:50:36.524041Z","shell.execute_reply.started":"2022-04-24T08:50:36.518136Z","shell.execute_reply":"2022-04-24T08:50:36.523126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('~> Question pairs are Similar:\\n {}'.format(round(df['is_duplicate'].mean()*100, 2)))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:36.525366Z","iopub.execute_input":"2022-04-24T08:50:36.525896Z","iopub.status.idle":"2022-04-24T08:50:36.536228Z","shell.execute_reply.started":"2022-04-24T08:50:36.525852Z","shell.execute_reply":"2022-04-24T08:50:36.535579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Number of unique questions**","metadata":{}},{"cell_type":"code","source":"qids = pd.Series(df['qid1'].tolist() + df['qid2'].to_list())\nunique_qs = len(np.unique(qids))\n\nqs_morethan_onetime = np.sum(qids.value_counts() > 1)\nprint('Total number of Unique Questions are: {}\\n'.format(unique_qs))\n\nprint('Number of unique questions that appear more than once time: {} ({}%)\\n'.format(qs_morethan_onetime,qs_morethan_onetime/unique_qs*100))\n\nprint('Max number of time a single question is repeated: {}\\n'.format(max(qids.value_counts())))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:36.537148Z","iopub.execute_input":"2022-04-24T08:50:36.537639Z","iopub.status.idle":"2022-04-24T08:50:37.380961Z","shell.execute_reply.started":"2022-04-24T08:50:36.537606Z","shell.execute_reply":"2022-04-24T08:50:37.380026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = [\"unique_questions\", \"Repeated Questions\"]\ny = [unique_qs, qs_morethan_onetime]\n\nplt.figure(figsize=(10,6))\nplt.title(\"Plot representing unique and repeated questions\")\nsns.barplot(x,y)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:37.383877Z","iopub.execute_input":"2022-04-24T08:50:37.384229Z","iopub.status.idle":"2022-04-24T08:50:37.554251Z","shell.execute_reply.started":"2022-04-24T08:50:37.384184Z","shell.execute_reply":"2022-04-24T08:50:37.553712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checking for Duplicates**","metadata":{}},{"cell_type":"code","source":"#checking whether there aaaare any repeated pair of questions\n\npair_duplicates = df[['qid1', 'qid2', 'is_duplicate']].groupby(['qid1', 'qid2', ]).count().reset_index()\nprint(\"Number of duplicate questions\", (pair_duplicates).shape[0] - df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:37.555239Z","iopub.execute_input":"2022-04-24T08:50:37.555558Z","iopub.status.idle":"2022-04-24T08:50:37.874504Z","shell.execute_reply.started":"2022-04-24T08:50:37.55552Z","shell.execute_reply":"2022-04-24T08:50:37.87353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Number of occurences of each question**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\n\nplt.hist(qids.value_counts(), bins=160)\n\nplt.yscale('log')\n\nplt.title('Log-Histogram of question appearance counts')\n\nplt.xlabel(\"Number of occurences of questions\")\n\nplt.ylabel(\"Number of questions\")\n\nprint('Maximum number of times a single question is repeated:  {}\\n'.format(max(qids.value_counts())))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:37.876Z","iopub.execute_input":"2022-04-24T08:50:37.876367Z","iopub.status.idle":"2022-04-24T08:50:39.607667Z","shell.execute_reply.started":"2022-04-24T08:50:37.876323Z","shell.execute_reply":"2022-04-24T08:50:39.606754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checking for Null values**","metadata":{}},{"cell_type":"code","source":"#Checking whether there are any rows with null values\n\nnan_rows = df[df.isnull().any(1)]\nprint(nan_rows)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:39.609076Z","iopub.execute_input":"2022-04-24T08:50:39.609362Z","iopub.status.idle":"2022-04-24T08:50:39.718874Z","shell.execute_reply.started":"2022-04-24T08:50:39.609323Z","shell.execute_reply":"2022-04-24T08:50:39.718249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are two rows with null values in question2","metadata":{}},{"cell_type":"code","source":"#Fill the null values with ' '\n\ndf = df.fillna('')\nnan_rows = df[df.isnull().any(1)]\nprint(nan_rows)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T08:50:39.72035Z","iopub.execute_input":"2022-04-24T08:50:39.720846Z","iopub.status.idle":"2022-04-24T08:50:39.999135Z","shell.execute_reply.started":"2022-04-24T08:50:39.720815Z","shell.execute_reply":"2022-04-24T08:50:39.998167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Basic Feature Extraction**<br>\nLet us now contruct few features like:\n\n* freq_qid1: Frequency of qid1's\n* freq_qid2: Frequency of qid2's\n* q1len: Length of q1\n* q2len: Length of q2\n* q1_n_words: Number of words in Questions 1\n* q2_n_words: Number of words in Questions 2\n* word_Common: (Number of common unique words in Question 1 and Questions 2)\n* word_Total: Total num of words in Question1 + Total num of words in Question 2\n* word_share : (word_common)/(word_Total)\n* freq_q1 + freq_q2: sum total of frequency of qid1 and qid2\n* freq_q1 - freq_q2: absolute difference of frequency of qid1 and qid2","metadata":{}},{"cell_type":"code","source":"if os.path.isfile('./df_fe_without_preprocessing_train.csv'):\n    df = pd.read_csv('./df_fe_without_preprocessing_train.csv', encoding='latin-1')\nelse:\n    df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count')\n    df['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count')\n    df['q1len'] = df['question1'].str.len()\n    df['q2len'] = df['question2'].str.len()\n    df['q1_n_words'] = df['question1'].apply(lambda row :len(row.split(\" \")))\n    df['q2_n_words'] = df['question2'].apply(lambda row :len(row.split(\" \")))\n    \n    def normalized_word_Common(row):\n        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split()))\n        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split()))\n        return 1.0* len(w1 & w2)\n    df['word_Common'] = df.apply(normalized_word_Common, axis=1)\n    \n    def normalized_word_Total(row):\n        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split()))\n        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split()))\n        return 1* (len(w1) + len(w2))\n    df['word_Total'] = df.apply(normalized_word_Total, axis = 1)\n    \n    def normalized_word_share(row):\n        w1 = set(map(lambda word: word.lower().strip(), row['question1'].split()))\n        w2 = set(map(lambda word: word.lower().strip(), row['question2'].split()))\n        return 1.0*len(w1 & w2) / (len(w1) + len(w2))\n    df['word_share'] = df.apply(normalized_word_share, axis = 1)\n    \n    df['freq_q1+q2'] = df['freq_qid1'] + df['freq_qid2']\n    df['freq_q1-q2'] = abs(df['freq_qid1'] - df['freq_qid2'])\n    \n    df.to_csv(\"df_fe_without_preprocessing_train.csv\", index= False)\n    \ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T09:11:16.314769Z","iopub.execute_input":"2022-04-24T09:11:16.315087Z","iopub.status.idle":"2022-04-24T09:11:59.609019Z","shell.execute_reply.started":"2022-04-24T09:11:16.315052Z","shell.execute_reply":"2022-04-24T09:11:59.608424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of some of the extracted features** <br>","metadata":{}},{"cell_type":"code","source":"print(\"Minimum length of the question in q1:\", min(df['q1_n_words']))\nprint(\"Minimum length of the question in q2:\", min(df['q2_n_words']))\n\nprint(\"Number of Questions with minimum length [question1] :\", df[df['q1_n_words']==1].shape[0])\nprint(\"Number of Questions with minimum length [question2] :\", df[df['q2_n_words']==1].shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T09:18:16.000248Z","iopub.execute_input":"2022-04-24T09:18:16.001123Z","iopub.status.idle":"2022-04-24T09:18:16.124555Z","shell.execute_reply.started":"2022-04-24T09:18:16.001084Z","shell.execute_reply":"2022-04-24T09:18:16.123689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature word share**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\n\nplt.subplot(1,2,1)\nsns.violinplot(x = 'is_duplicate', y='word_share', data = df[0:])\n\nplt.subplot(1,2,2)\nsns.distplot(df[df['is_duplicate'] == 1.0]['word_share'][0:], label = \"1\", color=\"red\")\nsns.distplot(df[df['is_duplicate'] == 0.0]['word_share'][0:], label = \"0\", color=\"blue\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T09:24:00.136464Z","iopub.execute_input":"2022-04-24T09:24:00.136833Z","iopub.status.idle":"2022-04-24T09:24:02.979928Z","shell.execute_reply.started":"2022-04-24T09:24:00.136794Z","shell.execute_reply":"2022-04-24T09:24:02.979041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The distributions for normalized word_share have some overlap on the far right-hand side, i.e., there are quite a lot of questions with high word similarity\n- The average word share and Common no. of words of qid1 and qid2 is more when they are duplicate(Similar)","metadata":{}},{"cell_type":"markdown","source":"**Feature word common**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\n\nplt.subplot(1,2,1)\nsns.violinplot(x = 'is_duplicate', y='word_Common', data = df[0:])\n\nplt.subplot(1,2,2)\nsns.distplot(df[df['is_duplicate'] == 1.0]['word_Common'][0:], label = \"1\", color=\"red\")\nsns.distplot(df[df['is_duplicate'] == 0.0]['word_Common'][0:], label = \"0\", color=\"blue\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T10:07:46.48446Z","iopub.execute_input":"2022-04-24T10:07:46.484718Z","iopub.status.idle":"2022-04-24T10:07:49.477599Z","shell.execute_reply.started":"2022-04-24T10:07:46.48469Z","shell.execute_reply":"2022-04-24T10:07:49.476784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The distribution of the word Common feature in similar and non similar questions are highly overlapping. ","metadata":{}},{"cell_type":"markdown","source":"### End of Notebook\nAdvance Feature Engineering is in Part 2 [Click Here](https://www.kaggle.com/code/akshat4112/quora-question-pair-similarity-part-2-adv-eda)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}