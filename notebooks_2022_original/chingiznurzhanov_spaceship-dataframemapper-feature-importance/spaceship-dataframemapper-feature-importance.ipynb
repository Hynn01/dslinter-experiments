{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category= DataConversionWarning)\nfrom IPython.core.display import HTML\nfrom collections import Counter\n\n# Data split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn_pandas import DataFrameMapper\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#Feature engineering\nfrom sklearn.inspection import permutation_importance\nimport shap\nfrom sklearn.feature_selection import mutual_info_classif\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:20.970965Z","iopub.execute_input":"2022-05-02T20:12:20.972231Z","iopub.status.idle":"2022-05-02T20:12:20.981528Z","shell.execute_reply.started":"2022-05-02T20:12:20.97217Z","shell.execute_reply":"2022-05-02T20:12:20.980805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# In this work I want to show how to use DataFrameMapper and how well it shows the processes that we do during preprocessing. Also i find not many works with ShuffleSplit and StratifiedShuffleSplit. ","metadata":{}},{"cell_type":"markdown","source":"### p.s. some cell have import this is to make it easier to copy","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:55:13.426739Z","iopub.execute_input":"2022-05-02T19:55:13.427096Z","iopub.status.idle":"2022-05-02T19:55:13.4319Z","shell.execute_reply.started":"2022-05-02T19:55:13.427061Z","shell.execute_reply":"2022-05-02T19:55:13.430667Z"}}},{"cell_type":"markdown","source":"## In this competition your task is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly. To help you make these predictions, you're given a set of personal records recovered from the ship's damaged computer system.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/spaceship-titanic/train.csv')\ntest = pd.read_csv('../input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:21.026714Z","iopub.execute_input":"2022-05-02T20:12:21.027482Z","iopub.status.idle":"2022-05-02T20:12:21.079081Z","shell.execute_reply.started":"2022-05-02T20:12:21.027435Z","shell.execute_reply":"2022-05-02T20:12:21.077884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train.csv - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n- PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n- HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n- CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n- Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\nDestination - The planet the passenger will be debarking to.\n- Age - The age of the passenger.\n- VIP - Whether the passenger has paid for special VIP service during the voyage.\nRoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n- Name - The first and last names of the passenger.\nTransported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.","metadata":{}},{"cell_type":"markdown","source":"### From https://www.kaggle.com/code/arootda/pycaret-visualization-optimization-0-81/notebook","metadata":{"execution":{"iopub.status.busy":"2022-05-02T19:22:42.857904Z","iopub.execute_input":"2022-05-02T19:22:42.860186Z","iopub.status.idle":"2022-05-02T19:22:42.871269Z","shell.execute_reply.started":"2022-05-02T19:22:42.860066Z","shell.execute_reply":"2022-05-02T19:22:42.869939Z"}}},{"cell_type":"code","source":"from IPython.core.display import HTML\n\ndef multi_table(table_list):\n    return HTML(\n        f\"<table><tr> {''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list])} </tr></table>\")\n\nmulti_table([pd.DataFrame(df[i].value_counts()) for i in df.columns if i != 'Age'])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:21.084257Z","iopub.execute_input":"2022-05-02T20:12:21.084544Z","iopub.status.idle":"2022-05-02T20:12:21.147321Z","shell.execute_reply.started":"2022-05-02T20:12:21.084494Z","shell.execute_reply":"2022-05-02T20:12:21.146614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# miss value everywhere\nplt.figure(figsize=(15,10))\nsns.heatmap(df.isna(),\n            cmap=\"YlGnBu\",\n            cbar_kws={'label': 'Missing Data'})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:21.148743Z","iopub.execute_input":"2022-05-02T20:12:21.149364Z","iopub.status.idle":"2022-05-02T20:12:22.213106Z","shell.execute_reply.started":"2022-05-02T20:12:21.149318Z","shell.execute_reply":"2022-05-02T20:12:22.212123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:22.215098Z","iopub.execute_input":"2022-05-02T20:12:22.215373Z","iopub.status.idle":"2022-05-02T20:12:22.258097Z","shell.execute_reply.started":"2022-05-02T20:12:22.215339Z","shell.execute_reply":"2022-05-02T20:12:22.256982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.dtypes[(df.dtypes==\"float64\")|(df.dtypes==\"int64\")]\n                        .index.values].hist(figsize=[24,24]);","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:22.259405Z","iopub.execute_input":"2022-05-02T20:12:22.259663Z","iopub.status.idle":"2022-05-02T20:12:23.427184Z","shell.execute_reply.started":"2022-05-02T20:12:22.259631Z","shell.execute_reply":"2022-05-02T20:12:23.426333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ok now outlier\ndf[df.dtypes[(df.dtypes==\"float64\")|(df.dtypes==\"int64\")]\n                        .index.values].boxplot(figsize=[15,10]);","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:23.429262Z","iopub.execute_input":"2022-05-02T20:12:23.429532Z","iopub.status.idle":"2022-05-02T20:12:23.819308Z","shell.execute_reply.started":"2022-05-02T20:12:23.429488Z","shell.execute_reply":"2022-05-02T20:12:23.818326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From https://www.kaggle.com/code/yassineghouzam/titanic-top-4-with-ensemble-modeling","metadata":{}},{"cell_type":"code","source":"from collections import Counter\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = df[col].quantile(0.25)\n        # 3rd quartile (75%)\n        Q3 = df[col].quantile(0.75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers  \n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(df,2,[\"RoomService\",\"FoodCourt\",\"ShoppingMall\",'Spa',\"VRDeck\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:23.820942Z","iopub.execute_input":"2022-05-02T20:12:23.821359Z","iopub.status.idle":"2022-05-02T20:12:23.855716Z","shell.execute_reply.started":"2022-05-02T20:12:23.821311Z","shell.execute_reply":"2022-05-02T20:12:23.854719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[Outliers_to_drop]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:23.857415Z","iopub.execute_input":"2022-05-02T20:12:23.857872Z","iopub.status.idle":"2022-05-02T20:12:23.893039Z","shell.execute_reply.started":"2022-05-02T20:12:23.85782Z","shell.execute_reply":"2022-05-02T20:12:23.891949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop outliers\ndf = df.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:23.894723Z","iopub.execute_input":"2022-05-02T20:12:23.895027Z","iopub.status.idle":"2022-05-02T20:12:23.904171Z","shell.execute_reply.started":"2022-05-02T20:12:23.894993Z","shell.execute_reply":"2022-05-02T20:12:23.903375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 100 #number of variables for heatmap\ncols = df.corr().nlargest(k, 'Transported')['Transported'].index\ncm = df[cols].corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(cm, annot=True, cmap = 'viridis')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:23.905619Z","iopub.execute_input":"2022-05-02T20:12:23.9059Z","iopub.status.idle":"2022-05-02T20:12:24.501942Z","shell.execute_reply.started":"2022-05-02T20:12:23.905868Z","shell.execute_reply":"2022-05-02T20:12:24.500975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['PasId_group', 'PasId_number']] = df.PassengerId.str.split('_', expand=True)\ntest[['PasId_group', 'PasId_number']] = test.PassengerId.str.split('_', expand=True)\n\ndf[['Cabin_deck', 'Cabin_num','Cabin_side']] = df.Cabin.str.split('/', expand=True)\ntest[['Cabin_deck', 'Cabin_num','Cabin_side']] = test.Cabin.str.split('/', expand=True)\n\ndf['Age_type']=pd.cut(df.Age, bins=[0, 18, 99], labels=['child', 'adult'])\ntest['Age_type']=pd.cut(test.Age, bins=[0, 18, 99], labels=['child', 'adult'])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:24.503463Z","iopub.execute_input":"2022-05-02T20:12:24.50371Z","iopub.status.idle":"2022-05-02T20:12:24.567385Z","shell.execute_reply.started":"2022-05-02T20:12:24.503681Z","shell.execute_reply":"2022-05-02T20:12:24.56669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['PasId_group'] = df['PasId_group'].astype('float64')\ntest['PasId_group'] = test['PasId_group'].astype('float64')\n\ndf['PasId_number'] = df['PasId_group'].astype('float64')\ntest['PasId_number'] = test['PasId_group'].astype('float64')\n\ndf['Cabin_num'] = df['Cabin_num'].astype('float64')\ntest['Cabin_num'] = test['Cabin_num'].astype('float64')\n\ndf['CryoSleep'] = df['CryoSleep'].astype('bool')\ntest['CryoSleep'] = test['CryoSleep'].astype('bool')\n\ndf['VIP'] = df['VIP'].astype('bool')\ntest['VIP'] = test['VIP'].astype('bool')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:24.570107Z","iopub.execute_input":"2022-05-02T20:12:24.570401Z","iopub.status.idle":"2022-05-02T20:12:24.592898Z","shell.execute_reply.started":"2022-05-02T20:12:24.570369Z","shell.execute_reply":"2022-05-02T20:12:24.59193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop('Name',axis=1)\ntest = test.drop('Name',axis=1)\ndf = df.drop('PassengerId',axis=1)\ntest = test.drop('PassengerId',axis=1)\ndf = df.drop('Cabin',axis=1)\ntest = test.drop('Cabin',axis=1)\ndf = df.drop('PasId_number',axis=1)\ntest = test.drop('PasId_number',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:24.594678Z","iopub.execute_input":"2022-05-02T20:12:24.596755Z","iopub.status.idle":"2022-05-02T20:12:24.616586Z","shell.execute_reply.started":"2022-05-02T20:12:24.596696Z","shell.execute_reply":"2022-05-02T20:12:24.615864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 100 #number of variables for heatmap\ncols = df.corr().nlargest(k, 'Transported')['Transported'].index\ncm = df[cols].corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(cm, annot=True, cmap = 'viridis')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:24.618243Z","iopub.execute_input":"2022-05-02T20:12:24.618864Z","iopub.status.idle":"2022-05-02T20:12:25.60934Z","shell.execute_reply.started":"2022-05-02T20:12:24.618818Z","shell.execute_reply":"2022-05-02T20:12:25.608337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.copy()\nX = X.drop('Transported', axis=1)\n\ny = df['Transported']","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.61094Z","iopub.execute_input":"2022-05-02T20:12:25.611651Z","iopub.status.idle":"2022-05-02T20:12:25.620661Z","shell.execute_reply.started":"2022-05-02T20:12:25.611604Z","shell.execute_reply":"2022-05-02T20:12:25.619437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data split","metadata":{"tags":[]}},{"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.33, shuffle=True,random_state=0,stratify=y)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.622353Z","iopub.execute_input":"2022-05-02T20:12:25.62271Z","iopub.status.idle":"2022-05-02T20:12:25.63001Z","shell.execute_reply.started":"2022-05-02T20:12:25.622664Z","shell.execute_reply":"2022-05-02T20:12:25.629045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Interesting train_test_split = StratifiedShuffleSplit with n_splits=1, and StratifiedShuffleSplit we can use in grid search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.33, random_state=0)\n\ntrain_index, val_index = next(iter(sss.split(X, y)))\nX_train, X_test = X.iloc[train_index], X.iloc[val_index]\ny_train, y_test = y.iloc[train_index], y.iloc[val_index]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.634187Z","iopub.execute_input":"2022-05-02T20:12:25.634867Z","iopub.status.idle":"2022-05-02T20:12:25.652328Z","shell.execute_reply.started":"2022-05-02T20:12:25.634803Z","shell.execute_reply":"2022-05-02T20:12:25.651606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train),len(X_test),len(y_train),len(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.653418Z","iopub.execute_input":"2022-05-02T20:12:25.654142Z","iopub.status.idle":"2022-05-02T20:12:25.6684Z","shell.execute_reply.started":"2022-05-02T20:12:25.6541Z","shell.execute_reply":"2022-05-02T20:12:25.667563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn_pandas import DataFrameMapper","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.670017Z","iopub.execute_input":"2022-05-02T20:12:25.671141Z","iopub.status.idle":"2022-05-02T20:12:25.6791Z","shell.execute_reply.started":"2022-05-02T20:12:25.671087Z","shell.execute_reply":"2022-05-02T20:12:25.67832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features = X_train.select_dtypes(include=['object','category']).columns\nnumerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\nboolean_features = X_train.select_dtypes(include=['bool']).columns\ncat = [([c], [SimpleImputer(strategy='most_frequent', fill_value='UNK'),\n              LabelEncoder()]) for c in categorical_features]\nnum = [([n], [SimpleImputer(strategy='median'),StandardScaler()]) for n in numerical_features]\n\nboolean = [([b], [OneHotEncoder(sparse=False, handle_unknown='ignore')]) for b in boolean_features]\nmapper_for_scale = DataFrameMapper(num + cat + boolean, input_df=True,df_out=True)\nmapper_for_pipe = DataFrameMapper(num + cat + boolean, input_df=True,df_out=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.680341Z","iopub.execute_input":"2022-05-02T20:12:25.681156Z","iopub.status.idle":"2022-05-02T20:12:25.700856Z","shell.execute_reply.started":"2022-05-02T20:12:25.681102Z","shell.execute_reply":"2022-05-02T20:12:25.69956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## When fit you need use X_train!!!","metadata":{}},{"cell_type":"code","source":"mapper_for_scale.fit(X_train);","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.702461Z","iopub.execute_input":"2022-05-02T20:12:25.703296Z","iopub.status.idle":"2022-05-02T20:12:25.785284Z","shell.execute_reply.started":"2022-05-02T20:12:25.703256Z","shell.execute_reply":"2022-05-02T20:12:25.784564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_scaled = mapper_for_scale.transform(X_train)\nX_test_scaled = mapper_for_scale.transform(X_test)\ntest_scaled = mapper_for_scale.transform(test)\n#if you want work with X\nX_scaled = mapper_for_scale.transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.786467Z","iopub.execute_input":"2022-05-02T20:12:25.787324Z","iopub.status.idle":"2022-05-02T20:12:25.998324Z","shell.execute_reply.started":"2022-05-02T20:12:25.787281Z","shell.execute_reply":"2022-05-02T20:12:25.997321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How X_train looks after preprocessing. Amazing you can see all old columns that you use\nX_train_scaled","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:25.999631Z","iopub.execute_input":"2022-05-02T20:12:25.999886Z","iopub.status.idle":"2022-05-02T20:12:26.033027Z","shell.execute_reply.started":"2022-05-02T20:12:25.999854Z","shell.execute_reply":"2022-05-02T20:12:26.031897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 100 #number of variables for heatmap\ncols = X_scaled.corr().index\ncm = X_scaled[cols].corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(cm, annot=True, cmap = 'viridis')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:26.034642Z","iopub.execute_input":"2022-05-02T20:12:26.035012Z","iopub.status.idle":"2022-05-02T20:12:27.943339Z","shell.execute_reply.started":"2022-05-02T20:12:26.034969Z","shell.execute_reply":"2022-05-02T20:12:27.942173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# With mapper and scaled X_train, y_train","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier( n_jobs=-1,\n                       random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:27.945043Z","iopub.execute_input":"2022-05-02T20:12:27.94532Z","iopub.status.idle":"2022-05-02T20:12:27.950843Z","shell.execute_reply.started":"2022-05-02T20:12:27.945281Z","shell.execute_reply":"2022-05-02T20:12:27.949577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# With scaled\nmodel.fit(X_train_scaled,y_train)\n\nmodel.score(X_train_scaled,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:27.95243Z","iopub.execute_input":"2022-05-02T20:12:27.952752Z","iopub.status.idle":"2022-05-02T20:12:28.626182Z","shell.execute_reply.started":"2022-05-02T20:12:27.952718Z","shell.execute_reply":"2022-05-02T20:12:28.625198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.score(X_test_scaled,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:28.627462Z","iopub.execute_input":"2022-05-02T20:12:28.627731Z","iopub.status.idle":"2022-05-02T20:12:28.741494Z","shell.execute_reply.started":"2022-05-02T20:12:28.6277Z","shell.execute_reply":"2022-05-02T20:12:28.740506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## If you want search best parameters\n#from sklearn.model_selection import RandomizedSearchCV\n#\n## Create the parameter grid\n#rf_param_grid = {\n#    'max_depth': np.arange(10,  25, 1),\n#    'n_estimators': np.arange(50, 200, 2),\n#    'min_samples_leaf': np.arange(2, 8, 1),\n#    'min_samples_split': np.arange(2, 8, 1),\n#    'criterion' : (\"gini\", \"entropy\")\n#}\n#\n## Perform RandomizedSearchCV, we use cv=sss, we use StratifiedShuffleSplit\n#gridsearch_roc_auc = RandomizedSearchCV(estimator=model, param_distributions=rf_param_grid,n_iter=100,\n#                                        scoring='roc_auc', cv=sss, verbose=1,n_jobs=-1,random_state=0)\n#\n## Fit the estimator\n#gridsearch_roc_auc.fit(X_scaled, y)\n#\n## Compute metrics\n#print('Score: ', gridsearch_roc_auc.best_score_)\n#print('Estimator: ', gridsearch_roc_auc.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:28.742995Z","iopub.execute_input":"2022-05-02T20:12:28.743338Z","iopub.status.idle":"2022-05-02T20:12:28.748864Z","shell.execute_reply.started":"2022-05-02T20:12:28.743292Z","shell.execute_reply":"2022-05-02T20:12:28.747796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = model.predict(test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:28.750375Z","iopub.execute_input":"2022-05-02T20:12:28.750728Z","iopub.status.idle":"2022-05-02T20:12:28.869013Z","shell.execute_reply.started":"2022-05-02T20:12:28.750685Z","shell.execute_reply":"2022-05-02T20:12:28.868057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline","metadata":{}},{"cell_type":"markdown","source":"### Now pipeline  with mapper","metadata":{}},{"cell_type":"code","source":"clf = RandomForestClassifier(n_jobs=-1,\n                       random_state=0)\n\nfrom sklearn.pipeline import Pipeline\npipeline = Pipeline([\n    (\"mapper\", mapper_for_pipe),    \n    (\"clf\", clf)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:28.873301Z","iopub.execute_input":"2022-05-02T20:12:28.873593Z","iopub.status.idle":"2022-05-02T20:12:28.879047Z","shell.execute_reply.started":"2022-05-02T20:12:28.873559Z","shell.execute_reply":"2022-05-02T20:12:28.878363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#With Pipeline\npipeline.fit(X_train,y_train)\n\npipeline.score(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:28.880033Z","iopub.execute_input":"2022-05-02T20:12:28.880678Z","iopub.status.idle":"2022-05-02T20:12:29.68978Z","shell.execute_reply.started":"2022-05-02T20:12:28.88064Z","shell.execute_reply":"2022-05-02T20:12:29.688551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:29.691529Z","iopub.execute_input":"2022-05-02T20:12:29.691846Z","iopub.status.idle":"2022-05-02T20:12:29.872413Z","shell.execute_reply.started":"2022-05-02T20:12:29.691805Z","shell.execute_reply":"2022-05-02T20:12:29.871449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true_pipeline = pipeline.predict(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:29.873937Z","iopub.execute_input":"2022-05-02T20:12:29.874193Z","iopub.status.idle":"2022-05-02T20:12:30.042297Z","shell.execute_reply.started":"2022-05-02T20:12:29.874162Z","shell.execute_reply":"2022-05-02T20:12:30.041313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:30.043782Z","iopub.execute_input":"2022-05-02T20:12:30.044112Z","iopub.status.idle":"2022-05-02T20:12:30.049815Z","shell.execute_reply.started":"2022-05-02T20:12:30.044065Z","shell.execute_reply":"2022-05-02T20:12:30.04863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's compare model with pipeline and without. Accuracy 1 they are the same.\n# I love DataFrameMapper you can see how your data change in procces\naccuracy_score(y_true_pipeline,y_true_pipeline)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:30.051277Z","iopub.execute_input":"2022-05-02T20:12:30.05229Z","iopub.status.idle":"2022-05-02T20:12:30.066132Z","shell.execute_reply.started":"2022-05-02T20:12:30.052248Z","shell.execute_reply":"2022-05-02T20:12:30.065449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with pipeline you need using this for param_grid\n#sorted(pipeline.get_params().keys())","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:30.06725Z","iopub.execute_input":"2022-05-02T20:12:30.068165Z","iopub.status.idle":"2022-05-02T20:12:30.075393Z","shell.execute_reply.started":"2022-05-02T20:12:30.068106Z","shell.execute_reply":"2022-05-02T20:12:30.074621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rf_param_grid_pipe= {\n#    'clf__max_depth': np.arange(3,  10, 1),\n#    'clf__n_estimators': np.arange(90, 200, 2),\n#    'clf__min_samples_leaf': np.arange(2, 4, 1)\n#\n#}\n#\n## Perform RandomizedSearchCV\n#gridsearch_roc_auc_pipe = GridSearchCV(estimator=pipeline, param_grid=rf_param_grid_pipe,\n#                                        scoring='roc_auc', cv=sss, verbose=1,n_jobs=-1)\n## Fit the estimator\n#gridsearch_roc_auc_pipe.fit(X, y)\n#\n## Compute metrics\n#print('Score: ', gridsearch_roc_auc_pipe.best_score_)\n#print('Estimator: ', gridsearch_roc_auc_pipe.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:30.076553Z","iopub.execute_input":"2022-05-02T20:12:30.077571Z","iopub.status.idle":"2022-05-02T20:12:30.089107Z","shell.execute_reply.started":"2022-05-02T20:12:30.077499Z","shell.execute_reply":"2022-05-02T20:12:30.088163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = pipeline.predict(test)\nsub = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\nsub['Transported'] = y_preds.astype('bool')\nsub.to_csv('submission.csv', index=False)\n\nplt.figure(figsize=(6,6))\nsub['Transported'].value_counts().plot.pie(explode=[0.1,0.1], autopct='%1.1f%%', shadow=True, textprops={'fontsize':16}).set_title(\"Prediction distribution\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:30.090885Z","iopub.execute_input":"2022-05-02T20:12:30.091426Z","iopub.status.idle":"2022-05-02T20:12:30.437581Z","shell.execute_reply.started":"2022-05-02T20:12:30.091374Z","shell.execute_reply":"2022-05-02T20:12:30.436257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Score: 0.79378 not bad","metadata":{}},{"cell_type":"markdown","source":"# Feature engineering","metadata":{"tags":[]}},{"cell_type":"code","source":"model = RandomForestClassifier(n_jobs=-1, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:30.439668Z","iopub.execute_input":"2022-05-02T20:12:30.440045Z","iopub.status.idle":"2022-05-02T20:12:30.450397Z","shell.execute_reply.started":"2022-05-02T20:12:30.439995Z","shell.execute_reply":"2022-05-02T20:12:30.448667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train_scaled,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:30.453246Z","iopub.execute_input":"2022-05-02T20:12:30.45485Z","iopub.status.idle":"2022-05-02T20:12:31.037879Z","shell.execute_reply.started":"2022-05-02T20:12:30.454765Z","shell.execute_reply":"2022-05-02T20:12:31.036857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RandomForestClassifier importances","metadata":{"tags":[]}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20,10)\n\n# do code to support model\n#\"data\" is the X dataframe and model is the SKlearn object\n\nfeats = {} # a dict to hold feature_name: feature_importance\nfor feature, importance in zip(X_train_scaled.columns, model.feature_importances_):\n    feats[feature] = importance #add the name/value pair \n\nimportances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\nimportances.sort_values(by='Gini-importance').plot(kind='bar', rot=90)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:31.039159Z","iopub.execute_input":"2022-05-02T20:12:31.039421Z","iopub.status.idle":"2022-05-02T20:12:31.52033Z","shell.execute_reply.started":"2022-05-02T20:12:31.039389Z","shell.execute_reply":"2022-05-02T20:12:31.519591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importance_score = importances.sort_values(by='Gini-importance')\n\n# I want to see >= 0.035\nfeature_importance_score_rf = importance_score[importance_score['Gini-importance'] >= 0.035]\n\nfeature_importance_score_rf.reset_index(inplace=True)\n\nfeature_importance_score_rf","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:31.52173Z","iopub.execute_input":"2022-05-02T20:12:31.522326Z","iopub.status.idle":"2022-05-02T20:12:31.537489Z","shell.execute_reply.started":"2022-05-02T20:12:31.522276Z","shell.execute_reply":"2022-05-02T20:12:31.536614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Permutation importance","metadata":{}},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\nresult = permutation_importance(model, X_train_scaled, y_train, n_repeats=30,random_state=0,n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:12:31.55622Z","iopub.execute_input":"2022-05-02T20:12:31.557054Z","iopub.status.idle":"2022-05-02T20:13:01.601803Z","shell.execute_reply.started":"2022-05-02T20:12:31.557002Z","shell.execute_reply":"2022-05-02T20:13:01.600774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"permutation_importance_score_columns = []\npermutation_importance_score = []\nfor i in result.importances_mean.argsort()[::-1]:\n    if result.importances_mean[i] - 2 * result.importances_std[i]:\n        print(f\"{X_train_scaled.columns[i]}\"\n            f\"{result.importances_mean[i]:.3f}\"\n            f\" +/- {result.importances_std[i]:.3f}\")\n        permutation_importance_score_columns.append(X_train_scaled.columns[i])\n        permutation_importance_score.append(result.importances_mean[i])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:13:01.60392Z","iopub.execute_input":"2022-05-02T20:13:01.604409Z","iopub.status.idle":"2022-05-02T20:13:01.615356Z","shell.execute_reply.started":"2022-05-02T20:13:01.604371Z","shell.execute_reply":"2022-05-02T20:13:01.612145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"permutation_importance_score = pd.DataFrame(permutation_importance_score, index=permutation_importance_score_columns,columns=['permutation_importance_score'])\n\n# I want to see 0.019\nfeature_permutation_importance_score = permutation_importance_score[permutation_importance_score['permutation_importance_score'] >= 0.019]\n\nfeature_permutation_importance_score.reset_index(inplace=True)\n\nfeature_permutation_importance_score","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:13:01.617125Z","iopub.execute_input":"2022-05-02T20:13:01.617791Z","iopub.status.idle":"2022-05-02T20:13:01.640305Z","shell.execute_reply.started":"2022-05-02T20:13:01.617744Z","shell.execute_reply":"2022-05-02T20:13:01.639596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shap feature importance","metadata":{}},{"cell_type":"code","source":"import shap","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:13:01.641431Z","iopub.execute_input":"2022-05-02T20:13:01.642164Z","iopub.status.idle":"2022-05-02T20:13:01.646337Z","shell.execute_reply.started":"2022-05-02T20:13:01.642125Z","shell.execute_reply":"2022-05-02T20:13:01.64549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(model)\n\n# calculate shap values. This is what we will plot.\n# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\nshap_values = explainer.shap_values(X_test_scaled)\nfeature_names = list(X_test_scaled.columns.values)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:13:01.648209Z","iopub.execute_input":"2022-05-02T20:13:01.648624Z","iopub.status.idle":"2022-05-02T20:15:27.894478Z","shell.execute_reply.started":"2022-05-02T20:13:01.648577Z","shell.execute_reply":"2022-05-02T20:15:27.893273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_values[0], feature_names,plot_type='bar')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:15:27.89654Z","iopub.execute_input":"2022-05-02T20:15:27.896893Z","iopub.status.idle":"2022-05-02T20:15:28.208414Z","shell.execute_reply.started":"2022-05-02T20:15:27.896845Z","shell.execute_reply":"2022-05-02T20:15:28.20739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_values[0], X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:15:28.210021Z","iopub.execute_input":"2022-05-02T20:15:28.210355Z","iopub.status.idle":"2022-05-02T20:15:29.785233Z","shell.execute_reply.started":"2022-05-02T20:15:28.210309Z","shell.execute_reply":"2022-05-02T20:15:29.784593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = list(X_test_scaled.columns.values)\nvals = np.abs(shap_values[0]).mean(0)\nfeature_importance_shap = pd.DataFrame(list(zip(feature_names, vals)), columns=['index','feature_importance_vals'])\nfeature_importance_shap.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\nfeature_importance_shap.reset_index(drop=True,inplace=True)\nfeature_importance_shap","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:15:29.78663Z","iopub.execute_input":"2022-05-02T20:15:29.787033Z","iopub.status.idle":"2022-05-02T20:15:29.803214Z","shell.execute_reply.started":"2022-05-02T20:15:29.786984Z","shell.execute_reply":"2022-05-02T20:15:29.80235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# mi_score","metadata":{}},{"cell_type":"code","source":"# mutual information\nfrom sklearn.feature_selection import mutual_info_classif\n\ndiscrete = []\nfor col in X_train_scaled.columns:\n    discrete.append(X_train_scaled[col].dtype == int)\n\nmi_score = pd.DataFrame(mutual_info_classif(X_train_scaled,y_train,discrete_features=discrete), index=X_train_scaled.columns, columns=['Mutual information'])\nplt.rcParams[\"figure.figsize\"] = (10,15)\nplt.barh(np.arange(len(discrete)), mi_score['Mutual information'])\nplt.yticks(ticks=np.arange(len(discrete)),labels=mi_score.index)\nplt.xlabel('Mutual information')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:15:29.804745Z","iopub.execute_input":"2022-05-02T20:15:29.805261Z","iopub.status.idle":"2022-05-02T20:15:30.420396Z","shell.execute_reply.started":"2022-05-02T20:15:29.805222Z","shell.execute_reply":"2022-05-02T20:15:30.419534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I want to see >= 0.019\nfeature = mi_score[mi_score['Mutual information'] >= 0.025]\nfeature_importance_mi_score = feature.reset_index()\nfeature_importance_mi_score","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:15:30.42206Z","iopub.execute_input":"2022-05-02T20:15:30.422615Z","iopub.status.idle":"2022-05-02T20:15:30.436796Z","shell.execute_reply.started":"2022-05-02T20:15:30.422563Z","shell.execute_reply":"2022-05-02T20:15:30.435744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{"tags":[]}},{"cell_type":"code","source":"dfs = [feature_importance_score_rf,feature_permutation_importance_score,feature_importance_shap,feature_importance_mi_score]\nfeature_importance_conclusion = pd.concat(dfs, join='outer',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:15:30.438009Z","iopub.execute_input":"2022-05-02T20:15:30.438408Z","iopub.status.idle":"2022-05-02T20:15:30.445405Z","shell.execute_reply.started":"2022-05-02T20:15:30.438364Z","shell.execute_reply":"2022-05-02T20:15:30.444776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataFrame with feature importance\nfeature_importance_conclusion","metadata":{"execution":{"iopub.status.busy":"2022-05-02T20:15:30.446695Z","iopub.execute_input":"2022-05-02T20:15:30.447222Z","iopub.status.idle":"2022-05-02T20:15:30.474572Z","shell.execute_reply.started":"2022-05-02T20:15:30.447183Z","shell.execute_reply":"2022-05-02T20:15:30.473872Z"},"trusted":true},"execution_count":null,"outputs":[]}]}