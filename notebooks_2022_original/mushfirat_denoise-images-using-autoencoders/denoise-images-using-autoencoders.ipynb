{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b>1 <span style='color:#FFDB00; font-weight: bold;'>|</span> Introduction</b>","metadata":{}},{"cell_type":"markdown","source":"An autoencoder is a neural network that is trained in an unsupervised way to learn how to represent a chunk of data as a smaller matrix, and can reconstruct it back to its original form.  \nAn autoencoder is composed of two parts -an encoder and a decoder. The encoder compresses information, and the decoder reconstructs the original information from that compressed form.  \nWe can use an autoencoder for a variety of tasks, such as:\n- Dimentionality reduction\n- Language translation\n- Image Generation\n- Anomaly detection\n- Image Segmentation\n\nAnd so much more! In this notebook, I will show you how to build an autoencoder that can remove noise from images","metadata":{}},{"cell_type":"markdown","source":"<adenoising><img src=\"https://i.ibb.co/McpDByt/image-c.png\" alt=\"image-c\" border=\"0\"></a>","metadata":{}},{"cell_type":"markdown","source":"The encoder compresses the input image into a latent space or 'bottleneck', where the information about the image is stored. The decoder then uses that compressed representation as the input to reconstruct the image with no noise.  \nBut there is a problem with this method, compressing the image to a smaller latent space results in a significant loss of data, and so the output of the decoder is a bit blurry (you can notice this in the above diagram). Fortunately, there are ways to tackle this problem:  \n\nIn this notebook, we will be building an autoencoder that denoises images of size `(224, 224, 3)`. The neural network will be fully convolutional, which means we can train it on images of any shape. We will be training the model on larger images ,images with shape `(384, 384, 3)`, so that it can learn more patterns and will be able to perform better on smaller images of shape `(224, 224, 3)`, making the reconstruction more detailed (less blurriness).  \n\nAlso, we will not build the decoder to reconstruct images based solely on the compressed representation, but will also pass in the output of previous layers of the encoder, this will allow the decoder to know more information about the original image, making the reconstruction more detailed. This is called the U-Net architecture,  \n![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)","metadata":{}},{"cell_type":"markdown","source":"U-Nets are popular for image segmentation tasks, and they can also be used for denoising images","metadata":{}},{"cell_type":"markdown","source":"# <b>2 <span style='color:#FFDB00; font-weight: bold;'>|</span> Imports</b>\n- **For ML Models**: tensorflow  \n- **For Data Processing**: numpy  \n- **For Data Visualization**: matplotlib","metadata":{}},{"cell_type":"code","source":"# For ML Models\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras import regularizers\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.preprocessing.image import load_img\n\n# For Data Processing\nimport numpy as np\n\n# For Data Visualization\nimport matplotlib.pyplot as plt\n\n# Miscellaneous\nimport os\nimport random\n\n# Turn off warnings\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-29T10:51:48.603978Z","iopub.execute_input":"2022-04-29T10:51:48.604236Z","iopub.status.idle":"2022-04-29T10:51:48.610291Z","shell.execute_reply.started":"2022-04-29T10:51:48.604208Z","shell.execute_reply":"2022-04-29T10:51:48.609612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>3 <span style='color:#FFDB00; font-weight: bold;'>|</span> Variables & Functions</b>","metadata":{}},{"cell_type":"markdown","source":"<h2>3.1 <span style='color:#FFDB00; font-weight: bold;'>|</span> Image Sizes</h2>  ","metadata":{}},{"cell_type":"markdown","source":"We will train out autoencoder to remove noise from images of size `(384,384,3)`, and watch its performance on images of size `(224,224,3)`","metadata":{}},{"cell_type":"code","source":"TRAIN_SIZE = 384\nINFERENCE_SIZE = 224","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>3.2 <span style='color:#FFDB00; font-weight: bold;'>|</span> Train-Test Split</h2>  ","metadata":{}},{"cell_type":"code","source":"main_dir = '/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/'\nall_image_paths = [main_dir+file for file in os.listdir(main_dir) if file.endswith('.jpg')]\n\nprint('Total number of images:', len(all_image_paths))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:20:02.07953Z","iopub.execute_input":"2022-04-29T10:20:02.079904Z","iopub.status.idle":"2022-04-29T10:20:02.73624Z","shell.execute_reply.started":"2022-04-29T10:20:02.079869Z","shell.execute_reply":"2022-04-29T10:20:02.735519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have ~32k images, we will use 25k images for training and the rest for testing and validation","metadata":{}},{"cell_type":"code","source":"train_image_paths = all_image_paths[:25000]\ntest_image_paths = all_image_paths[25000:]","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:50:38.28945Z","iopub.execute_input":"2022-04-29T10:50:38.289954Z","iopub.status.idle":"2022-04-29T10:50:38.294389Z","shell.execute_reply.started":"2022-04-29T10:50:38.289919Z","shell.execute_reply":"2022-04-29T10:50:38.293667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>3.3 <span style='color:#FFDB00; font-weight: bold;'>|</span> Function to open images</h2>  ","metadata":{}},{"cell_type":"code","source":"def open_images(paths, size=TRAIN_SIZE):\n    '''\n    Given an array of paths to images, this function opens those images,\n    and returns them as an array of shape (None, Height, Width, Channels)\n    '''\n    images = []\n    for path in paths:\n        image = load_img(path, target_size=(size, size, 3))\n        image = np.array(image)/255.0 # Normalize image pixel values to be between 0 and 1\n        images.append(image)\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:39:44.014713Z","iopub.execute_input":"2022-04-29T10:39:44.015491Z","iopub.status.idle":"2022-04-29T10:39:44.020962Z","shell.execute_reply.started":"2022-04-29T10:39:44.01545Z","shell.execute_reply":"2022-04-29T10:39:44.019952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>3.4 <span style='color:#FFDB00; font-weight: bold;'>|</span> Function to add noise</h2>  ","metadata":{}},{"cell_type":"code","source":"def add_noise(images, amount=0.1):\n    '''\n    Given an array of images [a shape of (None, Height, Width, Channels)],\n    this function adds gaussian noise to every channel of the images\n    '''\n    # Create a matrix with values with a mean of 0 and standard deviation of \"amount\"\n    noise = np.random.normal(0, amount, images.shape[0]*images.shape[1]*images.shape[2]*images.shape[3]).reshape(images.shape)\n    # Add noise to images\n    noise_img = images+noise\n    return noise_img","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Example usage of functions `open_images` and `add_noise` :","metadata":{}},{"cell_type":"code","source":"image = open_images([train_image_paths[27]])\nnoise_img = add_noise(image, amount=0.2)\n\nfig = plt.figure(figsize=(10, 5))\n# Plot Image\nfig.add_subplot(1, 2, 1)\nplt.axis('off')\nplt.title('Image')\nplt.imshow(image[0])\n# Plot Image with noise\nfig.add_subplot(1, 2, 2)\nplt.axis('off')\nplt.title('Image with noise')\nplt.imshow(noise_img[0])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:05:44.170813Z","iopub.execute_input":"2022-04-29T11:05:44.171516Z","iopub.status.idle":"2022-04-29T11:05:44.440761Z","shell.execute_reply.started":"2022-04-29T11:05:44.17148Z","shell.execute_reply":"2022-04-29T11:05:44.440113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>4 <span style='color:#FFDB00; font-weight: bold;'>|</span> Data Generator</b>","metadata":{}},{"cell_type":"markdown","source":"This generator function returns batches on which the neural network can train on","metadata":{}},{"cell_type":"code","source":"def datagen(paths, size=TRAIN_SIZE, batch_size=5):\n    '''\n    Given an array of images to paths,\n    this function returns batch of images as (noise_image, real_image)\n    '''\n    for x in range(0, len(paths), batch_size):\n        batch_paths = paths[x:x+batch_size]\n        batch_images = open_images(batch_paths, size=size)\n        amount = random.uniform(0,0.2) # Amount of noise = random value between 0 and 0.2\n        noise_images = add_noise(batch_images, amount=amount)\n        yield noise_images, batch_images","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:05:49.573571Z","iopub.execute_input":"2022-04-29T11:05:49.574142Z","iopub.status.idle":"2022-04-29T11:05:49.579541Z","shell.execute_reply.started":"2022-04-29T11:05:49.574105Z","shell.execute_reply":"2022-04-29T11:05:49.578713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>5 <span style='color:#FFDB00; font-weight: bold;'>|</span> Model</b>","metadata":{}},{"cell_type":"markdown","source":"<h2>5.1 <span style='color:#FFDB00; font-weight: bold;'>|</span> Build Model</h2>  ","metadata":{}},{"cell_type":"markdown","source":"The neural network is fully convolutional, so it can be applied on images of any shapes.  \nTo make the model accept variable size inputs, we set the input shape parameter to `(None, None, 3)`","metadata":{}},{"cell_type":"code","source":"image = Input(shape=(None,None,3))\n\n# Encoder\nl1 = Conv2D(64, (3,3), padding='same', activation='relu',\n            activity_regularizer=regularizers.l1(10e-10))(image)     \nl2 = Conv2D(64, (3,3), padding='same', activation='relu',\n            activity_regularizer=regularizers.l1(10e-10))(l1)\n\nl3 = MaxPooling2D(padding='same')(l2)\nl3 = Dropout(0.3)(l3)\nl4 = Conv2D(128, (3,3), padding='same', activation='relu',\n            activity_regularizer=regularizers.l1(10e-10))(l3)\nl5 = Conv2D(128, (3,3), padding='same', activation='relu',\n            activity_regularizer=regularizers.l1(10e-10))(l4)\n\nl6 = MaxPooling2D(padding='same')(l5)\nl7 = Conv2D(256, (3,3), padding='same', activation='relu',\n            activity_regularizer=regularizers.l1(10e-10))(l6)\n\n#Decoder\nl8 = UpSampling2D()(l7)\nl9 = Conv2D(128, (3,3), padding='same', activation='relu',\n           activity_regularizer=regularizers.l1(10e-10))(l8)\nl10 = Conv2D(128, (3,3), padding='same', activation='relu',\n            activity_regularizer=regularizers.l1(10e-10))(l9)\n\nl11 = add([l5,l10])\nl12 = UpSampling2D()(l11)\nl13 = Conv2D(64, (3,3), padding='same', activation='relu',\n            activity_regularizer=regularizers.l1(10e-10))(l12)\nl14 = Conv2D(64, (3,3), padding='same', activation='relu',\n            activity_regularizer=regularizers.l1(10e-10))(l13)\n\nl15 = add([l14,l2])\n\ndecoded = Conv2D(3, (3,3), padding='same', activation='relu',\n                activity_regularizer=regularizers.l1(10e-10))(l15)\nmodel = Model(image, decoded)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:20:17.245887Z","iopub.execute_input":"2022-04-29T10:20:17.246278Z","iopub.status.idle":"2022-04-29T10:20:19.752875Z","shell.execute_reply.started":"2022-04-29T10:20:17.246245Z","shell.execute_reply":"2022-04-29T10:20:19.752186Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T10:20:21.598249Z","iopub.execute_input":"2022-04-29T10:20:21.598851Z","iopub.status.idle":"2022-04-29T10:20:21.616365Z","shell.execute_reply.started":"2022-04-29T10:20:21.598806Z","shell.execute_reply":"2022-04-29T10:20:21.615074Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=False, dpi=70)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-29T11:15:06.650123Z","iopub.execute_input":"2022-04-29T11:15:06.650408Z","iopub.status.idle":"2022-04-29T11:15:06.836913Z","shell.execute_reply.started":"2022-04-29T11:15:06.650375Z","shell.execute_reply":"2022-04-29T11:15:06.836161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.2 <span style='color:#FFDB00; font-weight: bold;'>|</span> Compile Model</h2>  ","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=RMSprop(learning_rate=0.0001),\n             loss='binary_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:44:28.74928Z","iopub.execute_input":"2022-04-28T13:44:28.750087Z","iopub.status.idle":"2022-04-28T13:44:28.762523Z","shell.execute_reply.started":"2022-04-28T13:44:28.750045Z","shell.execute_reply":"2022-04-28T13:44:28.761446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.3 <span style='color:#FFDB00; font-weight: bold;'>|</span> Train Model</h2>  ","metadata":{}},{"cell_type":"markdown","source":"Train model on images of shape `TRAIN_SIZE`, and a batch size of 10","metadata":{}},{"cell_type":"code","source":"batch_size=10\nsteps = int(len(train_image_paths)/batch_size)\nepochs = 3\nfor epoch in range(epochs):\n    model.fit(datagen(train_image_paths, size=TRAIN_SIZE, batch_size=batch_size), epochs=1, steps_per_epoch=steps)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:44:34.610488Z","iopub.execute_input":"2022-04-28T13:44:34.611052Z","iopub.status.idle":"2022-04-28T13:59:52.920621Z","shell.execute_reply.started":"2022-04-28T13:44:34.611011Z","shell.execute_reply":"2022-04-28T13:59:52.918231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.4 <span style='color:#FFDB00; font-weight: bold;'>|</span> Evaluate Model</h2>  ","metadata":{}},{"cell_type":"markdown","source":"Evaluate the model's performance on images of shape `INFERENCE_SIZE`","metadata":{}},{"cell_type":"code","source":"batch_size=10\nsteps = int(len(test_image_paths)/batch_size)\nmodel.evaluate(datagen(test_image_paths, size=INFERENCE_SIZE, batch_size=batch_size), steps=steps)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T13:34:53.350538Z","iopub.execute_input":"2022-04-28T13:34:53.351177Z","iopub.status.idle":"2022-04-28T13:36:52.329906Z","shell.execute_reply.started":"2022-04-28T13:34:53.35114Z","shell.execute_reply":"2022-04-28T13:36:52.329126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>6 <span style='color:#FFDB00; font-weight: bold;'>|</span> Result</b>","metadata":{}},{"cell_type":"code","source":"def plot_results(noise_image, reconstructed_image, image):\n    w = 15\n    h = len(noise_image)*5\n    fig = plt.figure(figsize=(w, h))\n    columns = 3\n    rows = len(noise_image)\n    for i in range(1, rows*columns, columns):\n        fig.add_subplot(rows, columns, i)\n        plt.axis('off')\n        plt.title('Image with noise')\n        plt.imshow(noise_images[int((i-1)/columns)])\n    \n        fig.add_subplot(rows, columns, i+1)\n        plt.axis('off')\n        plt.title('Reconstructed Image')\n        plt.imshow(reconstructed[int((i-1)/columns)])\n        \n        fig.add_subplot(rows, columns, i+2)\n        plt.axis('off')\n        plt.title('Original Image')\n        plt.imshow(images[int((i-1)/columns)])\n    \n    plt.show()\n    \nbatch_size = 7\n\npaths = random.sample(test_image_paths, batch_size)\nimages = open_images(paths, size=INFERENCE_SIZE)\n# Amount of noise = random value between 0.1 and 0.15\namount = random.uniform(0.1,0.15)\nnoise_images = add_noise(images, amount=amount)\nreconstructed = model.predict(noise_images)\n\nplot_results(noise_images, reconstructed, images)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:17:45.481773Z","iopub.execute_input":"2022-04-29T11:17:45.484015Z","iopub.status.idle":"2022-04-29T11:17:47.313456Z","shell.execute_reply.started":"2022-04-29T11:17:45.483975Z","shell.execute_reply":"2022-04-29T11:17:47.312592Z"},"trusted":true},"execution_count":null,"outputs":[]}]}