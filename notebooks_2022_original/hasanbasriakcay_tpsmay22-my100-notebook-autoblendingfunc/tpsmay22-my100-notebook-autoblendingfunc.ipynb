{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nHey, thanks for viewing my Kernel!\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! :)\n\nðŸŽ‰ My 100. notebook! ðŸŽ‰","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\n\nwarnings.simplefilter(\"ignore\")\ntrain = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-may-2022/test.csv\")\nsub = pd.read_csv(\"../input/tabular-playground-series-may-2022/sample_submission.csv\")\ndisplay(train.head())\ndisplay(test.head())\ndisplay(sub.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:59:16.145908Z","iopub.execute_input":"2022-05-08T05:59:16.146397Z","iopub.status.idle":"2022-05-08T05:59:31.57674Z","shell.execute_reply.started":"2022-05-08T05:59:16.146293Z","shell.execute_reply":"2022-05-08T05:59:31.57509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"def create_features(data):\n    object_data_cols = [f\"f_27_{i+1}\" for i in range(10)]\n    object_data = pd.DataFrame(data['f_27'].apply(list).tolist(), columns=object_data_cols)\n    for feature in object_data_cols:\n        object_data[feature] = object_data[feature].apply(ord) - ord('A')\n    \n    data = pd.concat([data, object_data], 1)\n    data[\"unique_characters\"] = data.f_27.apply(lambda s: len(set(s)))\n    \n    ## sum\n    # float\n    data['f_sum_2'] = (data['f_21']+data['f_22'])\n    data['f_sum_3'] = (data['f_23']-data['f_20'])\n    \n    continuous_feat = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_19', 'f_20', 'f_21', 'f_22', \n                       'f_23', 'f_24', 'f_25', 'f_26', 'f_28']\n    \n    data['f_sum']  = data[continuous_feat].sum(axis=1)\n    data['f_min']  = data[continuous_feat].min(axis=1)\n    data['f_max']  = data[continuous_feat].max(axis=1)\n    data['f_std']  = data[continuous_feat].std(axis=1)    \n    data['f_mad']  = data[continuous_feat].mad(axis=1)\n    data['f_mean'] = data[continuous_feat].mean(axis=1)\n    data['f_kurt'] = data[continuous_feat].kurt(axis=1)\n    data['f_count_pos']  = data[continuous_feat].gt(0).count(axis=1)\n    \n    # int\n    data['f_sum_10'] = (data['f_07']-data['f_10'])\n    data['f_sum_13'] = (data['f_08']-data['f_10'])\n    \n    return data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-08T06:01:17.89476Z","iopub.execute_input":"2022-05-08T06:01:17.895632Z","iopub.status.idle":"2022-05-08T06:01:17.906032Z","shell.execute_reply.started":"2022-05-08T06:01:17.895565Z","shell.execute_reply":"2022-05-08T06:01:17.905526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_fe = create_features(train.copy())\ntest_fe = create_features(test.copy())\ntrain_fe.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:01:22.380333Z","iopub.execute_input":"2022-05-08T06:01:22.380705Z","iopub.status.idle":"2022-05-08T06:01:33.851032Z","shell.execute_reply.started":"2022-05-08T06:01:22.380667Z","shell.execute_reply":"2022-05-08T06:01:33.850134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ntrain_tr = pd.DataFrame(scaler.fit_transform(train_fe.drop(['id', 'f_27', \"target\"], 1)), columns=train_fe.drop(['id', 'f_27', \"target\"], 1).columns)\ntest_tr = pd.DataFrame(scaler.transform(test_fe.drop(['id', 'f_27'], 1)), columns=train_fe.drop(['id', 'f_27', \"target\"], 1).columns)\ntrain_tr.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:01:38.870817Z","iopub.execute_input":"2022-05-08T06:01:38.871057Z","iopub.status.idle":"2022-05-08T06:01:41.416736Z","shell.execute_reply.started":"2022-05-08T06:01:38.871032Z","shell.execute_reply":"2022-05-08T06:01:41.416134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"def get_lr_metric(optimizer):\n    def lr(y_true, y_pred):\n        return optimizer._decayed_lr(tf.float32) # I use ._decayed_lr method instead of .lr\n    return lr","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-08T06:01:45.144973Z","iopub.execute_input":"2022-05-08T06:01:45.146416Z","iopub.status.idle":"2022-05-08T06:01:45.152261Z","shell.execute_reply.started":"2022-05-08T06:01:45.146342Z","shell.execute_reply":"2022-05-08T06:01:45.151162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Input, InputLayer, Add, Dropout\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import clone_model\n\ninitial_learning_rate = 0.01\nn_epoch = 200\n\nfeatures = train_fe.drop(['id', 'f_27', 'target'], 1).columns\ndef tf_model():\n    activation = 'swish'\n    inputs = Input(shape=(len(features)))\n    x = Dense(128, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(inputs)\n    #x = Dropout(0.25)(x)\n    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    #x = Dropout(0.25)(x)\n    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    #x = Dropout(0.25)(x)\n    x = Dense(32, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    #x = Dropout(0.25)(x)\n    x = Dense(16, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    x = Dense(8, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    #x = Dropout(0.25)(x)\n    x = Dense(1, #kernel_regularizer=tf.keras.regularizers.l2(1e-6),\n              activation='sigmoid',\n             )(x)\n    model = Model(inputs, x)\n    \n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n                    initial_learning_rate,\n                    decay_steps=n_epoch/2,\n                    decay_rate=0.995,\n                    staircase=True)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=0.1)\n    lr_metric = get_lr_metric(optimizer)\n    \n    model.compile(optimizer=optimizer,\n                  loss=tf.keras.losses.BinaryCrossentropy(), metrics=[lr_metric])\n    return model","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-08T06:02:11.891937Z","iopub.execute_input":"2022-05-08T06:02:11.892197Z","iopub.status.idle":"2022-05-08T06:02:18.414563Z","shell.execute_reply.started":"2022-05-08T06:02:11.892172Z","shell.execute_reply":"2022-05-08T06:02:18.413752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(tf_model(), show_layer_names=False, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:02:38.035042Z","iopub.execute_input":"2022-05-08T06:02:38.035488Z","iopub.status.idle":"2022-05-08T06:02:39.145444Z","shell.execute_reply.started":"2022-05-08T06:02:38.035461Z","shell.execute_reply":"2022-05-08T06:02:39.144176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Automated Blending Function","metadata":{}},{"cell_type":"code","source":"def automated_blending(model_ori, X, y, X_test, nfold=10, plot=True, figsize=(16, 8), tf=False, verbose=0):\n    from sklearn.model_selection import StratifiedKFold\n    from sklearn.base import clone\n    from sklearn.metrics import roc_auc_score\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    sns.set()\n    \n    train_preds = []\n    train_targets = []\n    auc = []\n    skf = StratifiedKFold(n_splits=nfold)\n    test_preds = 0\n    if tf:\n        ncols=5\n        nrows=round(nfold/ncols)\n        fig, axes = plt.subplots(nrows, ncols, figsize=(16, round(nrows*16/ncols)))\n        col_i, row_i = 0, 0\n    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n        print(f\"Fold: {fold+1},\", end=' ')\n        X_train, X_valid = X.iloc[train_idx, :], X.iloc[test_idx, :]\n        y_train, y_valid = y.iloc[train_idx, :], y.iloc[test_idx, :]\n        \n        if tf:\n            model = model_ori()\n        else:\n            model = clone(model_ori)\n            \n        try:\n            if tf:\n                es = EarlyStopping(monitor=\"val_loss\",\n                                   patience=24, \n                                   verbose=verbose,\n                                   mode=\"min\", \n                                   restore_best_weights=True)\n                callbacks = [es]\n                history = model.fit(X_train, y_train, \n                                    validation_data=(X_valid, y_valid), \n                                    epochs=n_epoch,\n                                    verbose=verbose,\n                                    batch_size=4096,\n                                    shuffle=True,\n                                    callbacks=callbacks)\n                preds = model.predict(X_valid)\n                pd.DataFrame(history.history, columns=[\"loss\", \"val_loss\"]).plot(ax=axes[row_i][col_i])\n                col_i += 1\n                if col_i == ncols:\n                    col_i = 0\n                    row_i += 1\n            else:\n                model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=20, verbose=verbose)\n                preds = model.predict_proba(X_valid)\n        except:\n            print(\"Warnings, model has not eval func...\")\n            model.fit(X_train, y_train)\n            preds = model.predict_proba(X_valid)\n        \n        if tf:\n            auc_score = roc_auc_score(y_valid.values, preds)\n\n            auc.append(auc_score/nfold)\n            train_preds.extend(preds[:, 0])\n            train_targets.extend(y_valid.values)\n\n            tpreds = model.predict(X_test)\n            test_preds += tpreds/nfold\n        else:\n            auc_score = roc_auc_score(y_valid.values, preds[:, 1])\n\n            auc.append(auc_score/nfold)\n            train_preds.extend(preds[:, 1])\n            train_targets.extend(y_valid.values)\n\n            tpreds = model.predict_proba(X_test)\n            test_preds += tpreds[:, 1]/nfold\n        print(f'auc: {round(auc_score, 5)}')\n    \n    print(f\"auc mean: {sum(auc)}\")\n    df_preds = pd.DataFrame()\n    df_preds['pred'] = train_preds\n    df_preds['label'] = np.array(train_targets).reshape(-1)\n    \n    zero_mean = df_preds.loc[df_preds['label']==0, 'pred'].mean()\n    zero_median = df_preds.loc[df_preds['label']==0, 'pred'].median()\n    \n    one_mean = df_preds.loc[df_preds['label']==1, 'pred'].mean()\n    one_median = df_preds.loc[df_preds['label']==1, 'pred'].median()\n    \n    \n    if plot:\n        fig, ax = plt.subplots(figsize=figsize)\n        palette ={0: \"blue\", 1: \"red\"}\n        sns.kdeplot(data=df_preds, x='pred', hue='label', ax=ax, palette=palette)\n        plt.axvline(x=zero_mean, color='blue', label=f'mean-zero-{round(zero_mean, 3)}', ls='--')\n        plt.axvline(x=zero_median, color='blue', label=f'median-zero-{round(zero_median, 3)}', ls=':')\n        \n        plt.axvline(x=one_mean, color='red', label=f'mean-one-{round(one_mean, 3)}', ls='--')\n        plt.axvline(x=one_median, color='red', label=f'median-one-{round(one_median, 3)}', ls=':')\n        plt.legend()\n        plt.show()\n    \n    return test_preds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-08T06:02:58.863176Z","iopub.execute_input":"2022-05-08T06:02:58.863933Z","iopub.status.idle":"2022-05-08T06:02:58.898838Z","shell.execute_reply.started":"2022-05-08T06:02:58.863886Z","shell.execute_reply":"2022-05-08T06:02:58.897829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\ntest_preds = automated_blending(tf_model, \n                                train_tr, train_fe[['target']], \n                                test_tr, nfold=15, tf=True, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T06:03:09.633571Z","iopub.execute_input":"2022-05-08T06:03:09.634059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_sub1 = pd.read_csv(\"../input/tpsmay22-keras-quickstart/submission.csv\")\npre_sub2 = pd.read_csv(\"../input/tps-may22-eda-neuronal-nets/my_submission_050722.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy\npre_sub2['target'] = scipy.stats.rankdata(pre_sub2['target'])\nsub['target'] = scipy.stats.rankdata(test_preds)\nsub['target'] = sub['target'] * 0.3 + pre_sub1['target'] * 0.3 + pre_sub2['target'] * 0.4\nsub.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References\n1. [notebook](https://www.kaggle.com/code/ambrosm/tpsmay22-keras-quickstart/notebook?scriptVersionId=94617937)\n2. [notebook](https://www.kaggle.com/code/cv13j0/tps-may22-eda-neuronal-nets/notebook?scriptVersionId=95032660)","metadata":{}}]}