{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Note (Its just a script for Training. You might need some processing to run on Kaggle.)","metadata":{}},{"cell_type":"markdown","source":"# Imports|","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2022-04-24T04:45:42.652183Z","iopub.execute_input":"2022-04-24T04:45:42.652757Z","iopub.status.idle":"2022-04-24T04:45:51.334869Z","shell.execute_reply.started":"2022-04-24T04:45:42.652705Z","shell.execute_reply":"2022-04-24T04:45:51.333774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport gc\ngc.enable()\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport cv2\nimport albumentations as A\nimport time\nimport os\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport segmentation_models_pytorch as smp\nfrom torch.cuda import amp\nscaler = amp.GradScaler()\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nimport numba\nimport numpy as np\nfrom math import sqrt\nfrom scipy.spatial.distance import directed_hausdorff\nfrom scipy.ndimage import convolve\nfrom scipy.ndimage.morphology import distance_transform_edt as edt\n\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport gc\nfrom sklearn.model_selection import KFold\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T04:45:51.337108Z","iopub.execute_input":"2022-04-24T04:45:51.337345Z","iopub.status.idle":"2022-04-24T04:45:51.347281Z","shell.execute_reply.started":"2022-04-24T04:45:51.337319Z","shell.execute_reply":"2022-04-24T04:45:51.346265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONFIG","metadata":{}},{"cell_type":"code","source":"CFG = {\n    'fold' : 0, \n    'batch_size' : 8,\n    'image_size' : 256,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    'init_lr' : 1e-3,\n    'warmup_factor' : 10,\n    'warmup_epo' : 3,\n    'n_epochs' : 25,\n    'num_workers' : 4,\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-24T04:47:26.558147Z","iopub.execute_input":"2022-04-24T04:47:26.558434Z","iopub.status.idle":"2022-04-24T04:47:26.563878Z","shell.execute_reply.started":"2022-04-24T04:47:26.558407Z","shell.execute_reply":"2022-04-24T04:47:26.563083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helping Functons","metadata":{}},{"cell_type":"code","source":"def hd_dist(preds, targets):\n    preds_coords = np.argwhere(preds) / np.array(preds.shape)\n    targets_coords = np.argwhere(targets) / np.array(preds.shape)\n    haussdorf_dist = directed_hausdorff(preds_coords, targets_coords)[0]\n    return haussdorf_dist\n\ndef dice(im1, im2, empty_score=1.0):\n\n    im1 = np.asarray(im1).astype(np.bool)\n    im2 = np.asarray(im2).astype(np.bool)\n\n    if im1.shape != im2.shape:\n        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n\n    im_sum = im1.sum() + im2.sum()\n    if im_sum == 0:\n        return empty_score\n\n    # Compute Dice coefficient\n    intersection = np.logical_and(im1, im2)\n\n    return 2. * intersection.sum() / im_sum\n\nclass GradualWarmupScheduler(_LRScheduler):\n    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n    Args:\n        optimizer (Optimizer): Wrapped optimizer.\n        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n        total_epoch: target learning rate is reached at total_epoch, gradually\n        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n    \"\"\"\n\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        self.multiplier = multiplier\n        if self.multiplier < 1.:\n            raise ValueError('multiplier should be greater thant or equal to 1.')\n        self.total_epoch = total_epoch\n        self.after_scheduler = after_scheduler\n        self.finished = False\n        super(GradualWarmupScheduler, self).__init__(optimizer)\n\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_last_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\n    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n        if epoch is None:\n            epoch = self.last_epoch + 1\n        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n        if self.last_epoch <= self.total_epoch:\n            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n                param_group['lr'] = lr\n        else:\n            if epoch is None:\n                self.after_scheduler.step(metrics, None)\n            else:\n                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n\n    def step(self, epoch=None, metrics=None):\n        if type(self.after_scheduler) != ReduceLROnPlateau:\n            if self.finished and self.after_scheduler:\n                if epoch is None:\n                    self.after_scheduler.step(None)\n                else:\n                    self.after_scheduler.step(epoch - self.total_epoch)\n                self._last_lr = self.after_scheduler.get_last_lr()\n            else:\n                return super(GradualWarmupScheduler, self).step(epoch)\n        else:\n            self.step_ReduceLROnPlateau(metrics, epoch)\n            \nclass TractDataset(Dataset):\n    def __init__(self, df, n_chans = 3, transform=None):\n        self.df = df\n        self.mask_path = df['mask_path']\n        self.image_path = df['image_path']\n        self.transform = transform\n        self.n_chans = n_chans\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n\n        img = Image.open(self.image_path[idx]).convert('RGB')\n        img = np.array(img)\n        mask = np.load(self.mask_path[idx])\n        if self.transform is not None:\n            aug = self.transform(image=img, mask=mask)\n            img = aug['image']\n            mask = aug['mask']\n        img = img / 255.0\n        img = np.transpose(img, (2, 0, 1))\n        mask = np.transpose(mask, (2, 0, 1))\n        \n        return torch.tensor(img, dtype=torch.float), torch.tensor(mask, dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T04:44:41.107219Z","iopub.execute_input":"2022-04-24T04:44:41.107484Z","iopub.status.idle":"2022-04-24T04:44:41.13189Z","shell.execute_reply.started":"2022-04-24T04:44:41.107454Z","shell.execute_reply":"2022-04-24T04:44:41.131118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Loss Functions","metadata":{}},{"cell_type":"code","source":"bce_loss = nn.BCEWithLogitsLoss()\nlovasz_loss = smp.losses.LovaszLoss(mode='binary', per_image=False)\ntversky_loss = smp.losses.TverskyLoss(mode='binary', log_loss=False, from_logits=True)\n\ndef bce_lovasz(output, target):\n    return (0.5 * bce_loss(output, target)) + (0.5 * lovasz_loss(output, target))\n\ndef bce_lovasz_tversky_loss(output, target):\n    return (0.25 * bce_loss(output, target)) + (0.25 * lovasz_loss(output, target)) + (0.5 * tversky_loss(output, target))\n\ndef get_loss(epoch):\n    if epoch <= 5:\n        return bce_lovasz\n    else:\n        return bce_lovasz_tversky_loss","metadata":{"execution":{"iopub.status.busy":"2022-04-24T04:44:42.246505Z","iopub.execute_input":"2022-04-24T04:44:42.247479Z","iopub.status.idle":"2022-04-24T04:44:42.255517Z","shell.execute_reply.started":"2022-04-24T04:44:42.247413Z","shell.execute_reply":"2022-04-24T04:44:42.254716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(epoch, model, loader, optimizer):\n\n    model.train()\n    loss_func = get_loss(epoch)\n\n    train_loss = []\n    bar = tqdm(loader, total=len(loader))\n    \n    for (data, target) in bar:\n        \n        data = data.to(CFG['device'])\n        target = target.to(CFG['device'])\n        \n        optimizer.zero_grad()\n        \n        with amp.autocast(False):\n            output = model(data)\n            \n            loss = loss_func(output, target)\n        \n        scaler.scale(loss).backward() \n        scaler.step(optimizer)\n        scaler.update()\n        \n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n        \n    return model, np.mean(train_loss)\n\n\n# In[7]:\n\n\ndef valid_epoch(epoch, model, loader):\n\n    loss_func = get_loss(epoch)\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    TARGETS = []\n    \n    with torch.no_grad():\n        \n        for (data, targets) in tqdm(loader, total=len(loader)):\n            \n            data, targets = data.to(CFG['device']), targets.to(CFG['device'])\n            \n            output = model(data)\n            \n            loss = loss_func(output, targets)\n\n            val_loss.append(loss.item())\n            \n            LOGITS.append(output.cpu())\n            TARGETS.append(targets.cpu())\n            \n    val_loss = np.mean(val_loss)\n    LOGITS = torch.cat(LOGITS)\n    TARGETS = torch.cat(TARGETS).numpy()\n    \n    return val_loss, LOGITS, TARGETS","metadata":{"execution":{"iopub.status.busy":"2022-04-24T04:44:43.168964Z","iopub.execute_input":"2022-04-24T04:44:43.169233Z","iopub.status.idle":"2022-04-24T04:44:43.178834Z","shell.execute_reply.started":"2022-04-24T04:44:43.169204Z","shell.execute_reply":"2022-04-24T04:44:43.178203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"train.csv\")\n\ndf[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\ndf[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n# 2. Get Day as a column\ndf[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\ndf[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n# 3. Get Slice Identifier as a column\ndf[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\nTRAIN_DIR = 'train'\n# Get all training images\nall_train_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n\np = []\nx = all_train_images[0].rsplit(\"/\", 4)[0]\nfor i in range(0, df.shape[0]):\n    p.append(os.path.join(x, df[\"case_id_str\"].values[i], df[\"case_id_str\"].values[i]+\"_\"+df[\"day_num_str\"].values[i], \"scans\", df[\"slice_id\"].values[i]))\ndf[\"_partial_ident\"] = p\n\np = []\nfor i in range(0, len(all_train_images)):\n    p.append(str(all_train_images[i].rsplit(\"_\",4)[0]))\n    \n_tmp_merge_df = pd.DataFrame()\n_tmp_merge_df['_partial_ident'] = p\n_tmp_merge_df['f_path'] = all_train_images\n\ndf = df.merge(_tmp_merge_df, on=\"_partial_ident\").drop(columns=[\"_partial_ident\"])\n\n# 5. Get slice dimensions from filepath (int in pixels)\ndf[\"slice_h\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\ndf[\"slice_w\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n\n# 6. Pixel spacing from filepath (float in mm)\ndf[\"px_spacing_h\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[3]))\ndf[\"px_spacing_w\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[4]))\n\ndf1 = df[df.index % 3 == 0]\ndf2 = df[df.index % 3 == 1]\ndf3 = df[df.index % 3 == 2]\ndf = df1.copy()\ndf.pop('class')\ngc.collect()\n\nx = df1.pop('segmentation')\nx1 = df2.pop('segmentation')\nx2 = df3.pop('segmentation')\ndf['large_bowel_segmentation'] = x.values\ndf['small_bowel_segmentation'] = x1.values\ndf['stomach_segmentation'] = x2.values\ndf.pop('segmentation')\ndel x, x2, x1, df1, df2, df3\ngc.collect()\ndf = df.reset_index(drop=True)\n\nun, co = np.unique(df['case_id'], return_counts=True)\npdf = pd.DataFrame()\npdf['cases'] = un\npdf['count'] = co\n\nskf = KFold(n_splits=5)\ni = 0\nfor fold, (train_index, test_index) in enumerate(skf.split(un, co)):\n    pdf.loc[test_index, \"kfold\"] = fold\n    i += 1\n    \ndf['kfold'] = -1\nfor i in range(0, 5):\n    df.loc[df[df['case_id'].isin(pdf[pdf['kfold'] == i]['cases'].values)].index, 'kfold'] = i\nprint (df['kfold'].value_counts())\n\nrle_paths = []\nimage_paths = []\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    rle_paths.append(os.path.join(\"train_masks\", row['id'] + '.npy'))\n    image_paths.append(os.path.join(\"train_images\", row['id'] + '.png'))\ndf['mask_path'] = rle_paths\ndf['image_path'] = image_paths","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformations","metadata":{}},{"cell_type":"code","source":"transform_train = A.Compose([A.Resize(CFG['image_size'], CFG['image_size'], interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(), \n                     A.GridDistortion(p=0.2), A.GaussNoise()])\ntransform_val = A.Compose([A.Resize(CFG['image_size'], CFG['image_size'], interpolation=cv2.INTER_NEAREST)])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train One Fold Function","metadata":{}},{"cell_type":"code","source":"def train_one_fold(fold):\n\n    train_set = TractDataset(df[df['kfold']!=fold].reset_index(drop=True), 3, transform_train)\n    val_set = TractDataset(df[df['kfold']==fold].reset_index(drop=True), 3, transform_val)\n\n    train_loader = DataLoader(train_set, batch_size=CFG['batch_size'], shuffle=True, num_workers=CFG['num_workers'])\n    val_loader = DataLoader(val_set, batch_size=CFG['batch_size'], shuffle=False, num_workers=CFG['num_workers'])      \n\n\n    model = smp.DeepLabV3Plus('efficientnet-b1', encoder_weights='imagenet', classes=3, activation=None)\n    model = model.to(CFG['device'])\n    model = nn.DataParallel(model)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG[\"init_lr\"]/CFG[\"warmup_factor\"])\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, CFG[\"n_epochs\"]-CFG['warmup_epo'])\n    scheduler = GradualWarmupScheduler(optimizer, multiplier=CFG[\"warmup_factor\"], total_epoch=CFG[\"warmup_epo\"], after_scheduler=scheduler_cosine)\n\n\n    max_vmetric = 0\n\n    model_file = f'deep_lab_best_fold_{fold}.pth'\n    final_file = f'deep_lab_final_fold_{fold}.pth'\n\n    for epoch in range(1, CFG['n_epochs']+1):\n\n        print(time.ctime(), 'Epoch:', epoch)\n        print (\"Training\")\n        model, train_loss = train_epoch(epoch, model, train_loader, optimizer)        \n        scheduler.step(epoch-1)\n        print (\"Validating\")\n        val_loss, LOGITS, TARGETS = valid_epoch(epoch, model, val_loader)\n        LOGITS = torch.sigmoid(LOGITS.cpu()).numpy()\n        LOGITS = np.round(LOGITS)\n\n        gc.collect()\n\n        dice1 = []\n        dice2 = []\n        dice3 = []\n\n        print (\"calculating validation scores\")\n        for i in tqdm(range(0, LOGITS.shape[0]), total=LOGITS.shape[0]):\n            dice1.append(dice(LOGITS[i, 0, :, :], TARGETS[i, 0, :, :]))\n            dice2.append(dice(LOGITS[i, 1, :, :], TARGETS[i, 1, :, :]))\n            dice3.append(dice(LOGITS[i, 2, :, :], TARGETS[i, 2, :, :]))\n\n \n        dice1 = np.mean(dice1)\n        dice2 = np.mean(dice2)\n        dice3 = np.mean(dice3)\n\n\n        h_dists1 = 1 - hd_dist(LOGITS[:, 0, :, :], TARGETS[:, 0, :, :])\n        h_dists2 = 1 - hd_dist(LOGITS[:, 1, :, :], TARGETS[:, 1, :, :])\n        h_dists3 = 1 - hd_dist(LOGITS[:, 2, :, :], TARGETS[:, 2, :, :])\n\n        vdice = (dice1 + dice2 + dice3) / 3.0\n        vhd = (h_dists1 + h_dists2 + h_dists3) / 3.0\n\n        vmetric = (0.4 * vdice) + (0.6 * vhd)\n        \n        content = time.ctime() + ' ' + f'Fold {fold} Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.4f}, valid loss: {(val_loss):.4f}, val_dice_large: {dice1:.5f}, val_dice_small: {dice2:.5f}, val_dice_stomach: {dice3:.5f}, val_dice: {vdice:.5f}, val_hd_large: {h_dists1:.5f}, val_hd_small: {h_dists2:.5f}, val_hd_stomach: {h_dists3:.5f}, val_hd: {vhd:.5f}, val_hd_dice: {vmetric:.5f}.'\n        print(content)\n\n        with open(f'deep_lab_log_{fold}_fold.txt', 'a') as appender:\n            appender.write(content + '\\n')\n\n        if max_vmetric < vmetric:\n            print('Metric Increased ({:.6f} --> {:.6f}).  Saving model ...'.format(max_vmetric, vmetric))\n            torch.save(model.state_dict(), model_file)\n            max_vmetric = vmetric\n\n    torch.save(model.state_dict(), final_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T04:48:07.06654Z","iopub.execute_input":"2022-04-24T04:48:07.066877Z","iopub.status.idle":"2022-04-24T04:48:07.086368Z","shell.execute_reply.started":"2022-04-24T04:48:07.066841Z","shell.execute_reply":"2022-04-24T04:48:07.085388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(0, 2):\n    train_one_fold(fold)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}