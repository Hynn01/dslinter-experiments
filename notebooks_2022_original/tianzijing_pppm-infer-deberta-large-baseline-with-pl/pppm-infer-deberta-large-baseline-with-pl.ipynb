{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Modified from https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference\n#### Train notebook: https://www.kaggle.com/tianzijing/pppm-train-deberta-large-baseline-with-pl/edit","metadata":{}},{"cell_type":"code","source":"!pip install ../input/pytorchlightning160/pytorch_lightning-1.6.0-py3-none-any.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T02:04:52.326292Z","iopub.execute_input":"2022-04-27T02:04:52.326841Z","iopub.status.idle":"2022-04-27T02:05:02.768845Z","shell.execute_reply.started":"2022-04-27T02:04:52.326748Z","shell.execute_reply":"2022-04-27T02:05:02.767814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Library","metadata":{}},{"cell_type":"code","source":"import os\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset transformers')\nos.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels-dataset tokenizers')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:02.772371Z","iopub.execute_input":"2022-04-27T02:05:02.772628Z","iopub.status.idle":"2022-04-27T02:05:22.74417Z","shell.execute_reply.started":"2022-04-27T02:05:02.772598Z","shell.execute_reply":"2022-04-27T02:05:22.743359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nimport pytorch_lightning as pl\nprint(f\"pytorch_lightning.__version__: {pl.__version__}\")\n\n# import tokenizers\nimport transformers\n# print(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:22.745611Z","iopub.execute_input":"2022-04-27T02:05:22.746148Z","iopub.status.idle":"2022-04-27T02:05:30.438986Z","shell.execute_reply.started":"2022-04-27T02:05:22.746109Z","shell.execute_reply":"2022-04-27T02:05:30.435866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CFG","metadata":{}},{"cell_type":"code","source":"class CFG:\n    ## 常规设置\n#     data_dir = '/home/tzj/data/pppm-data/us-patent-phrase-to-phrase-matching'\n    data_dir = '../input/us-patent-phrase-to-phrase-matching'\n    output_dir = './'\n\n    weight_path = [\n        '../input/pppm-single'\n    ]\n    weight_scores = [\n    ]\n    t = 0.01\n    cpc_dir = ''\n    cpc_data_path = '../input/cpc-texts/cpc_texts.pth'\n\n    debug = False\n\n    seed = 6001\n    n_fold = 4\n    trn_fold = [0, 1, 2, 3]\n\n    ## 数据设置\n    num_workers = 4\n    batch_size = 16\n    max_len = 512\n    pin_memory = True\n    target_size = 1\n\n    ## 模型设置\n    model = \"../input/deberta-v3-large/deberta-v3-large\"\n#     model = '/home/tzj/pretrained_models/en-deberta-v3-large'\n    fgm = False\n    label_smooth = False\n    smoothing = 0.1\n\n    fc_dropout = 0.2","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.441623Z","iopub.execute_input":"2022-04-27T02:05:30.441963Z","iopub.status.idle":"2022-04-27T02:05:30.449025Z","shell.execute_reply.started":"2022-04-27T02:05:30.441924Z","shell.execute_reply":"2022-04-27T02:05:30.448368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.458865Z","iopub.execute_input":"2022-04-27T02:05:30.459882Z","iopub.status.idle":"2022-04-27T02:05:30.464831Z","shell.execute_reply.started":"2022-04-27T02:05:30.459839Z","shell.execute_reply":"2022-04-27T02:05:30.463836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### get_cpc_data","metadata":{}},{"cell_type":"code","source":"def get_cpc_texts(cpc_dir):\n    # 找出每个 context 对应的 CPC 描述，包括大类描述和子类描述\n    contexts = []\n    pattern = '[A-Z]\\d+'   # 找出 context， 如：A47\n    for file_name in os.listdir(os.path.join(cpc_dir, 'CPCSchemeXML202105')):\n        result = re.findall(pattern, file_name)\n        if result:\n            contexts.append(result)\n    contexts = sorted(set(sum(contexts, [])))  # 将列表拼接，并去重排序\n    results = {}\n    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n        with open(os.path.join(cpc_dir, f'CPCTitleList202202/cpc-section-{cpc}_20220201.txt')) as f:\n            s = f.read()\n        pattern = f'{cpc}\\t\\t.+'\n        result = re.findall(pattern, s)\n        cpc_result = result[0].lstrip(pattern)  # 找出每个大类的描述\n        for context in [c for c in contexts if c[0] == cpc]:\n            pattern = f'{context}\\t\\t.+'\n            result = re.findall(pattern, s)\n            cpc_sub_result = result[0].lstrip(pattern) # 找出每个子类的描述\n            results[context] = cpc_result + '. ' + cpc_sub_result\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.466611Z","iopub.execute_input":"2022-04-27T02:05:30.467246Z","iopub.status.idle":"2022-04-27T02:05:30.479512Z","shell.execute_reply.started":"2022-04-27T02:05:30.467206Z","shell.execute_reply":"2022-04-27T02:05:30.478721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DataModule","metadata":{}},{"cell_type":"markdown","source":"### CV split","metadata":{}},{"cell_type":"code","source":"def CV_group_split(dataset, n_splits=5, shuffle=True, seed=0, debug=False, debug_size=1000):\n    # 本次比赛的score是离散型的分值，因此可以看成分类问题（回归问题也可以），因此将得分映射成 5 个类别，并根据类别标签分层采样\n    dataset['score_map'] = dataset['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n    Fold = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=seed)\n\n    for n, (train_index, val_index) in enumerate(Fold.split(dataset, dataset['score_map'])):\n        dataset.loc[val_index, 'fold'] = int(n)\n    dataset['fold'] = dataset['fold'].astype(int)\n    if debug:\n        dataset = dataset.sample(n=debug_size, random_state=seed).reset_index(drop=True)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.483171Z","iopub.execute_input":"2022-04-27T02:05:30.483904Z","iopub.status.idle":"2022-04-27T02:05:30.493328Z","shell.execute_reply.started":"2022-04-27T02:05:30.483837Z","shell.execute_reply":"2022-04-27T02:05:30.492504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get Tokenizer","metadata":{}},{"cell_type":"code","source":"def get_tokenizer(tokenizer_path):\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n    return tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.494972Z","iopub.execute_input":"2022-04-27T02:05:30.495586Z","iopub.status.idle":"2022-04-27T02:05:30.505495Z","shell.execute_reply.started":"2022-04-27T02:05:30.495549Z","shell.execute_reply":"2022-04-27T02:05:30.504652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PPPMDataModule(pl.LightningDataModule):\n    def __init__(self, config, prepare_train=True, prepare_test=True):\n        super().__init__()\n        self.prepare_data_per_node = False\n        self.seed = config.seed\n        self.debug = config.debug\n        self.debug_size = 0 if self.debug == False else config.debug_size\n        self.shuffle = (self.debug == False)\n        self.batch_size = config.batch_size\n        self.pin_memory = config.pin_memory\n        self.num_workers = config.num_workers\n        self.max_len = config.max_len\n        self.data_dir = config.data_dir\n        self.output_dir = config.output_dir\n        self.cpc_dir = config.cpc_dir\n        self.cpc_data_path = config.cpc_data_path\n        self.n_fold = config.n_fold\n\n        self.tokenizer = get_tokenizer(config.model)\n\n        self.prepare_train = prepare_train\n        self.prepare_test = prepare_test\n\n    def set_trn_fold(self, trn_fold):\n        self.trn_fold = trn_fold\n\n    def load_train(self):\n        train = pd.read_csv(Path(self.data_dir) / 'train.csv')\n        if self.cpc_data_path != '':\n            cpc_texts = torch.load(self.cpc_data_path)\n        else:\n            cpc_texts = get_cpc_texts(self.cpc_dir)\n            torch.save(cpc_texts, Path(self.output_dir) / 'cpc_texts.pth')\n        train['context_text'] = train['context'].map(cpc_texts)\n        train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]' + train['context_text']\n        return train\n\n    def load_test(self):\n        test = pd.read_csv(Path(self.data_dir) / 'test.csv')\n        submission = pd.read_csv(Path(self.data_dir) / 'sample_submission.csv')\n        if self.cpc_data_path != '':\n            cpc_texts = torch.load(self.cpc_data_path)\n        else:\n            cpc_texts = get_cpc_texts(self.cpc_dir)\n            torch.save(cpc_texts, Path(self.output_dir) / 'cpc_texts.pth')\n        test['context_text'] = test['context'].map(cpc_texts)\n        test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]' + test['context_text']\n        return test, submission\n\n    def calculate_max_len(self, dataset):\n        dataset['text'].fillna('')\n        tqdm.pandas(desc=\"text_lens\")\n        text_lens = dataset['text'].progress_apply(\n            lambda x: len(self.tokenizer(x, add_special_tokens=False)['input_ids']))\n        max_len_text = text_lens.max()\n        return max_len_text + 2  # text 包括了 anchor + '[SEP]' + target + '[SEP]' + context_text，还要加上开头 ’[CLS]'，结尾 '[SEP]'\n\n    def prepare_data(self):\n        if self.prepare_train == True:\n            train = self.load_train()\n            # 将数据切分成 n 折\n            train = CV_group_split(train, self.n_fold, self.shuffle, self.seed, self.debug, self.debug_size)\n            self.train_max_len = self.calculate_max_len(train)\n            self.train = train\n            self.prepare_train = False\n            print('Train data prepared!')\n\n        if self.prepare_test == True:\n            self.test, self.submission = self.load_test()\n            self.test_max_len = self.calculate_max_len(self.test)\n            self.prepare_test = False\n            print('Test data prepared!')\n\n    def setup(self, stage='fit'):\n        if stage == 'fit':\n            self.build_fit_dataset(trn_fold=self.trn_fold)\n\n        elif stage == 'test':\n            self.build_test_dataset()\n\n        elif stage == 'predict':\n            self.build_predict_dataset()\n\n    def build_fit_dataset(self, trn_fold=None):\n        df = self.train\n        if trn_fold != None:\n            self.train_df = df[df['fold'] != trn_fold].reset_index(drop=True)\n            self.val_df = df[df['fold'] == trn_fold].reset_index(drop=True)\n            self.train_dataset = PPPMDataset(self.train_df, self.tokenizer, self.train_max_len)\n            self.val_dataset = PPPMDataset(self.val_df, self.tokenizer, self.train_max_len)\n\n    def build_test_dataset(self):\n        self.test_dataset = PPPMInferDataset(self.test, self.tokenizer, self.test_max_len)\n\n    def build_predict_dataset(self):\n        self.predict_dataset = PPPMInferDataset(self.test, self.tokenizer, self.test_max_len)\n\n    def train_dataloader(self):\n        loader = DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers,\n                            pin_memory=self.pin_memory, shuffle=self.shuffle)\n        return loader\n\n    def val_dataloader(self):\n        loader = DataLoader(self.val_dataset, batch_size=self.batch_size * 4, num_workers=self.num_workers,\n                            shuffle=False)\n        return loader\n\n    def test_dataloader(self):\n        loader = DataLoader(self.test_dataset, batch_size=self.batch_size * 4, num_workers=self.num_workers,\n                            shuffle=False)\n        return loader\n\n    def predict_dataloader(self):\n        loader = DataLoader(self.predict_dataset, batch_size=self.batch_size * 4, num_workers=self.num_workers,\n                            shuffle=False)\n        return loader\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.507182Z","iopub.execute_input":"2022-04-27T02:05:30.507714Z","iopub.status.idle":"2022-04-27T02:05:30.547712Z","shell.execute_reply.started":"2022-04-27T02:05:30.507677Z","shell.execute_reply":"2022-04-27T02:05:30.546939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"markdown","source":"### Prepare inputs","metadata":{}},{"cell_type":"code","source":"def tokenize(tokenizer, text, max_len=512, return_offsets_mapping=False):\n    inputs = tokenizer(\n        text, \n        add_special_tokens=True,  # cls, sep\n        max_length=max_len,\n        padding='max_length',\n        return_offsets_mapping=return_offsets_mapping)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.549349Z","iopub.execute_input":"2022-04-27T02:05:30.550153Z","iopub.status.idle":"2022-04-27T02:05:30.558478Z","shell.execute_reply.started":"2022-04-27T02:05:30.550101Z","shell.execute_reply":"2022-04-27T02:05:30.557502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PPPMInferDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        super().__init__()\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        single_data = self.df.iloc[index]\n        inputs = tokenize(self.tokenizer, single_data['text'], self.max_len)\n        return inputs\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.560038Z","iopub.execute_input":"2022-04-27T02:05:30.5606Z","iopub.status.idle":"2022-04-27T02:05:30.56828Z","shell.execute_reply.started":"2022-04-27T02:05:30.560564Z","shell.execute_reply":"2022-04-27T02:05:30.567404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.569918Z","iopub.execute_input":"2022-04-27T02:05:30.570526Z","iopub.status.idle":"2022-04-27T02:05:30.578374Z","shell.execute_reply.started":"2022-04-27T02:05:30.570476Z","shell.execute_reply":"2022-04-27T02:05:30.577481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class LabelSmoothLoss(nn.Module):\n#     def __init__(self, smoothing=0.0, loss_func=nn.BCEWithLogitsLoss(reduction='sum')):\n#         super(LabelSmoothLoss, self).__init__()\n#         self.smoothing = smoothing\n#         self.loss_func = loss_func\n\n#     def forward(self, inputs, target):\n#         # inputs为未经过激活的logits\n#         #target为数值时才使用scatter_， 此处target为one-hot\n#         '''\n#         log_prob = F.log_softmax(inputs, dim=-1)\n#         weight = inputs.new_ones(inputs.size()) * self.smoothing / (inputs.size(-1) - 1.)\n#         weight.scatter_(-1, target.unsqueeze(-1), (1. - self.smoothing))\n#         loss = (-weight * log_prob).sum(dim=-1).mean()'''\n#         '''\n#         log_prob = F.log_softmax(inputs, dim=-1)\n#         # 由于将多标签看为多个二分类，因此不用除以类别数\n#         weight = inputs.new_ones(inputs.size()) * self.smoothing\n#         weight[target==1] = 1. - self.smoothing\n#         loss = (-weight * log_prob).sum(dim=-1).mean()'''\n\n#         weight = inputs.new_ones(inputs.size()) * self.smoothing\n#         weight[target == 1] = 1. - self.smoothing\n#         loss = self.loss_func(inputs, weight)\n#         return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.580063Z","iopub.execute_input":"2022-04-27T02:05:30.580678Z","iopub.status.idle":"2022-04-27T02:05:30.59086Z","shell.execute_reply.started":"2022-04-27T02:05:30.580638Z","shell.execute_reply":"2022-04-27T02:05:30.590026Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FGM():\n    \"\"\"\n    定义对抗训练方法FGM,对模型embedding参数进行扰动\n    \"\"\"\n    def __init__(self, model, epsilon=0.25):\n        self.model = model\n        self.epsilon = epsilon\n        self.backup = {}\n\n    def attack(self, embed_name='word_embeddings'):\n        \"\"\"\n        得到对抗样本\n        :param emb_name:模型中embedding的参数名\n        :return:\n        \"\"\"\n        for name, param in self.model.named_parameters():\n            if param.requires_grad and embed_name in name:\n                self.backup[name] = param.data.clone()\n                norm = torch.norm(param.grad)\n\n                if norm != 0 and not torch.isnan(norm):\n                    r_at = self.epsilon * param.grad / norm\n                    param.data.add_(r_at)\n\n    def restore(self, embed_name='word_embeddings'):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad and embed_name in name:\n                assert name in self.backup\n                param.data = self.backup[name]\n        self.backup = {}\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.59237Z","iopub.execute_input":"2022-04-27T02:05:30.593014Z","iopub.status.idle":"2022-04-27T02:05:30.604269Z","shell.execute_reply.started":"2022-04-27T02:05:30.592975Z","shell.execute_reply":"2022-04-27T02:05:30.603576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PPPMModel(pl.LightningModule):\n    def __init__(self, config, model_config_path=None, pretrained=False, weight_path=None):\n        super().__init__()\n        self.save_hyperparameters('config')\n\n        if model_config_path:\n            self.model_config = torch.load(model_config_path)\n        else:\n            self.model_config = AutoConfig.from_pretrained(config.model, output_hidden_states=True)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(config.model, config=self.model_config)\n        else:\n            self.model = AutoModel.from_config(self.model_config)\n\n        self.attention = nn.Sequential(\n            nn.Linear(self.model_config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n\n        self.fc = nn.Linear(self.model_config.hidden_size, config.target_size)\n\n        # TODO multi_dropout / layer norm\n        self.dropout_0 = nn.Dropout(config.fc_dropout / 2.)\n        self.dropout_1 = nn.Dropout(config.fc_dropout / 1.5)\n        self.dropout_2 = nn.Dropout(config.fc_dropout)\n        self.dropout_3 = nn.Dropout(config.fc_dropout * 1.5)\n        self.dropout_4 = nn.Dropout(config.fc_dropout * 2.)\n\n        self.__init_weight(self.fc)\n        self.__set_metrics()\n\n        if config.label_smooth:\n            self.criterion = LabelSmoothLoss(smoothing=config.smoothing,\n                                             loss_func=nn.BCEWithLogitsLoss(reduction=\"mean\"))\n        else:\n            self.criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n\n        if hasattr(self.hparams.config, 'fgm') and self.hparams.config.fgm:\n            self.automatic_optimization = False\n            self.fgm = FGM(self)\n\n        if weight_path != None:\n            weight = torch.load(weight_path, map_location='cpu')\n            if 'state_dict' in weight.keys():\n                weight = weight['state_dict']\n            self.load_state_dict(weight)\n\n    def __set_metrics(self):\n        self.train_losses = AverageMeter()\n        self.val_losses = AverageMeter()\n        self.val_acc = AverageMeter()\n\n        self.train_losses.reset()\n        self.val_losses.reset()\n        self.val_acc.reset()\n\n    def __init_weight(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.model_config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n\n    def forward(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states, pooler_output = outputs[0], outputs[1]\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        #         output_0 = self.fc(self.dropout_0(feature))\n        #         output_1 = self.fc(self.dropout_1(feature))\n        output_2 = self.fc(self.dropout_2(feature))\n        #         output_3 = self.fc(self.dropout_3(feature))\n        #         output_4 = self.fc(self.dropout_4(feature))\n        #         return (output_0 + output_1 + output_2 + output_3 + output_4) / 5\n        return output_2\n\n    def training_step(self, batch, batch_idx):\n        inputs, labels = batch\n        y_preds = self.forward(inputs)\n        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n        # loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n        self.train_losses.update(loss.item(), len(labels))\n        self.log('train/avg_loss', self.train_losses.avg)\n        # 因为 optimizer 有 3 组参数，所有 get_last_lr() 会返回含有 3 个元素的列表\n        en_lr = self.trainer.lr_scheduler_configs[0].scheduler.get_last_lr()[0]\n        de_lr = self.trainer.lr_scheduler_configs[0].scheduler.get_last_lr()[-1]\n        self.log('train/en_lr', en_lr, prog_bar=True)\n        self.log('train/de_lr', de_lr, prog_bar=True)\n\n        if (self.trainer.global_step) % self.hparams.config.print_freq == 0:\n            # if (self.trainer.global_step + 1) % self.hparams.config.print_freq == 0:\n            self.print('Global step:{global_step}.'\n                       'Train Loss: {loss.val:.4f}(avg: {loss.avg:.4f}) '\n                       'Encoder LR: {en_lr:.8f}, Decoder LR: {de_lr:.8f}'\n                       .format(global_step=self.trainer.global_step,\n                               loss=self.train_losses,\n                               en_lr=en_lr,\n                               de_lr=de_lr))\n        # 如果没有FGM，在这里就可以返回loss\n        # 为了使用FGM，这里要手动进行求导和优化器更新\n        if self.hparams.config.fgm:\n            # loss regularization， 但是不加效果要更好一些\n            # if self.hparams.config.gradient_accumulation_steps > 1:\n            #     loss = loss / self.hparams.config.gradient_accumulation_steps\n            self.manual_backward(loss)\n            torch.nn.utils.clip_grad_norm(self.parameters(), self.hparams.config.max_grad_norm)\n            # 这里不能用 global_step ，否则因为关闭了自动优化，global_step 只能在 step 之后才会更新，会陷入死循环\n            if (batch_idx + 1) % self.hparams.config.gradient_accumulation_steps == 0:\n                # if (self.trainer.global_step + 1) % self.hparams.config.gradient_accumulation_steps == 0:\n                self.fgm.attack()\n                y_preds_adv = self.forward(inputs)\n                loss_adv = self.criterion(y_preds_adv.view(-1, 1), labels.view(-1, 1))\n                loss_adv = torch.masked_select(loss_adv, labels.view(-1, 1) != -1).mean()\n                self.manual_backward(loss_adv)\n                self.fgm.restore()\n\n                opt = self.optimizers()\n                opt.step()\n                opt.zero_grad()\n                sch = self.lr_schedulers()\n                sch.step()\n\n        return loss\n\n    def training_epoch_end(self, outs):\n        torch.cuda.empty_cache()\n\n    def validation_step(self, batch, batch_idx):\n        inputs, labels = batch\n        y_preds = self.forward(inputs)\n        loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n        # loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n        self.val_losses.update(loss.item(), len(labels))\n        self.log('val/avg_loss', self.val_losses.avg)\n        return y_preds.sigmoid().cpu().numpy(), labels.cpu()\n\n    def validation_epoch_end(self, outs):\n        # val_df = self.trainer.datamodule.val_df\n        # val_labels = val_df['score'].values\n        val_labels = np.concatenate([item[1] for item in outs])\n        preds = np.concatenate([item[0] for item in outs]).squeeze(axis=-1)\n        val_loss_avg = self.val_losses.avg\n        #  ======================== scoring ============================\n        score = get_score(val_labels, preds)\n        self.log(f'val/loss_avg', val_loss_avg)\n        self.log(f'val/score', score)\n        self.print(f'Global step:{self.trainer.global_step}.\\n Val loss avg: {val_loss_avg}, score: {score}')\n\n        self.val_losses.reset()\n        self.val_acc.reset()\n\n    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n        inputs = batch\n        y_preds = self.forward(inputs)\n        return y_preds.sigmoid().cpu().numpy()\n\n    def configure_optimizers(self):\n        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n        encoder_lr = self.hparams.config.encoder_lr\n        decoder_lr = self.hparams.config.decoder_lr\n        num_cycles = self.hparams.config.num_cycles\n        # end_lr = self.hparams.config.min_lr\n        weight_decay = self.hparams.config.weight_decay\n        eps = self.hparams.config.eps\n        betas = self.hparams.config.betas\n        optimizer_parameters = [\n            {'params': [p for n, p in self.model.named_parameters()\n                        if not any(nd in n for nd in no_decay)],\n             'lr': encoder_lr, 'weight_decay': weight_decay,\n             },\n            {'params': [p for n, p in self.model.named_parameters()\n                        if any(nd in n for nd in no_decay)],\n             'lr': encoder_lr, 'weight_decay': 0.0,\n             },\n            {'params': [p for n, p in self.named_parameters() if \"model\" not in n],\n             'lr': decoder_lr, 'weight_decay': 0.0,\n             }\n        ]\n        optimizer = AdamW(optimizer_parameters,\n                          lr=encoder_lr, eps=eps, betas=betas)\n\n        if self.trainer.max_steps == None or self.trainer.max_epochs != None:\n            # 注意，因为使用FGM需要关闭自动优化，传入 trainer 的 accumulate_grad_batches 是None\n            # 因此这里计算不能使用 trainer 的参数，要使用 config 里的参数\n            # max_steps = (\n            #         len(self.trainer.datamodule.train_dataloader()) * self.trainer.max_epochs\n            #         // self.trainer.accumulate_grad_batches\n            # )\n            max_steps = (\n                    len(self.trainer.datamodule.train_dataloader()) * self.trainer.max_epochs\n                    // self.hparams.config.gradient_accumulation_steps\n            )\n        else:\n            max_steps = self.trainer.max_steps\n\n        warmup_steps = self.hparams.config.warmup_steps\n        if isinstance(warmup_steps, float):\n            warmup_steps = int(warmup_steps * max_steps)\n\n        print(f'====== Max steps: {max_steps},\\t Warm up steps: {warmup_steps} =========')\n\n        if self.hparams.config.scheduler == 'linear':\n            scheduler = get_linear_schedule_with_warmup(\n                optimizer, num_warmup_steps=warmup_steps, num_training_steps=max_steps,\n            )\n        elif self.hparams.config.scheduler == 'cosine':\n            scheduler = get_cosine_schedule_with_warmup(\n                optimizer, num_warmup_steps=warmup_steps, num_training_steps=max_steps,\n                num_cycles=num_cycles\n            )\n        else:\n            scheduler = None\n        sched = {\n            'scheduler': scheduler, 'interval': 'step'\n        }\n        return ([optimizer], [sched])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.606084Z","iopub.execute_input":"2022-04-27T02:05:30.606707Z","iopub.status.idle":"2022-04-27T02:05:30.659204Z","shell.execute_reply.started":"2022-04-27T02:05:30.60667Z","shell.execute_reply":"2022-04-27T02:05:30.658292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Infer","metadata":{}},{"cell_type":"code","source":"pl.seed_everything(CFG.seed)\ndm = PPPMDataModule(CFG, prepare_train=False)\ndm.prepare_data()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:30.660584Z","iopub.execute_input":"2022-04-27T02:05:30.661404Z","iopub.status.idle":"2022-04-27T02:05:31.482676Z","shell.execute_reply.started":"2022-04-27T02:05:30.661363Z","shell.execute_reply":"2022-04-27T02:05:31.481921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weight_paths = []\nfor p in CFG.weight_path:\n    weight_paths.extend(list(Path(p).rglob('*.ckpt')))\n# 手动输入权重，如果没有，则用验证的得分作为权重\nif CFG.weight_scores != []:\n    cv_score = CFG.weight_scores\nelse:\n    cv_score = [float(re.search('score([\\d.]*)', weight_path.stem).group(1)) for weight_path in weight_paths]\ncv_score = torch.tensor(cv_score)\n\nweights = nn.functional.softmax(cv_score / CFG.t, dim=0).float().numpy()\nweight_paths","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:31.483853Z","iopub.execute_input":"2022-04-27T02:05:31.484599Z","iopub.status.idle":"2022-04-27T02:05:31.52916Z","shell.execute_reply.started":"2022-04-27T02:05:31.48456Z","shell.execute_reply":"2022-04-27T02:05:31.528331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_score, weights","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:31.53049Z","iopub.execute_input":"2022-04-27T02:05:31.5308Z","iopub.status.idle":"2022-04-27T02:05:31.570277Z","shell.execute_reply.started":"2022-04-27T02:05:31.530763Z","shell.execute_reply":"2022-04-27T02:05:31.569092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor weight_path in weight_paths:\n    weight_name = weight_path.name\n    print(f\"Using weight from {weight_name}.\")\n\n    model = PPPMModel(CFG, model_config_path=None, pretrained=False, weight_path=weight_path)\n    trainer = pl.Trainer(\n        gpus=[0],\n        default_root_dir=CFG.output_dir,\n    )\n    prediction = trainer.predict(model, datamodule=dm)\n    prediction = np.concatenate([batch_pred for batch_pred in prediction])\n    predictions.append(prediction)\n\n    del model, trainer, prediction\n    gc.collect()\n    torch.cuda.empty_cache()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:05:31.572699Z","iopub.execute_input":"2022-04-27T02:05:31.57367Z","iopub.status.idle":"2022-04-27T02:06:01.260282Z","shell.execute_reply.started":"2022-04-27T02:05:31.573633Z","shell.execute_reply":"2022-04-27T02:06:01.259491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.asarray(predictions)\npredictions = np.sum([w * p for w, p in zip(weights, predictions)], axis=0)\n\ndm.submission['score'] = predictions\ndm.submission[['id', 'score']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:06:01.26202Z","iopub.execute_input":"2022-04-27T02:06:01.26229Z","iopub.status.idle":"2022-04-27T02:06:01.274756Z","shell.execute_reply.started":"2022-04-27T02:06:01.262252Z","shell.execute_reply":"2022-04-27T02:06:01.273976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dm.submission","metadata":{"execution":{"iopub.status.busy":"2022-04-27T02:06:01.276362Z","iopub.execute_input":"2022-04-27T02:06:01.277026Z","iopub.status.idle":"2022-04-27T02:06:01.294469Z","shell.execute_reply.started":"2022-04-27T02:06:01.276985Z","shell.execute_reply":"2022-04-27T02:06:01.293709Z"},"trusted":true},"execution_count":null,"outputs":[]}]}