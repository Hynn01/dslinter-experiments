{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> The 16 Personalities Dataset: By Anshul </center>\n\n\n#### Link to the Dataset:\n#### [Dataset](https://www.kaggle.com/datasets/anshulmehtakaggl/60k-responses-of-16-personalities-test-mbt)\n<img src='https://i.pinimg.com/originals/a8/9f/5f/a89f5ff47344c8329e54706767eac545.jpg' >\n\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T10:47:07.511711Z","iopub.execute_input":"2022-05-06T10:47:07.512843Z","iopub.status.idle":"2022-05-06T10:47:07.52198Z","shell.execute_reply.started":"2022-05-06T10:47:07.512782Z","shell.execute_reply":"2022-05-06T10:47:07.521123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\ntrain_data=pd.read_csv('../input/60k-responses-of-16-personalities-test-mbt/16P.csv',encoding='cp1252')\ntrain_data=train_data.drop(columns={'Response Id'})\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T10:47:23.94362Z","iopub.execute_input":"2022-05-06T10:47:23.94483Z","iopub.status.idle":"2022-05-06T10:47:24.446492Z","shell.execute_reply.started":"2022-05-06T10:47:23.944769Z","shell.execute_reply":"2022-05-06T10:47:24.445497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pycaret","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-06T10:47:31.657272Z","iopub.execute_input":"2022-05-06T10:47:31.657653Z","iopub.status.idle":"2022-05-06T10:48:29.626027Z","shell.execute_reply.started":"2022-05-06T10:47:31.657617Z","shell.execute_reply":"2022-05-06T10:48:29.624459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX=train_data.drop(columns=\"Personality\")\ny=train_data[\"Personality\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-06T10:48:32.406594Z","iopub.execute_input":"2022-05-06T10:48:32.407015Z","iopub.status.idle":"2022-05-06T10:48:32.424537Z","shell.execute_reply.started":"2022-05-06T10:48:32.406971Z","shell.execute_reply":"2022-05-06T10:48:32.423465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardizing the features\nX = StandardScaler().fit_transform(X)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=21)\nprincipalComponents = pca.fit_transform(X)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['pc1', 'pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10','pc11','pc12','pc13','pc14','pc15','pc16','pc17','pc18','pc19','pc20','pc21'])\nfinalDf = pd.concat([principalDf, train_data[['Personality']]], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T10:48:34.522198Z","iopub.execute_input":"2022-05-06T10:48:34.522513Z","iopub.status.idle":"2022-05-06T10:48:35.59136Z","shell.execute_reply.started":"2022-05-06T10:48:34.522481Z","shell.execute_reply":"2022-05-06T10:48:35.59002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"finalDf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T10:48:39.224214Z","iopub.execute_input":"2022-05-06T10:48:39.224541Z","iopub.status.idle":"2022-05-06T10:48:39.254905Z","shell.execute_reply.started":"2022-05-06T10:48:39.224508Z","shell.execute_reply":"2022-05-06T10:48:39.253787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pycaret.classification import *\n#df = pd.read_csv(\"../input/60k-responses-of-16-personalities-test-mbt/16_Personalities_v1.csv\")\n\nclf = setup(\n    data=finalDf,\n    target=\"Personality\",\n    remove_multicollinearity=True,\n    remove_outliers=True,\n    remove_perfect_collinearity=True,\n    fix_imbalance=True,\n    log_experiment=True,\n    normalize=True,\n    transformation=True,\n    verbose=True,\n    silent=True,\n    feature_interaction=True,\n    feature_selection=True,\n    pca=True\n)\n%time best_model = compare_models()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T10:48:47.187517Z","iopub.execute_input":"2022-05-06T10:48:47.188101Z","iopub.status.idle":"2022-05-06T13:43:01.949542Z","shell.execute_reply.started":"2022-05-06T10:48:47.188026Z","shell.execute_reply":"2022-05-06T13:43:01.948466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\n# import optuna.integration.lightgbm as lgb\n# import pandas as pd\n# from lightgbm import early_stopping, log_evaluation\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import train_test_split\n\n\n# def objective(trial: optuna.Trial):\n# #     df = pd.read_csv(\"../input/60k-responses-of-16-personalities-test-mbt/16_PERSONALITIES.csv\",encoding='cp1252')\n\n#     train_x, test_x, train_y, test_y = train_test_split(\n#         finalDf.drop(columns=\"Personality\"), finalDf[\"Personality\"], test_size=0.2\n#     )\n\n#     params = {\n#         \"metric\": \"auc\",\n#         \"objective\": \"binary\",\n#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 1, 100),\n#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n#         \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n#         \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n#         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n#     }\n\n#     dtrain = lgb.Dataset(train_x, label=train_y)\n#     dval = lgb.Dataset(test_x, label=test_y)\n\n#     model = lgb.train(\n#         params,\n#         dtrain,\n#         valid_sets=[dtrain, dval],\n#         callbacks=[early_stopping(100), log_evaluation(100)],\n#     )\n\n#     prediction = model.predict(test_x, num_iteration=model.best_iteration)\n#     return roc_auc_score(test_y, prediction)\n\n\n# study = optuna.create_study()\n# study.optimize(objective, n_jobs=-1, n_trials=100)\n# print(study.best_params)","metadata":{},"execution_count":null,"outputs":[]}]}