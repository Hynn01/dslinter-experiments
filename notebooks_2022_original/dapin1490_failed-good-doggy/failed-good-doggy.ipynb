{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, _ in os.walk('/kaggle/input'):\n    print(dirname)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2022-05-07T12:15:53.067665Z","iopub.execute_input":"2022-05-07T12:15:53.06799Z","iopub.status.idle":"2022-05-07T12:16:01.341426Z","shell.execute_reply.started":"2022-05-07T12:15:53.067888Z","shell.execute_reply":"2022-05-07T12:16:01.340665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 120 Dog Breeds - classification\n---\n\\* All English explanations have been translated.   \n   \n\\* 모든 영어 설명은 번역되었다.   ","metadata":{}},{"cell_type":"markdown","source":"## set seed\n---","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\nseed = 3\nnp.random.seed(seed)\ntf.random.set_seed(seed)\n\nprint(\"seed =\", seed)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T12:16:01.343067Z","iopub.execute_input":"2022-05-07T12:16:01.343313Z","iopub.status.idle":"2022-05-07T12:16:05.328682Z","shell.execute_reply.started":"2022-05-07T12:16:01.343276Z","shell.execute_reply":"2022-05-07T12:16:05.327946Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## set variables and load data\n---\nreference : [Load and preprocess images](https://www.tensorflow.org/tutorials/load_data/images)   \n   \n텐서플로우 공식 문서 참고 : [이미지 로드 및 전처리하기](https://www.tensorflow.org/tutorials/load_data/images?hl=ko)   ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras import layers\n\nepoch = 50\nbatch = 5000\nimg_height = 32\nimg_width = 32\n\ntrain_ds = image_dataset_from_directory(\"/kaggle/input/120-dog-breeds-breed-classification/Images/\", validation_split=0.2, subset=\"training\", seed=seed, image_size=(img_height, img_width), batch_size=batch)\ntest_ds = image_dataset_from_directory(\"/kaggle/input/120-dog-breeds-breed-classification/Images/\", validation_split=0.2, subset=\"validation\", seed=seed, image_size=(img_height, img_width), batch_size=batch)\n\nresize_and_rescale = tf.keras.Sequential([\n  # layers.experimental.preprocessing.Resizing(img_height, img_width),\n  layers.experimental.preprocessing.Rescaling(1./255),  # layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1)\n  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n  layers.experimental.preprocessing.RandomRotation(0.2),\n])\n\nnormalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n# normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1)\n\ntrain_augment = train_ds.map(lambda x, y: (resize_and_rescale(x, training=True), y))\ntest_normal = test_ds.map(lambda x, y: (normalization_layer(x), y))\n\n# show sample\n# image_batch, labels_batch = next(iter(train_augment))\n# first_image = image_batch[0]\n# Notice the pixels values are now in `[0,1]`.\n# print(first_image)","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2022-05-07T12:16:05.329977Z","iopub.execute_input":"2022-05-07T12:16:05.330218Z","iopub.status.idle":"2022-05-07T12:16:09.930615Z","shell.execute_reply.started":"2022-05-07T12:16:05.330183Z","shell.execute_reply":"2022-05-07T12:16:09.929925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## build model\n---\n* Additional Features Used   \n    * `ModelCheckpoint` : You can save the best performing model and recall it after the learning is completed.   \n    * `EarlyStopping` : prevention of overfitting   \n   \n* Model Configuration   \n    * `dense` : basic layer   \n    * `dropout` : prevention of overfitting   \n    * `Conv2D` : Features of the image(2D) are extracted using the kernel.   \n    * `MaxPooling2D` : Reduce the size of the image(2D) with Max pooling.   \n    * `Flatten` : The image in the form of a two-dimensional array is converted into a one-dimensional array.   \n\n---   \n   \n* 사용한 부가기능   \n    * `ModelCheckpoint` : 가장 성능이 좋은 모델을 저장해 두고 학습이 완료된 후 다시 불러올 수 있다.   \n    * `EarlyStopping` : 과적합 방지   \n   \n* 모델 구성   \n    * `dense` : 기본적인 층   \n    * `dropout` : 과적합 방지   \n    * `Conv2D` : 커널을 이용해 이미지(2D)의 특징을 추출한다.   \n    * `MaxPooling2D` : 맥스 풀링으로 이미지(2D)의 크기를 줄인다.   \n    * `Flatten` : 2차원 배열 형태의 이미지를 1차원 배열로 바꾼다.   ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n\nMODEL_DIR = '/kaggle/working/model/'\nif not os.path.exists(MODEL_DIR):\n   os.mkdir(MODEL_DIR)\n\nmodelpath=\"/kaggle/working/model/my_best_model.hdf5\"\n\nmodel = Sequential()\nmodel.add(Conv2D(128, (4, 4), input_shape=(img_height, img_width, 3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\n\nmodel.add(Conv2D(128, (4, 4), activation=\"relu\", padding=\"same\"))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(120, activation=\"softmax\"))\n\nmodel.summary()","metadata":{"scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-07T12:16:09.932331Z","iopub.execute_input":"2022-05-07T12:16:09.934143Z","iopub.status.idle":"2022-05-07T12:16:10.02128Z","shell.execute_reply.started":"2022-05-07T12:16:09.934104Z","shell.execute_reply":"2022-05-07T12:16:10.020585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# additional features\ncheckpointer = ModelCheckpoint(filepath=modelpath, monitor='val_accuracy', verbose=1, save_best_only=True)\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n\n# model compile and fit\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nhistory = model.fit(train_augment, validation_data=test_normal, epochs=epoch, batch_size=batch, verbose=0, callbacks=[checkpointer, early_stopping_callback])","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2022-05-07T12:16:10.022582Z","iopub.execute_input":"2022-05-07T12:16:10.022812Z","iopub.status.idle":"2022-05-07T12:37:51.421355Z","shell.execute_reply.started":"2022-05-07T12:16:10.022778Z","shell.execute_reply":"2022-05-07T12:37:51.420583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## evaluate model\n---","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.models import load_model\n\nmodel = load_model('/kaggle/working/model/my_best_model.hdf5')\n\nloss, acc = model.evaluate(test_normal)\nprint(\"acc : {:.3f}\\nloss : {:.3f}\\n\".format(acc, loss))\n\n# sns.set(rc={'figure.figsize':(16, 9)})\nsns.set_style(\"ticks\")\n\nprint(\"\\n정확도 그래프\")\n# 테스트 셋의 정확도\ny_vacc = history.history['val_accuracy']\n\n# 학습셋의 정확도\ny_acc = history.history['accuracy']\n\n# 그래프로 표현\nx_len = np.arange(len(y_acc))\nplt.plot(x_len, y_acc, c=\"blue\", label='Trainset_accuracy')\nplt.plot(x_len, y_vacc, c=\"green\", label='Testset_accuracy')\n\n# 그래프에 그리드를 주고 레이블을 표시\nplt.legend(loc='lower right')\nplt.grid()\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.show()\n\nprint(\"\\n오차 그래프\")\n# 테스트 셋의 오차\ny_vloss = history.history['val_loss']\n\n# 학습셋의 오차\ny_loss = history.history['loss']\n\n# 그래프로 표현\nx_len = np.arange(len(y_loss))\nplt.plot(x_len, y_loss, c=\"blue\", label='Trainset_loss')\nplt.plot(x_len, y_vloss, c=\"green\", label='Testset_loss')\n\n# 그래프에 그리드를 주고 레이블을 표시\nplt.legend(loc='upper right')\nplt.grid()\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-07T12:37:51.423189Z","iopub.execute_input":"2022-05-07T12:37:51.423465Z","iopub.status.idle":"2022-05-07T12:37:56.742867Z","shell.execute_reply.started":"2022-05-07T12:37:51.423413Z","shell.execute_reply":"2022-05-07T12:37:56.741811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Record Results | 결과 기록\n---\n### model 1   \n```python\nepoch = 30\nbatch = 1000\nimg_height = 32\nimg_width = 32\n```   \n```python\nmodel = Sequential()\nmodel.add(Conv2D(64, (4, 4), input_shape=(img_height, img_width, 3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (8, 8), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(120, activation=\"softmax\"))\n\n# additional features\ncheckpointer = ModelCheckpoint(filepath=modelpath, monitor='val_accuracy', verbose=1, save_best_only=True)\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=epoch//10 + 2)\n\n# model compile and fit\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nhistory = model.fit(train_normal, validation_data=test_normal, epochs=epoch, batch_size=batch, verbose=0, callbacks=[checkpointer, early_stopping_callback])\n```\n\\- used : 0~1 normalized images   \n   \n**accuracy : 0.0628**   \n**loss : 4.397**   \n   \nopinion : I have many things to do   \n   \n---   \n   \n### model 2\n```python\nepoch = 500\nbatch = 1000\nimg_height = 32\nimg_width = 32\n```   \n   \n**acc : 0.115**   \n**loss : 3.957**   \nNumber of epochs performed : 422 / 500   \n   \nopinion : oh I forgot to use data augmentation!    \n    \nmy plan : batch size up, EarlyStopping patience down    \n   \n---   \n   \n### model 3   \n   \n```python\nbatch = 5000\npatience = 10\n```\n   \nresult : I interrupted it. too slow, too low accuracy.   \nopinion : should I have to increase batch size more? or change model layer factors?   \n   \n---   \n   \n### model 4   \n   \n```python\nepoch = 50\n```   \n   \n```python\nmodel = Sequential()\nmodel.add(Conv2D(128, (4, 4), input_shape=(img_height, img_width, 3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (8, 8), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(120, activation=\"softmax\"))\n```   \n   \n\\- train data augmented   \n   \n**acc : 0.090**   \n**loss : 4.293**   \n   \nopinion : more nodes -> more accuracy! but still incomplete   \nmy plan : a little bit more nodes and more layers? or bigger image?   \n   \n---   \n   \n### model 5   \n   \n```python\nimg_height = 64\nimg_width = 64\n```   \n```python\nmodel = Sequential()\nmodel.add(Conv2D(256, (4, 4), input_shape=(img_height, img_width, 3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(364, (8, 8), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(512, (2, 2), activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(768, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(120, activation=\"softmax\"))\n```   \n   \n`ResourceExhaustedError`   \n   \nopinion : oh..   \nmy plan : less nodes   \nresult : one more `ResourceExhaustedError`   \nSo I decided to reduce the size of the image.   \n   \n---   \n   \n### model 6   \n   \n```python\nimg_height = 32\nimg_width = 32\n```   \n```python\nmodel = Sequential()\nmodel.add(Conv2D(256, (4, 4), input_shape=(img_height, img_width, 3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (2, 2), activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(120, activation=\"softmax\"))\n```\n   \n`ResourceExhaustedError`   \n   \nopinion : I need to reduce the number of nodes. or image size.   \n   \n---   \n   \n### model 7   \n   \n```python\nmodel = Sequential()\nmodel.add(Conv2D(256, (4, 4), input_shape=(img_height, img_width, 3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\n\nmodel.add(Conv2D(128, (4, 4), activation=\"relu\", padding=\"same\"))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(120, activation=\"softmax\"))\n```\n   \n**acc : 0.052**   \n**loss : 4.462**   \n   \nopinion : I think changing the number of nodes or batch size will not solve the performance problem. I don't know how to preprocess image data yet. There's nothing more I can do.   \n의견 : 내 생각에 노드 수나 배치 사이즈를 바꾸는 것만으로는 성능 문제가 해결되지 않을 것 같다. 나는 아직 이미지 데이터를 전처리할 줄 모른다. 내가 더 이상 할 수 있는 게 없다.   \n   ","metadata":{"_kg_hide-input":false}},{"cell_type":"markdown","source":"## memo\n---\n\\- `flow_from_directory`와 달리 `image_dataset_from_directory`는 모델을 실행하면서 하나의 `epoch`가 끝날 때마다 메모리를 비우는 것 같다. `flow_from_directory`를 쓸 때는 GPU 용량 부족 오류가 자주 났는데 이번에 데이터 로드 함수를 바꾸면서 그 오류가 거의 발생하지 않았다. 그리고 매번 `epoch`가 끝날 때마다 `Cleanup called...`라는 문구가 출력되면서 다음 에포크가 바로 시작되지 않고 잠시 지연된다. 이때 메모리를 비우는 것이라고 추측했다. 검색이라도 해서 제대로 찾아보고 싶었는데 검색어를 어떻게 써야 나올지 모르겠다. 못찾았다.   \n   \n\\- 드롭아웃은 `0.5` 정도는 써줘야 티가 난다!   \n   \n\\- `EarlyStopping`의 `patience` 설정을 바꿔봤다. 숫자로 직접 넣지 않고 `epoch`의 일정 비율만큼 자동으로 계산되어 들어가도록 했다. `+ 2`가 붙은 이유는 `epoch`가 적을 때 `patience`가 `0`이나 `1`이 되지 않도록 하기 위해서이다. -> 4시간 걸려서 학습시켜봤는데 일단 과적합 시작되면 기다려도 안 돌아오니 그냥 작게 잡기로 했다.   ","metadata":{}}]}