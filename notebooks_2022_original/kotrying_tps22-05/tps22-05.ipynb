{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Idea\n  \n**See the previous kernel for details**\n\n**success**  \nautomating feature generating and selection by AutoFeat (LGBM)   \nLabel-Encoding  \nhyperparameter tuning by Optuna   \nsplit f_27 one character at a time  \nnumber of unique characters in f_27  \n\n**failures(not use)**  \nSimple Target-Encoding    \ncombine a small number of labels (8,9 or more) of categorical variables into one label  \ncount the maximum number of consecutive strings in f_27  ","metadata":{}},{"cell_type":"code","source":"# base\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# encoding\nfrom sklearn.preprocessing import LabelEncoder\n\n# CV\nfrom sklearn.model_selection import KFold\n\n# lgb\nimport lightgbm as lgb\n\nfrom sklearn.preprocessing import StandardScaler\n\n# tensorflow/keras\nimport tensorflow as tf\nfrom tensorflow.keras import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras.callbacks import *\n\n# metrics\nfrom sklearn.metrics import roc_curve, auc\n\n# plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# warning\nimport warnings\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\n# param\nn_splits=5\nseed=2022","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:52:18.489477Z","iopub.execute_input":"2022-05-07T18:52:18.48991Z","iopub.status.idle":"2022-05-07T18:52:27.069125Z","shell.execute_reply.started":"2022-05-07T18:52:18.489826Z","shell.execute_reply":"2022-05-07T18:52:27.068306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nset_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:52:27.070362Z","iopub.execute_input":"2022-05-07T18:52:27.070542Z","iopub.status.idle":"2022-05-07T18:52:27.076984Z","shell.execute_reply.started":"2022-05-07T18:52:27.070511Z","shell.execute_reply":"2022-05-07T18:52:27.075816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2022/train.csv')\nsub = pd.read_csv('../input/tabular-playground-series-may-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:52:27.079769Z","iopub.execute_input":"2022-05-07T18:52:27.080449Z","iopub.status.idle":"2022-05-07T18:52:35.232896Z","shell.execute_reply.started":"2022-05-07T18:52:27.080366Z","shell.execute_reply":"2022-05-07T18:52:35.232332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features generated by AutoFeat (Vesion8)\ntrain_x_feature_creation = pd.read_csv('../input/tps0522-autofeat/train_x_feature_creation.csv')\ntest_feature_creation = pd.read_csv('../input/tps0522-autofeat/test_feature_creation.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:52:35.2358Z","iopub.execute_input":"2022-05-07T18:52:35.236055Z","iopub.status.idle":"2022-05-07T18:54:46.656017Z","shell.execute_reply.started":"2022-05-07T18:52:35.236021Z","shell.execute_reply":"2022-05-07T18:54:46.653764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x_feature_creation.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:54:46.658959Z","iopub.execute_input":"2022-05-07T18:54:46.659352Z","iopub.status.idle":"2022-05-07T18:54:46.710458Z","shell.execute_reply.started":"2022-05-07T18:54:46.659307Z","shell.execute_reply":"2022-05-07T18:54:46.709686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_feature_creation.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:54:46.711816Z","iopub.execute_input":"2022-05-07T18:54:46.712673Z","iopub.status.idle":"2022-05-07T18:54:46.739606Z","shell.execute_reply.started":"2022-05-07T18:54:46.712592Z","shell.execute_reply":"2022-05-07T18:54:46.738603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# lightgbm\nclass ModelLgb:\n\n    def __init__(self):\n        self.model = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        params = {\n        'objective':'binary',\n        'metric':'auc',\n        'seed': seed,\n        'verbosity':-1,\n        'learning_rate':0.1,\n        'reg_alpha':0,\n        'reg_lambda':1,\n        'num_leaves': 480, \n        'max_depth': 31,\n        'feature_fraction': 0.9558908495366608, \n        'bagging_fraction': 0.9018494038054344, \n        'bagging_freq': 5, \n        'min_child_samples': 8,\n        }\n        \n        num_round = 10000\n        early_stopping_rounds=50\n        \n        lgb_train = lgb.Dataset(tr_x, tr_y)\n        lgb_eval = lgb.Dataset(va_x, va_y)\n        \n        self.model = lgb.train(params, lgb_train, valid_sets=lgb_eval, \n                               num_boost_round=num_round, early_stopping_rounds=early_stopping_rounds,\n                               verbose_eval=100\n                              )\n        \n        lgb.plot_importance(self.model, figsize=(30,60))\n        \n    def predict(self, x):\n        pred = self.model.predict(x, num_iteration=self.model.best_iteration)\n        return pred","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:54:46.741526Z","iopub.execute_input":"2022-05-07T18:54:46.741783Z","iopub.status.idle":"2022-05-07T18:54:46.756295Z","shell.execute_reply.started":"2022-05-07T18:54:46.741747Z","shell.execute_reply":"2022-05-07T18:54:46.755343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NN\nclass ModelNN:\n\n    def __init__(self):\n        self.model = None\n        self.scaler = None\n\n    def fit(self, tr_x, tr_y, va_x, va_y):\n        self.scaler = StandardScaler()\n        self.scaler.fit(tr_x)\n\n        batch_size = 128\n        epochs = 100\n\n        tr_x = self.scaler.transform(tr_x)\n        va_x = self.scaler.transform(va_x)\n        \n        model = Sequential()\n        model.add(Dense(128, kernel_regularizer=tf.keras.regularizers.l2(30e-6), activation='swish', input_shape=(tr_x.shape[1],)))\n        model.add(Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6), activation='swish'))\n        model.add(Dense(32, kernel_regularizer=tf.keras.regularizers.l2(30e-6), activation='swish'))\n        model.add(Dense(16, kernel_regularizer=tf.keras.regularizers.l2(30e-6), activation='swish'))\n        model.add(Dense(1, activation='sigmoid'))\n\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])\n        \n        #callbacks\n        lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.7, patience=2, verbose=1)\n        es = EarlyStopping(monitor='val_loss', patience=5, min_delta=1e-3, restore_best_weights=True)\n        \n        history = model.fit(tr_x, tr_y,\n                            batch_size=batch_size, epochs=epochs,\n                            verbose=1, validation_data=(va_x, va_y), callbacks=[lr,es])\n        self.model = model\n\n    def predict(self, x):\n        x = self.scaler.transform(x)\n        pred = self.model.predict(x)\n        return pred","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:54:46.757846Z","iopub.execute_input":"2022-05-07T18:54:46.758031Z","iopub.status.idle":"2022-05-07T18:54:46.777806Z","shell.execute_reply.started":"2022-05-07T18:54:46.758007Z","shell.execute_reply":"2022-05-07T18:54:46.776279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run","metadata":{}},{"cell_type":"code","source":"base_col = train_x_feature_creation.columns[:41]\ntrain_x = train_x_feature_creation[base_col]\ntrain_y = train.target","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:54:46.77953Z","iopub.execute_input":"2022-05-07T18:54:46.780118Z","iopub.status.idle":"2022-05-07T18:54:46.805644Z","shell.execute_reply.started":"2022-05-07T18:54:46.780033Z","shell.execute_reply":"2022-05-07T18:54:46.804495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(name='lgb'):\n    models=[]\n    total_auc = []\n    \n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    for i, (tr_idx, va_idx) in tqdm(enumerate(kf.split(train_x))):\n        \n        print('='*15 + f'fold{i+1}' + '='*15)\n\n        tr_x, va_x = train_x.iloc[tr_idx].copy(), train_x.iloc[va_idx].copy()\n        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n        \n        if name == 'lgb':\n            model = ModelLgb()\n        if name == 'nn':\n            model = ModelNN()\n\n        model.fit(tr_x, tr_y, va_x, va_y)\n        models.append(model)\n        \n        # val_auc  \n        va_pred = model.predict(va_x)\n        \n        fpr, tpr, _ = roc_curve(va_y, va_pred)\n        va_auc = auc(fpr, tpr)\n        print(f'AUC : {va_auc}')\n        total_auc.append(va_auc)\n    \n    print(f'Mean AUC : {np.mean(total_auc)}')\n         \n    return models","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:54:46.809636Z","iopub.execute_input":"2022-05-07T18:54:46.810801Z","iopub.status.idle":"2022-05-07T18:54:46.826066Z","shell.execute_reply.started":"2022-05-07T18:54:46.810723Z","shell.execute_reply":"2022-05-07T18:54:46.825529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_nn = run_training('nn')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:54:46.827742Z","iopub.execute_input":"2022-05-07T18:54:46.828272Z","iopub.status.idle":"2022-05-07T18:54:46.848642Z","shell.execute_reply.started":"2022-05-07T18:54:46.828238Z","shell.execute_reply":"2022-05-07T18:54:46.847529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# models_lgb = run_training('lgb')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T18:54:46.850225Z","iopub.execute_input":"2022-05-07T18:54:46.850455Z","iopub.status.idle":"2022-05-07T19:04:16.704293Z","shell.execute_reply.started":"2022-05-07T18:54:46.850418Z","shell.execute_reply":"2022-05-07T19:04:16.702307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict & Submit","metadata":{}},{"cell_type":"code","source":"# NN\npreds=[]\n\nfor model in models_nn:\n    pred = model.predict(test_feature_creation[base_col])\n    preds.append(pred)\n\ntest_pred = sum(preds) / len(preds)\n\nsub.target = test_pred\nsub.to_csv('submission_nn.csv', index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-07T19:04:16.705771Z","iopub.status.idle":"2022-05-07T19:04:16.706348Z","shell.execute_reply.started":"2022-05-07T19:04:16.706182Z","shell.execute_reply":"2022-05-07T19:04:16.7062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # LGB\n# preds=[]\n\n# for model in models_lgb:\n#     pred = model.predict(test_feature_creation)\n#     preds.append(pred)\n\n# test_pred = sum(preds) / len(preds)\n\n# sub.target = test_pred\n# sub.to_csv('submission_lgb.csv', index=False)\n# sub","metadata":{"execution":{"iopub.status.busy":"2022-05-07T19:04:16.707438Z","iopub.status.idle":"2022-05-07T19:04:16.707683Z","shell.execute_reply.started":"2022-05-07T19:04:16.707556Z","shell.execute_reply":"2022-05-07T19:04:16.707569Z"},"trusted":true},"execution_count":null,"outputs":[]}]}