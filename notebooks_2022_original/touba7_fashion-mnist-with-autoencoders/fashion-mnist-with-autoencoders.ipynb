{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:53:04.721093Z","iopub.execute_input":"2022-05-06T11:53:04.721362Z","iopub.status.idle":"2022-05-06T11:53:09.361382Z","shell.execute_reply.started":"2022-05-06T11:53:04.721326Z","shell.execute_reply":"2022-05-06T11:53:09.360581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fashion_mnist = keras.datasets.fashion_mnist","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:53:09.363291Z","iopub.execute_input":"2022-05-06T11:53:09.363575Z","iopub.status.idle":"2022-05-06T11:53:10.240386Z","shell.execute_reply.started":"2022-05-06T11:53:09.363535Z","shell.execute_reply":"2022-05-06T11:53:10.239547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:53:10.242515Z","iopub.execute_input":"2022-05-06T11:53:10.242741Z","iopub.status.idle":"2022-05-06T11:53:31.111362Z","shell.execute_reply.started":"2022-05-06T11:53:10.242712Z","shell.execute_reply":"2022-05-06T11:53:31.110618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\nX_train_target= X_train\nX_valid_target = X_valid","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:53:31.113892Z","iopub.execute_input":"2022-05-06T11:53:31.114183Z","iopub.status.idle":"2022-05-06T11:53:31.24693Z","shell.execute_reply.started":"2022-05-06T11:53:31.114145Z","shell.execute_reply":"2022-05-06T11:53:31.245971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacked Autoencoders\nstacked autoencoders(or deep autoencoders): Adding more layers helps the autoencoder learn more complex codings. That said, one must be careful not to make the autoencoder too powerful.","metadata":{}},{"cell_type":"code","source":"stacked_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.Dense(30, activation=\"selu\"),\n])\n\nstacked_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\n\nstacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\nstacked_ae.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.SGD(learning_rate=1.5))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:53:31.248624Z","iopub.execute_input":"2022-05-06T11:53:31.248942Z","iopub.status.idle":"2022-05-06T11:53:33.71082Z","shell.execute_reply.started":"2022-05-06T11:53:31.2489Z","shell.execute_reply":"2022-05-06T11:53:33.710109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = stacked_ae.fit(X_train, X_train_target, epochs=10, validation_data=(X_valid, X_valid_target))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:53:33.712105Z","iopub.execute_input":"2022-05-06T11:53:33.712329Z","iopub.status.idle":"2022-05-06T11:54:17.777014Z","shell.execute_reply.started":"2022-05-06T11:53:33.712296Z","shell.execute_reply":"2022-05-06T11:54:17.776251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_image(image):\n    plt.imshow(image, cmap=\"binary\")\n    plt.axis(\"off\")\n\ndef show_reconstructions(model, n_images=5):\n    reconstructions = model.predict(X_valid[:n_images])\n    fig = plt.figure(figsize=(n_images * 1.5, 3))\n    for image_index in range(n_images):\n        plt.subplot(2, n_images, 1 + image_index)\n        plot_image(X_valid[image_index])\n        plt.subplot(2, n_images, 1 + n_images + image_index)\n        plot_image(reconstructions[image_index])\n\n\nshow_reconstructions(stacked_ae)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:54:17.778444Z","iopub.execute_input":"2022-05-06T11:54:17.778899Z","iopub.status.idle":"2022-05-06T11:54:18.337908Z","shell.execute_reply.started":"2022-05-06T11:54:17.778856Z","shell.execute_reply":"2022-05-06T11:54:18.337142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convolutional Autoencoder\nIf you want to build an autoencoder for images,you will need to build a convolutional autoencoder. The\nencoder is a regular CNN composed of convolutional layers and pooling layers. It typically reduces the spatial dimensionality of the inputs (i.e., height and width) while increasing the depth (i.e., the number of feature maps). The decoder must do the reverse (upscale the image and reduce its depth back to the original dimensions),and for this you can use transpose convolutional layers (alternatively, you could combine upsampling layers with convolutional layers).","metadata":{}},{"cell_type":"code","source":"conv_encoder = keras.models.Sequential([\n     keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n     keras.layers.Conv2D(16, kernel_size=3, padding=\"same\", activation=\"selu\"),\n     keras.layers.MaxPool2D(pool_size=2),\n     keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"selu\"),\n     keras.layers.MaxPool2D(pool_size=2),\n     keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"selu\"),\n     keras.layers.MaxPool2D(pool_size=2)\n])\nconv_decoder = keras.models.Sequential([\n     keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"valid\",\n     activation=\"selu\",\n     input_shape=[3, 3, 64]),\n     keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"same\", activation=\"selu\"),\n     keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"same\", activation=\"sigmoid\"),\n     keras.layers.Reshape([28, 28])\n])\n\nconv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:54:18.339095Z","iopub.execute_input":"2022-05-06T11:54:18.339657Z","iopub.status.idle":"2022-05-06T11:54:18.48427Z","shell.execute_reply.started":"2022-05-06T11:54:18.339611Z","shell.execute_reply":"2022-05-06T11:54:18.483517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_ae.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.SGD(learning_rate=1.5))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:54:18.485564Z","iopub.execute_input":"2022-05-06T11:54:18.485838Z","iopub.status.idle":"2022-05-06T11:54:18.496712Z","shell.execute_reply.started":"2022-05-06T11:54:18.485804Z","shell.execute_reply":"2022-05-06T11:54:18.495484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = conv_ae.fit(X_train, X_train_target, epochs=10, validation_data=(X_valid, X_valid_target))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:54:18.501196Z","iopub.execute_input":"2022-05-06T11:54:18.501563Z","iopub.status.idle":"2022-05-06T11:55:41.632158Z","shell.execute_reply.started":"2022-05-06T11:54:18.501512Z","shell.execute_reply":"2022-05-06T11:55:41.631416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_reconstructions(conv_ae)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:55:41.633706Z","iopub.execute_input":"2022-05-06T11:55:41.633944Z","iopub.status.idle":"2022-05-06T11:55:42.389063Z","shell.execute_reply.started":"2022-05-06T11:55:41.633909Z","shell.execute_reply":"2022-05-06T11:55:42.388338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recurrent Autoencoders\nIf you want to build an autoencoder for sequences, such as time series or text (e.g., for unsupervised learning or dimensionality reduction),then recurrent neural networks (see Chapter 15) may be better suited than dense networks. Building a recurrent autoencoder is straightforward: the encoder is typically a sequence-to-vector RNN which compresses the input sequence down to a single vector. The decoder is a vector-to-sequence RNN that does the reverse.","metadata":{}},{"cell_type":"code","source":"recurrent_encoder = keras.models.Sequential([\n     keras.layers.LSTM(100, return_sequences=True, input_shape=[None, 28]),\n     keras.layers.LSTM(30)\n])\n\nrecurrent_decoder = keras.models.Sequential([\n     keras.layers.RepeatVector(28, input_shape=[30]),\n     keras.layers.LSTM(100, return_sequences=True),\n     keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n])\n\nrecurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:55:42.390245Z","iopub.execute_input":"2022-05-06T11:55:42.391017Z","iopub.status.idle":"2022-05-06T11:55:43.573044Z","shell.execute_reply.started":"2022-05-06T11:55:42.390974Z","shell.execute_reply":"2022-05-06T11:55:43.572345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recurrent_ae.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.SGD(learning_rate=1.5))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:55:43.57411Z","iopub.execute_input":"2022-05-06T11:55:43.574342Z","iopub.status.idle":"2022-05-06T11:55:43.585623Z","shell.execute_reply.started":"2022-05-06T11:55:43.574309Z","shell.execute_reply":"2022-05-06T11:55:43.584972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = recurrent_ae.fit(X_train, X_train_target, epochs=10, validation_data=(X_valid, X_valid_target))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:55:43.586831Z","iopub.execute_input":"2022-05-06T11:55:43.587143Z","iopub.status.idle":"2022-05-06T11:58:09.363632Z","shell.execute_reply.started":"2022-05-06T11:55:43.587103Z","shell.execute_reply":"2022-05-06T11:58:09.362571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_reconstructions(recurrent_ae)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:58:09.366972Z","iopub.execute_input":"2022-05-06T11:58:09.367179Z","iopub.status.idle":"2022-05-06T11:58:10.529645Z","shell.execute_reply.started":"2022-05-06T11:58:09.367152Z","shell.execute_reply":"2022-05-06T11:58:10.528929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Denoising Autoencoders\nAnother way to force the autoencoder to learn useful features is to add noise to its inputs, training it to recover the original, noise-free inputs. Autoencoders could also be used for feature extraction. \nThe noise can be pure Gaussian noise added to the inputs, or it can be randomly switched-off inputs, just like in dropout. ","metadata":{}},{"cell_type":"code","source":"denoising_encoder = keras.models.Sequential([\n     keras.layers.Flatten(input_shape=[28, 28]),\n     keras.layers.Dropout(0.5),\n     keras.layers.Dense(100, activation=\"selu\"),\n     keras.layers.Dense(30, activation=\"selu\")\n])\n\ndenoising_decoder = keras.models.Sequential([\n     keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n     keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n     keras.layers.Reshape([28, 28])\n])\n\ndenoising_ae = keras.models.Sequential([denoising_encoder, denoising_decoder])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:58:10.530786Z","iopub.execute_input":"2022-05-06T11:58:10.531635Z","iopub.status.idle":"2022-05-06T11:58:10.604354Z","shell.execute_reply.started":"2022-05-06T11:58:10.531594Z","shell.execute_reply":"2022-05-06T11:58:10.603491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"denoising_ae.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.SGD(learning_rate=1.5))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:58:10.60565Z","iopub.execute_input":"2022-05-06T11:58:10.605924Z","iopub.status.idle":"2022-05-06T11:58:10.615861Z","shell.execute_reply.started":"2022-05-06T11:58:10.605889Z","shell.execute_reply":"2022-05-06T11:58:10.615006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = denoising_ae.fit(X_train, X_train_target, epochs=10, validation_data=(X_valid, X_valid_target))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:58:10.617433Z","iopub.execute_input":"2022-05-06T11:58:10.617797Z","iopub.status.idle":"2022-05-06T11:59:33.635762Z","shell.execute_reply.started":"2022-05-06T11:58:10.617758Z","shell.execute_reply":"2022-05-06T11:59:33.634947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_reconstructions(denoising_ae)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:59:33.637294Z","iopub.execute_input":"2022-05-06T11:59:33.637525Z","iopub.status.idle":"2022-05-06T11:59:34.145358Z","shell.execute_reply.started":"2022-05-06T11:59:33.63749Z","shell.execute_reply":"2022-05-06T11:59:34.144626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sparse Autoencoders\nAnother kind of constraint that often leads to good feature extraction is sparsity: by adding an appropriate term to the cost function, the autoencoder is pushed to reduce the number of active neurons in the coding layer. For example, it may be pushed to have on average only 5% significantly active neurons in the coding layer. This forces the autoencoder to represent each input as a combination of a small number of acti‚Äê vations. As a result, each neuron in the coding layer typically ends up representing a useful feature.","metadata":{}},{"cell_type":"code","source":"sparse_l1_encoder = keras.models.Sequential([\n     keras.layers.Flatten(input_shape=[28, 28]),\n     keras.layers.Dense(100, activation=\"selu\"),\n     keras.layers.Dense(300, activation=\"sigmoid\"),\n     keras.layers.ActivityRegularization(l1=1e-3)\n])\n\nsparse_l1_decoder = keras.models.Sequential([\n     keras.layers.Dense(100, activation=\"selu\", input_shape=[300]),\n     keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n     keras.layers.Reshape([28, 28])\n])\n\nsparse_l1_ae = keras.models.Sequential([sparse_l1_encoder, sparse_l1_decoder])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:59:34.146694Z","iopub.execute_input":"2022-05-06T11:59:34.147091Z","iopub.status.idle":"2022-05-06T11:59:34.229333Z","shell.execute_reply.started":"2022-05-06T11:59:34.14705Z","shell.execute_reply":"2022-05-06T11:59:34.228619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sparse_l1_ae.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.SGD(learning_rate=1.5))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:59:34.230457Z","iopub.execute_input":"2022-05-06T11:59:34.232523Z","iopub.status.idle":"2022-05-06T11:59:34.241342Z","shell.execute_reply.started":"2022-05-06T11:59:34.232487Z","shell.execute_reply":"2022-05-06T11:59:34.240489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = sparse_l1_ae.fit(X_train, X_train_target, epochs=10, validation_data=(X_valid, X_valid_target))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:59:34.243043Z","iopub.execute_input":"2022-05-06T11:59:34.243587Z","iopub.status.idle":"2022-05-06T12:00:22.793198Z","shell.execute_reply.started":"2022-05-06T11:59:34.243536Z","shell.execute_reply":"2022-05-06T12:00:22.792425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_reconstructions(sparse_l1_ae)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:00:22.794861Z","iopub.execute_input":"2022-05-06T12:00:22.795154Z","iopub.status.idle":"2022-05-06T12:00:23.333821Z","shell.execute_reply.started":"2022-05-06T12:00:22.795115Z","shell.execute_reply":"2022-05-06T12:00:23.333042Z"},"trusted":true},"execution_count":null,"outputs":[]}]}