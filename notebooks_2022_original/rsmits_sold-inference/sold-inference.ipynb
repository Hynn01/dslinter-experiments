{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Modules\nimport numpy as np \nimport pandas as pd\nimport csv\nimport cv2\nimport gc\nimport torch\nimport sys\n\n# SOLD2\nsys.path.append('../input/sold2linematching')\nfrom sold2.model.line_matcher import LineMatcher\nfrom sold2.misc.visualize_util import plot_images, plot_lines, plot_line_matches, plot_color_line_matches, plot_keypoints","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T14:15:27.208744Z","iopub.execute_input":"2022-05-07T14:15:27.209436Z","iopub.status.idle":"2022-05-07T14:15:31.835836Z","shell.execute_reply.started":"2022-05-07T14:15:27.209308Z","shell.execute_reply":"2022-05-07T14:15:31.834893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Torch - Device\nif not torch.cuda.is_available():\n    print('You may want to enable the GPU switch?')    \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:31.837861Z","iopub.execute_input":"2022-05-07T14:15:31.838165Z","iopub.status.idle":"2022-05-07T14:15:31.910467Z","shell.execute_reply.started":"2022-05-07T14:15:31.838124Z","shell.execute_reply":"2022-05-07T14:15:31.90958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Data","metadata":{}},{"cell_type":"code","source":"src = '/kaggle/input/image-matching-challenge-2022/'\n\ntest_samples = []\nwith open(f'{src}/test.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for i, row in enumerate(reader):\n        # Skip header.\n        if i == 0:\n            continue\n        test_samples += [row]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:31.9123Z","iopub.execute_input":"2022-05-07T14:15:31.913081Z","iopub.status.idle":"2022-05-07T14:15:31.93043Z","shell.execute_reply.started":"2022-05-07T14:15:31.913032Z","shell.execute_reply":"2022-05-07T14:15:31.929381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup SOLD2","metadata":{}},{"cell_type":"code","source":"ckpt_path = '../input/sold2linematching/pretrained/sold2_wireframe.tar'\nmode = 'dynamic'  # 'dynamic' or 'static'\n\n# Initialize the line matcher\nconfig = {\n    'model_cfg': {\n        'model_name': \"lcnn_simple\",\n        'model_architecture': \"simple\",\n        # Backbone related config\n        'backbone': \"lcnn\",\n        'backbone_cfg': {\n            'input_channel': 1, # Use RGB images or grayscale images.\n            'depth': 4,\n            'num_stacks': 2,\n            'num_blocks': 1,\n            'num_classes': 5\n        },\n        # Junction decoder related config\n        'junction_decoder': \"superpoint_decoder\",\n        'junc_decoder_cfg': {},\n        # Heatmap decoder related config\n        'heatmap_decoder': \"pixel_shuffle\",\n        'heatmap_decoder_cfg': {},\n        # Descriptor decoder related config\n        'descriptor_decoder': \"superpoint_descriptor\",\n        'descriptor_decoder_cfg': {},\n        # Shared configurations\n        'grid_size': 8,\n        'keep_border_valid': True,\n        # Threshold of junction detection\n        'detection_thresh': 0.0153846, # 1/65\n        'max_num_junctions': 300,\n        # Threshold of heatmap detection\n        'prob_thresh': 0.5,\n        # Weighting related parameters\n        'weighting_policy': mode,\n        # [Heatmap loss]\n        'w_heatmap': 0.,\n        'w_heatmap_class': 1,\n        'heatmap_loss_func': \"cross_entropy\",\n        'heatmap_loss_cfg': {\n            'policy': mode\n        },\n        # [Heatmap consistency loss]\n        # [Junction loss]\n        'w_junc': 0.,\n        'junction_loss_func': \"superpoint\",\n        'junction_loss_cfg': {\n            'policy': mode\n        },\n        # [Descriptor loss]\n        'w_desc': 0.,\n        'descriptor_loss_func': \"regular_sampling\",\n        'descriptor_loss_cfg': {\n            'dist_threshold': 8,\n            'grid_size': 4,\n            'margin': 1,\n            'policy': mode\n        },\n    },\n    'line_detector_cfg': {\n        'detect_thresh': 0.25,  # depending on your images, you might need to tune this parameter\n        'num_samples': 512,     # Original: 64\n        'sampling_method': \"local_max\",\n        'inlier_thresh': 0.9,\n        \"use_candidate_suppression\": True,\n        \"nms_dist_tolerance\": 3.,\n        \"use_heatmap_refinement\": True,\n        \"heatmap_refine_cfg\": {\n            \"mode\": \"local\",\n            \"ratio\": 0.2,\n            \"valid_thresh\": 1e-3,\n            \"num_blocks\": 20,\n            \"overlap_ratio\": 0.5\n        }\n    },\n    'multiscale': False,\n    'line_matcher_cfg': {\n        'cross_check': True,\n        'num_samples': 5,\n        'min_dist_pts': 8,\n        'top_k_candidates': 10,\n        'grid_size': 4\n    }\n}\n\n# Create SOLD2 Matcher\nsold2_matcher = LineMatcher(config[\"model_cfg\"], ckpt_path, device, config[\"line_detector_cfg\"], config[\"line_matcher_cfg\"], config[\"multiscale\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:31.934865Z","iopub.execute_input":"2022-05-07T14:15:31.935594Z","iopub.status.idle":"2022-05-07T14:15:37.769487Z","shell.execute_reply.started":"2022-05-07T14:15:31.935555Z","shell.execute_reply":"2022-05-07T14:15:37.768358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Functions","metadata":{}},{"cell_type":"code","source":"def FlattenMatrix(M, num_digits = 8):\n    '''Convenience function to write CSV files.'''    \n    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n\ndef get_fundamental_matrix(kpts1, kpts2):    \n    if len(kpts1) > 7:\n        F, inliers = cv2.findFundamentalMat(kpts1, \n                                            kpts2, \n                                            cv2.USAC_MAGSAC, \n                                            ransacReprojThreshold = 0.20, \n                                            confidence = 0.99999, \n                                            maxIters = 100000)\n        return F, inliers\n    else:\n        return np.zeros((3, 3)), None\n    \n\ndef load_image(image_path):\n    img = cv2.imread(image_path, 0)\n    \n    # Scale Factor...recommended to scale images to between 400 - 800\n    scale_factor = 800 / max(img.shape[0], img.shape[1]) \n    w = int(img.shape[1] * scale_factor)\n    h = int(img.shape[0] * scale_factor)\n    \n    # Resize\n    img = cv2.resize(img, (w, h), interpolation = cv2.INTER_AREA)\n    img = (img / 255.).astype(float)\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:37.771826Z","iopub.execute_input":"2022-05-07T14:15:37.772071Z","iopub.status.idle":"2022-05-07T14:15:37.793548Z","shell.execute_reply.started":"2022-05-07T14:15:37.772042Z","shell.execute_reply":"2022-05-07T14:15:37.792373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the SOLD2 model we eventually have a set of matched lines. When using Ransac (or one of its variants..) in the process to calculate a fundamental matrix we can't use the lines. So what we instead do is use the start and endpoints of a line as unique keypoints.","metadata":{}},{"cell_type":"code","source":"def get_keypoints(batch_id, img_id1, img_id2, plot = False):\n    image_fpath_1 = f'{src}/test_images/{batch_id}/{img_id1}.png'\n    image_fpath_2 = f'{src}/test_images/{batch_id}/{img_id2}.png'\n    \n    # Process Image 1\n    img1 = load_image(image_fpath_1)\n    torch_img1 = torch.tensor(img1, dtype=torch.float)[None, None]\n    \n    # Process Image 2\n    img2 = load_image(image_fpath_2)\n    torch_img2 = torch.tensor(img2, dtype=torch.float)[None, None]\n\n    # Match the lines\n    outputs = sold2_matcher([torch_img1, torch_img2])\n    line_seg1 = outputs[\"line_segments\"][0]\n    line_seg2 = outputs[\"line_segments\"][1]\n    matches = outputs[\"matches\"]\n\n    # Get Valid Matches\n    valid_matches = matches != -1\n    match_indices = matches[valid_matches]\n    matched_lines1 = line_seg1[valid_matches][:, :, ::-1]\n    matched_lines2 = line_seg2[match_indices][:, :, ::-1]\n    \n    # Plot the matches\n    if plot:\n        plot_images([img1, img2], ['Image1 - detected lines', 'Image2 - detected lines'])\n        plot_lines([line_seg1[:, :, ::-1], line_seg2[:, :, ::-1]], ps=3, lw=2)\n        plot_images([img1, img2], ['Image1 - matched lines', 'Image2 - matched lines'])\n        plot_color_line_matches([matched_lines1, matched_lines2], lw=2)\n\n    # Get start and end point of matched lines as regular keypoints\n    mkpts1 = matched_lines1.reshape(matched_lines1.shape[0] * 2, 2)\n    mkpts2 = matched_lines2.reshape(matched_lines2.shape[0] * 2, 2)\n    \n    return mkpts1, mkpts2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions","metadata":{}},{"cell_type":"code","source":"f_matrix_dict = {}\nfor i, row in enumerate(test_samples):\n    sample_id, batch_id, img_id1, img_id2 = row\n\n    # Get SOLD2 Keypoints\n    plot = False\n    if i < 3: plot = True\n    mkpts1, mkpts2 = get_keypoints(batch_id, img_id1, img_id2, plot)\n    \n    # Get Fundamental matrix\n    f_matrix_dict[sample_id], _ = get_fundamental_matrix(mkpts1, mkpts2)\n    \n    # Mem Cleanup\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:37.796147Z","iopub.execute_input":"2022-05-07T14:15:37.796479Z","iopub.status.idle":"2022-05-07T14:15:52.621898Z","shell.execute_reply.started":"2022-05-07T14:15:37.796431Z","shell.execute_reply":"2022-05-07T14:15:52.62096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission","metadata":{}},{"cell_type":"code","source":"# Write Submission File   \nwith open('submission.csv', 'w') as f:\n    f.write('sample_id,fundamental_matrix\\n')\n    for sample_id, F in f_matrix_dict.items():\n                \n        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:52.623507Z","iopub.execute_input":"2022-05-07T14:15:52.624373Z","iopub.status.idle":"2022-05-07T14:15:52.631164Z","shell.execute_reply.started":"2022-05-07T14:15:52.624331Z","shell.execute_reply":"2022-05-07T14:15:52.629987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary\nsub = pd.read_csv('submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T14:15:52.632823Z","iopub.execute_input":"2022-05-07T14:15:52.634007Z","iopub.status.idle":"2022-05-07T14:15:52.662781Z","shell.execute_reply.started":"2022-05-07T14:15:52.633959Z","shell.execute_reply":"2022-05-07T14:15:52.661867Z"},"trusted":true},"execution_count":null,"outputs":[]}]}