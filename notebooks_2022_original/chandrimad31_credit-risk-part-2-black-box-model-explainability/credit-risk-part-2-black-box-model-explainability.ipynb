{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Background:\n\nIn [Part-1](https://www.kaggle.com/code/chandrimad31/credit-risk-part-1-probability-of-default-model), we built PD model (white box) which is fully explainable. While using Black-Box models like Neural Net, Gradient Boosting, Random Forest etc. explability is a challenge. We will use two packages [LIME (Local Interpretable Model-Agnostic Explanations)](https://lime-ml.readthedocs.io/en/latest/) and [SHAP (SHapley Additive exPlanations)](https://shap.readthedocs.io/en/latest/index.html) here to work on model explainability.","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-05-04T19:48:58.836724Z","iopub.execute_input":"2022-05-04T19:48:58.837641Z","iopub.status.idle":"2022-05-04T19:49:00.148648Z","shell.execute_reply.started":"2022-05-04T19:48:58.837475Z","shell.execute_reply":"2022-05-04T19:49:00.147525Z"}}},{"cell_type":"markdown","source":"For data preprocessing, we will work more or less on the same line of approach that we followed in Part-1, except for the fact, here we need to use Label Encoder to convert categorical variables to numeric.","metadata":{}},{"cell_type":"code","source":"# import libraries \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(context='notebook')\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nplt.tight_layout()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n\ndata = pd.read_csv(r'../input/loan-data-2007-2014/loan_data_2007_2014/loan_data_2007_2014.csv')\n\n# create a new column based on the loan_status column that will be our target variable\ndata['bad_loan'] = np.where(data.loc[:, 'loan_status'].isin(['Charged Off', 'Default', 'Late (31-120 days)', 'Does not meet the credit policy. Status:Charged Off']), 0, 1)\n# Drop the original 'loan_status' column\ndata.drop(columns = ['loan_status'], inplace = True)\ndata.drop('Unnamed: 0', inplace=True, axis=1)\n\nX = data.drop('bad_loan', axis = 1)\ny = data['bad_loan']\n\n#dropping irrelevant cols & cols with missing values\n\ncolumns_to_drop = ['id', 'member_id', 'sub_grade', 'emp_title', 'url', 'desc', 'title', 'zip_code', 'next_pymnt_d',\n                  'recoveries', 'collection_recovery_fee', 'total_rec_prncp', 'total_rec_late_fee', 'desc', 'mths_since_last_record',\n                  'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'open_acc_6m', 'open_il_6m',\n                  'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m',\n                  'max_bal_bc', 'all_util', 'inq_fi', 'total_cu_tl', 'inq_last_12m','policy_code', 'mths_since_last_delinq']\ndata.drop(columns=columns_to_drop, inplace=True, axis=1)\n\ndata.dropna(inplace=True)\n\n# Removing multicollinear features \ndata.drop(columns=['loan_amnt', 'revol_bal', 'funded_amnt', 'funded_amnt_inv', 'installment',  'total_pymnt_inv',  'out_prncp_inv',  'total_acc'], inplace=True)\n\n# converting emp_length to numeric and assign NaN to zero\n\ndef emp_length_convert(df, column):\n    df[column] = df[column].str.replace('\\+ years', '')\n    df[column] = df[column].str.replace('< 1 year', str(0))\n    df[column] = df[column].str.replace(' years', '')\n    df[column] = df[column].str.replace(' year', '')\n    df[column] = pd.to_numeric(df[column])\n    df[column].fillna(value = 0, inplace = True)\n    \nemp_length_convert(data, 'emp_length')\n\n# converting term to numeric\n\ndef term_numeric(df, column):\n    df[column] = pd.to_numeric(df[column].str.replace(' months', ''))\n    \nterm_numeric(data, 'term')\n\n# preprocessing date cols \n\ndef date_columns(df, column):\n    # store current month\n    today_date = pd.to_datetime('2020-08-01')\n    # convert to datetime format\n    df[column] = pd.to_datetime(df[column], format = \"%b-%y\")\n    # calculate the difference in months and add to a new column\n    df['mths_since_' + column] = round(pd.to_numeric((today_date - df[column]) / np.timedelta64(1, 'M')))\n    # make any resulting -ve values to be equal to the max date\n    df['mths_since_' + column] = df['mths_since_' + column].apply(lambda x: df['mths_since_' + column].max() if x < 0 else x)\n    # drop the original date column\n    df.drop(columns = [column], inplace = True)\n    \n\ndate_columns(data, 'issue_d')\ndate_columns(data, 'last_pymnt_d')\ndate_columns(data, 'last_credit_pull_d')\ndate_columns(data, 'earliest_cr_line')\n\n# converting to dataframe \nbackup_data = data\npreprocess_data = data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-06T16:38:32.17389Z","iopub.execute_input":"2022-05-06T16:38:32.174475Z","iopub.status.idle":"2022-05-06T16:38:45.330272Z","shell.execute_reply.started":"2022-05-06T16:38:32.174381Z","shell.execute_reply":"2022-05-06T16:38:45.329513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert categorical features to continuous features with Label Encoding\nfrom sklearn.preprocessing import LabelEncoder\nlencoders = {}\nfor col in preprocess_data.select_dtypes(include=['object']).columns:\n    lencoders[col] = LabelEncoder()\n    preprocess_data[col] = lencoders[col].fit_transform(preprocess_data[col])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:40:09.285099Z","iopub.execute_input":"2022-05-06T16:40:09.285599Z","iopub.status.idle":"2022-05-06T16:40:10.246842Z","shell.execute_reply.started":"2022-05-06T16:40:09.28556Z","shell.execute_reply":"2022-05-06T16:40:10.246078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#seperating data into target and features\nX= preprocess_data.drop(columns='bad_loan', axis=1)\ny=preprocess_data['bad_loan']","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-05-06T16:40:27.304699Z","iopub.execute_input":"2022-05-06T16:40:27.304976Z","iopub.status.idle":"2022-05-06T16:40:27.409071Z","shell.execute_reply.started":"2022-05-06T16:40:27.304945Z","shell.execute_reply":"2022-05-06T16:40:27.408344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:40:58.731063Z","iopub.execute_input":"2022-05-06T16:40:58.731353Z","iopub.status.idle":"2022-05-06T16:40:58.834791Z","shell.execute_reply.started":"2022-05-06T16:40:58.731321Z","shell.execute_reply":"2022-05-06T16:40:58.834136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Explainability with LIME","metadata":{}},{"cell_type":"code","source":"from lime.lime_tabular import LimeTabularExplainer\nimport time\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:41:05.284578Z","iopub.execute_input":"2022-05-06T16:41:05.284846Z","iopub.status.idle":"2022-05-06T16:41:05.717428Z","shell.execute_reply.started":"2022-05-06T16:41:05.284819Z","shell.execute_reply":"2022-05-06T16:41:05.716668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrained_models = [] #  keep track of all details for models we train\ndef train_model(model, data, labels): \n  X = data\n  y = labels.values\n  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 12345)\n  pipe = Pipeline([('scaler', StandardScaler()),('clf', model[\"clf\"])])\n  start_time = time.time()\n  pipe.fit(X_train, y_train)\n  train_time = time.time() - start_time\n\n  train_accuracy =  pipe.score(X_train, y_train)\n  test_accuracy = pipe.score(X_test, y_test) \n  model_details = {\"name\": model[\"name\"], \"train_accuracy\":train_accuracy, \"test_accuracy\":test_accuracy, \"train_time\": train_time, \"model\": pipe}\n  return model_details\n\nmodels = [\n          {\"name\": \"Extra Trees\", \"clf\": ExtraTreesClassifier()},\n          {\"name\": \"Random Forest\", \"clf\": RandomForestClassifier(n_estimators=100)}, \n          {\"name\": \"Gradient Boosting\", \"clf\": GradientBoostingClassifier(n_estimators=100)},\n          {\"name\": \"XGBoost\", \"clf\": XGBClassifier(silent=True)},\n          {\"name\": \"CatBoost\", \"clf\": CatBoostClassifier()}, \n          {\"name\": \"MLP Neural Net\", \"clf\": MLPClassifier(solver='adam', alpha=1e-1, hidden_layer_sizes=(10,10,5,2), max_iter=500, random_state=42)}]\n\nfor model in models:\n  model_details = train_model(model, X, y) \n  trained_models.append(model_details)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-06T16:41:14.965894Z","iopub.execute_input":"2022-05-06T16:41:14.966189Z","iopub.status.idle":"2022-05-06T16:48:18.825098Z","shell.execute_reply.started":"2022-05-06T16:41:14.966155Z","shell.execute_reply":"2022-05-06T16:48:18.824203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lime.lime_tabular import LimeTabularExplainer\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 12345) \n\ndef get_lime_explainer(model, data, labels):  \n\n  cat_feat_ix = [i for i,c in enumerate(data.columns) if pd.api.types.is_categorical_dtype(data[c])]\n  feat_names = list(data.columns)\n  class_names = list(labels.unique())\n  scaler = model[\"model\"][\"scaler\"]\n  data = scaler.transform(data) # scale data to reflect train time scaling\n  lime_explainer = LimeTabularExplainer(data,\n                                      feature_names=feat_names,\n                                      class_names=class_names,\n                                      categorical_features=cat_feat_ix ,\n                                      mode=\"classification\"\n                                      )\n  return lime_explainer\n\ndef lime_explain(explainer, data, predict_method, num_features): \n  explanation = explainer.explain_instance(data, predict_method, num_features=num_features) \n  return explanation\n\nlime_data_explainations = []\nlime_metrics = []\nlime_explanation_time = []\nfeat_names = list(X.columns)\ntest_data_index = 6\nfor current_model in trained_models:  \n  scaler = current_model[\"model\"][\"scaler\"]\n  scaled_test_data = scaler.transform(X_test)\n  predict_method = current_model[\"model\"][\"clf\"].predict_proba \n  top_x = 10\n  start_time = time.time()\n  # explain first sample from test data\n  lime_explainer = get_lime_explainer(current_model, X_train, y_train)\n  explanation = lime_explain(lime_explainer, scaled_test_data[test_data_index], predict_method, top_x) \n  elapsed_time = time.time() - start_time \n\n  ex_holder = {}\n  for feat_index,ex in explanation.as_map()[1] :\n    ex_holder[feat_names[feat_index]] = ex\n  \n  lime_data_explainations.append(ex_holder) \n  actual_pred = predict_method(scaled_test_data[test_data_index].reshape(1,-1))\n  perc_pred_diff =  abs(actual_pred[0][1] - explanation.local_pred[0])   \n  lime_explanation_time.append({\"time\": elapsed_time, \"model\": current_model[\"name\"] })\n  lime_metrics.append({\"lime class1\": explanation.local_pred[0], \"actual class1\": actual_pred[0][1], \"class_diff\": round(perc_pred_diff,3), \"model\": current_model[\"name\"] })","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:48:57.213281Z","iopub.execute_input":"2022-05-06T16:48:57.213599Z","iopub.status.idle":"2022-05-06T16:50:17.615147Z","shell.execute_reply.started":"2022-05-06T16:48:57.213563Z","shell.execute_reply":"2022-05-06T16:50:17.614189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def setup_plot():\n  plt.rcParams[\"axes.grid.axis\"] =\"y\"\n  plt.rcParams[\"axes.grid\"] = True\n  plt.rcParams[\"legend.fontsize\"] = 20\n  plt.rc('grid', linestyle=\"dashed\", color='lightgrey', linewidth=1)\n  plt.rcParams[\"xtick.labelsize\"] = 18\n  plt.rcParams[\"ytick.labelsize\"]  = 18","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:51:03.51385Z","iopub.execute_input":"2022-05-06T16:51:03.514114Z","iopub.status.idle":"2022-05-06T16:51:03.519408Z","shell.execute_reply.started":"2022-05-06T16:51:03.514085Z","shell.execute_reply":"2022-05-06T16:51:03.518586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_list =  sns.color_palette(\"viridis\", len(X.columns)) \n\ndef plot_lime_exp(fig, fig_index, exp_data, title):\n  features =  list(exp_data.keys())[::-1]\n  explanations = list(exp_data.values())[::-1]\n  ax = fig.add_subplot(fig_index) \n  lime_bar = ax.barh( features, explanations ) \n  ax.set_title(title, fontsize = 20)\n  for i,bar in enumerate(lime_bar):\n    bar.set_color(color_list[list(X.columns).index(features[i])])\n    plt.box(False) \nfig = plt.figure(figsize=(20,30))\n\n# Plot lime explanations for trained models\nfor i, dex in enumerate(lime_data_explainations):\n  fig_index = int(\"61\" + str(i+1))\n  plot_lime_exp(fig, fig_index, lime_data_explainations[i], trained_models[i][\"name\"])\n\nplt.suptitle( \" LIME Explanation for single test data instance:  Top \" + str(top_x) + \" Features\", fontsize=20, fontweight=\"normal\")\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])\n\n# Plot run time for explanations\nlx_df = pd.DataFrame(lime_explanation_time)\nlx_df.sort_values(\"time\", inplace=True)\nsetup_plot()\nlx_ax = lx_df.plot(kind=\"line\", marker=\"o\", mfc=\"red\", mec=\"white\", markersize=16, x=\"model\", title=\"Runtime (seconds) for single test data instance LIME explanation\", figsize=(20,6))\nlx_ax.title.set_size(20)\nlx_ax.legend([\"Run time\"])\nplt.box(False)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:58:11.124821Z","iopub.execute_input":"2022-05-06T16:58:11.125076Z","iopub.status.idle":"2022-05-06T16:58:13.561932Z","shell.execute_reply.started":"2022-05-06T16:58:11.125045Z","shell.execute_reply":"2022-05-06T16:58:13.561001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking if the above Explainability derived by LIME can be Trusted or Not\n\nWe need to compare local prediction by LIME vs actual prediction for all the models to verify if the above model explainabilities are reliable or not. If there is very minimal difference between local vs actual prediction, then the model explainability by LIME (above) should be trusted, else not.","metadata":{}},{"cell_type":"code","source":"# Plot run time for explanations\nlime_metrics_df = pd.DataFrame(lime_metrics)  \nlime_metrics_df_ax = lime_metrics_df[[\"lime class1\", \"actual class1\", \"model\"]].plot(kind=\"line\", marker=\"o\", mfc=\"red\", mec=\"white\", markersize=16, x=\"model\", title=\"LIME Actual Prediction vs Local Prediction \", figsize=(20,6))\nlime_metrics_df_ax.title.set_size(20)\nlime_metrics_df_ax.legend([\"Lime Local Prediction\", \"Actual Prediction\"])\nplt.box(False)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:59:44.12445Z","iopub.execute_input":"2022-05-06T16:59:44.124706Z","iopub.status.idle":"2022-05-06T16:59:44.425292Z","shell.execute_reply.started":"2022-05-06T16:59:44.124677Z","shell.execute_reply":"2022-05-06T16:59:44.424596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We observe: \n* The difference between local prediction and actual prediction is the least for XGBoost. Hence, we can trust model explainablity for XGBoost using LIME. \n* \"total_pymnt\", \"mnths_since_last_pymnt\", \"term\", \"collections_12_mnths_ex_med\", \"acc_now_delinq\", \"annual_inc\",  are the features which negatively contribute towards bad loan (i.e. positively contributes to good loan)\n* \"out_prncp\", \"total_rec_int\", \"int_rate\", \"last_pymnt_amnt\" positively contribute towards bad loan","metadata":{}},{"cell_type":"markdown","source":"# SHAP Kernel Explainer\n\nThere is another alternative SHAP Tree Explainer which is a faster alternative. You may use that too instead of Kernel Explainer.","metadata":{}},{"cell_type":"code","source":"import shap\ncurrent_model = trained_models[3] # Explain the XGBoost Model\nclf = current_model[\"model\"][\"clf\"]\nscaler = current_model[\"model\"][\"scaler\"]\nscaled_train_data = scaler.transform(X_train)\nsub_sampled_train_data = shap.sample(scaled_train_data, 1000, random_state=0) \n# use 1000 samples of train data as background data\n\nscaled_test_data = scaler.transform(X_test) \nsubsampled_test_data =scaled_test_data[test_data_index].reshape(1,-1)\n\nstart_time = time.time()\nexplainer = shap.KernelExplainer(clf.predict_proba, sub_sampled_train_data)\nshap_values = explainer.shap_values(subsampled_test_data,  l1_reg=\"aic\")\nelapsed_time = time.time() - start_time\n# explain first sample from test data\nprint(\"Kernel Explainer SHAP run time\", round(elapsed_time,3) , \" seconds. \", current_model[\"name\"])\nprint(\"SHAP expected value\", explainer.expected_value)\nprint(\"Model mean value\", clf.predict_proba(scaled_train_data).mean(axis=0))\nprint(\"Model prediction for test data\", clf.predict_proba(subsampled_test_data))\nshap.initjs()\npred_ind = 0\nshap.force_plot(explainer.expected_value[1], shap_values[1][0], subsampled_test_data[0], feature_names=X_train.columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T17:01:21.865309Z","iopub.execute_input":"2022-05-06T17:01:21.865567Z","iopub.status.idle":"2022-05-06T17:01:36.538406Z","shell.execute_reply.started":"2022-05-06T17:01:21.865538Z","shell.execute_reply":"2022-05-06T17:01:36.537766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SHAP shows: \n- \"mths_since_last_pymnt_d\", \"total_pymnt\", \"last_pymnt_amnt\" contribute negatively towards default. \n- \"out_prncp\" contributes positively towards default.\n","metadata":{}},{"cell_type":"code","source":"shap.initjs()\nshap.summary_plot(shap_values, subsampled_test_data, feature_names=X_train.columns, max_display=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T17:01:54.203334Z","iopub.execute_input":"2022-05-06T17:01:54.203603Z","iopub.status.idle":"2022-05-06T17:01:54.499234Z","shell.execute_reply.started":"2022-05-06T17:01:54.203572Z","shell.execute_reply":"2022-05-06T17:01:54.498546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explain a Test Data Instance for all Models","metadata":{}},{"cell_type":"code","source":"import shap\n\ndef get_kernel_shap_explainer(model, background_data, train_data):  \n  shap_explainer = shap.KernelExplainer(model.predict_proba, background_data)   \n  return shap_explainer \n\ndef shap_explain(explainer, test_data): \n  shap_values = explainer.shap_values(test_data, l1_reg=\"aic\")\n  \n  return shap_values\n\nshap_data_explainations = []\nshape_explanation_time = []\nfeat_names = list(X.columns) \ndata_subsample = 500 \nfor current_model in trained_models:  \n  scaler = current_model[\"model\"][\"scaler\"]\n  scaled_test_data = scaler.transform(X_test)\n  scaled_train_data = scaler.transform(X_train)\n  sampled_scaled_train_data = shap.sample(scaled_train_data, data_subsample) # subsample background data to make things faster\n  \n  start_time = time.time()\n  shap_explainer  = get_kernel_shap_explainer(current_model[\"model\"][\"clf\"], sampled_scaled_train_data, scaled_train_data)\n\n  # explain first sample from test data \n  sampled_scaled_test_data = scaled_test_data[test_data_index].reshape(1,-1)\n  shap_values = shap_explain(shap_explainer, sampled_scaled_test_data) \n  elapsed_time = time.time() - start_time \n  idx = np.argsort(np.abs(shap_values[1][0]))[::-1] \n  ex_holder = { feat_names[idx[i]] : shap_values[1][0][idx[i]] for i in range(top_x)} \n   \n \n  shap_data_explainations.append(ex_holder) \n  shape_explanation_time.append({\"time\": elapsed_time, \"model\": current_model[\"name\"] })","metadata":{"execution":{"iopub.status.busy":"2022-05-06T17:02:57.130249Z","iopub.execute_input":"2022-05-06T17:02:57.130514Z","iopub.status.idle":"2022-05-06T17:04:13.466068Z","shell.execute_reply.started":"2022-05-06T17:02:57.130487Z","shell.execute_reply":"2022-05-06T17:04:13.465128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_shap_exp(fig, fig_index, exp_data, title):\n  features =  list(exp_data.keys())[::-1]\n  explanations = list(exp_data.values())[::-1]\n  ax = fig.add_subplot(fig_index) \n  lime_bar = ax.barh( features, explanations ) \n  ax.set_title(title, fontsize = 20)\n  for i,bar in enumerate(lime_bar):\n    bar.set_color(color_list[list(current_data.columns).index(features[i])])\n    plt.box(False) \n\n\n# Plot SHAP explanations for a given test set item\nfig = plt.figure(figsize=(20,30))\nfor i, dex in enumerate(shap_data_explainations):\n  fig_index = int(\"61\" + str(i+1))\n  plot_lime_exp(fig, fig_index, shap_data_explainations[i], trained_models[i][\"name\"])\n\nplt.suptitle( \"Kernel SHAP Explanation for single test data instance:  Top \" + str(top_x) + \" Features\", fontsize=20, fontweight=\"normal\")\nfig.tight_layout(rect=[0, 0.03, 1, 0.95])\n\n# Plot SHAP explanation run time\nshapx_df = pd.DataFrame(shape_explanation_time)\nshapx_df.sort_values(\"time\", inplace=True)\n\n# Plot both LIME and SHAP explanation run times\nm_df =  shapx_df.merge(lx_df, on=\"model\", suffixes=(\"_SHAP\", \"_LIME\")) \nm_df.head() \nmx_df_ax = m_df.plot(kind=\"line\", marker=\"o\", mfc=\"red\", mec=\"white\", markersize=16, x=\"model\", title=\"Kernel SHAP vs LIME: Runtime (seconds) for single instance explanation\", figsize=(20,6))\nmx_df_ax.title.set_size(20)\nmx_df_ax.legend([\"Run time for SHAP\", \"Run time for LIME\"])\nplt.box(False)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T17:06:07.884887Z","iopub.execute_input":"2022-05-06T17:06:07.88517Z","iopub.status.idle":"2022-05-06T17:06:10.1305Z","shell.execute_reply.started":"2022-05-06T17:06:07.885135Z","shell.execute_reply":"2022-05-06T17:06:10.129678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Acknowledgement: \n\n[Colab research notebooks on LIME and SHAP for model interpretablity](https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N#scrollTo=-YRBzUfRVTTD) \n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}