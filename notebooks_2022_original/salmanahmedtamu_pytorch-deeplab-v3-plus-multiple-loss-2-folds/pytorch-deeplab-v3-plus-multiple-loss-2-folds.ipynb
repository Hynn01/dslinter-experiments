{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DeepLabV3Plus Simple Trained on Multiple Losses for almost 20 Epochs. (0.837)","metadata":{}},{"cell_type":"markdown","source":"# Training Notebook [https://www.kaggle.com/code/salmanahmedtamu/deeplab-v3-pytorch-training-notebook-0-837](https://www.kaggle.com/code/salmanahmedtamu/deeplab-v3-pytorch-training-notebook-0-837)","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-master\")\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom glob import glob\nimport gc\ngc.enable()\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport cv2\nimport albumentations as A\nimport time\nimport os\nfrom tqdm.notebook import tqdm\nimport segmentation_models_pytorch as smp\nfrom torch.cuda import amp\nscaler = amp.GradScaler()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:11:35.650694Z","iopub.execute_input":"2022-04-23T23:11:35.651213Z","iopub.status.idle":"2022-04-23T23:11:42.525519Z","shell.execute_reply.started":"2022-04-23T23:11:35.651175Z","shell.execute_reply":"2022-04-23T23:11:42.524553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:11:42.527544Z","iopub.execute_input":"2022-04-23T23:11:42.52777Z","iopub.status.idle":"2022-04-23T23:11:42.535802Z","shell.execute_reply.started":"2022-04-23T23:11:42.527741Z","shell.execute_reply":"2022-04-23T23:11:42.535088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv\")\nDEBUG = False\nif df.shape[0] == 0:\n    DEBUG = True\nif DEBUG == True:\n    df = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/train.csv\")\n    df.pop('segmentation')\n    df['predicted'] = \"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:14:00.475753Z","iopub.execute_input":"2022-04-23T23:14:00.476036Z","iopub.status.idle":"2022-04-23T23:14:00.97103Z","shell.execute_reply.started":"2022-04-23T23:14:00.476006Z","shell.execute_reply":"2022-04-23T23:14:00.970311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"case_id_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[0])\ndf[\"case_id\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[0].replace(\"case\", \"\")))\n\n# 2. Get Day as a column\ndf[\"day_num_str\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[1])\ndf[\"day_num\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\", 2)[1].replace(\"day\", \"\")))\n\n# 3. Get Slice Identifier as a column\ndf[\"slice_id\"] = df[\"id\"].apply(lambda x: x.split(\"_\", 2)[2])\n\nif DEBUG:\n    TRAIN_DIR = '../input/uw-madison-gi-tract-image-segmentation/train'\nelse:\n    TRAIN_DIR = '../input/uw-madison-gi-tract-image-segmentation/test'\n# Get all training images\nall_train_images = glob(os.path.join(TRAIN_DIR, \"**\", \"*.png\"), recursive=True)\n\n# 4. Get full file paths for the representative scans\n# df[\"_partial_ident\"] = (+ \"\\\\\" + +\"\\\\\"+ \n#                        + \"\\\\scans\\\\\"+df[\"slice_id\"]) \n\np = []\nx = all_train_images[0].rsplit(\"/\", 4)[0]\nfor i in range(0, df.shape[0]):\n    p.append(os.path.join(x, df[\"case_id_str\"].values[i], df[\"case_id_str\"].values[i]+\"_\"+df[\"day_num_str\"].values[i], \"scans\", df[\"slice_id\"].values[i]))\ndf[\"_partial_ident\"] = p\n\np = []\nfor i in range(0, len(all_train_images)):\n    p.append(str(all_train_images[i].rsplit(\"_\",4)[0]))\n    \n_tmp_merge_df = pd.DataFrame()\n_tmp_merge_df['_partial_ident'] = p\n_tmp_merge_df['f_path'] = all_train_images\n\n\ndf = df.merge(_tmp_merge_df, on=\"_partial_ident\").drop(columns=[\"_partial_ident\"])\n\n# 5. Get slice dimensions from filepath (int in pixels)\ndf[\"slice_h\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\ndf[\"slice_w\"] = df[\"f_path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n\n# 6. Pixel spacing from filepath (float in mm)\ndf[\"px_spacing_h\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[3]))\ndf[\"px_spacing_w\"] = df[\"f_path\"].apply(lambda x: float(x[:-4].rsplit(\"_\",4)[4]))\n\ndf1 = df[df.index % 3 == 0]\ndf2 = df[df.index % 3 == 1]\ndf3 = df[df.index % 3 == 2]\ndf = df1.copy()\ndf.pop('class')\ngc.collect()\n\ndel x, df1, df2, df3, _tmp_merge_df, all_train_images\ngc.collect()\ndf = df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:14:02.160527Z","iopub.execute_input":"2022-04-23T23:14:02.161285Z","iopub.status.idle":"2022-04-23T23:14:10.955447Z","shell.execute_reply.started":"2022-04-23T23:14:02.161247Z","shell.execute_reply":"2022-04-23T23:14:10.954685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (df.shape)\nif DEBUG:\n    df = df.sample(frac=0.1).reset_index(drop=True)\nprint (df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:14:10.956829Z","iopub.execute_input":"2022-04-23T23:14:10.957075Z","iopub.status.idle":"2022-04-23T23:14:10.97458Z","shell.execute_reply.started":"2022-04-23T23:14:10.957043Z","shell.execute_reply":"2022-04-23T23:14:10.973903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TractDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.sh = df[\"slice_h\"]\n        self.sw = df[\"slice_w\"]\n        \n        self.image_path = df['f_path']\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        \n        _img = self.open_gray16(self.image_path[idx])\n        _img = ((_img-_img.min())/(_img.max()-_img.min())).astype(np.float32)\n        img = (_img * 255.0).astype('uint8')\n        \n        if self.transform is not None:\n            aug = self.transform(image=img)\n            img = aug['image']\n            \n        img = img / 255.0\n        img = np.transpose(img, (2, 0, 1))\n        \n        return torch.tensor(img, dtype=torch.float), self.sh[idx], self.sw[idx]\n    \n    def open_gray16(self, _path, normalize=True, to_rgb=True):\n        \"\"\" Helper to open files \"\"\"\n        if normalize:\n            if to_rgb:\n                return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535., axis=-1), 3)\n            else:\n                return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535.\n        else:\n            if to_rgb:\n                return np.tile(np.expand_dims(cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n            else:\n                return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:16:36.607487Z","iopub.execute_input":"2022-04-23T23:16:36.607915Z","iopub.status.idle":"2022-04-23T23:16:36.628662Z","shell.execute_reply.started":"2022-04-23T23:16:36.60787Z","shell.execute_reply":"2022-04-23T23:16:36.627673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_epoch(loader):\n    for each in models:\n        each.eval()\n        \n    lbs = []\n    sbs = []\n    sts = []\n    LOGITS = []\n    \n    with torch.no_grad():\n        \n        for (data, sh, sw) in tqdm(loader):\n            \n            data = data.to(CFG['device'])\n            outputs = []\n            for each in models:\n                output = each(data)\n                output = torch.sigmoid(output.cpu())\n                outputs.append(output)\n            \n            output = (outputs[0] + outputs[1] ) / 2.0\n            output = torch.round(output).numpy()\n            \n            \n            for idx in range(0, len(sh)):\n                root_shape = (int(sh[idx]), int(sw[idx]))\n                pred_arr = np.round(cv2.resize(output[idx, 0, :, :].astype('uint8'), root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n                lbs.append(rle_encode(pred_arr))\n                pred_arr = np.round(cv2.resize(output[idx, 1, :, :].astype('uint8'), root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n                sbs.append(rle_encode(pred_arr))\n                pred_arr = np.round(cv2.resize(output[idx, 2, :, :].astype('uint8'), root_shape, interpolation=cv2.INTER_NEAREST)).astype('uint8')\n                sts.append(rle_encode(pred_arr))\n\n    gc.collect()\n    return lbs, sbs, sts","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:14:12.86464Z","iopub.execute_input":"2022-04-23T23:14:12.865169Z","iopub.status.idle":"2022-04-23T23:14:12.875392Z","shell.execute_reply.started":"2022-04-23T23:14:12.865134Z","shell.execute_reply":"2022-04-23T23:14:12.874624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:14:14.257745Z","iopub.execute_input":"2022-04-23T23:14:14.258017Z","iopub.status.idle":"2022-04-23T23:14:14.263455Z","shell.execute_reply.started":"2022-04-23T23:14:14.257982Z","shell.execute_reply":"2022-04-23T23:14:14.262757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG = {\n    'fold' : 0, \n    'batch_size' : 8,\n    'image_size' : 256,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    'init_lr' : 1e-3,\n    'warmup_factor' : 10,\n    'warmup_epo' : 4,\n    'n_epochs' : 20,\n    'num_workers' : 4,\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:14:14.651452Z","iopub.execute_input":"2022-04-23T23:14:14.652002Z","iopub.status.idle":"2022-04-23T23:14:14.658042Z","shell.execute_reply.started":"2022-04-23T23:14:14.651966Z","shell.execute_reply":"2022-04-23T23:14:14.657265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor fold in range(0, 2):\n    model = smp.DeepLabV3Plus('efficientnet-b1', encoder_weights=None, classes=3, activation=None)\n    model = model.to(CFG['device'])\n    model = nn.DataParallel(model)\n    model_file = f'../input/../input/deeplab-20-epochs/deep_lab_final_fold_{fold}.pth'\n    model.load_state_dict(torch.load(model_file))\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:15:22.482971Z","iopub.execute_input":"2022-04-23T23:15:22.483237Z","iopub.status.idle":"2022-04-23T23:15:26.621852Z","shell.execute_reply.started":"2022-04-23T23:15:22.483208Z","shell.execute_reply":"2022-04-23T23:15:26.621116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_test = A.Compose([A.Resize(CFG['image_size'], CFG['image_size'], interpolation=cv2.INTER_NEAREST)])\ntest_set = TractDataset(df.reset_index(drop=True), transform_test)\ntest_loader = DataLoader(test_set, batch_size=CFG['batch_size'], shuffle=False) \nlbs, sbs, sts = test_epoch(test_loader)\n\ndel test_set, test_loader, transform_test\ngc.collect()\n\ndf = df[['id', 'slice_h', 'slice_w']]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:16:40.289528Z","iopub.execute_input":"2022-04-23T23:16:40.290286Z","iopub.status.idle":"2022-04-23T23:18:10.20813Z","shell.execute_reply.started":"2022-04-23T23:16:40.29023Z","shell.execute_reply":"2022-04-23T23:18:10.207392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del models\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:18:10.209663Z","iopub.execute_input":"2022-04-23T23:18:10.210323Z","iopub.status.idle":"2022-04-23T23:18:10.363126Z","shell.execute_reply.started":"2022-04-23T23:18:10.210284Z","shell.execute_reply":"2022-04-23T23:18:10.362406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[['id']]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:18:10.364429Z","iopub.execute_input":"2022-04-23T23:18:10.364815Z","iopub.status.idle":"2022-04-23T23:18:10.51668Z","shell.execute_reply.started":"2022-04-23T23:18:10.364774Z","shell.execute_reply":"2022-04-23T23:18:10.515231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nclasses = []\nrles = []\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    ids.extend([row['id']] * 3)\n    classes.extend(['large_bowel', 'small_bowel', 'stomach'])\n    rles.extend([lbs[index], sbs[index], sts[index]])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:18:10.518761Z","iopub.execute_input":"2022-04-23T23:18:10.519175Z","iopub.status.idle":"2022-04-23T23:18:10.742885Z","shell.execute_reply.started":"2022-04-23T23:18:10.51909Z","shell.execute_reply":"2022-04-23T23:18:10.742105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del lbs, sbs, sts\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:18:10.744271Z","iopub.execute_input":"2022-04-23T23:18:10.744556Z","iopub.status.idle":"2022-04-23T23:18:10.891194Z","shell.execute_reply.started":"2022-04-23T23:18:10.744519Z","shell.execute_reply":"2022-04-23T23:18:10.890386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['id'] = ids\ndf['class'] = classes\ndf['predicted'] = rles\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:18:10.89319Z","iopub.execute_input":"2022-04-23T23:18:10.893625Z","iopub.status.idle":"2022-04-23T23:18:11.008101Z","shell.execute_reply.started":"2022-04-23T23:18:10.893586Z","shell.execute_reply":"2022-04-23T23:18:11.007283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:18:11.009491Z","iopub.execute_input":"2022-04-23T23:18:11.009763Z","iopub.status.idle":"2022-04-23T23:18:11.024556Z","shell.execute_reply.started":"2022-04-23T23:18:11.009727Z","shell.execute_reply":"2022-04-23T23:18:11.023912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}