{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# WGAN Pests  - 128x128","metadata":{}},{"cell_type":"markdown","source":"Import libraries","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function\nimport os\nimport time\nimport datetime\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.utils as utils\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom PIL import Image\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:52.147995Z","iopub.execute_input":"2022-05-08T08:36:52.148308Z","iopub.status.idle":"2022-05-08T08:36:53.726839Z","shell.execute_reply.started":"2022-05-08T08:36:52.148225Z","shell.execute_reply":"2022-05-08T08:36:53.7261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set up paths","metadata":{}},{"cell_type":"code","source":"PEST = \"TU\"\ndataset_dir = f'../input/tomato-pests-gan/{PEST}'\nload_checkpoints = f'../input/checkpoints'\nfigures_dir = f'./figures/{PEST}/'\ncheckpoints_dir = f'./checkpoints/{PEST}/'\ngraphs_dir = f'./graphs/{PEST}'\n\nif not(os.path.exists(figures_dir)): os.makedirs(figures_dir)\nif not(os.path.exists(checkpoints_dir)): os.makedirs(checkpoints_dir)\nif not(os.path.exists(graphs_dir)): os.makedirs(graphs_dir)\n    \nfg = open(\"g_losses.txt\", \"a\")\nfd = open(\"d_losses.txt\", \"a\")\nfe = open(\"epoch.txt\", \"a\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:53.728368Z","iopub.execute_input":"2022-05-08T08:36:53.728615Z","iopub.status.idle":"2022-05-08T08:36:53.736546Z","shell.execute_reply.started":"2022-05-08T08:36:53.728582Z","shell.execute_reply":"2022-05-08T08:36:53.735794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set up hyperparameters","metadata":{}},{"cell_type":"code","source":"workers = 2\n\nbatch_size = 128\nimage_size = 128\n\nnc = 3\nnoise_dim = 100\n\nnfg = 64\nnfd = 64\n\nepochs = 14401\n\ng_learning_rate = 5e-5\nd_learning_rate = 5e-5\nbeta1 = 0.5\nbeta2 = 0.999\ncritic_iterations = 5\nlambda_gp=10","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:53.737836Z","iopub.execute_input":"2022-05-08T08:36:53.738223Z","iopub.status.idle":"2022-05-08T08:36:53.745394Z","shell.execute_reply.started":"2022-05-08T08:36:53.738187Z","shell.execute_reply":"2022-05-08T08:36:53.744553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"True if you want to load the model from disk, False if you want the model to be initialized from scratch","metadata":{}},{"cell_type":"code","source":"load_model = True","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:53.747526Z","iopub.execute_input":"2022-05-08T08:36:53.747783Z","iopub.status.idle":"2022-05-08T08:36:53.753444Z","shell.execute_reply.started":"2022-05-08T08:36:53.747749Z","shell.execute_reply":"2022-05-08T08:36:53.752759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set up GPU device for training","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:53.754869Z","iopub.execute_input":"2022-05-08T08:36:53.755124Z","iopub.status.idle":"2022-05-08T08:36:53.76106Z","shell.execute_reply.started":"2022-05-08T08:36:53.755091Z","shell.execute_reply":"2022-05-08T08:36:53.760205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the dataset","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n                                transforms.ToTensor()\n                                ])\ntrain_data = datasets.ImageFolder(dataset_dir, transform=transform)\ndata_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=workers)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:53.762463Z","iopub.execute_input":"2022-05-08T08:36:53.762776Z","iopub.status.idle":"2022-05-08T08:36:53.847864Z","shell.execute_reply.started":"2022-05-08T08:36:53.762742Z","shell.execute_reply":"2022-05-08T08:36:53.847131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"View samples from the dataset","metadata":{}},{"cell_type":"code","source":"ds_sample = next(iter(data_loader))\n\nplt.figure(figsize=(8, 8))\nplt.axis('off')\nplt.title('Train data')\ngrid = np.transpose(utils.make_grid(ds_sample[0].to(device)[:64], padding=4, normalize=True).cpu(), (1, 2, 0))\nplt.imshow(grid)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:53.849391Z","iopub.execute_input":"2022-05-08T08:36:53.850017Z","iopub.status.idle":"2022-05-08T08:36:57.574428Z","shell.execute_reply.started":"2022-05-08T08:36:53.849982Z","shell.execute_reply":"2022-05-08T08:36:57.573775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a method for weights initialization","metadata":{}},{"cell_type":"code","source":"def init_weights(model):\n    if model.__class__.__name__.find('Conv') != -1:\n        nn.init.normal_(model.weight, 0.0, 0.02)\n    elif model.__class__.__name__.find('BatchNorm') != -1:\n        nn.init.normal_(model.weight, 1.0, 0.02)\n        nn.init.zeros_(model.bias)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:57.575602Z","iopub.execute_input":"2022-05-08T08:36:57.576622Z","iopub.status.idle":"2022-05-08T08:36:57.582799Z","shell.execute_reply.started":"2022-05-08T08:36:57.576581Z","shell.execute_reply":"2022-05-08T08:36:57.582146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the generator network","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        \n        self.model = nn.Sequential(\n            nn.ConvTranspose2d(noise_dim, nfg*16, kernel_size=4, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(nfg*16),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg*16, nfg*8, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*8),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg*8, nfg*4, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*4),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg*4, nfg*2, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*2),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg*2, nfg, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(nfg, nc, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.Tanh()\n        )\n        \n    def forward(self, input):\n        return self.model(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:57.584263Z","iopub.execute_input":"2022-05-08T08:36:57.584831Z","iopub.status.idle":"2022-05-08T08:36:57.599191Z","shell.execute_reply.started":"2022-05-08T08:36:57.584798Z","shell.execute_reply":"2022-05-08T08:36:57.598471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the discriminator network","metadata":{}},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        \n        self.model = nn.Sequential(\n            nn.Conv2d(nc, nfd, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Dropout2d(0.5, inplace=False),\n            \n            nn.Conv2d(nfd, nfd*2, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*2),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(nfd*2, nfd*4, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*4),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(nfd*4, nfd*8, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*8),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(nfd*8, nfd*16, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nfg*16),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Dropout2d(0.5, inplace=False),\n            \n            nn.Conv2d(nfd*16, 1, kernel_size=4, stride=2, padding=0, bias=False),\n        )\n        \n    def forward(self, input):\n        return self.model(input)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:57.603486Z","iopub.execute_input":"2022-05-08T08:36:57.604226Z","iopub.status.idle":"2022-05-08T08:36:57.614133Z","shell.execute_reply.started":"2022-05-08T08:36:57.604184Z","shell.execute_reply":"2022-05-08T08:36:57.613377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Instantiate the generator and initialize its weights (option 1)","metadata":{}},{"cell_type":"code","source":"if load_model == False:\n    generator = Generator().to(device)\n    generator.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:57.615522Z","iopub.execute_input":"2022-05-08T08:36:57.616013Z","iopub.status.idle":"2022-05-08T08:36:57.624941Z","shell.execute_reply.started":"2022-05-08T08:36:57.615978Z","shell.execute_reply":"2022-05-08T08:36:57.624272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Instantiate the discriminator and initialize its weights (option 1)","metadata":{}},{"cell_type":"code","source":"if load_model == False:\n    discriminator = Discriminator().to(device)\n    discriminator.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:57.626023Z","iopub.execute_input":"2022-05-08T08:36:57.626436Z","iopub.status.idle":"2022-05-08T08:36:57.632944Z","shell.execute_reply.started":"2022-05-08T08:36:57.6264Z","shell.execute_reply":"2022-05-08T08:36:57.632219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the model from the disk (option 2)","metadata":{}},{"cell_type":"code","source":"if load_model == True:\n    for filename in os.listdir(load_checkpoints):\n        root, ext = os.path.splitext(filename)\n        if root.startswith('disc'):\n            discriminator = torch.load(os.path.join(load_checkpoints, filename))\n        elif root.startswith('gen'):\n            generator = torch.load(os.path.join(load_checkpoints, filename))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:57.634105Z","iopub.execute_input":"2022-05-08T08:36:57.634868Z","iopub.status.idle":"2022-05-08T08:36:58.61774Z","shell.execute_reply.started":"2022-05-08T08:36:57.634769Z","shell.execute_reply":"2022-05-08T08:36:58.61689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the loss function (BinaryCrossEntropy)","metadata":{}},{"cell_type":"code","source":"# cross_entropy = nn.BCELoss()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:58.62086Z","iopub.execute_input":"2022-05-08T08:36:58.621121Z","iopub.status.idle":"2022-05-08T08:36:58.625264Z","shell.execute_reply.started":"2022-05-08T08:36:58.621093Z","shell.execute_reply":"2022-05-08T08:36:58.624165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a noise vector to use to track progress","metadata":{}},{"cell_type":"code","source":"sample_noise = torch.randn(64, noise_dim, 1, 1, device=device)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:58.627265Z","iopub.execute_input":"2022-05-08T08:36:58.62752Z","iopub.status.idle":"2022-05-08T08:36:58.635418Z","shell.execute_reply.started":"2022-05-08T08:36:58.627486Z","shell.execute_reply":"2022-05-08T08:36:58.634583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the optimizers (Adam)","metadata":{}},{"cell_type":"code","source":"disc_optimizer = optim.RMSprop(discriminator.parameters(), lr=d_learning_rate)\ngen_optimizer = optim.RMSprop(generator.parameters(), lr=g_learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:58.636635Z","iopub.execute_input":"2022-05-08T08:36:58.637007Z","iopub.status.idle":"2022-05-08T08:36:58.643991Z","shell.execute_reply.started":"2022-05-08T08:36:58.636971Z","shell.execute_reply":"2022-05-08T08:36:58.642779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define a function to plot loss","metadata":{}},{"cell_type":"code","source":"def plot_loss(gen_losses, disc_losses, epoch=None, save=False, show=True):\n    plt.figure(figsize=(10, 5))\n    plt.title('Generator and Discriminator losses')\n    plt.plot(gen_losses, label='G')\n    plt.plot(disc_losses, label='D')\n    plt.xlabel('Iteration')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    if save == True:\n        plt.savefig(os.path.join(graphs_dir, f'loss_{epoch}.jpg'))\n    if show == True:\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:58.645313Z","iopub.execute_input":"2022-05-08T08:36:58.645668Z","iopub.status.idle":"2022-05-08T08:36:58.655037Z","shell.execute_reply.started":"2022-05-08T08:36:58.645633Z","shell.execute_reply":"2022-05-08T08:36:58.654352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gradient_penalty(critic, real, fake, device):\n    batch_size, C, H, W = real.shape\n    epsilon = torch.rand((batch_size, 1, 1, 1)).repeat(1, C, H, W).to(device)\n    try:\n        interpolated_images = real * epsilon + fake * (1 - epsilon)\n    except:\n        print(real.shape)\n        print(fake.shape)\n        print(epsilon.shape)\n    \n    mixed_scores = critic(interpolated_images)\n    \n    gradient = torch.autograd.grad(\n        inputs=interpolated_images,\n        outputs=mixed_scores,\n        grad_outputs=torch.ones_like(mixed_scores),\n        create_graph=True,\n        retain_graph=True,\n    )[0]\n    \n    gradient = gradient.view(gradient.shape[0], -1)\n    gradient_norm = gradient.norm(2, dim=1)\n    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n    return gradient_penalty","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:58.656752Z","iopub.execute_input":"2022-05-08T08:36:58.657405Z","iopub.status.idle":"2022-05-08T08:36:58.666757Z","shell.execute_reply.started":"2022-05-08T08:36:58.657363Z","shell.execute_reply":"2022-05-08T08:36:58.666023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train both networks simultaneously","metadata":{}},{"cell_type":"code","source":"# gen_losses = []\n# disc_losses = []\n\n# for epoch in range(epochs):\n#     start = time.time()\n#     for i, data in enumerate(data_loader, 0):\n#         # Train the discriminator\n#         # Fetch the real data\n#         ###TRAIN DISCRIMINATOR\n#         #Put the real images on the GPU\n#         real = data[0].to(device)\n#         #Iterate\n#         for _ in range(critic_iterations):\n#         #Generate fake images for later use\n#             size = real.size(0)\n#             noise = torch.randn(size, noise_dim, 1, 1, device=device)\n#             fake = generator(noise)\n#             label = torch.full((size,), 1, device=device, dtype=torch.float)\n#             output_real = discriminator(real).view(-1)  \n#             real_mean = output_real.mean().item()\n#             output_fake = discriminator(fake.detach()).view(-1)\n#             fake_mean = output_fake.mean().item()\n#             gp = gradient_penalty(discriminator, real, fake, device)\n#             disc_err = (-(torch.mean(output_real) - torch.mean(output_fake))+lambda_gp*gp)\n#             # Zero out gradients prior to backward passes\n#             discriminator.zero_grad()    \n#             disc_err.backward(retain_graph=True)\n#             disc_optimizer.step()\n            \n#         # TRAIN THE GENERATOR\n#         # Discriminate on fake with updated discriminator\n#         output = discriminator(fake).view(-1)\n#         gen_mean = output.mean().item()\n#         # Calculate loss on fake\n#         gen_err = -torch.mean(output)\n#         generator.zero_grad()\n#         gen_err.backward()\n#         gen_optimizer.step()\n        \n#         if i % 100 == 0:\n#             print('[%d/%d][%d/%d] \\tD-Loss:%.4f\\t G-Loss:%.4f\\t D(x):%.4f\\t D(G(z)):%.4f\\t G(z):%.4f' \n#                   % (epoch + 1, epochs, i + 1, len(data_loader), disc_err.item(), gen_err.item(), real_mean, fake_mean, gen_mean))\n            \n#         gen_losses.append(gen_err.item())\n#         disc_losses.append(disc_err.item())\n        \n#         with open(\"g_losses.txt\", \"a\") as file_object:\n#             # Append 'hello' at the end of file\n#             file_object.write(str(gen_err.item())+\"\\n\")\n#         with open(\"d_losses.txt\", \"a\") as file_object:\n#             # Append 'hello' at the end of file\n#             file_object.write(str(disc_err.item())+\"\\n\")\n        \n#     end = time.time()\n#     timedelta = datetime.timedelta(seconds=int(end - start))\n#     print(f'Time elapsed for epoch {epoch + 1}: {timedelta}\\n')\n#     with torch.no_grad():\n#         sample = generator(sample_noise).detach().cpu()\n#     grid = np.transpose(utils.make_grid(sample, padding=4, normalize=True).cpu(), (1, 2, 0))\n    \n\n    \n#     if epoch % 1000 == 0 or epoch == 14400:\n#         # Generate loss graph\n#         plot_loss(gen_losses, disc_losses, epoch + 1, save=True, show=False)\n        \n#         # Save progress\n#         torch.save(generator, os.path.join(checkpoints_dir, f'generator{epoch}.pt'))\n#         torch.save(discriminator, os.path.join(checkpoints_dir, f'discriminator{epoch}.pt'))\n        \n#             # Generate samples after every epoch\n#         plt.figure(figsize=(8, 8))\n#         plt.axis('off')\n#         plt.imshow(grid)\n#         plt.savefig(os.path.join(figures_dir, f'epoch_{epoch + 1}.png'))\n#         plt.close()","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2022-05-08T08:36:58.66895Z","iopub.execute_input":"2022-05-08T08:36:58.669134Z","iopub.status.idle":"2022-05-08T08:36:58.68095Z","shell.execute_reply.started":"2022-05-08T08:36:58.669111Z","shell.execute_reply":"2022-05-08T08:36:58.679324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clear CUDA cache if needed","metadata":{}},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:58.681748Z","iopub.status.idle":"2022-05-08T08:36:58.682051Z","shell.execute_reply.started":"2022-05-08T08:36:58.681889Z","shell.execute_reply":"2022-05-08T08:36:58.681908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the loss graph","metadata":{}},{"cell_type":"code","source":"# plot_loss(gen_losses, disc_losses, epoch='final', save=True, show=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:36:58.684573Z","iopub.status.idle":"2022-05-08T08:36:58.685459Z","shell.execute_reply.started":"2022-05-08T08:36:58.685151Z","shell.execute_reply":"2022-05-08T08:36:58.685224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate samples on random noise","metadata":{}},{"cell_type":"code","source":"noise = torch.randn(1000, noise_dim, 1, 1, device=device).detach()\nwith torch.no_grad():\n    sample = generator(noise).detach().cpu()\n# grid = np.transpose(utils.make_grid(sample, padding=4, nrow=5).cpu(), (1, 2, 0))\n# plt.figure(figsize=(5, 5))\n# plt.axis('off')\n# plt.imshow(grid)\n# plt.savefig(os.path.join(figures_dir, f'random_{i}.jpg'))\n# plt.close()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:40:19.153854Z","iopub.execute_input":"2022-05-08T08:40:19.154125Z","iopub.status.idle":"2022-05-08T08:40:20.025343Z","shell.execute_reply.started":"2022-05-08T08:40:19.154095Z","shell.execute_reply":"2022-05-08T08:40:20.024618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir('sample')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:39:12.235479Z","iopub.execute_input":"2022-05-08T08:39:12.235755Z","iopub.status.idle":"2022-05-08T08:39:12.241035Z","shell.execute_reply.started":"2022-05-08T08:39:12.235705Z","shell.execute_reply":"2022-05-08T08:39:12.240078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import save_image\nfor i in range (1000):\n    img = sample[i]\n    save_image(img, f'gan{i}.png')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:40:27.529685Z","iopub.execute_input":"2022-05-08T08:40:27.530305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls","metadata":{"execution":{"iopub.status.busy":"2022-05-08T08:37:39.489877Z","iopub.execute_input":"2022-05-08T08:37:39.490608Z","iopub.status.idle":"2022-05-08T08:37:39.496366Z","shell.execute_reply.started":"2022-05-08T08:37:39.49057Z","shell.execute_reply":"2022-05-08T08:37:39.495586Z"},"trusted":true},"execution_count":null,"outputs":[]}]}