{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\n\nfrom sklearn.model_selection import RandomizedSearchCV, cross_validate\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\nfrom xgboost import XGBClassifier, XGBRegressor\n\nimport seaborn as sns\nimport scipy.stats as st\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":1.664642,"end_time":"2022-04-13T05:23:48.610461","exception":false,"start_time":"2022-04-13T05:23:46.945819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:06:09.006316Z","iopub.execute_input":"2022-05-07T22:06:09.006775Z","iopub.status.idle":"2022-05-07T22:06:09.708952Z","shell.execute_reply.started":"2022-05-07T22:06:09.006633Z","shell.execute_reply":"2022-05-07T22:06:09.707899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#changable parameters\ntarget = \"diagnosis\"\ntest_size = 0.2\n","metadata":{"papermill":{"duration":0.024344,"end_time":"2022-04-13T05:23:48.651112","exception":false,"start_time":"2022-04-13T05:23:48.626768","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:06:53.080983Z","iopub.execute_input":"2022-05-07T22:06:53.082099Z","iopub.status.idle":"2022-05-07T22:06:53.086398Z","shell.execute_reply.started":"2022-05-07T22:06:53.081987Z","shell.execute_reply":"2022-05-07T22:06:53.085724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/cardiac-arrhythmia-database/data_arrhythmia.csv\",sep=';')\ndf.dropna(axis=0, inplace=True)\nj = []\nfor i in df.diagnosis:\n    if i > 1 :\n        j.append(1)\n    else:\n        j.append(0)\ndf.diagnosis = j\ndf.head()","metadata":{"papermill":{"duration":0.052308,"end_time":"2022-04-13T05:23:49.468189","exception":false,"start_time":"2022-04-13T05:23:49.415881","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:20:31.943675Z","iopub.execute_input":"2022-05-07T22:20:31.944012Z","iopub.status.idle":"2022-05-07T22:20:32.003622Z","shell.execute_reply.started":"2022-05-07T22:20:31.943981Z","shell.execute_reply":"2022-05-07T22:20:32.002731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classification or regression\nif (type(df[target][0]) == str) or (type(df[target][0]) == int) or (type(df[target][0]) == np.int64):\n    models_type = 'classification'\nelse:\n    models_type = 'regression'\n    \n    \nprint(models_type)","metadata":{"papermill":{"duration":0.030843,"end_time":"2022-04-13T05:23:49.516473","exception":false,"start_time":"2022-04-13T05:23:49.48563","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:19:46.108214Z","iopub.execute_input":"2022-05-07T22:19:46.10891Z","iopub.status.idle":"2022-05-07T22:19:46.118678Z","shell.execute_reply.started":"2022-05-07T22:19:46.108863Z","shell.execute_reply":"2022-05-07T22:19:46.117864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encoding(old_column):\n    le = LabelEncoder()\n    le.fit(old_column)\n    new_column = le.transform(old_column)\n    return new_column","metadata":{"papermill":{"duration":0.025649,"end_time":"2022-04-13T05:23:49.559973","exception":false,"start_time":"2022-04-13T05:23:49.534324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:20:42.330228Z","iopub.execute_input":"2022-05-07T22:20:42.330753Z","iopub.status.idle":"2022-05-07T22:20:42.334882Z","shell.execute_reply.started":"2022-05-07T22:20:42.330689Z","shell.execute_reply":"2022-05-07T22:20:42.334153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#encoding string parameters\nfor i in df.columns:\n    if type(df[i][0]) == str:\n        df[i] = label_encoding(df[i])","metadata":{"papermill":{"duration":0.027617,"end_time":"2022-04-13T05:23:49.605754","exception":false,"start_time":"2022-04-13T05:23:49.578137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:20:42.545501Z","iopub.execute_input":"2022-05-07T22:20:42.545982Z","iopub.status.idle":"2022-05-07T22:20:42.568261Z","shell.execute_reply.started":"2022-05-07T22:20:42.545943Z","shell.execute_reply":"2022-05-07T22:20:42.567255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extracting x and y\ny = df[target].values\n \nx = df.drop([target], axis=1).values","metadata":{"papermill":{"duration":0.03225,"end_time":"2022-04-13T05:23:49.655887","exception":false,"start_time":"2022-04-13T05:23:49.623637","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:20:42.749453Z","iopub.execute_input":"2022-05-07T22:20:42.750131Z","iopub.status.idle":"2022-05-07T22:20:42.76103Z","shell.execute_reply.started":"2022-05-07T22:20:42.750094Z","shell.execute_reply":"2022-05-07T22:20:42.759994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#spliting  data\nX_train, X_test, y_train, y_test = train_test_split(x, \n                                                    y, \n                                                    test_size=test_size)","metadata":{"papermill":{"duration":0.025439,"end_time":"2022-04-13T05:23:49.699188","exception":false,"start_time":"2022-04-13T05:23:49.673749","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:20:43.296783Z","iopub.execute_input":"2022-05-07T22:20:43.298124Z","iopub.status.idle":"2022-05-07T22:20:43.304428Z","shell.execute_reply.started":"2022-05-07T22:20:43.298023Z","shell.execute_reply":"2022-05-07T22:20:43.303645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ensemble models for classification\n\nif models_type == 'classification':\n\n    model_1 = RandomForestClassifier()\n\n    k_fold_cv = 5 \n    params = {\n     \"n_estimators\" : [10,50,100],\n     \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n     \"bootstrap\" : [True, False]\n     }\n    clf1 = RandomizedSearchCV(model_1, param_distributions=params, cv=k_fold_cv,\n     n_iter = 5, scoring=\"accuracy\",verbose=2, random_state=42,\n     n_jobs=-1, return_train_score=True)\n    clf1.fit(X_train, y_train)\n\n\n\n    #######################################\n\n\n    model_2 = XGBClassifier(eval_metric='mlogloss')\n\n    params = {  \n                \"n_estimators\": st.randint(3, 40),\n                \"max_depth\": st.randint(3, 40),\n                \"learning_rate\": st.uniform(0.05, 0.4),\n                \"colsample_bytree\": st.beta(10, 1),\n                \"subsample\": st.beta(10, 1),\n                \"gamma\": st.uniform(0, 10),\n                'objective': ['binary:logistic'],\n                'scale_pos_weight': st.randint(0, 2),\n                \"min_child_weight\": st.expon(0, 50),\n\n            }\n\n    # Random Search Training with 5 folds Cross Validation\n    clf2 = RandomizedSearchCV(model_2, params, cv=5,\n                             n_jobs=1, n_iter=100) \n\n    clf2.fit(X_train, y_train)  \n\n\n\n    #######################################\n\n\n    model_3 = LogisticRegression(max_iter=160)\n    model_3.fit(X_train,y_train)\n\n    params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n\n\n    clf3 = RandomizedSearchCV(model_3, params, cv=5,\n                             n_jobs=1, n_iter=100) \n\n    clf3.fit(X_train, y_train)  \n\n\n\n    #######################################\n\n\n\n    model_4 = KNeighborsClassifier()\n    model_4.fit(X_train,y_train)\n\n    param_grid=dict(n_neighbors=list(range(1,31)))\n    print(param_grid)\n\n    clf4 = RandomizedSearchCV(model_4, param_grid, cv=10, scoring='accuracy')\n    clf4.fit(X_train, y_train)  \n\n\n\n    #######################################\n\n\n\n    train_results = np.array([clf1.predict(X_train), \n                        clf2.predict(X_train),\n                        clf3.predict(X_train),\n                        clf4.predict(X_train)]).T\n\n\n\n    final_model = XGBClassifier()\n\n    final_model = final_model.fit(train_results, y_train)\n\n    test_results = np.array([clf1.predict(X_test), \n                        clf2.predict(X_test),\n                        clf3.predict(X_test),\n                        clf4.predict(X_test)]).T\n\n\n    pred_final = final_model.predict(test_results)\n\n    print(\"accuracy is: \",accuracy_score(y_test, pred_final))\n    \n    \n    #######################################\n    \n    #save models\n\n    filename = 'clf1.sav'\n    pickle.dump(clf1, open(filename, 'wb'))\n    \n    filename = 'clf2.sav'\n    pickle.dump(clf2, open(filename, 'wb'))\n    \n    filename = 'clf3.sav'\n    pickle.dump(clf3, open(filename, 'wb'))\n    \n    filename = 'clf4.sav'\n    pickle.dump(clf4, open(filename, 'wb'))\n    \n    filename = 'final_model.sav'\n    pickle.dump(final_model, open(filename, 'wb'))\n    ","metadata":{"papermill":{"duration":51.842097,"end_time":"2022-04-13T05:24:41.559371","exception":false,"start_time":"2022-04-13T05:23:49.717274","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:20:43.950017Z","iopub.execute_input":"2022-05-07T22:20:43.950315Z","iopub.status.idle":"2022-05-07T22:21:54.205285Z","shell.execute_reply.started":"2022-05-07T22:20:43.950287Z","shell.execute_reply":"2022-05-07T22:21:54.204133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ensemble models for regression\n\nif models_type == 'regression':\n\n    model_1 = RandomForestRegressor()\n\n    k_fold_cv = 5 \n    params = {\n     \"n_estimators\" : [10,50,100],\n     \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n     \"bootstrap\" : [True, False]\n     }\n    clf1 = RandomizedSearchCV(model_1, param_distributions=params, cv=k_fold_cv,\n     n_iter = 5, scoring=\"neg_mean_squared_error\",verbose=2, random_state=42,\n     n_jobs=-1, return_train_score=True)\n    clf1.fit(X_train, y_train)\n\n\n\n    #######################################\n\n\n    model_2 = XGBRegressor()\n\n    params = {  \n                \"n_estimators\": st.randint(3, 40),\n                \"max_depth\": st.randint(3, 40),\n                \"learning_rate\": st.uniform(0.05, 0.4),\n                \"colsample_bytree\": st.beta(10, 1),\n                \"subsample\": st.beta(10, 1),\n                \"gamma\": st.uniform(0, 10),\n                'scale_pos_weight': st.randint(0, 2),\n                \"min_child_weight\": st.expon(0, 50),\n\n            }\n\n    # Random Search Training with 5 folds Cross Validation\n    clf2 = RandomizedSearchCV(model_2, params, cv=5,\n                             n_jobs=1, n_iter=100) \n\n    clf2.fit(X_train, y_train)  \n\n\n\n    #######################################\n\n\n    clf3 = LinearRegression()\n    \n    clf3.fit(X_train,y_train)\n\n\n\n\n\n    #######################################\n\n\n\n    model_4 = KNeighborsRegressor()\n    model_4.fit(X_train,y_train)\n\n    param_grid=dict(n_neighbors=list(range(1,31)))\n\n    clf4 = RandomizedSearchCV(model_4, param_grid, cv=10, scoring='accuracy')\n    clf4.fit(X_train, y_train)  \n\n\n\n    #######################################\n\n\n\n    train_results = np.array([clf1.predict(X_train), \n                        clf2.predict(X_train),\n                        clf3.predict(X_train),\n                        clf4.predict(X_train)]).T\n\n\n\n    final_model = XGBRegressor()\n\n    final_model = final_model.fit(train_results, y_train)\n\n    test_results = np.array([clf1.predict(X_test), \n                        clf2.predict(X_test),\n                        clf3.predict(X_test),\n                        clf4.predict(X_test)]).T\n\n\n    pred_final = final_model.predict(test_results)\n\n    print(\"socre is: \",mean_squared_error(y_test, pred_final))\n    \n    \n    #######################################\n    \n    #save models\n    \n    filename = 'clf1.sav'\n    pickle.dump(clf1, open(filename, 'wb'))\n    \n    filename = 'clf2.sav'\n    pickle.dump(clf2, open(filename, 'wb'))\n    \n    filename = 'clf3.sav'\n    pickle.dump(clf3, open(filename, 'wb'))\n    \n    filename = 'clf4.sav'\n    pickle.dump(clf4, open(filename, 'wb'))\n    \n    filename = 'final_model.sav'\n    pickle.dump(final_model, open(filename, 'wb'))\n    ","metadata":{"execution":{"iopub.execute_input":"2022-04-13T05:24:41.627019Z","iopub.status.busy":"2022-04-13T05:24:41.626179Z","iopub.status.idle":"2022-04-13T05:24:41.628837Z","shell.execute_reply":"2022-04-13T05:24:41.629366Z","shell.execute_reply.started":"2022-04-13T05:21:57.865846Z"},"papermill":{"duration":0.045108,"end_time":"2022-04-13T05:24:41.629549","exception":false,"start_time":"2022-04-13T05:24:41.584441","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#confusion matrix plot\nif models_type == 'classification': \n    cm = confusion_matrix(y_test, pred_final)\n    sns.set(rc={\"figure.figsize\":(4, 2)})\n    sns.heatmap(cm, annot=True)","metadata":{"papermill":{"duration":0.279568,"end_time":"2022-04-13T05:24:41.928837","exception":false,"start_time":"2022-04-13T05:24:41.649269","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-05-07T22:21:54.214266Z","iopub.execute_input":"2022-05-07T22:21:54.219477Z","iopub.status.idle":"2022-05-07T22:21:54.534536Z","shell.execute_reply.started":"2022-05-07T22:21:54.219334Z","shell.execute_reply":"2022-05-07T22:21:54.533639Z"},"trusted":true},"execution_count":null,"outputs":[]}]}