{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b>1 <span style='color:#ea4335'>|</span> Setup</b>","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries\n- **For ML Models**: sklearn  \n- **For Data Processing**: numpy, pandas, sklearn  \n- **For Data Visualization**: matplotlib, seaborn, plotly  ","metadata":{}},{"cell_type":"code","source":"# For ML models\nfrom sklearn.linear_model import LinearRegression, BayesianRidge, TweedieRegressor, LassoLars\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\nfrom sklearn.model_selection import GridSearchCV\n\n# For Data Processing\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split \n\n# For Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Miscellaneous\nimport os\nimport random\nimport math","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-27T14:02:04.431713Z","iopub.execute_input":"2022-04-27T14:02:04.432015Z","iopub.status.idle":"2022-04-27T14:02:04.439601Z","shell.execute_reply.started":"2022-04-27T14:02:04.431982Z","shell.execute_reply":"2022-04-27T14:02:04.43881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting up sklearnex to speed up training\nIf you don't know about sklearnex, this is a tool you can use to speed up training sklearn models, without having to change any code.  \nA simple 2 line of code can speed up training by 2x.  \nYou can follow [this kernel by Devlikamov Vlad](https://www.kaggle.com/code/lordozvlad/let-s-speed-up-your-kernels-using-sklearnex) to learn more about it","metadata":{}},{"cell_type":"code","source":"from sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:02:06.779091Z","iopub.execute_input":"2022-04-27T14:02:06.779561Z","iopub.status.idle":"2022-04-27T14:02:06.783867Z","shell.execute_reply.started":"2022-04-27T14:02:06.779527Z","shell.execute_reply":"2022-04-27T14:02:06.783174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>2 <span style='color:#ea4335'>|</span> About the Dataset</b>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/insurance/insurance.csv')\ndf","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-27T14:02:09.060166Z","iopub.execute_input":"2022-04-27T14:02:09.060893Z","iopub.status.idle":"2022-04-27T14:02:09.086208Z","shell.execute_reply.started":"2022-04-27T14:02:09.060852Z","shell.execute_reply":"2022-04-27T14:02:09.085642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Column Descriptions\n\n- `age`: age of primary beneficiary\n- `sex`: insurance contractor gender, female, male\n- `bmi`: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n- `children`: Number of children covered by health insurance / Number of dependents\n- `smoker`: Smoking\n- `region`: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n- `charges`: Individual medical costs billed by health insurance\n\nCategorical Features  \n`sex`, `smoker`, `region`  \nContinuous Features  \n`age`, `children`, `bmi`, `charges`","metadata":{}},{"cell_type":"markdown","source":"## Column Statistics (of numerical data)","metadata":{}},{"cell_type":"code","source":"df.describe()[1:][['age','children','bmi', 'charges']].T.style.background_gradient(cmap=sns.light_palette(\"#ea4335\", as_cmap=True), axis=1)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-27T14:02:12.248109Z","iopub.execute_input":"2022-04-27T14:02:12.248756Z","iopub.status.idle":"2022-04-27T14:02:12.283705Z","shell.execute_reply.started":"2022-04-27T14:02:12.248715Z","shell.execute_reply":"2022-04-27T14:02:12.282859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Column Statistics (of categorical data)","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(\n    rows=1, cols=3, subplot_titles=(\"sex\", \"smoker\",\n                                    \"region\"),\n    specs=[[{\"type\": \"domain\"}, {\"type\": \"domain\"}, {\"type\": \"domain\"}]],\n)\n\ncolours = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']\n\nfig.add_trace(go.Pie(labels=np.array(df['sex'].value_counts().index),\n                     values=[x for x in df['sex'].value_counts()],\n                     textinfo='label+percent', rotation=-45, hole=.35,\n                     marker_colors=colours),\n              row=1, col=1)\n\nfig.add_trace(go.Pie(labels=np.array(df['smoker'].value_counts().index),\n                     values=[x for x in df['smoker'].value_counts()],\n                     textinfo='label+percent', hole=.35,\n                     marker_colors=colours),\n              row=1, col=2)\n\nfig.add_trace(go.Pie(labels=np.array(df['region'].value_counts().index),\n                     values=[x for x in df['region'].value_counts()],\n                     textinfo='label+percent', rotation=-45, hole=.35,\n                     marker_colors=colours),\n              row=1, col=3)\n\n\nfig.update_layout(height=450, font=dict(size=14), showlegend=False)\n\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-27T14:02:15.03075Z","iopub.execute_input":"2022-04-27T14:02:15.031434Z","iopub.status.idle":"2022-04-27T14:02:15.069165Z","shell.execute_reply.started":"2022-04-27T14:02:15.031371Z","shell.execute_reply":"2022-04-27T14:02:15.068378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>3 <span style='color:#ea4335'>|</span> Exploratory Analysis</b>","metadata":{}},{"cell_type":"code","source":"fig = px.scatter(df, x=\"charges\", y=\"age\", color='smoker', color_continuous_scale='Blues', color_discrete_map={'yes':'#ea4335', 'no':'#4285f4'})\nfig.update_layout(legend_title_text='Smoker')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-27T14:02:20.014521Z","iopub.execute_input":"2022-04-27T14:02:20.015209Z","iopub.status.idle":"2022-04-27T14:02:20.086559Z","shell.execute_reply.started":"2022-04-27T14:02:20.015177Z","shell.execute_reply":"2022-04-27T14:02:20.085761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n- Individuals who smoke have a higher medical bill than individuals who do not smoke\n- We can see 3 categories of medical bill paid, 0-15k, 15k-32k, 32k-50k, but why?","metadata":{}},{"cell_type":"code","source":"fig = px.scatter(df, x=\"bmi\", y=\"charges\", color='age', color_continuous_scale='RdBu')\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-27T14:02:22.331743Z","iopub.execute_input":"2022-04-27T14:02:22.332784Z","iopub.status.idle":"2022-04-27T14:02:22.40371Z","shell.execute_reply.started":"2022-04-27T14:02:22.332731Z","shell.execute_reply":"2022-04-27T14:02:22.402997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n- Here, those 3 categories of charges appear again, with ranges: 0-15k, 15k-32k, 32k-50k  \n- It can be seen that those 3 categories of charges has a strong correlation with age\n- The correlation of charge and age is linear in each of the categories  \n- From this, we can determine that these 3 categories mean how bad the health condition of the patient is!","metadata":{}},{"cell_type":"code","source":"fig = go.Figure()\ncolors = ['#4285f4', '#ea4335', '#fbbc05', '#34a853']\nfor i,x in enumerate(df['region'].unique()):\n    fig.add_trace(go.Box(\n        x=df[df['region']==x]['bmi'],\n        y=df[df['region']==x]['region'], name=x, marker_color=colors[i]\n    ))\n\nfig.update_layout(\n    yaxis_title='region', xaxis_title='bmi'\n)\nfig.update_traces(orientation='h')\nfig.update_layout(legend_title_text='region')\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-27T14:02:25.03431Z","iopub.execute_input":"2022-04-27T14:02:25.034635Z","iopub.status.idle":"2022-04-27T14:02:25.073482Z","shell.execute_reply.started":"2022-04-27T14:02:25.034603Z","shell.execute_reply":"2022-04-27T14:02:25.072435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n- Southeast-ern people have the highest bmi, a median bmi of 33.33\n- Northeast-ern people have the lowest bmi, a median bmi of 28.88","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(df, x=\"bmi\", color=\"sex\", marginal='box', nbins=80, color_discrete_map = {'male':'#ea4335','female':'#4285f4'})\nfig.update_layout(barmode='overlay')\nfig.update_traces(opacity=0.75)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:06:32.786172Z","iopub.execute_input":"2022-04-27T14:06:32.786469Z","iopub.status.idle":"2022-04-27T14:06:32.886188Z","shell.execute_reply.started":"2022-04-27T14:06:32.786435Z","shell.execute_reply":"2022-04-27T14:06:32.885656Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n- The bmi of a person is independent of their gender","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(df, x=\"sex\", color='smoker', color_discrete_map = {'yes':'#ea4335','no':'#4285f4'})\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:02:59.36482Z","iopub.execute_input":"2022-04-27T10:02:59.365632Z","iopub.status.idle":"2022-04-27T10:02:59.426302Z","shell.execute_reply.started":"2022-04-27T10:02:59.36559Z","shell.execute_reply":"2022-04-27T10:02:59.425465Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n- Looks like people smoke regardless of their gender\n- More Males seem to be smokers than females, but the difference is minimal, also the number of females tested is slightly less than the number of males\n- It cannot be concluded that more males smoke because we do not have sufficient data","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(df, x=\"children\", color='smoker', barmode='group', color_discrete_map = {'yes':'#ea4335','no':'#4285f4'})\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:38:53.665627Z","iopub.execute_input":"2022-04-27T13:38:53.665897Z","iopub.status.idle":"2022-04-27T13:38:53.739295Z","shell.execute_reply.started":"2022-04-27T13:38:53.66587Z","shell.execute_reply":"2022-04-27T13:38:53.73845Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n- Smokers usually have less children than non-smokers  \n\nNice to see that most parents do not smoke 😀","metadata":{}},{"cell_type":"markdown","source":"# <b>4 <span style='color:#ea4335'>|</span> Data Cleaning & Preprocessing</b>","metadata":{}},{"cell_type":"markdown","source":"<h2>4.1 <span style='color:#ea4335'>|</span> Encoding Categorical Features</h2>","metadata":{}},{"cell_type":"code","source":"print('\\nCategorical Columns\\n')\ndf.select_dtypes(include=['O']).nunique()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:03:02.032492Z","iopub.execute_input":"2022-04-27T10:03:02.033211Z","iopub.status.idle":"2022-04-27T10:03:02.043782Z","shell.execute_reply.started":"2022-04-27T10:03:02.033165Z","shell.execute_reply":"2022-04-27T10:03:02.043202Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`sex` and `smoker` have 2 unique values, and `region` have more than 2 unique values.  \nHere, I am converting the columns with 2 unique values to binary (either 1 or 0)  \nAnd one-hot encode the other categorical columns which has more than 2 unique values  ","metadata":{}},{"cell_type":"code","source":"# Integer encode columns with 2 unique values\nfor col in ['sex', 'smoker']:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n# One-hot encode columns with more than 2 unique values\ndf = pd.get_dummies(df, columns=['region'], prefix = ['region'])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:03:03.928753Z","iopub.execute_input":"2022-04-27T10:03:03.929198Z","iopub.status.idle":"2022-04-27T10:03:03.939033Z","shell.execute_reply.started":"2022-04-27T10:03:03.929165Z","shell.execute_reply":"2022-04-27T10:03:03.938144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>4.2 <span style='color:#ea4335'>|</span> Train-Val Split</h2>  ","metadata":{}},{"cell_type":"code","source":"features = np.array(df[[col for col in df.columns if col!='charges']])\nlabels = np.array(df['charges'])\n\nx_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:03:05.889686Z","iopub.execute_input":"2022-04-27T10:03:05.89023Z","iopub.status.idle":"2022-04-27T10:03:05.903894Z","shell.execute_reply.started":"2022-04-27T10:03:05.89018Z","shell.execute_reply":"2022-04-27T10:03:05.903212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>5 <span style='color:#ea4335'>|</span> Models</b>","metadata":{}},{"cell_type":"markdown","source":"**Metrics we will be using,**\n$$\\text{Root Mean Squared Error, } \\mathbf{RMSE} = \\sqrt{\\cfrac{\\sum_{i=1}^N (y_i - \\hat y_i)^2}{N}}$$\n\n$$\\text{Mean Absolute Percentage Error, } \\mathbf{MAPE} = \\cfrac{1}{N}\\sum_{i=1}^N \\Big|\\cfrac{y_i - \\hat y_i}{y_i}\\Big|$$\n\n$$\\text{coefficient of determination, } \\mathbf{R^2} = 1 - \\cfrac{\\sum_{i=1}^N (\\hat y_i - y_i)^2}{\\sum_{i=1}^N (y_i - \\bar y)^2}$$\n\nwhere,  \n$\\hat y$ is the predicted variable, and $y$ is the target variable  \n$\\bar y$ represents the mean of all values of $y$   \n$y_i$ = $i^\\mathbf{th}$ sample of target variable $y$  \n$\\hat y_i$ = $i^\\mathbf{th}$ sample of predicted variable $\\hat y$  \n$N$ = Number of training samples  ","metadata":{}},{"cell_type":"code","source":"model_comparison = {} # We will use this to store the performance of different models on the validation dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-27T11:26:21.199229Z","iopub.execute_input":"2022-04-27T11:26:21.199504Z","iopub.status.idle":"2022-04-27T11:26:21.20396Z","shell.execute_reply.started":"2022-04-27T11:26:21.199476Z","shell.execute_reply":"2022-04-27T11:26:21.203113Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.1 <span style='color:#ea4335'>|</span> RandomForestRegressor</h2>  \n\n> A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the `max_samples` parameter if `bootstrap=True` (default), otherwise the whole dataset is used to build each tree.\n\nLearn more about RandomForestRegressor at [scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), [wikipedia.org](https://en.wikipedia.org/wiki/Random_forest)","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor()\n\nparameters = {'n_estimators': [160,180,200,220], 'max_depth':[16,18,20,22,24]}\nclf = GridSearchCV(rf, parameters)\nprint(\"Searching for best hyperparameters ...\")\nclf.fit(x_train, y_train)\nprint(f'Best Hyperparameters: {clf.best_params_}')\n\ny_pred = clf.predict(x_val)\n\nrmse = math.sqrt(mean_squared_error(y_val,y_pred))\nmape = mean_absolute_percentage_error(y_val, y_pred)\nr2 = r2_score(y_val, y_pred)\n\nprint('\\nRMSE:', rmse)\nprint('MAPE:', mape)\nprint('R2 Score:', r2)\n\nmodel_comparison['RandomForestRegressor'] = [rmse, mape, r2]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T11:27:05.858148Z","iopub.execute_input":"2022-04-27T11:27:05.85844Z","iopub.status.idle":"2022-04-27T11:27:21.020033Z","shell.execute_reply.started":"2022-04-27T11:27:05.858411Z","shell.execute_reply":"2022-04-27T11:27:21.019071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.2 <span style='color:#ea4335'>|</span> LinearRegression</h2>  \n\n> LinearRegression fits a linear model with coefficients w = (w1, …, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.  \n\nLearn more about LinearRegression at [scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), [wikipedia.org](https://en.wikipedia.org/wiki/Linear_regression)","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression().fit(x_train, y_train)\n\ny_pred = lr.predict(x_val)\n\nrmse = math.sqrt(mean_squared_error(y_val,y_pred))\nmape = mean_absolute_percentage_error(y_val, y_pred)\nr2 = r2_score(y_val, y_pred)\n\nprint('\\nRMSE:', rmse)\nprint('MAPE:', mape)\nprint('R2 Score:', r2)\n\nmodel_comparison['LinearRegression'] = [rmse, mape, r2]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T11:27:43.430677Z","iopub.execute_input":"2022-04-27T11:27:43.431498Z","iopub.status.idle":"2022-04-27T11:27:43.445027Z","shell.execute_reply.started":"2022-04-27T11:27:43.431459Z","shell.execute_reply":"2022-04-27T11:27:43.443923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.3 <span style='color:#ea4335'>|</span> DecisionTreeRegressor</h2>  \n\n> Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes.\n\nLearn more about DecisionTreeRegressor at [scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html), [wikipedia.org](https://en.wikipedia.org/wiki/Decision_tree_learning)","metadata":{}},{"cell_type":"code","source":"tree = DecisionTreeRegressor().fit(x_train, y_train)\n\ny_pred = tree.predict(x_val)\n\nrmse = math.sqrt(mean_squared_error(y_val,y_pred))\nmape = mean_absolute_percentage_error(y_val, y_pred)\nr2 = r2_score(y_val, y_pred)\n\nprint('\\nRMSE:', rmse)\nprint('MAPE:', mape)\nprint('R2 Score:', r2)\n\nmodel_comparison['DecisionTreeRegressor'] = [rmse, mape, r2]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T11:27:47.538156Z","iopub.execute_input":"2022-04-27T11:27:47.538413Z","iopub.status.idle":"2022-04-27T11:27:47.552395Z","shell.execute_reply.started":"2022-04-27T11:27:47.538385Z","shell.execute_reply":"2022-04-27T11:27:47.551354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.4 <span style='color:#ea4335'>|</span> BayesianRidge</h2>  \n\n> Bayesian regression allows a natural mechanism to survive insufficient data or poorly distributed data by formulating linear regression using probability distributors rather than point estimates. The output or response 'y' is assumed to drawn from a probability distribution rather than estimated as a single value.\n\nLearn more about BayesianRidge at [scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html), [wikipedia.org](https://en.wikipedia.org/wiki/Bayesian_linear_regression)","metadata":{}},{"cell_type":"code","source":"br = BayesianRidge().fit(x_train, y_train)\n\ny_pred = br.predict(x_val)\n\nrmse = math.sqrt(mean_squared_error(y_val,y_pred))\nmape = mean_absolute_percentage_error(y_val, y_pred)\nr2 = r2_score(y_val, y_pred)\n\nprint('\\nRMSE:', rmse)\nprint('MAPE:', mape)\nprint('R2 Score:', r2)\n\nmodel_comparison['BayesianRidge'] = [rmse, mape, r2]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T11:27:51.8374Z","iopub.execute_input":"2022-04-27T11:27:51.837672Z","iopub.status.idle":"2022-04-27T11:27:51.860055Z","shell.execute_reply.started":"2022-04-27T11:27:51.837626Z","shell.execute_reply":"2022-04-27T11:27:51.852683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.5 <span style='color:#ea4335'>|</span> TweedieRegressor</h2>  \n\n> Tweedie distribution is a special case of exponential dispersion models and is often used as a distribution for generalized linear models. It can have a cluster of data items at zero and this particular property makes it useful for modeling claims in the insurance industry.  \n\nLearn more about TweedieRegressor at [wikipedia.org](https://en.wikipedia.org/wiki/Tweedie_distribution), [scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TweedieRegressor.html)","metadata":{}},{"cell_type":"code","source":"tr = TweedieRegressor().fit(x_train, y_train)\n\ny_pred = tr.predict(x_val)\n\nrmse = math.sqrt(mean_squared_error(y_val,y_pred))\nmape = mean_absolute_percentage_error(y_val, y_pred)\nr2 = r2_score(y_val, y_pred)\n\nprint('\\nRMSE:', rmse)\nprint('MAPE:', mape)\nprint('R2 Score:', r2)\n\nmodel_comparison['TweedieRegressor'] = [rmse, mape, r2]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T11:27:56.461437Z","iopub.execute_input":"2022-04-27T11:27:56.461714Z","iopub.status.idle":"2022-04-27T11:27:56.501758Z","shell.execute_reply.started":"2022-04-27T11:27:56.461686Z","shell.execute_reply":"2022-04-27T11:27:56.50086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.6 <span style='color:#ea4335'>|</span> LassoLars</h2>  \n\n> LassoLars is a lasso model implemented using the LARS algorithm, and unlike the implementation based on coordinate descent, this yields the exact solution, which is piecewise linear as a function of the norm of its coefficients. Lasso model fit with Least Angle Regression a.k.a. Lars.\n\nLearn more about LassoLars at [wikipedia.org](https://en.wikipedia.org/wiki/Least-angle_regression), [scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html)","metadata":{}},{"cell_type":"code","source":"ll = LassoLars(alpha=.1, normalize=False).fit(x_train, y_train)\n\ny_pred = ll.predict(x_val)\n\nrmse = math.sqrt(mean_squared_error(y_val,y_pred))\nmape = mean_absolute_percentage_error(y_val, y_pred)\nr2 = r2_score(y_val, y_pred)\n\nprint('\\nRMSE:', rmse)\nprint('MAPE:', mape)\nprint('R2 Score:', r2)\n\nmodel_comparison['LassoLars'] = [rmse, mape, r2]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T11:28:07.817427Z","iopub.execute_input":"2022-04-27T11:28:07.81771Z","iopub.status.idle":"2022-04-27T11:28:07.832287Z","shell.execute_reply.started":"2022-04-27T11:28:07.817681Z","shell.execute_reply":"2022-04-27T11:28:07.831451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>5.7 <span style='color:#ea4335'>|</span> Model Comparison</h2>  ","metadata":{}},{"cell_type":"code","source":"model_comparison_df = pd.DataFrame.from_dict(model_comparison).T\nmodel_comparison_df.columns = ['MSE', 'MAPE', 'R2 Score']\nmodel_comparison_df = model_comparison_df.sort_values('R2 Score', ascending=True)\n\nmodel_comparison_df.style.background_gradient(cmap=sns.light_palette(\"#ea4335\", as_cmap=True))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T11:28:16.369329Z","iopub.execute_input":"2022-04-27T11:28:16.369583Z","iopub.status.idle":"2022-04-27T11:28:16.392722Z","shell.execute_reply.started":"2022-04-27T11:28:16.369555Z","shell.execute_reply":"2022-04-27T11:28:16.391178Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='R2 Score', y=model_comparison_df.index, x=model_comparison_df['R2 Score'],\n           orientation='h', marker_color=['#f5a19a', '#f28e86', '#f07b72', '#ee695d', '#ec5649', '#ea4335'])\n])\nfig.update_layout(barmode='group')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T12:16:55.975771Z","iopub.execute_input":"2022-04-27T12:16:55.976059Z","iopub.status.idle":"2022-04-27T12:16:55.987541Z","shell.execute_reply.started":"2022-04-27T12:16:55.976026Z","shell.execute_reply":"2022-04-27T12:16:55.986705Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Please Upvote this notebook as it encourages me in doing better.\n![](http://68.media.tumblr.com/e1aed171ded2bd78cc8dc0e73b594eaf/tumblr_o17frv0cdu1u9u459o1_500.gif)","metadata":{}}]}