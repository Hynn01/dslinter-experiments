{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T07:11:46.968888Z","iopub.execute_input":"2022-05-07T07:11:46.969223Z","iopub.status.idle":"2022-05-07T07:11:46.99323Z","shell.execute_reply.started":"2022-05-07T07:11:46.969143Z","shell.execute_reply":"2022-05-07T07:11:46.992508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip',sep='\\t')\ntest=pd.read_csv('/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip',sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:11:47.01049Z","iopub.execute_input":"2022-05-07T07:11:47.011088Z","iopub.status.idle":"2022-05-07T07:11:47.299756Z","shell.execute_reply.started":"2022-05-07T07:11:47.011053Z","shell.execute_reply":"2022-05-07T07:11:47.299055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:11:47.301327Z","iopub.execute_input":"2022-05-07T07:11:47.301573Z","iopub.status.idle":"2022-05-07T07:11:47.305188Z","shell.execute_reply.started":"2022-05-07T07:11:47.301539Z","shell.execute_reply":"2022-05-07T07:11:47.304421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras_sequential_ascii","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:25:49.205377Z","iopub.execute_input":"2022-05-07T07:25:49.205658Z","iopub.status.idle":"2022-05-07T07:26:00.945577Z","shell.execute_reply.started":"2022-05-07T07:25:49.205629Z","shell.execute_reply":"2022-05-07T07:26:00.944647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dropout, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom tensorflow.keras.utils import to_categorical\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:25:00.556989Z","iopub.execute_input":"2022-05-07T08:25:00.557252Z","iopub.status.idle":"2022-05-07T08:25:00.563506Z","shell.execute_reply.started":"2022-05-07T08:25:00.557224Z","shell.execute_reply":"2022-05-07T08:25:00.56239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = train[['Phrase', 'Sentiment']]\n\n\ndata['Sentiment_value'] = pd.Categorical(data['Sentiment'])\n\n\ndata['Sentiment'] = data['Sentiment_value'].cat.codes","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:11:53.015053Z","iopub.execute_input":"2022-05-07T07:11:53.015697Z","iopub.status.idle":"2022-05-07T07:11:53.041582Z","shell.execute_reply.started":"2022-05-07T07:11:53.015658Z","shell.execute_reply":"2022-05-07T07:11:53.040896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = train_test_split(data, test_size = 0.25)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:11:53.042712Z","iopub.execute_input":"2022-05-07T07:11:53.043493Z","iopub.status.idle":"2022-05-07T07:11:53.065963Z","shell.execute_reply.started":"2022-05-07T07:11:53.043454Z","shell.execute_reply":"2022-05-07T07:11:53.065349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1) BERT**","metadata":{}},{"cell_type":"code","source":"from transformers import TFBertModel,  BertConfig, BertTokenizerFast","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:15:16.086566Z","iopub.execute_input":"2022-05-07T07:15:16.087123Z","iopub.status.idle":"2022-05-07T07:15:17.794659Z","shell.execute_reply.started":"2022-05-07T07:15:16.087083Z","shell.execute_reply":"2022-05-07T07:15:17.793946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Name of the BERT model to use\nmodel_name = 'bert-base-uncased'\n\n# Max length of tokens\nmax_length = 45\n\n# Load transformers config and set output_hidden_states to False\nconfig = BertConfig.from_pretrained(model_name)\nconfig.output_hidden_states = False\n\n# Load BERT tokenizer\ntokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n\n# Load the Transformers BERT model\ntransformer_bert_model = TFBertModel.from_pretrained(model_name, config = config)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:15:17.796398Z","iopub.execute_input":"2022-05-07T07:15:17.796633Z","iopub.status.idle":"2022-05-07T07:15:43.724256Z","shell.execute_reply.started":"2022-05-07T07:15:17.7966Z","shell.execute_reply":"2022-05-07T07:15:43.723502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the MainLayer\nbert = transformer_bert_model.layers[0]\n\n# Build your model input\ninput_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\ninputs = {'input_ids': input_ids}\n\n# Load the Transformers BERT model as a layer in a Keras model\nbert_model = bert(inputs)[1]\ndropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\npooled_output = dropout(bert_model, training=False)\n\n# Then build your model output\nSentiments = Dense(units=len(train_data.Sentiment_value.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Sentiment')(pooled_output)\noutputs = {'Sentiment': Sentiments}\n\n# And combine it all in a model object\nmodel_bert = Model(inputs=inputs, outputs=outputs, name='BERT_MultiClass')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:15:43.728598Z","iopub.execute_input":"2022-05-07T07:15:43.730723Z","iopub.status.idle":"2022-05-07T07:15:50.484613Z","shell.execute_reply.started":"2022-05-07T07:15:43.730679Z","shell.execute_reply":"2022-05-07T07:15:50.483768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_bert.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:26:53.854158Z","iopub.execute_input":"2022-05-07T07:26:53.85521Z","iopub.status.idle":"2022-05-07T07:26:53.882436Z","shell.execute_reply.started":"2022-05-07T07:26:53.855164Z","shell.execute_reply":"2022-05-07T07:26:53.881738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set an optimizer\noptimizer = Adam(learning_rate=5e-05,epsilon=1e-08,decay=0.01,clipnorm=1.0)\n\n# Set loss and metrics\nloss = {'Sentiment': CategoricalCrossentropy(from_logits = True)}\n\n# Compile the model\nmodel_bert.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n\n# Ready output data for the model\ny_train = to_categorical(train_data['Sentiment'])\n\n# Tokenize the input \nx_train = tokenizer(\n          text=train_data['Phrase'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = True,\n          verbose = True)\n\ny_val = to_categorical(test_data['Sentiment'])\n\nx_val = tokenizer(\n          text=test_data['Phrase'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = True,\n          verbose = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:44:15.049654Z","iopub.execute_input":"2022-05-07T07:44:15.04992Z","iopub.status.idle":"2022-05-07T07:44:24.121344Z","shell.execute_reply.started":"2022-05-07T07:44:15.049892Z","shell.execute_reply":"2022-05-07T07:44:24.120558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nhistory_bert = model_bert.fit(\n    x={'input_ids': x_train['input_ids']},\n    y={'Sentiment': y_train},\n    validation_data=({'input_ids': x_val['input_ids']},{'Sentiment': y_val}),\n    batch_size=64,\n    epochs=3,\n    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:10:55.768738Z","iopub.execute_input":"2022-05-07T08:10:55.769029Z","iopub.status.idle":"2022-05-07T08:23:17.729301Z","shell.execute_reply.started":"2022-05-07T08:10:55.769Z","shell.execute_reply":"2022-05-07T08:23:17.728106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_train = history_bert.history['loss']\nepochs = range(1,4)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.title('Training loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:25:18.181275Z","iopub.execute_input":"2022-05-07T08:25:18.18153Z","iopub.status.idle":"2022-05-07T08:25:18.396763Z","shell.execute_reply.started":"2022-05-07T08:25:18.181504Z","shell.execute_reply":"2022-05-07T08:25:18.396077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_train = history_bert.history['accuracy']\nepochs = range(1,4)\nplt.plot(epochs, accuracy_train, 'g', label='Training Accuracy')\nplt.title('Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:25:24.376568Z","iopub.execute_input":"2022-05-07T08:25:24.376829Z","iopub.status.idle":"2022-05-07T08:25:24.567352Z","shell.execute_reply.started":"2022-05-07T08:25:24.376802Z","shell.execute_reply":"2022-05-07T08:25:24.566688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_bert.save('MODEL-BERT.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:49:34.801201Z","iopub.status.idle":"2022-05-07T07:49:34.802133Z","shell.execute_reply.started":"2022-05-07T07:49:34.801878Z","shell.execute_reply":"2022-05-07T07:49:34.801904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model_bert, to_file='model.png')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:50:48.087208Z","iopub.execute_input":"2022-05-07T07:50:48.087778Z","iopub.status.idle":"2022-05-07T07:50:48.30913Z","shell.execute_reply.started":"2022-05-07T07:50:48.087734Z","shell.execute_reply":"2022-05-07T07:50:48.308222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_eval = model_bert.evaluate(\n    x={'input_ids': x_val['input_ids']},\n    y={'Sentiment': y_val}\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:07:37.464371Z","iopub.execute_input":"2022-05-07T04:07:37.467456Z","iopub.status.idle":"2022-05-07T04:09:59.510084Z","shell.execute_reply.started":"2022-05-07T04:07:37.467403Z","shell.execute_reply":"2022-05-07T04:09:59.509009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val_predicted = model_bert.predict(\n    x={'input_ids': x_val['input_ids']},\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:09:59.513249Z","iopub.execute_input":"2022-05-07T04:09:59.513581Z","iopub.status.idle":"2022-05-07T04:12:25.441969Z","shell.execute_reply.started":"2022-05-07T04:09:59.513536Z","shell.execute_reply":"2022-05-07T04:12:25.440929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = tokenizer(\n          text=test['Phrase'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = False,\n          verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:12:25.444302Z","iopub.execute_input":"2022-05-07T04:12:25.444637Z","iopub.status.idle":"2022-05-07T04:12:28.762645Z","shell.execute_reply.started":"2022-05-07T04:12:25.444593Z","shell.execute_reply":"2022-05-07T04:12:28.761576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_predicted_bert = model_bert.predict(\n    x={'input_ids': x_test['input_ids']},\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:12:55.742139Z","iopub.execute_input":"2022-05-07T04:12:55.742772Z","iopub.status.idle":"2022-05-07T04:16:17.703531Z","shell.execute_reply.started":"2022-05-07T04:12:55.742738Z","shell.execute_reply":"2022-05-07T04:16:17.702261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_pred_bert=[np.argmax(i) for i in label_predicted_bert['Sentiment']]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:16:17.706592Z","iopub.execute_input":"2022-05-07T04:16:17.707007Z","iopub.status.idle":"2022-05-07T04:16:17.893785Z","shell.execute_reply.started":"2022-05-07T04:16:17.706962Z","shell.execute_reply":"2022-05-07T04:16:17.89261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_pred_bert[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:16:17.895256Z","iopub.execute_input":"2022-05-07T04:16:17.895583Z","iopub.status.idle":"2022-05-07T04:16:17.906437Z","shell.execute_reply.started":"2022-05-07T04:16:17.895544Z","shell.execute_reply":"2022-05-07T04:16:17.90523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission=pd.read_csv('../input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv')\nsample_submission['Sentiment'] = label_pred_bert\nsample_submission.to_csv(\"submission_BERT.csv\", index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:16:17.909072Z","iopub.execute_input":"2022-05-07T04:16:17.909971Z","iopub.status.idle":"2022-05-07T04:16:18.094605Z","shell.execute_reply.started":"2022-05-07T04:16:17.909923Z","shell.execute_reply":"2022-05-07T04:16:18.09363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2) ROBERTA**","metadata":{}},{"cell_type":"code","source":"from transformers import RobertaTokenizer, TFRobertaModel, RobertaConfig  ","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:59:56.168804Z","iopub.execute_input":"2022-05-07T07:59:56.169552Z","iopub.status.idle":"2022-05-07T07:59:56.213059Z","shell.execute_reply.started":"2022-05-07T07:59:56.169514Z","shell.execute_reply":"2022-05-07T07:59:56.212358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'roberta-base'\n\n# Max length of tokens\nmax_length = 45\n\n# Load transformers config and set output_hidden_states to False\nconfig = RobertaConfig.from_pretrained(model_name)\nconfig.output_hidden_states = False\n\n# Load Roberta tokenizer\ntokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n\n# Load the Roberta model\ntransformer_roberta_model = TFRobertaModel.from_pretrained(model_name, config = config)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T07:59:58.370551Z","iopub.execute_input":"2022-05-07T07:59:58.371099Z","iopub.status.idle":"2022-05-07T08:00:22.908913Z","shell.execute_reply.started":"2022-05-07T07:59:58.371061Z","shell.execute_reply":"2022-05-07T08:00:22.908172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the MainLayer\nroberta = transformer_roberta_model.layers[0]\n\n# Build your model input\ninput_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\ninputs = {'input_ids': input_ids}\n\n# Load the Transformers RoBERTa model as a layer in a Keras model\nroberta_model = roberta(inputs)[1]\ndropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\npooled_output = dropout(roberta_model, training=False)\n\n# Then build your model output\nSentiments = Dense(units=len(train_data.Sentiment_value.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='Sentiment')(pooled_output)\noutputs = {'Sentiment': Sentiments}\n\n# And combine it all in a model object\nmodel_roberta = Model(inputs=inputs, outputs=outputs, name='RoBERTa_MultiClass')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:00:28.032379Z","iopub.execute_input":"2022-05-07T08:00:28.032967Z","iopub.status.idle":"2022-05-07T08:01:17.774824Z","shell.execute_reply.started":"2022-05-07T08:00:28.032932Z","shell.execute_reply":"2022-05-07T08:01:17.7741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_roberta.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:17.776509Z","iopub.execute_input":"2022-05-07T08:01:17.776744Z","iopub.status.idle":"2022-05-07T08:01:17.796351Z","shell.execute_reply.started":"2022-05-07T08:01:17.776711Z","shell.execute_reply":"2022-05-07T08:01:17.795706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model_roberta, to_file='model.png')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:33.918648Z","iopub.execute_input":"2022-05-07T08:01:33.918934Z","iopub.status.idle":"2022-05-07T08:01:34.132493Z","shell.execute_reply.started":"2022-05-07T08:01:33.918904Z","shell.execute_reply":"2022-05-07T08:01:34.131699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set an optimizer\noptimizer = Adam(learning_rate=1e-05,epsilon=1e-06,decay=0.01)\n\n# Set loss and metrics\nloss = {'Sentiment': CategoricalCrossentropy(from_logits = True)}\n\n# Compile the model\nmodel_roberta.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n\n# Ready output data for the model\ny_train = to_categorical(train_data['Sentiment'])\n\n# Tokenize the input \nx_train = tokenizer(\n          text=train_data['Phrase'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = True,\n          verbose = True)\n\ny_val = to_categorical(test_data['Sentiment'])\n\nx_val = tokenizer(\n          text=test_data['Phrase'].to_list(),\n          add_special_tokens=True,max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = True,\n          verbose = True)\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:47:55.115417Z","iopub.execute_input":"2022-05-07T04:47:55.116275Z","iopub.status.idle":"2022-05-07T04:49:18.195811Z","shell.execute_reply.started":"2022-05-07T04:47:55.116242Z","shell.execute_reply":"2022-05-07T04:49:18.194567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nhistory_roberta = model_roberta.fit(\n    x={'input_ids': x_train['input_ids']},\n    y={'Sentiment': y_train},\n    validation_data=({'input_ids': x_val['input_ids']},{'Sentiment': y_val}),\n    batch_size=64,\n    epochs=3,\n    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T04:49:18.198374Z","iopub.execute_input":"2022-05-07T04:49:18.198793Z","iopub.status.idle":"2022-05-07T05:02:59.385976Z","shell.execute_reply.started":"2022-05-07T04:49:18.198746Z","shell.execute_reply":"2022-05-07T05:02:59.38493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_train = history_roberta.history['loss']\nepochs = range(1,4)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.title('Training loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_train = history_roberta.history['accuracy']\nepochs = range(1,4)\nplt.plot(epochs, accuracy_train, 'g', label='Training Accuracy')\nplt.title('Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_roberta.save('MODEL-ROBERTA.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-07T05:02:59.392405Z","iopub.execute_input":"2022-05-07T05:02:59.393098Z","iopub.status.idle":"2022-05-07T05:03:04.475125Z","shell.execute_reply.started":"2022-05-07T05:02:59.393053Z","shell.execute_reply":"2022-05-07T05:03:04.474055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_eval_roberta = model_roberta.evaluate(\n    x={'input_ids': x_val['input_ids']},\n    y={'Sentiment': y_val}\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T05:03:04.478645Z","iopub.execute_input":"2022-05-07T05:03:04.478984Z","iopub.status.idle":"2022-05-07T05:04:52.130925Z","shell.execute_reply.started":"2022-05-07T05:03:04.47894Z","shell.execute_reply":"2022-05-07T05:04:52.129844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val_predicted = model_roberta.predict(\n    x={'input_ids': x_val['input_ids']},\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T05:05:05.678012Z","iopub.execute_input":"2022-05-07T05:05:05.678323Z","iopub.status.idle":"2022-05-07T05:06:47.5473Z","shell.execute_reply.started":"2022-05-07T05:05:05.67828Z","shell.execute_reply":"2022-05-07T05:06:47.5462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = tokenizer(\n          text=test['Phrase'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = False,\n          verbose = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-07T05:04:52.133474Z","iopub.execute_input":"2022-05-07T05:04:52.133767Z","iopub.status.idle":"2022-05-07T05:05:05.676611Z","shell.execute_reply.started":"2022-05-07T05:04:52.133736Z","shell.execute_reply":"2022-05-07T05:05:05.675634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_predicted = model_roberta.predict(\n    x={'input_ids': x_test['input_ids']},\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T05:06:47.54947Z","iopub.execute_input":"2022-05-07T05:06:47.549844Z","iopub.status.idle":"2022-05-07T05:10:09.513586Z","shell.execute_reply.started":"2022-05-07T05:06:47.549798Z","shell.execute_reply":"2022-05-07T05:10:09.512369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_pred_roberta=[np.argmax(i) for i in label_predicted['Sentiment']]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T05:10:09.515825Z","iopub.execute_input":"2022-05-07T05:10:09.516151Z","iopub.status.idle":"2022-05-07T05:10:09.698552Z","shell.execute_reply.started":"2022-05-07T05:10:09.516108Z","shell.execute_reply":"2022-05-07T05:10:09.697568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission=pd.read_csv('../input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv')\nsample_submission['Sentiment'] = label_pred_roberta\nsample_submission.to_csv(\"submission_ROBERTA.csv\", index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T05:11:06.779144Z","iopub.execute_input":"2022-05-07T05:11:06.77945Z","iopub.status.idle":"2022-05-07T05:11:06.963172Z","shell.execute_reply.started":"2022-05-07T05:11:06.779417Z","shell.execute_reply":"2022-05-07T05:11:06.962108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}