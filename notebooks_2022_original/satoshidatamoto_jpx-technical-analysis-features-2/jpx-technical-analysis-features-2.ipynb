{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":">### Technical Analysis Indicators #2\n>- Here are some simple indexes to analyze the charts. some can even be used as features to a model.\n>- Ta-lib is very good and very helpful library for calculating various indexes, but kernel doesn't support.\n>- Enjoy the short scripts to obtain them! \n>\n\n[1]: TBD","metadata":{"_cell_guid":"8af163ff-915a-4fae-aefe-6447e64952e5","_uuid":"b328cc9e-a536-4347-beed-d033e9f5ac6a","papermill":{"duration":0.020028,"end_time":"2021-12-06T15:53:55.370959","exception":false,"start_time":"2021-12-06T15:53:55.350931","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#### Code starts here ‚¨á","metadata":{"_cell_guid":"d849b62e-dcc7-4e5a-95c7-031dee523204","_uuid":"359fc054-a69e-481b-938b-6fedc83ddc9b","papermill":{"duration":0.021728,"end_time":"2021-12-06T15:53:55.737353","exception":false,"start_time":"2021-12-06T15:53:55.715625","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport gc\nimport traceback\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=pd.core.common.SettingWithCopyWarning)\n    \nplt.style.use('bmh')\nplt.rcParams['figure.figsize'] = [14, 8]  # width, height","metadata":{"_cell_guid":"7b701afb-9ee3-4f9e-a219-3b6206a8283d","_uuid":"35744779-02d1-445c-a8d4-dcbf1e1bdba2","jupyter":{"outputs_hidden":false},"papermill":{"duration":0.198453,"end_time":"2021-12-06T15:53:55.95798","exception":false,"start_time":"2021-12-06T15:53:55.759527","status":"completed"},"tags":[],"collapsed":false,"execution":{"iopub.status.busy":"2022-04-23T10:48:02.845992Z","iopub.execute_input":"2022-04-23T10:48:02.846408Z","iopub.status.idle":"2022-04-23T10:48:02.851679Z","shell.execute_reply.started":"2022-04-23T10:48:02.846377Z","shell.execute_reply":"2022-04-23T10:48:02.850853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"loading\">Data Loading üóÉÔ∏è</span>\n<hr>\n\nIn the real competition data, the number of datapoints per day (that is per \"group\") is not constant as it was in the spoofed data. We need to confirm that the time series split respects that there are different counts of samples in the the days. We load the data and reduce memory footprint.","metadata":{"_cell_guid":"0f8bf214-4860-4c6f-97fc-e3e374d5b646","_uuid":"1034e975-839a-4c8d-96eb-c83436fb735a","papermill":{"duration":0.02172,"end_time":"2021-12-06T15:53:56.001845","exception":false,"start_time":"2021-12-06T15:53:55.980125","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype.name\n\n        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"_cell_guid":"b56ab916-dae6-4ff7-bb2d-52398dd52e1c","_kg_hide-input":true,"_uuid":"1146dd4e-6f2e-45c4-a2fd-7fee6e751e98","papermill":{"duration":0.040317,"end_time":"2021-12-06T15:53:56.064531","exception":false,"start_time":"2021-12-06T15:53:56.024214","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:48:02.858381Z","iopub.execute_input":"2022-04-23T10:48:02.859313Z","iopub.status.idle":"2022-04-23T10:48:02.871383Z","shell.execute_reply.started":"2022-04-23T10:48:02.859274Z","shell.execute_reply":"2022-04-23T10:48:02.870543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"loading\">Data Loading üóÉÔ∏è</span>\n<hr>\n\nThe data organisation has already been done and saved to Kaggle datasets. Here we choose which years to load. We can use either 2017, 2018, 2019, 2020, 2021, Original, Supplement by changing the `INC2021`, `INC2020`, `INC2019`, `INC2018`, `INC2017`, `INCCOMP`, `INCSUPP` variables in the preceeding code section. These datasets are discussed [here][1].\n\n[1]: https://www.kaggle.com/c/g-research-crypto-forecasting/discussion/285726\n","metadata":{"papermill":{"duration":0.021974,"end_time":"2021-12-06T15:53:56.108867","exception":false,"start_time":"2021-12-06T15:53:56.086893","status":"completed"},"tags":[]}},{"cell_type":"code","source":"stock_list = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")\nprices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")\nstock_list = stock_list.loc[stock_list['SecuritiesCode'].isin(prices['SecuritiesCode'].unique())]\nstock_name_dict = {stock_list['SecuritiesCode'].tolist()[idx]: stock_list['Name'].tolist()[idx] for idx in range(len(stock_list))}\n\ndef load_training_data(asset_id = None):\n    prices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")\n    supplemental_prices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\")\n    df_train = pd.concat([prices, supplemental_prices]) if INCSUPP else prices\n    df_train = pd.merge(df_train, stock_list[['SecuritiesCode', 'Name']], left_on = 'SecuritiesCode', right_on = 'SecuritiesCode', how = 'left')\n    df_train['date'] = pd.to_datetime(df_train['Date'])\n    df_train['year'] = df_train['date'].dt.year\n    if not INC2022: df_train = df_train.loc[df_train['year'] != 2022]\n    if not INC2021: df_train = df_train.loc[df_train['year'] != 2021]\n    if not INC2020: df_train = df_train.loc[df_train['year'] != 2020]\n    if not INC2019: df_train = df_train.loc[df_train['year'] != 2019]\n    if not INC2018: df_train = df_train.loc[df_train['year'] != 2018]\n    if not INC2017: df_train = df_train.loc[df_train['year'] != 2017]\n    # asset_id = 1301 # Remove before flight\n    if asset_id is not None: df_train = df_train.loc[df_train['SecuritiesCode'] == asset_id]\n    # df_train = df_train[:1000] # Remove before flight\n    return df_train","metadata":{"_cell_guid":"8da68356-63f7-49c7-aca2-b61019c278b6","_kg_hide-input":true,"_uuid":"aafb204a-c174-4898-af33-eede907e879b","jupyter":{"outputs_hidden":false},"papermill":{"duration":24.54551,"end_time":"2021-12-06T15:54:20.676557","exception":false,"start_time":"2021-12-06T15:53:56.131047","status":"completed"},"tags":[],"collapsed":false,"execution":{"iopub.status.busy":"2022-04-23T10:48:02.872745Z","iopub.execute_input":"2022-04-23T10:48:02.873126Z","iopub.status.idle":"2022-04-23T10:48:06.631917Z","shell.execute_reply.started":"2022-04-23T10:48:02.873074Z","shell.execute_reply":"2022-04-23T10:48:06.630911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WHICH YEARS TO INCLUDE? YES=1 NO=0\nINC2022 = 1\nINC2021 = 1\nINC2020 = 1\nINC2019 = 1\nINC2018 = 1\nINC2017 = 1\nINCSUPP = 1\nprint(\"Loaded all data!\")\n\ntrain = load_training_data().sort_values('date').set_index(\"date\")\ntrain_data = train.copy()\ntrain_data['date'] = pd.to_datetime(train_data['Date'])\ndf = train_data.loc[train_data['SecuritiesCode'] == 1301]","metadata":{"papermill":{"duration":16.070117,"end_time":"2021-12-06T15:54:36.768788","exception":false,"start_time":"2021-12-06T15:54:20.698671","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:48:06.63343Z","iopub.execute_input":"2022-04-23T10:48:06.633706Z","iopub.status.idle":"2022-04-23T10:48:13.076958Z","shell.execute_reply.started":"2022-04-23T10:48:06.633677Z","shell.execute_reply":"2022-04-23T10:48:13.075995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span class=\"title-section w3-xxlarge\" id=\"features\">Feature Engineering üî¨</span>\n<hr>","metadata":{"_cell_guid":"22bb5d25-9c27-4be9-b9ac-0701b71058a5","_uuid":"137210f4-aa91-4525-9f53-5e91f4bf9ced","papermill":{"duration":0.022191,"end_time":"2021-12-06T15:54:36.813781","exception":false,"start_time":"2021-12-06T15:54:36.79159","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\n\nimport numpy\nimport pandas as pd\n\n\ndef rolling_mean(series, window): return series.rolling(window).mean()\ndef rolling_std(series, window): return series.rolling(window).std()\ndef rolling_sum(series, window): return series.rolling(window).sum()\ndef ewma(series, span, min_periods): return series.ewm(span = span, min_periods = min_periods).mean()\ndef get_value(df, idx, col): return df.iloc[idx][col]\n\n#Moving Average\ndef MA(df, n):\n    MA = pd.Series(rolling_mean(df['Close'], n), name = 'MA_' + str(n))\n    df['MA'] = MA\n    return df\n\n#Exponential Moving Average\ndef EMA(df, n):\n    EMA = pd.Series(ewma(df['Close'], span = n, min_periods = n - 1), name = 'EMA_' + str(n))\n    df['EMA'] = EMA\n    return df\n\n#Momentum\ndef MOM(df, n):\n    M = pd.Series(df['Close'].diff(n), name = 'Momentum_' + str(n))\n    df['MOM'] = M\n    return df\n\n#Rate of Change\ndef ROC(df, n):\n    M = df['Close'].diff(n - 1)\n    N = df['Close'].shift(n - 1)\n    ROC = pd.Series(M / N, name = 'ROC_' + str(n))\n    df['ROC'] = ROC\n    return df\n\n#Average True Range\ndef ATR(df, n):\n    i = 0\n    TR_l = [0]\n    while i < len(df) - 1:\n        TR = max(get_value(df, i + 1, 'High'), get_value(df, i, 'Close')) - min(get_value(df, i + 1, 'Low'), get_value(df, i, 'Close'))\n        TR_l.append(TR)\n        i = i + 1\n    TR_s = pd.Series(TR_l)\n    ATR = pd.Series(ewma(TR_s, span = n, min_periods = n), name = 'ATR_' + str(n))\n    df['ATR'] = ATR\n    return df\n\n#Bollinger Bands\ndef BBANDS(df, n):\n    MA = pd.Series(rolling_mean(df['Close'], n))\n    MSD = pd.Series(rolling_std(df['Close'], n))\n    b1 = 4 * MSD / MA\n    B1 = pd.Series(b1, name = 'BollingerB_' + str(n))\n    df['B1'] = B1\n    b2 = (df['Close'] - MA + 2 * MSD) / (4 * MSD)\n    B2 = pd.Series(b2, name = 'Bollinger%b_' + str(n))\n    df['B2'] = B2\n    return df\n\n#Pivot Points, Supports and Resistances\ndef PPSR(df):\n    PP = pd.Series((df['High'] + df['Low'] + df['Close']) / 3)\n    R1 = pd.Series(2 * PP - df['Low'])\n    S1 = pd.Series(2 * PP - df['High'])\n    R2 = pd.Series(PP + df['High'] - df['Low'])\n    S2 = pd.Series(PP - df['High'] + df['Low'])\n    R3 = pd.Series(df['High'] + 2 * (PP - df['Low']))\n    S3 = pd.Series(df['Low'] - 2 * (df['High'] - PP))\n    psr = {'PP':PP, 'R1':R1, 'S1':S1, 'R2':R2, 'S2':S2, 'R3':R3, 'S3':S3}\n    PSR = pd.DataFrame(psr)\n    for col in PSR.columns:\n        df['PSR_' + col] = PSR[col]\n    return df\n\n#Stochastic oscillator %K\ndef STOK(df):\n    SOk = pd.Series((df['Close'] - df['Low']) / (df['High'] - df['Low']), name = 'SO%k')\n    df['SOk'] = SOk\n    return df\n\n# Stochastic Oscillator, EMA smoothing, nS = slowing (1 if no slowing)\ndef STO(df,  nK, nD, nS=1):\n    SOk = pd.Series((df['Close'] - df['Low'].rolling(nK).min()) / (df['High'].rolling(nK).max() - df['Low'].rolling(nK).min()), name = 'SO%k'+str(nK))\n    SOd = pd.Series(SOk.ewm(ignore_na=False, span=nD, min_periods=nD-1, adjust=True).mean(), name = 'SO%d'+str(nD))\n    SOk = SOk.ewm(ignore_na=False, span=nS, min_periods=nS-1, adjust=True).mean()\n    SOd = SOd.ewm(ignore_na=False, span=nS, min_periods=nS-1, adjust=True).mean()\n    df['SOk'] = SOk\n    df['SOd'] = SOd\n    return df\n\n#Trix\ndef TRIX(df, n):\n    EX1 = ewma(df['Close'], span = n, min_periods = n - 1)\n    EX2 = ewma(EX1, span = n, min_periods = n - 1)\n    EX3 = ewma(EX2, span = n, min_periods = n - 1)\n    i = 0\n    ROC_l = [0]\n    while i + 1 <= len(df) - 1:\n        ROC = (EX3.iloc[i + 1] - EX3.iloc[i]) / EX3.iloc[i]\n        ROC_l.append(ROC)\n        i = i + 1\n    Trix = pd.Series(ROC_l, name = 'Trix_' + str(n))\n    df['Trix'] = Trix\n    return df\n\n#Average Directional Movement Index\ndef ADX(df, n, n_ADX):\n    i = 0\n    UpI = []\n    DoI = []\n    while i + 1 <= len(df) - 1:\n        UpMove = get_value(df, i + 1, 'High') - get_value(df, i, 'High')\n        DoMove = get_value(df, i, 'Low') - get_value(df, i + 1, 'Low')\n        if UpMove > DoMove and UpMove > 0:\n            UpD = UpMove\n        else: UpD = 0\n        UpI.append(UpD)\n        if DoMove > UpMove and DoMove > 0:\n            DoD = DoMove\n        else: DoD = 0\n        DoI.append(DoD)\n        i = i + 1\n    i = 0\n    TR_l = [0]\n    while i < len(df) - 1:\n        TR = max(get_value(df, i + 1, 'High'), get_value(df, i, 'Close')) - min(get_value(df, i + 1, 'Low'), get_value(df, i, 'Close'))\n        TR_l.append(TR)\n        i = i + 1\n    TR_s = pd.Series(TR_l)\n    ATR = pd.Series(ewma(TR_s, span = n, min_periods = n))\n    UpI = pd.Series(UpI)\n    DoI = pd.Series(DoI)\n    PosDI = pd.Series(ewma(UpI, span = n, min_periods = n - 1) / ATR)\n    NegDI = pd.Series(ewma(DoI, span = n, min_periods = n - 1) / ATR)\n    ADX = pd.Series(ewma(abs(PosDI - NegDI) / (PosDI + NegDI), span = n_ADX, min_periods = n_ADX - 1), name = 'ADX_' + str(n) + '_' + str(n_ADX))\n    df['ADX'] = ADX\n    return df\n\n#MACD, MACD Signal and MACD difference\ndef MACD(df, n_fast, n_slow):\n    EMAfast = pd.Series(ewma(df['Close'], span = n_fast, min_periods = n_slow - 1))\n    EMAslow = pd.Series(ewma(df['Close'], span = n_slow, min_periods = n_slow - 1))\n    MACD = pd.Series(EMAfast - EMAslow, name = 'MACD_' + str(n_fast) + '_' + str(n_slow))\n    MACDsign = pd.Series(ewma(MACD, span = 9, min_periods = 8), name = 'MACDsign_' + str(n_fast) + '_' + str(n_slow))\n    MACDdiff = pd.Series(MACD - MACDsign, name = 'MACDdiff_' + str(n_fast) + '_' + str(n_slow))\n    df['MACD'] = MACD\n    df['MACDsign'] = MACDsign\n    df['MACDdiff'] = MACDdiff\n    return df\n\n#Mass Index\ndef MassI(df):\n    Range = df['High'] - df['Low']\n    EX1 = ewma(Range, span = 9, min_periods = 8)\n    EX2 = ewma(EX1, span = 9, min_periods = 8)\n    Mass = EX1 / EX2\n    MassI = pd.Series(rolling_sum(Mass, 25), name = 'Mass Index')\n    df['MassI'] = MassI\n    return df\n\n#Vortex Indicator: http://www.vortexindicator.com/VFX_VORTEX.PDF\ndef Vortex(df, n):\n    i = 0\n    TR = [0]\n    while i < len(df) - 1:\n        Range = max(get_value(df, i + 1, 'High'), get_value(df, i, 'Close')) - min(get_value(df, i + 1, 'Low'), get_value(df, i, 'Close'))\n        TR.append(Range)\n        i = i + 1\n    i = 0\n    VM = [0]\n    while i < len(df) - 1:\n        Range = abs(get_value(df, i + 1, 'High') - get_value(df, i, 'Low')) - abs(get_value(df, i + 1, 'Low') - get_value(df, i, 'High'))\n        VM.append(Range)\n        i = i + 1\n    VI = pd.Series(rolling_sum(pd.Series(VM), n) / rolling_sum(pd.Series(TR), n), name = 'Vortex_' + str(n))\n    df['VI'] = VI\n    return df\n\n#KST Oscillator\ndef KST(df, r1, r2, r3, r4, n1, n2, n3, n4):\n    M = df['Close'].diff(r1 - 1)\n    N = df['Close'].shift(r1 - 1)\n    ROC1 = M / N\n    M = df['Close'].diff(r2 - 1)\n    N = df['Close'].shift(r2 - 1)\n    ROC2 = M / N\n    M = df['Close'].diff(r3 - 1)\n    N = df['Close'].shift(r3 - 1)\n    ROC3 = M / N\n    M = df['Close'].diff(r4 - 1)\n    N = df['Close'].shift(r4 - 1)\n    ROC4 = M / N\n    KST = pd.Series(rolling_sum(ROC1, n1) + rolling_sum(ROC2, n2) * 2 + rolling_sum(ROC3, n3) * 3 + rolling_sum(ROC4, n4) * 4, name = 'KST_' + str(r1) + '_' + str(r2) + '_' + str(r3) + '_' + str(r4) + '_' + str(n1) + '_' + str(n2) + '_' + str(n3) + '_' + str(n4))\n    df['KST'] = KST\n    return df\n\n#Relative Strength Index\ndef RSI(df, n):\n    i = 0\n    UpI = [0]\n    DoI = [0]\n    while i + 1 <= len(df) - 1:\n        UpMove = get_value(df, i + 1, 'High') - get_value(df, i, 'High')\n        DoMove = get_value(df, i, 'Low') - get_value(df, i + 1, 'Low')\n        if UpMove > DoMove and UpMove > 0:\n            UpD = UpMove\n        else: UpD = 0\n        UpI.append(UpD)\n        if DoMove > UpMove and DoMove > 0:\n            DoD = DoMove\n        else: DoD = 0\n        DoI.append(DoD)\n        i = i + 1\n    UpI = pd.Series(UpI)\n    DoI = pd.Series(DoI)\n    PosDI = pd.Series(ewma(UpI, span = n, min_periods = n - 1))\n    NegDI = pd.Series(ewma(DoI, span = n, min_periods = n - 1))\n    RSI = pd.Series(PosDI / (PosDI + NegDI), name = 'RSI_' + str(n))\n    df['RSI'] = RSI\n    return df\n\n#True Strength Index\ndef TSI(df, r, s):\n    M = pd.Series(df['Close'].diff(1))\n    aM = abs(M)\n    EMA1 = pd.Series(ewma(M, span = r, min_periods = r - 1))\n    aEMA1 = pd.Series(ewma(aM, span = r, min_periods = r - 1))\n    EMA2 = pd.Series(ewma(EMA1, span = s, min_periods = s - 1))\n    aEMA2 = pd.Series(ewma(aEMA1, span = s, min_periods = s - 1))\n    TSI = pd.Series(EMA2 / aEMA2, name = 'TSI_' + str(r) + '_' + str(s))\n    df['TSI'] = TSI\n    return df\n\n#Accumulation/Distribution\ndef ACCDIST(df, n):\n    ad = (2 * df['Close'] - df['High'] - df['Low']) / (df['High'] - df['Low']) * df['Volume']\n    M = ad.diff(n - 1)\n    N = ad.shift(n - 1)\n    ROC = M / N\n    AD = pd.Series(ROC, name = 'Acc/Dist_ROC_' + str(n))\n    df['AD'] = AD\n    return df\n\n#Chaikin Oscillator\ndef Chaikin(df):\n    ad = (2 * df['Close'] - df['High'] - df['Low']) / (df['High'] - df['Low']) * df['Volume']\n    Chaikin = pd.Series(ewma(ad, span = 3, min_periods = 2) - ewma(ad, span = 10, min_periods = 9), name = 'Chaikin')\n    df['Chaikin'] = Chaikin\n    return df\n\n#Money Flow Index and Ratio\ndef MFI(df, n):\n    PP = (df['High'] + df['Low'] + df['Close']) / 3\n    i = 0\n    PosMF = [0]\n    while i < len(df) - 1:\n        if PP.iloc[i + 1] > PP.iloc[i]:\n            PosMF.append(PP.iloc[i + 1] * get_value(df, i + 1, 'Volume'))\n        else:\n            PosMF.append(0)\n        i = i + 1\n    PosMF = pd.Series(PosMF)\n    TotMF = PP * df['Volume']\n    MFR = pd.Series(PosMF / TotMF)\n    MFI = pd.Series(rolling_mean(MFR, n), name = 'MFI_' + str(n))\n    df['MFI'] = MFI\n    return df\n\n#On-balance Volume\ndef OBV(df, n):\n    i = 0\n    OBV = [0]\n    while i < len(df) - 1:\n        if get_value(df, i + 1, 'Close') - get_value(df, i, 'Close') > 0:\n            OBV.append(get_value(df, i + 1, 'Volume'))\n        if get_value(df, i + 1, 'Close') - get_value(df, i, 'Close') == 0:\n            OBV.append(0)\n        if get_value(df, i + 1, 'Close') - get_value(df, i, 'Close') < 0:\n            OBV.append(-get_value(df, i + 1, 'Volume'))\n        i = i + 1\n    OBV = pd.Series(OBV)\n    OBV_ma = pd.Series(rolling_mean(OBV, n), name = 'OBV_' + str(n))\n    df['OBV_ma'] = OBV_ma\n    return df\n\n#Force Index\ndef FORCE(df, n):\n    F = pd.Series(df['Close'].diff(n) * df['Volume'].diff(n), name = 'Force_' + str(n))\n    df['F'] = F\n    return df\n\n#Ease of Movement\ndef EOM(df, n):\n    EoM = (df['High'].diff(1) + df['Low'].diff(1)) * (df['High'] - df['Low']) / (2 * df['Volume'])\n    Eom_ma = pd.Series(rolling_mean(EoM, n), name = 'EoM_' + str(n))\n    df['Eom_ma'] = Eom_ma\n    return df\n\n#Commodity Channel Index\ndef CCI(df, n):\n    PP = (df['High'] + df['Low'] + df['Close']) / 3\n    CCI = pd.Series((PP - rolling_mean(PP, n)) / rolling_std(PP, n), name = 'CCI_' + str(n))\n    df['CCI'] = CCI\n    return df\n\n#Coppock Curve\ndef COPP(df, n):\n    M = df['Close'].diff(int(n * 11 / 10) - 1)\n    N = df['Close'].shift(int(n * 11 / 10) - 1)\n    ROC1 = M / N\n    M = df['Close'].diff(int(n * 14 / 10) - 1)\n    N = df['Close'].shift(int(n * 14 / 10) - 1)\n    ROC2 = M / N\n    Copp = pd.Series(ewma(ROC1 + ROC2, span = n, min_periods = n), name = 'Copp_' + str(n))\n    df['Copp'] = Copp\n    return df\n\n#Keltner Channel\ndef KELCH(df, n):\n    KelChM = pd.Series(rolling_mean((df['High'] + df['Low'] + df['Close']) / 3, n), name = 'KelChM_' + str(n))\n    KelChU = pd.Series(rolling_mean((4 * df['High'] - 2 * df['Low'] + df['Close']) / 3, n), name = 'KelChU_' + str(n))\n    KelChD = pd.Series(rolling_mean((-2 * df['High'] + 4 * df['Low'] + df['Close']) / 3, n), name = 'KelChD_' + str(n))\n    df['KelChM'] = KelChM\n    df['KelChU'] = KelChU\n    df['KelChD'] = KelChD\n    return df\n\n#Ultimate Oscillator\ndef ULTOSC(df):\n    i = 0\n    TR_l = [0]\n    BP_l = [0]\n    while i < len(df) - 1:\n        TR = max(get_value(df, i + 1, 'High'), get_value(df, i, 'Close')) - min(get_value(df, i + 1, 'Low'), get_value(df, i, 'Close'))\n        TR_l.append(TR)\n        BP = get_value(df, i + 1, 'Close') - min(get_value(df, i + 1, 'Low'), get_value(df, i, 'Close'))\n        BP_l.append(BP)\n        i = i + 1\n    UltO = pd.Series((4 * rolling_sum(pd.Series(BP_l), 7) / rolling_sum(pd.Series(TR_l), 7)) + (2 * rolling_sum(pd.Series(BP_l), 14) / rolling_sum(pd.Series(TR_l), 14)) + (rolling_sum(pd.Series(BP_l), 28) / rolling_sum(pd.Series(TR_l), 28)), name = 'Ultimate_Osc')\n    df['UltO'] = UltO\n    return df\n\n#Donchian Channel\ndef DONCH(df, n):\n    i = 0\n    DC_l = []\n    while i < n - 1:\n        DC_l.append(0)\n        i = i + 1\n    i = 0\n    while i + n - 1 < len(df) - 1:\n        DC = max(df['High'].iloc[i:i + n - 1]) - min(df['Low'].iloc[i:i + n - 1])\n        DC_l.append(DC)\n        i = i + 1\n    DonCh = pd.Series(DC_l, name = 'Donchian_' + str(n))\n    DonCh = DonCh.shift(n - 1)\n    df['DonCh'] = DonCh\n    return df\n\n#Standard Deviation\ndef STDDEV(df, n):\n    std_dev = pd.Series(rolling_std(df['Close'], n), name = 'STD_' + str(n))\n    df['std_dev'] = std_dev\n    return df\n\n\n\n\n\nn = 15\nnK = 5\nnD = 7\nn_fast = 5\nn_slow = 10\nn_ADX = 10\nr = 3\ns = 7\n\ndf = MA(df, n)\ndf = EMA(df, n)\ndf = MOM(df, n)\ndf = ROC(df, n)\ndf = ATR(df, n)\ndf = BBANDS(df, n)\ndf = PPSR(df)\ndf = STOK(df)\ndf = STO(df,  nK, nD, nS=1)\ndf = TRIX(df, n)\ndf = ADX(df, n, n_ADX)\ndf = MACD(df, n_fast, n_slow)\ndf = MassI(df)\ndf = Vortex(df, n)\ndf = RSI(df, n)\ndf = TSI(df, r, s)\ndf = ACCDIST(df, n)\ndf = Chaikin(df)\ndf = MFI(df, n)\ndf = OBV(df, n)\ndf = FORCE(df, n)\ndf = EOM(df, n)\ndf = CCI(df, n)\ndf = COPP(df, n)\ndf = KELCH(df, n)\ndf = ULTOSC(df)\ndf = DONCH(df, n)\ndf = STDDEV(df, n)","metadata":{"papermill":{"duration":16659.52693,"end_time":"2021-12-06T20:32:16.362941","exception":false,"start_time":"2021-12-06T15:54:36.836011","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-04-23T10:48:13.078715Z","iopub.execute_input":"2022-04-23T10:48:13.079182Z","iopub.status.idle":"2022-04-23T10:48:21.225268Z","shell.execute_reply.started":"2022-04-23T10:48:13.079135Z","shell.execute_reply":"2022-04-23T10:48:21.224351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# More to come..","metadata":{"papermill":{"duration":0.023515,"end_time":"2021-12-06T20:32:16.414397","exception":false,"start_time":"2021-12-06T20:32:16.390882","status":"completed"},"tags":[],"pycharm":{"name":"#%% md\n"}}}]}