{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**导入必要的包**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nimport torchvision.transforms as transforms\nimport PIL.Image as pil_image\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:56:12.820834Z","iopub.execute_input":"2022-05-07T09:56:12.821964Z","iopub.status.idle":"2022-05-07T09:56:12.828187Z","shell.execute_reply.started":"2022-05-07T09:56:12.821917Z","shell.execute_reply":"2022-05-07T09:56:12.827283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**加载自定义的数据**\n\n*参考链接： https://zhuanlan.zhihu.com/p/32506912","metadata":{}},{"cell_type":"code","source":"# 分割的类别\nclasses = ['background','aeroplane','bicycle','bird','boat',\n           'bottle','bus','car','cat','chair','cow','diningtable',\n           'dog','horse','motorbike','person','potted plant',\n           'sheep','sofa','train','tv/monitor']\n\n# 每个类别对应的RGB值\ncolormap = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n            [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n            [0,192,0],[128,192,0],[0,64,128]]\n\ncm2lbl = np.zeros(256**3) # 每个像素点有 0 ~ 255 的选择，RGB 三个通道\nfor i,cm in enumerate(colormap):\n    cm2lbl[(cm[0]*256+cm[1])*256+cm[2]] = i # 建立索引\n    \n# 将图片映射成索引数组\ndef image_to_label(image):\n    \"\"\"将图片映射成类别索引的数组\"\"\"\n    data=np.array(image,dtype='int32')\n    # 按照上面一样的计算规则，得到对应的值\n    index = (data[:, :, 0] * 256 + data[:, :, 1]) * 256 + data[:, :, 2]\n    return np.array(cm2lbl[index],dtype='int64')\n\ndef random_crop(image,width,height):\n    \"\"\"随机裁剪\"\"\"\n    pass\n\n\n# 测试\nimage=pil_image.open('../input/voc2012/data/VOCdevkit/VOC2012/SegmentationClass/2007_000032.png').convert('RGB')\n# image = transforms.RandomCrop((224, 224))(image)\n# print(image)\n# plt.imshow(image)\n# label = transforms.FixedCrop(*rect)(label)\n# image_array=image_to_label(image)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:56:12.888432Z","iopub.execute_input":"2022-05-07T09:56:12.888644Z","iopub.status.idle":"2022-05-07T09:56:12.916095Z","shell.execute_reply.started":"2022-05-07T09:56:12.888616Z","shell.execute_reply":"2022-05-07T09:56:12.915325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VOCDataset(Dataset):\n    \"\"\"自定义数据类加载规则\"\"\"\n    def __init__(self,file_path=None,transform=None):\n        \"\"\"初始化函数\"\"\"\n        \n        images_labels=[]\n        file=open(file_path)\n        for name in file.readlines():\n            \n            # 移除空格和换行符\n            name=name.strip()\n            \n            image=\"../input/voc2012/data/VOCdevkit/VOC2012/JPEGImages/\"+name+\".jpg\"\n            label=\"../input/voc2012/data/VOCdevkit/VOC2012/SegmentationClass/\"+name+\".png\"\n            images_labels.append((image,label))\n            \n        self.images_labels=images_labels\n        self.transform=transform\n    \n    def __getitem__(self,index):\n        \"\"\"在DataLoader中会调用这个方法读取一个batch的数据\"\"\"\n        \n        image_path,label_path=self.images_labels[index]\n\n        # 使用image.open加载目标图和特征图\n        image=pil_image.open(image_path)\n        label=pil_image.open(label_path).convert('RGB')\n        \n#         # 裁剪图片，使其所有的图片输入一致   \n#         x,y,width,height=transforms.RandomCrop.get_params(img=image,output_size=(224,224))\n#         image=function.crop(image,x,y,width,height)\n#         label=function.crop(label,x,y,width,height)\n\n        image=transforms.Resize((512,512))(image)\n        label=transforms.Resize((512,512))(label)\n        \n        # 转化特征图\n        if self.transform is not None:\n            image=self.transform(image)\n            \n        # 映射目标图\n        label=image_to_label(label)\n        # 从numpy数组转化成张量\n        label=torch.from_numpy(label)\n        \n        # 返回\n        return image,label\n    \n    def __len__(self):\n        \"\"\"获取整个dataset的数据大小\"\"\"\n        return len(self.images_labels)\n    \n    \n# 数据预处理，增强，归一化\ntransform_train=transforms.Compose([\n    # 将数据转化成张量，并且归一化到[0,1]\n    transforms.ToTensor(),\n    # 将数据标准化到[-1,1]，image=(image-mean)/std\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n\ntransform_test=transforms.Compose([\n    # 将数据转化成张量，并且归一化到[0,1]\n    transforms.ToTensor(),\n    # 将数据标准化到[-1,1]，image=(image-mean)/std\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n\n\ntrain_datasets=VOCDataset(file_path=\"../input/voc2012/data/VOCdevkit/VOC2012/ImageSets/Segmentation/train.txt\",transform=transform_train)\ntest_datasets=VOCDataset(file_path=\"../input/voc2012/data/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt\",transform=transform_test)\n\ntrain_loader=DataLoader(dataset=train_datasets,batch_size=8,shuffle=False,sampler=None)\ntest_loader=DataLoader(dataset=test_datasets,batch_size=8,shuffle=False,sampler=None)\n\nprint(len(train_loader))\n# print(next(iter(train_loader)))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:56:13.056939Z","iopub.execute_input":"2022-05-07T09:56:13.057138Z","iopub.status.idle":"2022-05-07T09:56:13.083288Z","shell.execute_reply.started":"2022-05-07T09:56:13.057114Z","shell.execute_reply":"2022-05-07T09:56:13.082546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FCN网络结构如下**\n\n前面由VGG16组成，分5个卷积层，后面有3个（1，1）卷积层，输出32s，16s，8s，然后在进行相加融合，上采样得出结果\n","metadata":{}},{"cell_type":"markdown","source":"![](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fwww.itdaan.com%2Fi%2Fd91a35b4436eba676dc2ee6cc6e45276.jpg&refer=http%3A%2F%2Fwww.itdaan.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=auto?sec=1653238248&t=2c48611d3c312d0356b18fff8f203e7f)","metadata":{}},{"cell_type":"markdown","source":"**构建FCN网络模型**\n* 参考链接：https://github.com/wkentaro/pytorch-fcn/blob/main/torchfcn/models/fcn8s.py","metadata":{}},{"cell_type":"code","source":"class FCN8s(nn.Module):\n    def __init__(self):\n        super(FCN8s,self).__init__()\n        \n        # 本项目有20个类别，一个背景，一共21类\n        n_class=21\n        \n        # conv1 \n        # 输入图像为3通道，输出64个特征图，卷积核大小为（3，3），步长为1，padding为100（避免图片不兼容，其实也可以为1的）\n        # 卷积输出公式：output=(input+2*padding-kernel_size)/stride+1\n        #  512=(512+2*1-3)/1+1\n        self.conv1_1=nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,stride=1,padding=1)\n        self.bn1_1=nn.BatchNorm2d(num_features=64)\n        self.relu1_1=nn.ReLU(inplace=True)\n        \n        self.conv1_2=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1)\n        self.bn1_2=nn.BatchNorm2d(num_features=64)\n        self.relu1_2=nn.ReLU(inplace=True)\n        \n        # 最大池化层进行下采样\n        # 采样输出公式：output=(input+2*padding-kernel_size)/stride+1\n        # 256=(512+2*0-2)/2+1\n        self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        # conv2\n        self.conv2_1=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1)\n        self.bn2_1=nn.BatchNorm2d(num_features=128)\n        self.relu2_1=nn.ReLU(inplace=True)\n        \n        self.conv2_2=nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1)\n        self.bn2_2=nn.BatchNorm2d(num_features=128)\n        self.relu2_2=nn.ReLU(inplace=True)\n        \n        # 最大池化层进行下采样\n        self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        \n        # conv3\n        self.conv3_1=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1)\n        self.bn3_1=nn.BatchNorm2d(num_features=256)\n        self.relu3_1=nn.ReLU(inplace=True)\n        \n        self.conv3_2=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1)\n        self.bn3_2=nn.BatchNorm2d(num_features=256)\n        self.relu3_2=nn.ReLU(inplace=True)\n        \n        self.conv3_3=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1)\n        self.bn3_3=nn.BatchNorm2d(num_features=256)\n        self.relu3_3=nn.ReLU(inplace=True)\n        \n        # 最大池化层进行下采样\n        self.maxpool3=nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        \n        # conv4\n        self.conv4_1=nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,stride=1,padding=1)\n        self.bn4_1=nn.BatchNorm2d(num_features=512)\n        self.relu4_1=nn.ReLU(inplace=True)\n        \n        self.conv4_2=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\n        self.bn4_2=nn.BatchNorm2d(num_features=512)\n        self.relu4_2=nn.ReLU(inplace=True)\n        \n        self.conv4_3=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\n        self.bn4_3=nn.BatchNorm2d(num_features=512)\n        self.relu4_3=nn.ReLU(inplace=True)\n        \n        # 最大池化层进行下采样\n        self.maxpool4=nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        \n        # conv5\n        # 输入图像为3通道，输出64个特征图，卷积核大小为（3，3），步长为1，padding为100（避免图片不兼容）\n        self.conv5_1=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\n        self.bn5_1=nn.BatchNorm2d(num_features=512)\n        self.relu5_1=nn.ReLU(inplace=True)\n        \n        self.conv5_2=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\n        self.bn5_2=nn.BatchNorm2d(num_features=512)\n        self.relu5_2=nn.ReLU(inplace=True)\n        \n        self.conv5_3=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,stride=1,padding=1)\n        self.bn5_3=nn.BatchNorm2d(num_features=512)\n        self.relu5_3=nn.ReLU(inplace=True)\n        \n        # 最大池化层进行下采样\n        self.maxpool5=nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        \n        # cnov6\n        self.conv6=nn.Conv2d(in_channels=512,out_channels=4096,kernel_size=7,stride=1,padding=1)\n        self.bn6=nn.BatchNorm2d(num_features=4096)\n        self.relu6=nn.ReLU(inplace=True)\n        self.drop6=nn.Dropout2d(p=0.5)\n        \n        # cnov7\n        self.conv7=nn.Conv2d(in_channels=4096,out_channels=4096,kernel_size=1,stride=1,padding=1)\n        self.bn7=nn.BatchNorm2d(num_features=4096)\n        self.relu7=nn.ReLU(inplace=True)\n        self.drop7=nn.Dropout2d(p=0.5)\n\n        # cnov8，本项目有20个类别，一个背景，一共21类\n        self.conv8=nn.Conv2d(in_channels=4096,out_channels=n_class,kernel_size=1,stride=1,padding=1)\n        \n        # 上采样2倍（16，16，21）————>（32，32，21）\n        self.up_conv8_2=nn.ConvTranspose2d(in_channels=n_class,out_channels=n_class,kernel_size=2,stride=2,bias=False)\n        \n        # 反卷积ConvTranspose2d操作输出宽高公式\n        # output=((input-1)*stride)+outputpadding-(2*padding)+kernelsize\n        # 34=(16-1)*2+0-(2*0)+4\n        \n        # 第4层maxpool值做卷积运算\n        self.pool4_conv=nn.Conv2d(in_channels=512,out_channels=n_class,kernel_size=1,stride=1)\n\n        # 利用反卷积上采样2倍\n        self.up_pool4_2=nn.ConvTranspose2d(in_channels=n_class,out_channels=n_class,kernel_size=2,stride=2,bias=False)\n    \n        # 第3层maxpool值做卷积运算\n        self.pool3_conv=nn.Conv2d(in_channels=256,out_channels=n_class,kernel_size=1,stride=1)\n\n        # 利用反卷积上采样8倍\n        self.up_pool3_8=nn.ConvTranspose2d(in_channels=n_class,out_channels=n_class,kernel_size=8,stride=8,bias=False)\n\n\n    def forward(self,x):\n        \"\"\"正向传播\"\"\"\n        \n        # 记录初始图片的大小（32，21，512，512）\n        h=x\n\n        # conv1\n        x=self.relu1_1(self.bn1_1(self.conv1_1(x)))\n        x=self.relu1_2(self.bn1_2(self.conv1_2(x)))\n        x=self.maxpool1(x)\n        \n        # conv2\n        x=self.relu2_1(self.bn2_1(self.conv2_1(x)))\n        x=self.relu2_2(self.bn2_2(self.conv2_2(x)))\n        x=self.maxpool2(x)\n\n        # conv3\n        x=self.relu3_1(self.bn3_1(self.conv3_1(x)))\n        x=self.relu3_2(self.bn3_2(self.conv3_2(x)))\n        x=self.relu3_3(self.bn3_3(self.conv3_3(x)))\n        x=self.maxpool3(x)\n        pool3=x\n        \n        # conv4\n        x=self.relu4_1(self.bn4_1(self.conv4_1(x)))\n        x=self.relu4_2(self.bn4_2(self.conv4_2(x)))\n        x=self.relu4_3(self.bn4_3(self.conv4_3(x)))\n        x=self.maxpool4(x)\n        pool4=x\n\n        # conv5\n        x=self.relu5_1(self.bn5_1(self.conv5_1(x)))\n        x=self.relu5_2(self.bn5_2(self.conv5_2(x)))\n        x=self.relu5_3(self.bn5_3(self.conv5_3(x)))\n        x=self.maxpool5(x)\n        \n        # conv6\n#         print(self.conv6(x).shape)\n#         print(self.bn6(self.conv6(x)).shape)\n#         print(self.relu6(self.bn6(self.conv6(x))).shape)\n#         print(self.drop6(self.relu6(self.bn6(self.conv6(x)))).shape)\n        x=self.drop6(self.relu6(self.bn6(self.conv6(x))))\n        \n        # conv7\n        x=self.drop7(self.relu7(self.bn7(self.conv7(x))))\n        \n        # conv8\n        x=self.up_conv8_2(self.conv8(x))\n        up_conv8=x \n        \n        # 计算第4层的值\n        x2=self.pool4_conv(pool4)\n        # 相加融合\n        x2=up_conv8+x2\n        # 反卷积上采样8倍\n        x2=self.up_pool4_2(x2)\n        up_pool4=x2\n        \n        # 计算第3层的值\n        x3=self.pool3_conv(pool3)\n        x3=up_pool4+x3\n        \n        # 反卷积上采样8倍\n        x3=self.up_pool3_8(x3)\n        return x3\n    \nmodel=FCN8s()\n# print(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:56:13.404781Z","iopub.execute_input":"2022-05-07T09:56:13.405089Z","iopub.status.idle":"2022-05-07T09:56:14.487158Z","shell.execute_reply.started":"2022-05-07T09:56:13.405057Z","shell.execute_reply":"2022-05-07T09:56:14.486377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**确定语义分割的评判标准**\n1. 准确率Acc 对应像素准确率PA\n1. 精准率Precision 对应类别像素准确率CPA\n1. 交并比IOU\n\n参考链接：https://blog.csdn.net/weixin_38353277/article/details/121029978?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.pc_relevant_default&utm_relevant_index=1","metadata":{}},{"cell_type":"code","source":"\"\"\"\nconfusionMetric  # 注意：此处横着代表预测值，竖着代表真实值，与之前介绍的相反\nP\\L     P    N\nP      TP    FP\nN      FN    TN\n\"\"\"\nclass SegmentationMetric():\n    \"\"\"语义分割评判标准\"\"\"\n    \n    def __init__(self,numClass):\n        \"\"\"初始化\"\"\"\n        # 分类个数\n        self.numClass=numClass\n        # 混淆矩阵\n        self.confusionMatrix=np.zeros((self.numClass,self.numClass))\n        \n    def addBatch(self,imgPredict,imgLabel):\n        \"\"\"添加一个batch_size数据\"\"\"\n        # 判断预测值和真实值大小是否一致，不一致直接抛出异常\n#         print(\"imgPredict\",imgPredict.shape,\"imgLabel\",imgLabel.shape)\n        assert imgPredict.shape==imgLabel.shape\n        self.confusionMatrix+=self.getConfusionMatrix(imgPredict,imgLabel)\n        return self.confusionMatrix\n    \n    def getConfusionMatrix(self,imgPredict,imgLabel):\n        \"\"\"获取混淆矩阵\"\"\"\n        # 筛选>=0,<类别数的标签\n        mask=(imgLabel>=0)&(imgLabel<self.numClass)\n        label=self.numClass*imgLabel[mask]+imgPredict[mask]\n        count=np.bincount(label,minlength=self.numClass**2)\n        # 调整形状\n        confusionMatrix=count.reshape(self.numClass,self.numClass)\n        return confusionMatrix\n    \n    def pixelAccuracy(self):\n        \"\"\"像素准确率，对应分类混淆矩阵中的准确率Accuracy\"\"\"\n        # PA=(TP+TN)/(TP+TN+FP+FN)\n        # 对角线相加之和/像素点之和\n        pa=np.diag(self.confusionMatrix).sum()/self.confusionMatrix.sum()\n        return pa\n    \n    def classPixelAccuracy(self):\n        \"\"\"类别像素准确率，对应分类混淆矩阵精准率Precision\"\"\"\n        # CPA=TP/(TP+FP)\n        # 计算横向的比值\n        cpa=np.diag(self.confusionMatrix)/self.confusionMatrix.sum(axis=1)\n        return cpa\n    \n    def meanPixelAccuracy(self):\n        \"\"\"平均类别像素准确率\"\"\"\n        cpa=self.classPixelAccuracy()\n        # 求平均值，遇到nan的填充0\n        mpa=np.nanmean(cpa)\n        return mpa\n    \n    def intersectionOverUnion(self):\n        \"\"\"计算交并比IOU\"\"\"\n        # IOU=TP/((TP+FP)+(TP+FN)-TP)\n        # 对角线的值是预测正确的值，作为交集\n        intersection=np.diag(self.confusionMatrix)\n        # 预测值+真实值-预测正确的值，作为并集\n        union=np.sum(self.confusionMatrix,axis=1)+np.sum(self.confusionMatrix,axis=0)-intersection\n        iou=intersection/union\n        return iou\n    \n    def meanIntersectionOverUnion(self):\n        \"\"\"计算交并比的平均值\"\"\"\n        iou=self.intersectionOverUnion()\n        miou=np.nanmean(iou)\n        return miou\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:56:14.488835Z","iopub.execute_input":"2022-05-07T09:56:14.489084Z","iopub.status.idle":"2022-05-07T09:56:14.502135Z","shell.execute_reply.started":"2022-05-07T09:56:14.489053Z","shell.execute_reply":"2022-05-07T09:56:14.501436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**模型训练**","metadata":{}},{"cell_type":"code","source":"# 配置训练参数\n\n# 选择设置，优先GPU\ndevice=torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n# 训练次数\nepochs=100\n# 损失函数，交叉熵\nlossfunciton=torch.nn.CrossEntropyLoss()\n# 优化方法\noptimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n\n# 将模型赋值到GPU中\nmodel=model.to(device)\n\nfor epoch in range(epochs):\n    loss_add=0\n    pa_add=0\n    mpa_add=0\n    miou_add=0\n    for i,(image,label) in enumerate(train_loader):\n        \n        # 将数据复制到GPU中\n        image=image.to(device)\n        label=label.to(device)\n        \n        # 梯度清零\n        optimizer.zero_grad()\n        \n        # 正向传播\n        output=model(image)\n        # 计算损失\n        loss=lossfunciton(output,label)\n        # 反向传播\n        loss.backward()\n        # 更新梯度\n        optimizer.step()\n        \n        # 获取当前损失\n        loss_add+=loss.data.item()\n        \n        # 获取评判标准\n        label_pred = output.max(dim=1)[1].data.cpu().numpy()\n        label_true = label.data.cpu().numpy()\n        metric=SegmentationMetric(21)\n        metric.addBatch(label_pred,label_true)\n        pa_add+=metric.pixelAccuracy()\n        mpa_add+=metric.meanPixelAccuracy()\n        miou_add+=metric.meanIntersectionOverUnion()\n#         print(loss_add,pa_add,cpa_add,iou_add)\n        \n    # 计算整体损失和评判标准\n    epoch_loss=loss_add/len(train_loader)\n    epoch_pa=pa_add/len(train_loader)\n    epoch_mpa=mpa_add/len(train_loader)\n    epoch_miou=miou_add/len(train_loader)\n    \n    print(\"epochs\",epoch,\"loss\",epoch_loss,\"pa\",epoch_pa,\"mpa\",epoch_mpa,\"miou\",epoch_miou)\n    \n# 保存模型\ntorch.save(model.state_dict(),\"./fcn8s.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:56:14.50319Z","iopub.execute_input":"2022-05-07T09:56:14.503862Z","iopub.status.idle":"2022-05-07T10:00:17.471162Z","shell.execute_reply.started":"2022-05-07T09:56:14.503807Z","shell.execute_reply":"2022-05-07T10:00:17.469943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**模型预测**","metadata":{}},{"cell_type":"code","source":"# 加载模型\n# model=torch.load(\"./fcn8s.pt\")\n# 进入评估模式\nmodel.eval()\n\ncm = np.array(colormap).astype('uint8')\n\n# 测试集梯度不更新\nwith torch.no_grad():\n    for image,label in test_loader:\n    \n        # 将数据复制到GPU中\n        image=image.to(device)\n        label=label.to(device)\n        \n        print(\"image\",image.shape,\"label\",label.shape)\n\n        # 正向传播\n        output=model(image)\n        \n        # 把数据从GPU复制到CPU中，plt才能调用\n        output=output.max(1)[1].squeeze().cpu().data.numpy()\n        pred = cm[output]\n        plt.imshow(pred[0])\n#         output=output.cpu().numpy()\n#         print(output.shape)\n        \n#         for i,eval_image in enumerate(output):\n#             plt.imshow(eval_image)\n            \n        break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-07T10:00:17.472451Z","iopub.status.idle":"2022-05-07T10:00:17.472861Z","shell.execute_reply.started":"2022-05-07T10:00:17.472639Z","shell.execute_reply":"2022-05-07T10:00:17.472661Z"},"trusted":true},"execution_count":null,"outputs":[]}]}