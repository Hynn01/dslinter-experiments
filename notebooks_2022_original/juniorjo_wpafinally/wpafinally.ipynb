{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.listdir('../input/swarm-intelligence')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-07T09:28:47.597584Z","iopub.execute_input":"2022-05-07T09:28:47.597969Z","iopub.status.idle":"2022-05-07T09:28:47.631751Z","shell.execute_reply.started":"2022-05-07T09:28:47.597864Z","shell.execute_reply":"2022-05-07T09:28:47.631189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import sys\n# sys.path.append('../swarm-intelligence')\n# sys.path.append('../swarm-intelligence/Utils')\n# sys.path.append(\"../input/swarm-intelligence/Utils/Assist.py\")\n# sys.path","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:28:47.633097Z","iopub.execute_input":"2022-05-07T09:28:47.633893Z","iopub.status.idle":"2022-05-07T09:28:47.637012Z","shell.execute_reply.started":"2022-05-07T09:28:47.633857Z","shell.execute_reply":"2022-05-07T09:28:47.636414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd ../input/swarm-intelligence/Utils","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:28:47.638001Z","iopub.execute_input":"2022-05-07T09:28:47.63843Z","iopub.status.idle":"2022-05-07T09:28:47.652957Z","shell.execute_reply.started":"2022-05-07T09:28:47.638397Z","shell.execute_reply":"2022-05-07T09:28:47.652257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n# import sys\n# sys.path.append(\"./Utils\")\nnp.set_printoptions(threshold=np.inf)\n\nimport Assist\nimport Standard\nimport community as community_louvain\nimport copy\nimport pandas as pd\nimport Algorithm\nimport igraph as ig\n\nPOP_SIZE = 100  # 每一代狼群数量\n# 头狼仅有一个\n# 探狼占比0.19\n# 猛狼占比0.8\nTan_Rate = 0.19\nMeng_Rate = 0.8\nTMAX = 3  # 探狼最大游走次数\n\n# 小网络地时候，比率大一些，karate&dolphins\nStep_Warder_Rate = 0.4  # 游走时候替代边的比率\nStep_Call_Rate = 0.8  # 召唤时候替代边的比率\nStep_Besiege_Rate = 0.2  # 围攻时替代边的比率\n\n# 适应度函数为exp-（Q-1）\n# 猛狼被召唤距离头狼适应度小于NEAR时候，发起围攻行为\nNEAR = 0.1\n\n#大网络地时候，比率小一些，football&polbooks\n# Step_Warder_Rate = 0.2      #游走时候替代边的比率\n# Step_Call_Rate = 0.4        #召唤时候替代边的比率\n# Step_Besiege_Rate = 0.1     #围攻时替代边的比率\n\n# 以上替代边仅为初始节点不变，被连节点变，每次替代的时候,有百分之10的概率，初始节点也变化\nMUTATION_RATE = 0.1  # 变异比率\n\nELISTISM_RATE = 0.1  # 第上一轮次的\n\nN_GENERATIONS = 50  # 迭代轮次\n\n\ndef ECList(initadjacencyMatrix):\n    # print(init_pop)\n    dimension = initadjacencyMatrix.shape[0]  # 维度为节点数量\n    sample = np.arange(dimension)  # 选取的样本池\n    # nn = initG.edges\n    totalExistLedge = [[i] for i in range(dimension)]  # m*n  每行第一个为该结点标号(id) 其余为邻居结点id\n    totalToConnectLedge = [[] for _ in range(dimension)]  # m*(62-n) 未连接的边\n    totalExistLedgeNumber = []  # 每个点已经连接到的边的数量\n    for i in range(dimension):\n        for j in range(i + 1, dimension):\n            if initadjacencyMatrix[i][j] == 1:\n                # 对应的id为i,j的结点邻居均增加\n                totalExistLedge[i].append(j)\n                totalExistLedge[j].append(i)\n\n    for i in range(dimension):\n        # 获取未获取边（可以重连的目标边）\n        totalToConnectLedge[i] = list(set(sample) - set(totalExistLedge[i]))\n        # 获取未获取边（可以重连的目标边）\n        totalExistLedgeNumber.append(len(totalExistLedge[i]) - 1)\n\n    return totalExistLedge, totalToConnectLedge, totalExistLedgeNumber\n\n\ndef InitPop(initadjacencyMatrix, T, POP_SIZE=100):\n    # 初始化种群 0 1 一行是一个个体，行数为种群大小  x与y共用一行 6*2*2（DNA_SIZE*2）\n    init_pop = np.random.randint(1, size=(POP_SIZE, T * 4))  # matrix,相当于np.zeros((POP_SIZE, DNA_SIZEp))\n    dimension = initadjacencyMatrix.shape[0]  # 维度为节点数量\n    totalExistLedge, totalToConnectLedge, totalExistLedgeNumber = ECList(initadjacencyMatrix)\n\n    indi = 0\n    while indi < POP_SIZE:\n        # 每个基因\n        for gene in range(T):\n\n            # 被选择的节点补充到基因中\n            fnode = np.random.randint(dimension)\n            # 保证结点有连边,且并未与其他节点都有连边\n            while not 0 < totalExistLedgeNumber[fnode] < dimension:\n                fnode = np.random.randint(dimension)  # 被选择的节点补充到基因中\n\n            # 0，2位均为起始点，起始点为自己\n            init_pop[indi][0 + gene * 4] = totalExistLedge[fnode][0]\n            init_pop[indi][2 + gene * 4] = totalExistLedge[fnode][0]\n\n            # 该结点将删除的边,totalExistLedge[fnode][0]是该节点本身\n            deleteLedge = np.random.randint(1, len(totalExistLedge[fnode]))\n            init_pop[indi][1 + gene * 4] = totalExistLedge[fnode][deleteLedge]\n            # 该结点将连接的边\n            addLedge = np.random.randint(0, len(totalToConnectLedge[fnode]))\n            init_pop[indi][3 + gene * 4] = totalToConnectLedge[fnode][addLedge]\n\n        # 该基因满足条件再去构建下一个基因\n        if checkOk(init_pop[indi]): indi += 1\n\n    return init_pop\n\n\n# 查看基因是否满足要求\n# 1.不许有重复的连边，重复的拆边\n# 2.拆掉此边不可以同时有连接此边\n\n# 3.修改后是否存在孤立节点，先不考虑，看看最后的情况再说\ndef checkOk(target):\n    # print(target)\n    # 基因数量\n    geneNumbers = len(target) // 4\n    halfGeneList = []\n    for i in range(geneNumbers):\n        # 删除部分,排序后便于比较验证\n        halfGeneList.append(sorted(target[i * 4:i * 4 + 2]))\n        # 连接部分,排序后便于比较验证\n        halfGeneList.append(sorted(target[i * + 2:i * 4 + 4]))\n\n    edgeNumber = len(halfGeneList)\n    for i in range(edgeNumber):\n        for j in range(i + 1, edgeNumber):\n            # 出现两组一样的连边,无论是重复连边、重复删边、亦或是删了又连边都是可以返回满足要求的\n            if halfGeneList[i] == halfGeneList[j]:\n                return False\n    return True\n\n\ndef fixMatrix(tip, adj, T):\n    # 深拷贝，不能修改初始的邻接矩阵\n    a = copy.deepcopy(adj)\n    for i in range(T):\n        # 拆边\n        a[tip[0 + i * 4]][tip[1 + i * 4]] = 0\n        a[tip[1 + i * 4]][tip[0 + i * 4]] = 0\n        # 连边\n        a[tip[2 + i * 4]][tip[3 + i * 4]] = 1\n        a[tip[3 + i * 4]][tip[2 + i * 4]] = 1\n    return a\n\n\n# 获取适应度,返回ndarray类对象\ndef getFitness(pop, adjacencyMatrix, T, alg):\n    # np的numpy.ndarray类，可以将整个ndarray当做索引\n    fitness = np.zeros(POP_SIZE, )\n    init_adj = copy.deepcopy(adjacencyMatrix)\n\n    # 获取每一个个体的适应度\n    for i in range(POP_SIZE):\n        # 获得最新邻接矩阵\n        new_adj = fixMatrix(pop[i], init_adj, T)\n        # 获取图\n        new_G_nx = Assist.AdjacencyMatrxiToGraph(new_adj)\n        new_G = ig.Graph.from_networkx(new_G_nx)\n        Partition = alg(new_G)\n        # if alg == Algorithm.SCA:\n        #\n        #     Partition = alg(new_G, K)\n        #\n        # elif alg == Algorithm.FastNewman or alg == Algorithm.LPA:\n        #\n        #     Partition = alg(new_G).Run()\n        #\n        # elif alg == community_louvain.best_partition:\n        #\n        #     Partition = list(alg(new_G).values())\n        # else:\n        #     Partition = alg(new_G)\n\n        # 获取这个个体的Q值\n        new_Q = Standard.Self_Modularity(new_adj, Partition)\n        # 将对应个体的Q值存入对应索引位置\n        # 适应度函数为exp-（Q-1）\n        fitness[i] = np.exp(-(new_Q - 1))\n\n    return fitness\n\n\ndef getFitnessSingle(single, adjacencyMatrix, T, alg):\n    init_adj = copy.deepcopy(adjacencyMatrix)\n    # 获得最新邻接矩阵\n    new_adj = fixMatrix(single, init_adj, T)\n    # 获取图\n    new_G_nx = Assist.AdjacencyMatrxiToGraph(new_adj)\n    new_G = ig.Graph.from_networkx(new_G_nx)\n    # if alg == Algorithm.SCA:\n    #\n    #     Partition = alg(new_G, K)\n    #\n    # elif alg == Algorithm.FastNewman or alg == Algorithm.LPA:\n    #\n    #     Partition = alg(new_G).Run()\n    #\n    # elif alg == community_louvain.best_partition:\n    #\n    #     Partition = list(alg(new_G).values())\n    # else:\n    #     Partition = alg(new_G)\n\n    # 获取这个个体的Q值\n    Partition = alg(new_G)\n    new_Q = Standard.Self_Modularity(new_adj, Partition)\n    # 将对应个体的Q值存入对应索引位置\n    # 适应度函数为exp-（Q-1）\n    return np.exp(-(new_Q - 1))\n\n\n# pop——list\n# 返回numpy.ndarray类对象,按顺序排列，适应度最高的为0 最低位POP_SIZE-1\n\ndef select(pop, fitness):\n    # 返回适应度的大小排序\n    bestIndex = np.array(Get_List_Max_Index(fitness, POP_SIZE))\n    return pop[bestIndex]\n\n\n# 游走行为\ndef Wander(popInit, initadjacencyMatrix, T, alg,TMAX=3):\n    pop = copy.deepcopy(popInit)\n    # 1-19号位探狼\n    dimension = initadjacencyMatrix.shape[0]\n    # 用初始矩阵得到的信息便可以，之后可以使用checkOk进行查验\n    totalExistLedge, totalToConnectLedge, totalExistLedgeNumber = ECList(initadjacencyMatrix)\n    # 头狼的适应度\n    maxFitness = getFitnessSingle(pop[0], initadjacencyMatrix, T, alg)\n    for tanId in range(1, int(POP_SIZE * Tan_Rate) + 1):\n\n        time = 1  # 游走次数\n        curFitness = getFitnessSingle(pop[tanId], initadjacencyMatrix, T, alg)\n\n        Beifen = pop[tanId].copy()  # 第x只探狼的备份\n        # 当前探狼的游走次数大于TMAX或者当前探狼的适应度大于头狼，退出循环\n        while time > TMAX or curFitness > maxFitness:\n            # 选中的基因\n            Genes = np.random.choice(T, size=int(T * Step_Warder_Rate), replace=False)\n            while True:\n                # 每个被选中的基因\n                for gene in Genes:\n\n                    # 被选择的节点补充到基因中\n                    fnode = np.random.randint(dimension)\n                    # 保证结点有连边,且并未与其他节点都有连边\n                    while not 0 < totalExistLedgeNumber[fnode] < dimension:\n                        fnode = np.random.randint(dimension)  # 被选择的节点补充到基因中\n\n                    # 0，2位均为起始点，起始点为自己\n                    Beifen[0 + gene * 4] = totalExistLedge[fnode][0]\n                    Beifen[2 + gene * 4] = totalExistLedge[fnode][0]\n\n                    # 该结点将删除的边,totalExistLedge[fnode][0]是该节点本身\n                    deleteLedge = np.random.randint(1, len(totalExistLedge[fnode]))\n                    Beifen[1 + gene * 4] = totalExistLedge[fnode][deleteLedge]\n                    # 该结点将连接的边\n                    addLedge = np.random.randint(0, len(totalToConnectLedge[fnode]))\n                    Beifen[3 + gene * 4] = totalToConnectLedge[fnode][addLedge]\n\n                # 该基因满足条件才去比对\n                if checkOk(Beifen): break\n\n            time += 1  # 游走数加一\n            preFitness = curFitness  # 上一轮的curFitness\n            curFitness = getFitnessSingle(Beifen, initadjacencyMatrix, T, alg)\n\n            # 如果当前适应度已经大于最大适应度，换！且退出循环\n            if curFitness > maxFitness:\n                # Beifen一定会被初始化，更换头狼\n                pop[tanId], pop[0] = pop[0], Beifen\n                # 头狼适应度更新\n                maxFitness = curFitness\n                break\n\n            # 如果这一次的fitness更大，pop[tanID]更新，继续使用此备份尝试\n            if curFitness > preFitness:\n                pop[tanId] = Beifen.copy()\n                # Beifen = pop[tanId].copy()\n            # 如果这一次的fitness小,取pop【tanId】那个较大的\n            else:\n                Beifen = pop[tanId].copy()\n    # 返回新的头狼、探狼以及猛狼\n    return pop\n\n\ndef CallUp(popInit, initadjacencyMatrix, T, alg):\n    pop = copy.deepcopy(popInit)\n    # 1-19号位探狼\n    dimension = initadjacencyMatrix.shape[0]\n    # 用初始矩阵得到的信息便可以，之后可以使用checkOk进行查验\n    totalExistLedge, totalToConnectLedge, totalExistLedgeNumber = ECList(initadjacencyMatrix)\n    # 头狼的适应度\n    maxFitness = getFitnessSingle(pop[0], initadjacencyMatrix, T, alg)\n\n    for call_ID in range(int(POP_SIZE * Tan_Rate) + 1, POP_SIZE):\n\n        Beifen = pop[call_ID].copy()  # 第x只探狼的备份\n\n        # 选中的基因,对应召唤的比率\n        Genes = np.random.choice(T, size=int(T * Step_Call_Rate), replace=False)\n        while True:\n            # 每个基因\n            for gene in Genes:\n\n                # 被选择的节点补充到基因中\n                fnode = np.random.randint(dimension)\n                # 保证结点有连边,且并未与其他节点都有连边\n                while not 0 < totalExistLedgeNumber[fnode] < dimension:\n                    fnode = np.random.randint(dimension)  # 被选择的节点补充到基因中\n\n                # 0，2位均为起始点，起始点为自己\n                Beifen[0 + gene * 4] = totalExistLedge[fnode][0]\n                Beifen[2 + gene * 4] = totalExistLedge[fnode][0]\n\n                # 该结点将删除的边,totalExistLedge[fnode][0]是该节点本身\n                deleteLedge = np.random.randint(1, len(totalExistLedge[fnode]))\n                Beifen[1 + gene * 4] = totalExistLedge[fnode][deleteLedge]\n                # 该结点将连接的边\n                addLedge = np.random.randint(0, len(totalToConnectLedge[fnode]))\n                Beifen[3 + gene * 4] = totalToConnectLedge[fnode][addLedge]\n\n            # 该基因满足条件才去比对\n            if checkOk(Beifen): break\n\n        curFitness = getFitnessSingle(Beifen, initadjacencyMatrix, T, alg)\n\n        # 大于头狼适应度，换！\n        if curFitness > maxFitness:\n            # Beifen一定会被初始化，更换头狼\n            pop[call_ID], pop[0] = pop[0], Beifen\n            # 头狼适应度更新\n            maxFitness = curFitness\n        # 是否进行围攻行为\n        elif maxFitness - curFitness < 0.1:\n            # 执行围攻行为\n            # 选中的基因,对应围攻的比率\n            Genes = np.random.choice(T, size=int(T * Step_Besiege_Rate), replace=False)\n            while True:\n                # 每个基因\n                for gene in Genes:\n\n                    # 被选择的节点补充到基因中\n                    fnode = np.random.randint(dimension)\n                    # 保证结点有连边,且并未与其他节点都有连边\n                    while not 0 < totalExistLedgeNumber[fnode] < dimension:\n                        fnode = np.random.randint(dimension)  # 被选择的节点补充到基因中\n\n                    # 0，2位均为起始点，起始点为自己\n                    Beifen[0 + gene * 4] = totalExistLedge[fnode][0]\n                    Beifen[2 + gene * 4] = totalExistLedge[fnode][0]\n\n                    # 该结点将删除的边,totalExistLedge[fnode][0]是该节点本身\n                    deleteLedge = np.random.randint(1, len(totalExistLedge[fnode]))\n                    Beifen[1 + gene * 4] = totalExistLedge[fnode][deleteLedge]\n                    # 该结点将连接的边\n                    addLedge = np.random.randint(0, len(totalToConnectLedge[fnode]))\n                    Beifen[3 + gene * 4] = totalToConnectLedge[fnode][addLedge]\n\n                # 该基因满足条件才去比对\n                if checkOk(Beifen): break\n        # 以上两者均不满足，啥也不做，现在的适应度比召唤之前的适应度还小也不关，大也不考虑\n        else:\n            pass\n\n    return pop\n\n\ndef Elistism(off, adjacencyMatrix, T, alg, ELISTISM_RATE=0.1):\n\n    #新生成百分之十\n    newPop = np.array(InitPop(adjacencyMatrix,T,int(POP_SIZE*ELISTISM_RATE)))\n\n    #初始的前百分之九十\n    off_fitness = np.array(getFitness(off, adjacencyMatrix, T, alg))\n    off_90 = np.array(Get_List_Max_Index(off_fitness, int(POP_SIZE * (1 - ELISTISM_RATE))))\n\n    #下一轮次的种群\n    real = np.array(list(off[off_90]) + list(newPop))\n\n    return real\n\n\ndef Get_List_Max_Index(list_, n):\n    \"\"\"\n    function：\n        计算列表中最大的N个数对应的索引\n\n    Parameters:\n        list_ - 要分析的列表(list)\n        n - 截取最大的n个数(int)\n\n    Returns:\n        n_index - 最大n个数的索引\n\n    Modify:\n        2020-11-23\n    \"\"\"\n    N_large = pd.DataFrame({'score': list_}).sort_values(by='score', ascending=[False])\n    return list(N_large.index)[:n]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:28:47.781607Z","iopub.execute_input":"2022-05-07T09:28:47.782205Z","iopub.status.idle":"2022-05-07T09:28:49.378989Z","shell.execute_reply.started":"2022-05-07T09:28:47.782154Z","shell.execute_reply":"2022-05-07T09:28:49.378202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd ../datasets","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:28:49.380907Z","iopub.execute_input":"2022-05-07T09:28:49.381311Z","iopub.status.idle":"2022-05-07T09:28:49.388079Z","shell.execute_reply.started":"2022-05-07T09:28:49.381265Z","shell.execute_reply":"2022-05-07T09:28:49.387293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # initG = nx.read_gml('./datasets/dolphins.gml')\n#     Achoice = int(input(\"请输入的社团划分算法：\\n\"\n#                          \"  Louvain  ————————1\\n\"\n#                          \"    GN     ————————2\\n\"\n#                          \"  Infomap  ————————3\\n\"\n#                          \" Fastgreedy————————4\\n\"\n#                          \"   LPA     ————————5\\n\"))\n#     datachoice = int(input(\"请选择进行操作的数据集：\\n\"\n#                            \"karate————————1\\n\"\n#                            \"dolphins————————2\\n\"\n#                            \"football————————3\\n\"\n#                            \"polbooks————————4\\n\"\n#                            # \"adjnoun——————————5\\n\"\n#                            ))\n    Achoice = 5\n    datachoice = 4\n    # Cost = int(input(\"请选择边代价比例(百分比)：\\n\"))\n    data = \"\"\n    autoencoder = \"\"\n    algorithm = \"\"\n    # k = -1\n    if Achoice == 1:\n        # 确立社团划分算法\n        algorithm = Algorithm.Louvain\n\n    elif Achoice == 2:\n        # 确立社团划分算法\n        algorithm = Algorithm.GN\n\n    elif Achoice == 3:\n        algorithm = Algorithm.Infomap\n\n    elif Achoice == 4:\n        algorithm = Algorithm.CNM\n\n    elif Achoice == 5:\n        algorithm = Algorithm.LPA\n\n    if datachoice == 1:\n        data = \"karate\"\n    elif datachoice == 2:\n        data = \"dolphins\"\n    elif datachoice == 3:\n        data = \"football\"\n    elif datachoice == 4:\n        data = \"polbooks\"\n    elif datachoice == 5:\n        data = \"adjnoun\"\n    # 获取图，真实分组，邻接矩阵\n    initG_nx, GTV, adjacencyMatrix = Assist.read_gml(f'{data}.gml')\n\n    initG = ig.Graph.from_networkx(initG_nx)\n    # print(\"Q:\", Standard.Self_Modularity(adjacencyMatrix,GTV))\n    # dolphins Q = 0.3735  football ：Q = 0.5539  #真实的划分却比louvain社团划分后的Q的值要小，\n    # 应该是louvain就是实现问题 后续考虑一下\n\n    # dolphinsQ = 0.5188 football Q =  0.6042\n    result = []\n    temp = list(range(6))\n    save_A = copy.deepcopy(adjacencyMatrix)\n    Cost = 0\n    while Cost < 10:\n        # 向上取整\n        Cost += 2\n        # T为替换边的数量\n        T = TrueCost = int(len(initG_nx.edges) * Cost / 100) + 1\n        # list对象->ndarray对象\n        # 五次一个平均\n        for i in range(5):\n            print(f\"Cost:{Cost}   \",f\"第{i+1}次平均\")\n            # 返回ndarray类对象\n            ParentPop = np.array(InitPop(adjacencyMatrix, T))\n\n            # ExceptionFlag = False\n            # while not ExceptionFlag:\n            #     try:\n                # for _ in range(N_GENERATIONS):\n            for _ in range(100):\n                # 返回ndarray类对象，这是初始化时的适应度\n                fitness = getFitness(ParentPop, adjacencyMatrix, T, algorithm)\n\n                # 输入是ndarray类对象，输出也是,获取头狼、探狼、猛狼的排序\n                SelectedPop = select(ParentPop, fitness)\n\n                # 输入是ndarray类对象，输出也是，使用1-19下标位置\n                WaitForCallPop = Wander(SelectedPop, adjacencyMatrix, T, algorithm)\n                # 使用20-99下标位置，猛狼被召唤并根据情况是否进行围攻\n                endPop = CallUp(WaitForCallPop, adjacencyMatrix, T, algorithm)\n\n                OffSpringPop = Elistism(endPop, adjacencyMatrix, T, algorithm)\n                # 子辈成父辈\n                ParentPop = OffSpringPop\n\n            # 获得适应度最大的个体的索引\n            last = getFitness(ParentPop, adjacencyMatrix, T, algorithm)\n            index = np.argmax(last)\n\n            # 获得最新邻接矩阵\n            new_adj = fixMatrix(ParentPop[index], adjacencyMatrix, T)\n            # 获取图\n            new_G_nx = Assist.AdjacencyMatrxiToGraph(new_adj)\n\n            new_G = ig.Graph.from_networkx(new_G_nx)\n            # Partition = list(community_louvain.best_partition(new_G).values())\n            # new_Q = Standard.Self_Modularity(new_adj, Partition)\n\n            # if Achoice == 1:\n            #     f1 = algorithm(initG)\n            #     initPartition = list(f1.values())\n            # elif Achoice == 2:\n            #     initPartition = algorithm(initG)\n            # elif Achoice == 3:\n            #     initPartition = algorithm(initG, k)\n            # # FN&LPA 4-5\n            # else:\n            #     initPartition = algorithm(initG).Run()\n            initPartition = algorithm(initG)\n\n            Partition = algorithm(new_G)\n            temp[0] = Standard.getNMI(GTV, initPartition)\n            temp[1] = Standard.getARI(GTV, initPartition)\n            temp[2] = Standard.Self_Modularity(adjacencyMatrix, initPartition)\n\n            temp[3] = Standard.getNMI(GTV, Partition)\n            temp[4] = Standard.getARI(GTV, Partition)\n            temp[5] = Standard.Self_Modularity(new_adj, Partition)\n            result.append(temp.copy())\n\n            # print(\"初始Q:\", Standard.Self_Modularity(adjacencyMatrix, initPartition))\n            # print(\"初始NMI:\", Standard.getNMI(GTV, initPartition))\n            # print(\"初始ARI：\", Standard.getARI(GTV, initPartition))\n            #\n            # print(\"结果Q:\", new_Q)\n            # print(\"结果NMI：\", Standard.getNMI(GTV, Partition))\n            # print(\"结果ARI：\", Standard.getARI(GTV, Partition))\n            if np.random.randint(10) < 2:\n                Assist.drawNet(new_G_nx, Partition)\n                # except Exception as e:\n                #     print(e)\n                #     ExceptionFlag = False\n                # else:\n                #     ExceptionFlag = True\n\n#     Assist.Writexcel(result, \"./Result/WPA.xlsx\", \"hhh\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:28:49.389487Z","iopub.execute_input":"2022-05-07T09:28:49.390079Z","iopub.status.idle":"2022-05-07T09:29:07.816669Z","shell.execute_reply.started":"2022-05-07T09:28:49.390039Z","shell.execute_reply":"2022-05-07T09:29:07.815634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:29:07.818013Z","iopub.execute_input":"2022-05-07T09:29:07.818277Z","iopub.status.idle":"2022-05-07T09:29:07.824959Z","shell.execute_reply.started":"2022-05-07T09:29:07.818244Z","shell.execute_reply":"2022-05-07T09:29:07.824131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans = pd.DataFrame(result)\nans.to_csv('./Answer.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T09:29:07.826952Z","iopub.execute_input":"2022-05-07T09:29:07.82784Z","iopub.status.idle":"2022-05-07T09:29:07.8411Z","shell.execute_reply.started":"2022-05-07T09:29:07.827792Z","shell.execute_reply":"2022-05-07T09:29:07.840151Z"},"trusted":true},"execution_count":null,"outputs":[]}]}