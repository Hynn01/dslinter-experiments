{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Dear Reader, please note that this notebook was written in Jupyter Notebook and as such some features (particularly graphs) may not work on kaggle - I have marked the respective parts and generally recommend downloading and opening in Jupyter Notebook to be able to follow my thoughts behind some graphs ","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:55:01.334738Z","iopub.execute_input":"2022-05-02T16:55:01.335453Z","iopub.status.idle":"2022-05-02T16:55:01.342207Z","shell.execute_reply.started":"2022-05-02T16:55:01.335409Z","shell.execute_reply":"2022-05-02T16:55:01.340763Z"}}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\") #can get annoying and visually distracting\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n\nimport pyLDAvis\nimport pyLDAvis.gensim #for kaggle\n#import pyLDAvis.gensim_models #for Jupyter\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport gensim\nfrom gensim import corpora\nimport en_core_web_sm\nimport re\nimport spacy\n\nfrom wordcloud import WordCloud","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:29.292226Z","iopub.execute_input":"2022-05-03T07:32:29.292965Z","iopub.status.idle":"2022-05-03T07:32:29.30112Z","shell.execute_reply.started":"2022-05-03T07:32:29.292918Z","shell.execute_reply":"2022-05-03T07:32:29.300372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading data directly in kaggle\ndf = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/train.csv\")\ntest = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\n\nprint(f\"train data shape: {df.shape}; test data shape: {test.shape}\")\n#notably, the test data very short and contains no output feature","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:29.3027Z","iopub.execute_input":"2022-05-03T07:32:29.303114Z","iopub.status.idle":"2022-05-03T07:32:29.395927Z","shell.execute_reply.started":"2022-05-03T07:32:29.303073Z","shell.execute_reply":"2022-05-03T07:32:29.394949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Breakdown of features:\n1. ID: unique identifier  - won't be used\n2. anchor: first phrase\n3. target: second phrase\n4. context: CPC Classification Number - scoring similarity within these groups (https://en.wikipedia.org/wiki/Cooperative_Patent_Classification)\n5. score: similarity score = outcome variable\n      * 1.0 = very close; 0.75 = close; 0.5 synonyms with different meaning; 0.25 = somewhat related; 0.0 = unrelated\n     ","metadata":{}},{"cell_type":"markdown","source":"# Goal:\npredict the score as value of similarity between anchor and target within each context\n\n\n-> While we want to score the similarity between anchor and target, the context can heavily impact this similarity! \n\nIn result, all columns of the data set (except ID) need to be explored","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:29.397304Z","iopub.execute_input":"2022-05-03T07:32:29.397764Z","iopub.status.idle":"2022-05-03T07:32:29.410205Z","shell.execute_reply.started":"2022-05-03T07:32:29.397732Z","shell.execute_reply":"2022-05-03T07:32:29.409459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Are all IDs unique identifiers? (because you never know)\nlen(np.unique(df.id)), df.shape[0]\n#the length of unique values matches the train shape; there are no duplicates in the dataset","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:29.411669Z","iopub.execute_input":"2022-05-03T07:32:29.411943Z","iopub.status.idle":"2022-05-03T07:32:29.455786Z","shell.execute_reply.started":"2022-05-03T07:32:29.411877Z","shell.execute_reply":"2022-05-03T07:32:29.455108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#unique values per feature (not including ID)\nvals = [len(np.unique(df.anchor)), len(np.unique(df.target)), len(np.unique(df.context))]\nsns.barplot(x = [\"anchor\", \"target\", \"context\"], y = vals)\n#notably, although anchor and target are heavily related by meaning, the unique values vary greatly. \n#However, ~7000 target values seem to be identical, given that there are 36473 unique entries in the df.","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:29.457738Z","iopub.execute_input":"2022-05-03T07:32:29.458106Z","iopub.status.idle":"2022-05-03T07:32:29.650251Z","shell.execute_reply.started":"2022-05-03T07:32:29.458071Z","shell.execute_reply":"2022-05-03T07:32:29.649375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature: Anchor","metadata":{}},{"cell_type":"code","source":"df.anchor.value_counts(), df.anchor.value_counts().reset_index().describe()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:29.651603Z","iopub.execute_input":"2022-05-03T07:32:29.65253Z","iopub.status.idle":"2022-05-03T07:32:29.674997Z","shell.execute_reply.started":"2022-05-03T07:32:29.652483Z","shell.execute_reply":"2022-05-03T07:32:29.674082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tip: double clicking the plot will increase readability.\nsns.set(font_scale = 0.5)\nfig, ax =plt.subplots(figsize = (65,30))\nsns.countplot(x = df.anchor, order = df.anchor.value_counts().index, ax = ax, color = \"b\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=90);\nax.axhline(df.anchor.value_counts().reset_index().describe().loc[\"25%\"][0], color = \"r\", label = \"25% percentile\")\nax.axhline(df.anchor.value_counts().reset_index().describe().loc[\"50%\"][0], color = \"orange\", label = \"50% percentile\")\nax.axhline(df.anchor.value_counts().reset_index().describe().loc[\"75%\"][0], color = \"r\", label = \"75% percentile\")\nplt.title(\"Counts of Anchors\", fontsize = 40)\nplt.legend(fontsize=40)\n#there are many values that are above the 3rd quartile and below the first quartile","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:29.676225Z","iopub.execute_input":"2022-05-03T07:32:29.6771Z","iopub.status.idle":"2022-05-03T07:32:58.623558Z","shell.execute_reply.started":"2022-05-03T07:32:29.67705Z","shell.execute_reply":"2022-05-03T07:32:58.622514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(font_scale = 0.6)\nsymbols = []\nfor i in df.anchor:\n    symbols.append(len(i))\n\nsns.countplot(x = symbols, color = \"b\")\nplt.title(\"Number of letters in Anchors\");\n#the number of symbols in the anchor are normally distributed","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:58.62485Z","iopub.execute_input":"2022-05-03T07:32:58.625096Z","iopub.status.idle":"2022-05-03T07:32:59.206249Z","shell.execute_reply.started":"2022-05-03T07:32:58.625065Z","shell.execute_reply":"2022-05-03T07:32:59.204995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count = []\nfor i in df.anchor:\n    word_count.append(len(i.split()))\n\nsns.countplot(x = word_count, color = \"b\")\nplt.title(\"Number of words in Anchors\")\n#the anchors contain 1-5 words; most of them contain 2 or 3 words","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:59.207865Z","iopub.execute_input":"2022-05-03T07:32:59.208209Z","iopub.status.idle":"2022-05-03T07:32:59.516917Z","shell.execute_reply.started":"2022-05-03T07:32:59.208167Z","shell.execute_reply":"2022-05-03T07:32:59.515959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target","metadata":{}},{"cell_type":"code","source":"df.target.value_counts(), df.target.value_counts().reset_index().describe()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:59.518522Z","iopub.execute_input":"2022-05-03T07:32:59.518834Z","iopub.status.idle":"2022-05-03T07:32:59.566167Z","shell.execute_reply.started":"2022-05-03T07:32:59.518794Z","shell.execute_reply":"2022-05-03T07:32:59.56541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking numbers in anchor feature\n#Code from: https://www.kaggle.com/code/remekkinas/eda-and-feature-engineering/notebook\n\npattern = '[0-9]'\nmask = df['anchor'].str.contains(pattern, na=False)\ndf['nun_anchor'] = mask\ndf[mask]['anchor'].value_counts()\n#5 anchors contain numbers\n#generally these names are rather cryptic","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:32:59.56731Z","iopub.execute_input":"2022-05-03T07:32:59.567506Z","iopub.status.idle":"2022-05-03T07:32:59.599939Z","shell.execute_reply.started":"2022-05-03T07:32:59.567477Z","shell.execute_reply":"2022-05-03T07:32:59.599223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.anchor == \"conh2\"]\n#there is a lot of domain knowledge necessary here","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:32:59.601078Z","iopub.execute_input":"2022-05-03T07:32:59.601804Z","iopub.status.idle":"2022-05-03T07:32:59.621776Z","shell.execute_reply.started":"2022-05-03T07:32:59.60176Z","shell.execute_reply":"2022-05-03T07:32:59.620871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(font_scale = 0.4)\nsymbols = []\nfor i in df.target:\n    symbols.append(len(i))\n\nsns.countplot(x = symbols, color = \"b\")\nplt.title(\"Number of letters in Anchors\");\n#the number of symbols in the target are (beautifully) normally distributed","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:32:59.623394Z","iopub.execute_input":"2022-05-03T07:32:59.623834Z","iopub.status.idle":"2022-05-03T07:33:01.13804Z","shell.execute_reply.started":"2022-05-03T07:32:59.623793Z","shell.execute_reply":"2022-05-03T07:33:01.137372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(font_scale = 0.75)\nword_count = []\nfor i in df.target:\n    word_count.append(len(i.split()))\n\nsns.countplot(x = word_count, color = \"b\")\nplt.title(\"Number of words in Anchors\");\n#the targets contain 1-15 words; most of them contain 1 to 3 words","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:01.141979Z","iopub.execute_input":"2022-05-03T07:33:01.142326Z","iopub.status.idle":"2022-05-03T07:33:01.530869Z","shell.execute_reply.started":"2022-05-03T07:33:01.142298Z","shell.execute_reply":"2022-05-03T07:33:01.529841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Context","metadata":{}},{"cell_type":"code","source":"#Dropping the int of the context to cluster on general category (called gen_cat)\ndf[\"gen_cat\"] = 0\nfor index in df.index:\n    df[\"gen_cat\"].iloc[index] = df.context.iloc[index][0]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:01.531961Z","iopub.execute_input":"2022-05-03T07:33:01.532162Z","iopub.status.idle":"2022-05-03T07:33:10.366549Z","shell.execute_reply.started":"2022-05-03T07:33:01.532137Z","shell.execute_reply":"2022-05-03T07:33:10.365685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.context.value_counts(), df.context.value_counts().reset_index().describe()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:10.368014Z","iopub.execute_input":"2022-05-03T07:33:10.368313Z","iopub.status.idle":"2022-05-03T07:33:10.390087Z","shell.execute_reply.started":"2022-05-03T07:33:10.368273Z","shell.execute_reply":"2022-05-03T07:33:10.38945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking numbers in target feature\n#Code from: https://www.kaggle.com/code/remekkinas/eda-and-feature-engineering/notebook\n\npattern = '[0-9]'\nmask = df['target'].str.contains(pattern, na=False)\ndf['num_target'] = mask\ndf[mask]['target'].value_counts()\n#there are more values in target containing numbers, but they are always less frequent.","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:10.391022Z","iopub.execute_input":"2022-05-03T07:33:10.391656Z","iopub.status.idle":"2022-05-03T07:33:10.425326Z","shell.execute_reply.started":"2022-05-03T07:33:10.391623Z","shell.execute_reply":"2022-05-03T07:33:10.424468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.target == \"h2o product\"]\n#this should have a higher score in my opinion.\n#0.5 implies synonyms without the same meaning, I disagree on this score :)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:10.426508Z","iopub.execute_input":"2022-05-03T07:33:10.426818Z","iopub.status.idle":"2022-05-03T07:33:10.442668Z","shell.execute_reply.started":"2022-05-03T07:33:10.426792Z","shell.execute_reply":"2022-05-03T07:33:10.44202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tip: double clicking the plot will increase readability.\nsns.set(font_scale = 1.5)\nfig, ax =plt.subplots(figsize = (65,30))\nsns.countplot(x = df.context, order = df.context.value_counts().index, ax = ax, color = \"b\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=90);\nax.axhline(df.context.value_counts().reset_index().describe().loc[\"25%\"][0], color = \"r\", linewidth = 3, label = \"25% percentile\")\nax.axhline(df.context.value_counts().reset_index().describe().loc[\"50%\"][0], color = \"orange\",linewidth = 3, label = \"50% percentile\")\nax.axhline(df.context.value_counts().reset_index().describe().loc[\"75%\"][0], color = \"r\", linewidth = 3, label = \"75% percentile\")\nplt.title(\"Counts of Context\", fontsize = 40)\nplt.legend(fontsize=40)\n#there are several values for context which heavily outweigh most other values","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:10.444128Z","iopub.execute_input":"2022-05-03T07:33:10.444445Z","iopub.status.idle":"2022-05-03T07:33:13.724083Z","shell.execute_reply.started":"2022-05-03T07:33:10.44442Z","shell.execute_reply":"2022-05-03T07:33:13.723268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tip: double clicking the plot will increase readability.\nsns.set(font_scale = 1.5)\nfig, ax =plt.subplots(figsize = (25,10))\nsns.countplot(x = df.gen_cat, order = df.gen_cat.value_counts().index, ax = ax, color = \"b\")\nax.set_xticklabels(ax.get_xticklabels());\nax.axhline(df.gen_cat.value_counts().reset_index().describe().loc[\"25%\"][0], color = \"r\", linewidth = 3, label = \"25% percentile\")\nax.axhline(df.gen_cat.value_counts().reset_index().describe().loc[\"50%\"][0], color = \"orange\",linewidth = 3, label = \"50% percentile\")\nax.axhline(df.gen_cat.value_counts().reset_index().describe().loc[\"75%\"][0], color = \"r\", linewidth = 3, label = \"75% percentile\")\nplt.title(\"Counts of general Categories\", fontsize = 25)\nplt.legend(fontsize=15)\n#unlike the individual contexts, the general contexts are more balanced\n#However, there is only little context for the general categories E & D","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:13.725417Z","iopub.execute_input":"2022-05-03T07:33:13.725722Z","iopub.status.idle":"2022-05-03T07:33:14.132499Z","shell.execute_reply.started":"2022-05-03T07:33:13.725683Z","shell.execute_reply":"2022-05-03T07:33:14.131884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#since there are many more anchors in the anchor-count plot than in the context-count plot, we know that some contexts\n#have multiple anchors; at the same time: multiple contexts can also have the same anchor!\nprint(df[df.anchor == \"activating position\"].context.nunique(), df[df.anchor == \"activating position\"].gen_cat.nunique())\ndf[df.anchor == \"activating position\"]\n#this example shows that some anchors are shared among contexts \n#(in this case 3 different contexts in 3 different general categories)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:14.133474Z","iopub.execute_input":"2022-05-03T07:33:14.133774Z","iopub.status.idle":"2022-05-03T07:33:14.163875Z","shell.execute_reply.started":"2022-05-03T07:33:14.133747Z","shell.execute_reply":"2022-05-03T07:33:14.163098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many unique contexts are given in train?\nnp.unique(df.context), f\"{len(np.unique(df.context))} unique values\"","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:14.165027Z","iopub.execute_input":"2022-05-03T07:33:14.165258Z","iopub.status.idle":"2022-05-03T07:33:14.209662Z","shell.execute_reply.started":"2022-05-03T07:33:14.165223Z","shell.execute_reply":"2022-05-03T07:33:14.20881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many unique contexts are given in test?\nnp.unique(test.context), f\"{len(np.unique(test.context))} unique values\"\n#notably, there are many context values given in the training data, which are not contained in the test data\n#However, this does not mean, that the final kaggle resut will not contain the missing 77 values!","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:14.210969Z","iopub.execute_input":"2022-05-03T07:33:14.211619Z","iopub.status.idle":"2022-05-03T07:33:14.22142Z","shell.execute_reply.started":"2022-05-03T07:33:14.211578Z","shell.execute_reply":"2022-05-03T07:33:14.220699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Closer look at the contexts which only have a few entries\ndf[df.context == \"F26\"]\n#it will probably be hard to train models on this little data.\n#is there a way to arbitrarily increase the combinations for these contexts?","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:14.222589Z","iopub.execute_input":"2022-05-03T07:33:14.223283Z","iopub.status.idle":"2022-05-03T07:33:14.244501Z","shell.execute_reply.started":"2022-05-03T07:33:14.223242Z","shell.execute_reply":"2022-05-03T07:33:14.24366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Closer look at the contexts which only have a few entries\ndf[df.context == \"A62\"]\n#some of these word combinations seem wildly different.\n#also, some of these word combinations seem again ambigiously placed: \n#matel phase -> metal of material = 0.5\n#metal phase -> metal material = 0.25","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:14.245754Z","iopub.execute_input":"2022-05-03T07:33:14.246438Z","iopub.status.idle":"2022-05-03T07:33:14.27403Z","shell.execute_reply.started":"2022-05-03T07:33:14.246394Z","shell.execute_reply":"2022-05-03T07:33:14.273141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(df[\"gen_cat\"].unique())\n#we would expect B, E, F, G and H to be close to another! (just from general domains)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:14.275592Z","iopub.execute_input":"2022-05-03T07:33:14.276077Z","iopub.status.idle":"2022-05-03T07:33:14.287674Z","shell.execute_reply.started":"2022-05-03T07:33:14.276036Z","shell.execute_reply":"2022-05-03T07:33:14.286919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    A: Human Necessities\n    B: Operations and Transport\n    C: Chemistry and Metallurgy\n    D: Textiles\n    E: Fixed Constructions\n    F: Mechanical Engineering\n    G: Physics\n    H: Electricity\n    Y: Emerging Cross-Sectional Technologies","metadata":{}},{"cell_type":"code","source":"#Wordcloud per (general) context (most frequent words per context)\nwc_a = WordCloud(width = 800, height = 400, background_color=\"white\").generate(\" \".join(target for target in df[df.gen_cat == \"A\"].target))\nwc_b = WordCloud(width = 800, height = 400, background_color=\"white\").generate(\" \".join(target for target in df[df.gen_cat == \"B\"].target))\nwc_c = WordCloud(width = 800, height = 400, background_color=\"white\").generate(\" \".join(target for target in df[df.gen_cat == \"C\"].target))\nwc_d = WordCloud(width = 800, height = 400, background_color=\"white\").generate(\" \".join(target for target in df[df.gen_cat == \"D\"].target))\nwc_e = WordCloud(width = 800, height = 400, background_color=\"white\").generate(\" \".join(target for target in df[df.gen_cat == \"E\"].target))\nwc_f = WordCloud(width = 800, height = 400, background_color=\"white\").generate(\" \".join(target for target in df[df.gen_cat == \"F\"].target))\nwc_g = WordCloud(width = 800, height = 400, background_color=\"white\").generate(\" \".join(target for target in df[df.gen_cat == \"G\"].target))\nwc_h = WordCloud(width = 800, height = 400, background_color=\"white\").generate(\" \".join(target for target in df[df.gen_cat == \"H\"].target))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:14.28884Z","iopub.execute_input":"2022-05-03T07:33:14.290078Z","iopub.status.idle":"2022-05-03T07:33:19.293686Z","shell.execute_reply.started":"2022-05-03T07:33:14.290034Z","shell.execute_reply":"2022-05-03T07:33:19.292915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show the wordclouds\nfig = plt.figure(figsize = (40,40))\nims = [[wc_a, \"Wordcloud: Context A\"],\n       [wc_b, \"Wordcloud: Context B\"],\n       [wc_c, \"Wordcloud: Context C\"],\n       [wc_d, \"Wordcloud: Context D\"],\n       [wc_e, \"Wordcloud: Context E\"],\n       [wc_f, \"Wordcloud: Context F\"],\n       [wc_g, \"Wordcloud: Context G\"],\n       [wc_h, \"Wordcloud: Context H\"]]\n\nfor a, b in enumerate(ims):\n    fig.add_subplot(4,2, a+1)\n    plt.imshow(b[0], interpolation='bilinear')\n    plt.title(b[1], fontsize = 30)\n    plt.axis(\"off\")\n    \n#Double-clicking may increase readability :) \n#Lets quickly look at the first things we can notice:\n    #Looking at the wordcloud, we see the word \"device\" being common in context A, B, E, G, H\n    #Context B and D both have the word \"layer\" as common occurence\n    #Context B, D, E and F all have the word \"water\" as common occurence\n    #Context A, B, E and F all have the word \"member\" as common occurence\n    #Context B and C both have the word \"metal\" as common occurence\n#In result, none of the wordclouds are fully disconnected from the others\n    #C seems \"the most disconnected\"","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:19.295114Z","iopub.execute_input":"2022-05-03T07:33:19.295725Z","iopub.status.idle":"2022-05-03T07:33:22.974235Z","shell.execute_reply.started":"2022-05-03T07:33:19.295656Z","shell.execute_reply":"2022-05-03T07:33:22.973322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lengths of target per context\ndf[\"target_length\"] = 0\nfor i in df.index:\n    df.target_length.iloc[i] = len(df.target.iloc[i].split())","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:22.975695Z","iopub.execute_input":"2022-05-03T07:33:22.975968Z","iopub.status.idle":"2022-05-03T07:33:34.797332Z","shell.execute_reply.started":"2022-05-03T07:33:22.975934Z","shell.execute_reply":"2022-05-03T07:33:34.796436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x = \"target_length\", y = \"gen_cat\", data = df, color = \"b\")\nplt.xticks([1,2,3,4,5, 10, 15]);\n#most context categories are in the area of 2-3 words for target\n#C has the relative-most longest targets\n# C and D have the relative-most shortest targets","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:34.798642Z","iopub.execute_input":"2022-05-03T07:33:34.798878Z","iopub.status.idle":"2022-05-03T07:33:35.080845Z","shell.execute_reply.started":"2022-05-03T07:33:34.79885Z","shell.execute_reply":"2022-05-03T07:33:35.079628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (15,60))\nsns.boxplot(x = \"target_length\", y = \"context\", data = df, hue = \"gen_cat\")\n#interestingly some contexts (such as C07 and C08) are very short but also have the strongest outliers\n#we can see that the sub categories' context-length are often similar within their categories","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-03T07:33:35.082842Z","iopub.execute_input":"2022-05-03T07:33:35.0832Z","iopub.status.idle":"2022-05-03T07:33:38.184051Z","shell.execute_reply.started":"2022-05-03T07:33:35.083157Z","shell.execute_reply":"2022-05-03T07:33:38.1832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking at these word lengths, lets have a look at the scores they receive\n#(because maybe they have a terrible score just because of the lengths)\ndf[df.target_length >= 6].head(25)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:38.18553Z","iopub.execute_input":"2022-05-03T07:33:38.186083Z","iopub.status.idle":"2022-05-03T07:33:38.208207Z","shell.execute_reply.started":"2022-05-03T07:33:38.186038Z","shell.execute_reply":"2022-05-03T07:33:38.207326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.target_length >= 6].boxplot(column = \"score\", by = \"target_length\")\n#it seems like longer targets will not be able to receive full score","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:38.209874Z","iopub.execute_input":"2022-05-03T07:33:38.210306Z","iopub.status.idle":"2022-05-03T07:33:38.514878Z","shell.execute_reply.started":"2022-05-03T07:33:38.210265Z","shell.execute_reply":"2022-05-03T07:33:38.514089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[(df.target_length >= 6) & (df.score == 1)]\n#the only case of a perfect score has a very long anchor itself (so its only 2 words longer)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:38.516383Z","iopub.execute_input":"2022-05-03T07:33:38.516848Z","iopub.status.idle":"2022-05-03T07:33:38.532581Z","shell.execute_reply.started":"2022-05-03T07:33:38.516805Z","shell.execute_reply":"2022-05-03T07:33:38.531982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Maybe instead of looking at absolute lengths, we should look at relative lengths compared to the anchor\ndf[\"length_diff\"] = 0\nfor i in df.index:\n    df.length_diff.iloc[i] = df[\"target_length\"].iloc[i] - len(df.anchor.iloc[i].split())","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:38.533821Z","iopub.execute_input":"2022-05-03T07:33:38.534563Z","iopub.status.idle":"2022-05-03T07:33:50.857638Z","shell.execute_reply.started":"2022-05-03T07:33:38.534528Z","shell.execute_reply":"2022-05-03T07:33:50.856544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.boxplot(column = \"score\", by = \"length_diff\")\n#it seems like a length difference of more than 3 and lower than -2 will not allow a perfect score\n#while it seems that the target being way shorter than the anchor is generally bad for score\n#the target being longer than the anchor seems to generally have a positive impact\n\n#these findings need to be looked at with some respect, though, given that there are only few data points, on which this data is based on\n# Accordingly, this may be completely different for unknown test data","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:50.858948Z","iopub.execute_input":"2022-05-03T07:33:50.859189Z","iopub.status.idle":"2022-05-03T07:33:51.30258Z","shell.execute_reply.started":"2022-05-03T07:33:50.859159Z","shell.execute_reply":"2022-05-03T07:33:51.301729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Score","metadata":{}},{"cell_type":"code","source":"sns.set(font_scale = 1)\nsns.boxplot(x = df.score)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:51.304169Z","iopub.execute_input":"2022-05-03T07:33:51.304584Z","iopub.status.idle":"2022-05-03T07:33:51.509514Z","shell.execute_reply.started":"2022-05-03T07:33:51.304552Z","shell.execute_reply":"2022-05-03T07:33:51.50862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(x = df.score, bins = 5)\nplt.xticks([0.0, 0.25, np.mean(df.score), 0.5, 0.75, 1.0]);\nplt.axvline(np.mean(df.score), color = \"red\", label = \"mean\")\nplt.legend()\nplt.title(\"Hitsogramm of Score\");","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:51.510681Z","iopub.execute_input":"2022-05-03T07:33:51.510887Z","iopub.status.idle":"2022-05-03T07:33:51.784016Z","shell.execute_reply.started":"2022-05-03T07:33:51.510863Z","shell.execute_reply":"2022-05-03T07:33:51.78314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Which entries have a score of 1?\ndf[df.score == 1].head(15)\n#it seems like patents with the same anchor and target have sometimes different context (B65 & G06; A41 & B23)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:51.785274Z","iopub.execute_input":"2022-05-03T07:33:51.785569Z","iopub.status.idle":"2022-05-03T07:33:51.804202Z","shell.execute_reply.started":"2022-05-03T07:33:51.785529Z","shell.execute_reply":"2022-05-03T07:33:51.803365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many are there per context group?\ncontext_counts = df[df.score == 1].groupby(\"context\").id.count().reset_index().sort_values(\"id\", ascending = False)\ncontext_counts","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:51.805458Z","iopub.execute_input":"2022-05-03T07:33:51.80566Z","iopub.status.idle":"2022-05-03T07:33:51.819983Z","shell.execute_reply.started":"2022-05-03T07:33:51.805636Z","shell.execute_reply":"2022-05-03T07:33:51.819424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#context groups where there is only one patent with the score 1.0\nlist(context_counts[context_counts.id == 1].context)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:51.823931Z","iopub.execute_input":"2022-05-03T07:33:51.824632Z","iopub.status.idle":"2022-05-03T07:33:51.831093Z","shell.execute_reply.started":"2022-05-03T07:33:51.824586Z","shell.execute_reply":"2022-05-03T07:33:51.830335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.context == \"A22\"].head(20)\n#maybe turning word groups into syllables will help in prediction\n#alternatively, it probably makes sense to reduce key words in to their parts for abbreviations\n#such as electromagnectic -> electro magnetic -> em  ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:51.832411Z","iopub.execute_input":"2022-05-03T07:33:51.833182Z","iopub.status.idle":"2022-05-03T07:33:51.858418Z","shell.execute_reply.started":"2022-05-03T07:33:51.833149Z","shell.execute_reply":"2022-05-03T07:33:51.857876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating this dataframe for a stacked barchart is tidious but mostly copy-paste\nscores_plot = df[df.score == 0].groupby([\"context\"]).id.count().reset_index()\nscores_plot.columns = [\"context\",\"count_score_0\"]\nscores_plot = scores_plot.merge(df[df.score == 0.25].groupby([\"context\"]).id.count().reset_index(), on = \"context\")\nscores_plot = scores_plot.merge(df[df.score == 0.50].groupby([\"context\"]).id.count().reset_index(), on = \"context\")\nscores_plot = scores_plot.merge(df[df.score == 0.75].groupby([\"context\"]).id.count().reset_index(), on = \"context\")\nscores_plot = scores_plot.merge(df[df.score == 1].groupby([\"context\"]).id.count().reset_index(), on = \"context\")\nscores_plot = scores_plot.merge(df.groupby(\"context\").id.count().reset_index(), on = \"context\")\nscores_plot.columns = [\"context\", \"count: score 0.0\", \"count: score 0.25\", \"count: score 0.50\", \"count: score 0.75\", \"count: score 1.0\", \"overall\"]\nscores_plot = scores_plot.sort_values(\"overall\", ascending = False).set_index(\"context\")\nscores_plot.drop(columns = [\"overall\"], inplace = True)\n\n#Creating the stacked barchart for scores\nfig, ax =plt.subplots(figsize = (65,30))\nscores_plot.plot(kind = \"bar\", stacked = True, ax = ax)\nplt.legend(fontsize = 40)\n#This plot underlines how rare perfect scores are and how very common 0.25 and 0.5 are as score.","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:51.859534Z","iopub.execute_input":"2022-05-03T07:33:51.859869Z","iopub.status.idle":"2022-05-03T07:33:55.639736Z","shell.execute_reply.started":"2022-05-03T07:33:51.85984Z","shell.execute_reply":"2022-05-03T07:33:55.636558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perfect_scores = df[df.score == 1].groupby(\"context\").id.count().reset_index().sort_values(\"id\", ascending = False)\n\n#tip: double clicking the plot will increase readability.\nsns.set(font_scale = 1.5)\nfig, ax =plt.subplots(figsize = (65,30))\nsns.barplot(x = \"context\", y =\"id\", data = perfect_scores, ax = ax, color = \"b\")\nsns.barplot(x = \"context\", y =\"id\", data = perfect_scores, ax = ax, color = \"b\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=90);\nax.axhline(perfect_scores.describe().loc[\"25%\"][0], color = \"r\", linewidth = 3, label = \"25% percentile\")\nax.axhline(perfect_scores.describe().loc[\"50%\"][0], color = \"orange\",linewidth = 3, label = \"50% percentile\")\nax.axhline(perfect_scores.describe().loc[\"75%\"][0], color = \"r\", linewidth = 3, label = \"75% percentile\")\nplt.title(\"Counts of perfect scores per context\", fontsize = 40)\nplt.ylabel(\"count\")\nplt.legend(fontsize=40);\n#again, some contexts are heavily outweighing the other contexts\n#However, the order of perfect scores is not identical to the order of overall counts per context","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:55.64088Z","iopub.execute_input":"2022-05-03T07:33:55.641323Z","iopub.status.idle":"2022-05-03T07:33:59.166847Z","shell.execute_reply.started":"2022-05-03T07:33:55.641289Z","shell.execute_reply":"2022-05-03T07:33:59.165971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Which entries have a score of 0?\ndf[df.score == 0].head(25)\n#some of these seem unjustified scored low: abatement- rent abatement; abatement- tax abatement","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-03T07:33:59.168139Z","iopub.execute_input":"2022-05-03T07:33:59.168381Z","iopub.status.idle":"2022-05-03T07:33:59.189508Z","shell.execute_reply.started":"2022-05-03T07:33:59.168353Z","shell.execute_reply":"2022-05-03T07:33:59.188715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.score == 0.75].head(25)\n#stopwords matter! (last two lines)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:59.191005Z","iopub.execute_input":"2022-05-03T07:33:59.19121Z","iopub.status.idle":"2022-05-03T07:33:59.210711Z","shell.execute_reply.started":"2022-05-03T07:33:59.191185Z","shell.execute_reply":"2022-05-03T07:33:59.209957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Similiarities\nFurther explore on the ideas that were first shown in the wordclouds","metadata":{}},{"cell_type":"code","source":"#This thing will take a hot minute but will help for word clouds and clustering\nnlp = en_core_web_sm.load()\n#Lemmatize the data \ndata_lem = []\nfor i in list(df.target): \n    lemma = nlp(i)\n    data_lem.append(\" \".join([word.lemma_ for word in lemma]))","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:33:59.212018Z","iopub.execute_input":"2022-05-03T07:33:59.212223Z","iopub.status.idle":"2022-05-03T07:36:55.756626Z","shell.execute_reply.started":"2022-05-03T07:33:59.212199Z","shell.execute_reply":"2022-05-03T07:36:55.755972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create dictionary and bag of words from the data\ntokens = [[word for word in data.split()] for data in data_lem]\ndictionary = corpora.Dictionary(tokens)\ndoc_term_matrix = [dictionary.doc2bow(patent) for patent in tokens]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:36:55.757844Z","iopub.execute_input":"2022-05-03T07:36:55.758324Z","iopub.status.idle":"2022-05-03T07:36:56.177688Z","shell.execute_reply.started":"2022-05-03T07:36:55.758291Z","shell.execute_reply":"2022-05-03T07:36:56.176687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initiate the gensim LDA model for pyLDAvis (also will take a short while)\nLDA = gensim.models.ldamodel.LdaModel\nldamodel = LDA(corpus = doc_term_matrix,\n               id2word = dictionary,\n               num_topics = len(list(df[\"gen_cat\"].unique())), \n               #it might make sense to explore how many ACTUALLY different topics there are based on the targets (probably less than 8)\n               random_state = 0,\n               chunksize = 2000,\n               passes = 50, \n               iterations = 100)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:36:56.178924Z","iopub.execute_input":"2022-05-03T07:36:56.179151Z","iopub.status.idle":"2022-05-03T07:39:09.826565Z","shell.execute_reply.started":"2022-05-03T07:36:56.179121Z","shell.execute_reply":"2022-05-03T07:39:09.825767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check coherence (high = good) and perplexity (low = good)\nfrom gensim.models import CoherenceModel\ncoherence_model = CoherenceModel(model = ldamodel, texts = tokens, dictionary = dictionary, coherence = \"c_v\")\nldamodel.log_perplexity(doc_term_matrix, total_docs = df.shape[0]), coherence_model.get_coherence()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:39:09.827566Z","iopub.execute_input":"2022-05-03T07:39:09.827775Z","iopub.status.idle":"2022-05-03T07:39:14.874934Z","shell.execute_reply.started":"2022-05-03T07:39:09.82775Z","shell.execute_reply":"2022-05-03T07:39:14.873979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looks a lot better on white background ;)\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(ldamodel, doc_term_matrix, dictionary) #for Kaggle\n#vis = pyLDAvis.gensim_models.prepare(ldamodel, doc_term_matrix, dictionary) for Jupyter\nvis\n\n#we can see that stopwords are often in the most salient terms. \n#However, since the targets are very short, it doesnt make sense to remove them, since they sometimes reduce overall score","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:39:14.876268Z","iopub.execute_input":"2022-05-03T07:39:14.876484Z","iopub.status.idle":"2022-05-03T07:39:18.511957Z","shell.execute_reply.started":"2022-05-03T07:39:14.876456Z","shell.execute_reply":"2022-05-03T07:39:18.510993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now, lets replicate the results with sk-learn (which shows the cluster less \"beautiful\")\n#Sklearn is a great alternative, because we can see how the groups are actually located\n\n#Vectorize data\nidf = TfidfVectorizer(min_df = 0.001) \n#0.001 will reduce computing time (a lot) and increase variance ratio on the first 3 PCs\ntext_idf = idf.fit_transform(df.target).toarray()\ny = list(df[\"gen_cat\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:39:18.513462Z","iopub.execute_input":"2022-05-03T07:39:18.513736Z","iopub.status.idle":"2022-05-03T07:39:18.934352Z","shell.execute_reply.started":"2022-05-03T07:39:18.513676Z","shell.execute_reply":"2022-05-03T07:39:18.933576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit classifier (may take a while)\nclf = LinearDiscriminantAnalysis()\nX_r2 = clf.fit(text_idf, y).transform(text_idf)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:39:18.935532Z","iopub.execute_input":"2022-05-03T07:39:18.93622Z","iopub.status.idle":"2022-05-03T07:39:22.747013Z","shell.execute_reply.started":"2022-05-03T07:39:18.936181Z","shell.execute_reply":"2022-05-03T07:39:22.745989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the first 3 components explain 70% of variance\nclf.explained_variance_ratio_","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:39:22.748763Z","iopub.execute_input":"2022-05-03T07:39:22.749321Z","iopub.status.idle":"2022-05-03T07:39:22.756219Z","shell.execute_reply.started":"2022-05-03T07:39:22.74927Z","shell.execute_reply":"2022-05-03T07:39:22.7554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_col = {\"A\":\"blue\",\n          \"B\":\"green\",\n          \"C\":\"black\",\n          \"D\":\"red\",\n          \"E\":\"yellow\",\n          \"F\":\"purple\",\n          \"G\":\"brown\",\n          \"H\":\"orange\"}\ndf[\"colours\"] = df[\"gen_cat\"].map(map_col)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:39:22.757945Z","iopub.execute_input":"2022-05-03T07:39:22.758428Z","iopub.status.idle":"2022-05-03T07:39:22.793702Z","shell.execute_reply.started":"2022-05-03T07:39:22.758386Z","shell.execute_reply":"2022-05-03T07:39:22.792802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this plot was created to be opened in jupyter notebook (to have an interactive 3D Chart and being able to see the clusters better)\n#%matplotlib notebook #activate this in jupyter\nfig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(111, projection = '3d')\n\n\nx = X_r2[:,0]\ny = X_r2[:,1]\nz = X_r2[:,2]\n\nax.scatter(x,y,z, c = df[\"colours\"], marker = \".\")\n\ncol_a = mpatches.Patch(color='blue', label='A / Human Necessities')\ncol_b = mpatches.Patch(color='green', label='B / Operations and Transport')\ncol_c = mpatches.Patch(color='black', label='C / Chemistry and Metallurgy')\ncol_d = mpatches.Patch(color='red', label='D / Textiles')\ncol_e = mpatches.Patch(color='yellow', label='E / Fixed Constructs')\ncol_f = mpatches.Patch(color='purple', label='F / Mechanical Engineering')\ncol_g = mpatches.Patch(color='brown', label='G / Physics')\ncol_h = mpatches.Patch(color='orange', label='H / Electricity')\nhandles=[col_a, col_b, col_c, col_d, col_e, col_f, col_g, col_h]\nplt.legend(handles=handles, loc = \"upper right\", fontsize = 8);\n\n#we would expect B, E, F, G and H to be close to another! (green, yellow, purple, brown, orange); just by topic names\n#others: black, blue, red\n#However, we can see that only black is clustered apart (and still some outliers fall into other clusters)\n#interestingly, purple seems somewhat separated as well.","metadata":{"execution":{"iopub.status.busy":"2022-05-03T07:39:22.79569Z","iopub.execute_input":"2022-05-03T07:39:22.796328Z","iopub.status.idle":"2022-05-03T07:39:24.325037Z","shell.execute_reply.started":"2022-05-03T07:39:22.796281Z","shell.execute_reply":"2022-05-03T07:39:24.324402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summarizing EDA & Preprocessing:\n - Some anchors are shared among several contexts (and general categories\n - Most context contain several different anchors\n - Some contexts are heavily outweighing others in overall occurence (heavily right-skewed)\n - In general, the contexts of the categories D & E are under-represented in the data\n - The proportion of scores are more or less similar around all contexts\n - Most of the contexts in which we want to predict the scores are similar in regards to words used and words lengths\n \n \n - It does not make sense to remove stop words or short words, since they actually impact the score (\"accept information -> accept this information\" = 0.75)\n - Abbreviations are a thing in the dataset (e.g., Electromagnetic = em; Water = h2o) -> It might makes sense to find a model for domain specific abbreviations (also for possibly unknown categories & abbreviations in the test set)\n     -> BUT: abreviations also penalize score!\n - Synonyms are often not as heavily penalized as abreviations - a good synonym finder will be helpful\n     -> generally, the penalization of synonyms seems to be sometimes weird (e.g., absorbant properties and absorbant characteristics is a perfect match at one point (id: 621b048d70aa8867) but absorption characteristics an inperfect match (0.75) at another point (id: e6f92889099fd908)) -> maybe lemmatization will mess up these relationships were they are considered \"inperfect\" because there are two small misallignments\n - Train Data is relatively small (given we also want validation), so we will need a pre-trained model (although it would be nice to train it ourselves, given we are acting in domain specific environments)","metadata":{}},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"TODO:\nNext steps:\n- similarities (maybe wordnet; maybe more domain specific?, gotta read into it)\n- abbreviations \n- generally, find pretrained model\n- just for fun: maybe score can be easily algorithmed (e.g., abbreviation = -0.25; using very similar word instead = -0; using two very similar words instead = -0.25; etc.; if target is way shorter than anchor = -0.25 etc.)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}