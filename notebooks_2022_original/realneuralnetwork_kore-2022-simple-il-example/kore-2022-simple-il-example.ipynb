{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport json\nfrom pathlib import Path\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport re\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-30T13:19:20.106545Z","iopub.execute_input":"2022-04-30T13:19:20.106916Z","iopub.status.idle":"2022-04-30T13:19:22.582887Z","shell.execute_reply.started":"2022-04-30T13:19:20.106882Z","shell.execute_reply":"2022-04-30T13:19:22.582113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed = 42\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:20:19.18628Z","iopub.execute_input":"2022-04-30T13:20:19.186823Z","iopub.status.idle":"2022-04-30T13:20:19.250789Z","shell.execute_reply.started":"2022-04-30T13:20:19.186781Z","shell.execute_reply":"2022-04-30T13:20:19.250059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def balance_samples(smps, n, maxn):\n    out = []\n    labels = [sample[-1] for sample in samples]\n    types = len(Counter(labels).keys())\n    groups = [[] for i in range(types + 1)]\n    for smp in smps:\n        if(len(groups[smp[-1]]) < maxn):\n            groups[smp[-1]].append(smp)\n            out.append(smp)\n    for i in range(types):\n        while(len(groups[i]) < n):\n            groups[i].append(groups[i][random.randint(0, len(groups[i]) - 1)])\n            out.append(groups[i][random.randint(0, len(groups[i]) - 1)])\n    return out\n    \ndef decode_pos(p):\n    return (p - (p - 1) % 21 - 1) // 21 - 1, (p - 1) % 21 \ndef get_shipyard_info(lst, sy_id):\n    p, sp, shp = lst\n    x, y = decode_pos(p)\n    return [(x-1, y-1), shp, sp, sy_id]\ndef get_ship_info(lst):\n    return (decode_pos(lst[0]), lst[1], lst[2])\ndef decode_dir(d):\n    return {\"S\" : 1, \"W\" : 2, \"N\" : 3, \"E\" : 4, \"C\": 5}[d]\ndef decode_flight_plan(plan):\n    dirs = [decode_dir(i) for i in re.sub(r'[^A-Z ]+','', plan)]\n    dirs += [0] * (4 - len(dirs))\n    lengths = [min(31,int(i)) for i in re.split(\"S|W|N|E|C\",plan) if(i)]\n    if(len(lengths) < len(dirs)):\n        lengths.append(31)\n    lengths += [0] * (4 - len(lengths))\n    return dirs + lengths\ndef decode_action(a):\n    a = a.split(\"_\")\n\n    if(\"LAUNCH\" in a):\n        return [0, int(a[1])] + a[2]\n    else:\n        return [1, int(a[1])]\n\ndef get_all_actions(episode_dir, min_cnt):\n    actions = list()\n    paths = [path for path in Path(episode_dir).glob('*.json') if 'info' not in path.name]\n    for filepath in tqdm(paths):\n        with open(filepath) as f:\n            json_load = json.load(f)\n            ep_id = json_load['info']['EpisodeId']\n            index = np.argmax([r or 0 for r in json_load['rewards']])\n            for i in range(len(json_load['steps'])-1):\n                if json_load['steps'][i][index]['status'] == 'ACTIVE':\n                    for a in json_load['steps'][i+1][index]['action']:\n                        action = json_load['steps'][i+1][index]['action'][a]\n                        if \"SPAWN\" in action:\n                            action=\"SPAWN_10\"\n                        actions.append(action)\n    actions = [i[0] for i in Counter(actions).most_common() if(i[1]>=min_cnt)]\n    with open(\"all_actions.txt\", \"w\") as f:\n        f.write(\" \".join(actions))\n    return actions\ndef create_dataset_from_json(episode_dir, possible_actions):\n    ob_id = -1\n    obses = {}\n    samples = []\n    paths = [path for path in Path(episode_dir).glob('*.json') if 'info' not in path.name]\n    for filepath in tqdm(paths):\n        with open(filepath) as f:\n            json_load = json.load(f)\n            ep_id = json_load['info']['EpisodeId']\n            index = np.argmax([r or 0 for r in json_load['rewards']])\n            for i in range(len(json_load['steps'])-1):\n                if json_load['steps'][i][index]['status'] == 'ACTIVE':\n                    ob_id += 1\n                    player = json_load['steps'][i][0]['observation']['player']\n                    me = json_load['steps'][i][0]['observation']['players'][player]\n                    acts = json_load['steps'][i+1][index]['action']\n                    actions = [[decode_pos(me[1][a][0]),acts[a]] for a in acts.keys() if a in me[1]]\n                    for pos, a in actions:\n                        if(a in possible_actions):\n                            if \"SPAWN\" in a:\n                                a = \"SPAWN_10\"\n                            samples.append([ob_id, pos, possible_actions.index(a)])\n                        #else:\n                        #    if(random.randint(1,100)==50):\n                        #        print(pos,a)\n                    obses[ob_id] = json_load['steps'][i][0]['observation']\n                    \n                        \n    return obses, samples","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:20:21.137746Z","iopub.execute_input":"2022-04-30T13:20:21.137999Z","iopub.status.idle":"2022-04-30T13:20:21.166028Z","shell.execute_reply.started":"2022-04-30T13:20:21.13797Z","shell.execute_reply":"2022-04-30T13:20:21.164498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"episode_dir = \"../input/koreepisodes\"","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:20:22.136753Z","iopub.execute_input":"2022-04-30T13:20:22.137616Z","iopub.status.idle":"2022-04-30T13:20:22.14192Z","shell.execute_reply.started":"2022-04-30T13:20:22.13757Z","shell.execute_reply":"2022-04-30T13:20:22.141024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"possible_actions = get_all_actions(episode_dir, 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:20:23.158322Z","iopub.execute_input":"2022-04-30T13:20:23.158865Z","iopub.status.idle":"2022-04-30T13:20:47.734638Z","shell.execute_reply.started":"2022-04-30T13:20:23.158825Z","shell.execute_reply":"2022-04-30T13:20:47.733751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obses, samples = create_dataset_from_json(episode_dir, possible_actions)\nprint('obses:', len(obses), 'samples:', len(samples), \"possible actions:\", len(possible_actions))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:21:20.490552Z","iopub.execute_input":"2022-04-30T13:21:20.491192Z","iopub.status.idle":"2022-04-30T13:21:42.269078Z","shell.execute_reply.started":"2022-04-30T13:21:20.491155Z","shell.execute_reply":"2022-04-30T13:21:42.268365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def make_obs(obs, pos):\n    kore = obs['kore']\n    step=obs[\"step\"]\n    player = obs['player']\n    me = obs['players'][player]\n    opponent = obs['players'][1 - player]\n    my_shipyards = [get_shipyard_info(me[1][sy_id],sy_id) for sy_id in me[1]]\n    opponent_shipyards = [get_shipyard_info(opponent[1][sy_id],sy_id) for sy_id in opponent[1]]\n    my_ships = [get_ship_info(me[2][sy_id]) for sy_id in me[2]]\n    opponent_ships = [get_ship_info(opponent[2][sy_id]) for sy_id in opponent[2]]\n    observation = np.zeros((8,21,21))\n    observation[0] = np.array(kore).reshape((21,21))\n    for sy in my_shipyards:\n        observation[1][sy[0]] = sy[1]\n    for sy in my_shipyards:\n        observation[2][sy[0]] = sy[2]\n    for sp in my_ships:\n        observation[3][sp[0]] = sp[1]\n    for sp in my_ships:\n        observation[4][sp[0]] = sp[2]\n    observation[5][pos] = 1\n    observation[6][(0,0)] = me[0]\n    observation[6][(0,1)] = len(me[1])\n    observation[6][(0,2)] = len(me[2])\n    observation[6][(1,0)] = opponent[0]\n    observation[6][(1,1)] = len(opponent[1])\n    observation[6][(1,2)] = len(opponent[2])\n    observation[6][2:]=step\n    observation[7] = np.random.rand(21,21)\n    return observation","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:21:45.464278Z","iopub.execute_input":"2022-04-30T13:21:45.464986Z","iopub.status.idle":"2022-04-30T13:21:45.479558Z","shell.execute_reply.started":"2022-04-30T13:21:45.464937Z","shell.execute_reply":"2022-04-30T13:21:45.478203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KoreDataset(Dataset):\n    def __init__(self, obses, samples):\n        self.obses = obses\n        self.samples = samples\n        \n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        obs_id, pos,  action = self.samples[idx]\n        obs = make_obs(self.obses[obs_id], pos)\n        \n        return obs, action","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:21:46.502325Z","iopub.execute_input":"2022-04-30T13:21:46.503Z","iopub.status.idle":"2022-04-30T13:21:46.508221Z","shell.execute_reply.started":"2022-04-30T13:21:46.502962Z","shell.execute_reply":"2022-04-30T13:21:46.507259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicConv2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        self.conv = nn.Conv2d(\n            input_dim, output_dim, \n            kernel_size=kernel_size, \n            padding=(kernel_size[0] // 2, kernel_size[1] // 2)\n        )\n        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n\n    def forward(self, x):\n        h = self.conv(x)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\n\nclass KoreNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        layers, filters = 12, 32\n        self.conv0 = BasicConv2d(8, filters, (3, 3), True)\n        self.blocks = nn.ModuleList([BasicConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n        self.head_p = nn.Linear(filters, len(possible_actions), bias=False)\n\n    def forward(self, x):\n        h = F.relu_(self.conv0(x))\n        for block in self.blocks:\n            h = F.relu_(h + block(h))\n        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n        p = self.head_p(h_head)\n        return p","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:21:47.373391Z","iopub.execute_input":"2022-04-30T13:21:47.373849Z","iopub.status.idle":"2022-04-30T13:21:47.386165Z","shell.execute_reply.started":"2022-04-30T13:21:47.373815Z","shell.execute_reply":"2022-04-30T13:21:47.385365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n    best_acc = 0.0\n    train_accuracy = []\n    val_accuracy = []\n    for epoch in range(num_epochs):\n        model.cuda()\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            epoch_loss = 0.0\n            epoch_acc = 0\n            \n            dataloader = dataloaders_dict[phase]\n            for item in tqdm(dataloader, leave=False):\n                states = item[0].cuda().float()\n                actions = item[1].cuda().long()\n\n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    policy = model(states)\n                    #print(actions)\n                    loss = criterion(policy, actions)\n                    _, preds = torch.max(policy, 1)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    epoch_loss += loss.item() * len(policy)\n                    epoch_acc += torch.sum(preds == actions.data)\n\n            data_size = len(dataloader.dataset)\n            epoch_loss = epoch_loss / data_size\n            epoch_acc = epoch_acc.double() / data_size\n            \n            if phase == 'train':\n                train_accuracy.append(epoch_acc)\n            else:\n                val_accuracy.append(epoch_acc)\n            \n            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')\n        \n        if epoch_acc > best_acc:\n            traced = torch.jit.trace(model.cpu(), torch.rand(32, 8, 3, 3))\n            traced.save('model.pth')\n            best_acc = epoch_acc\n    return train_accuracy, val_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:21:48.01525Z","iopub.execute_input":"2022-04-30T13:21:48.015945Z","iopub.status.idle":"2022-04-30T13:21:48.028156Z","shell.execute_reply.started":"2022-04-30T13:21:48.015913Z","shell.execute_reply":"2022-04-30T13:21:48.027485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = KoreNet()\nlabels = [sample[-1] for sample in samples]\ntrain, val = train_test_split(samples, test_size=0.1, random_state=42, stratify=labels)\ntrain, val = balance_samples(train, 720, 720), balance_samples(val, 80, 80)\nbatch_size = 32\ntrain_loader = DataLoader(\n    KoreDataset(obses, train), \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=2\n)\nval_loader = DataLoader(\n    KoreDataset(obses, val), \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=2\n)\ndataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:21:48.78984Z","iopub.execute_input":"2022-04-30T13:21:48.790285Z","iopub.status.idle":"2022-04-30T13:21:49.165414Z","shell.execute_reply.started":"2022-04-30T13:21:48.790227Z","shell.execute_reply":"2022-04-30T13:21:49.16475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = [[], []]\nschedule = [\n    (1e-3, 2),\n    (1e-4, 4),\n    (1e-5, 4),\n    (1e-6, 2)\n]\nfor lr, epochs in schedule:\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n    train_accuracy, val_accuracy = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=epochs)\n    history[0] += train_accuracy\n    history[1] += val_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:21:51.507381Z","iopub.execute_input":"2022-04-30T13:21:51.507787Z","iopub.status.idle":"2022-04-30T13:28:15.629311Z","shell.execute_reply.started":"2022-04-30T13:21:51.507751Z","shell.execute_reply":"2022-04-30T13:28:15.627189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([i.cpu().numpy() for i in history[0]])\nplt.title(\"Train accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:30:58.28276Z","iopub.execute_input":"2022-04-30T13:30:58.28306Z","iopub.status.idle":"2022-04-30T13:30:58.490097Z","shell.execute_reply.started":"2022-04-30T13:30:58.283028Z","shell.execute_reply":"2022-04-30T13:30:58.489429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([i.cpu().numpy() for i in history[1]])\nplt.title(\"Val accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:30:59.72792Z","iopub.execute_input":"2022-04-30T13:30:59.7282Z","iopub.status.idle":"2022-04-30T13:30:59.913996Z","shell.execute_reply.started":"2022-04-30T13:30:59.728168Z","shell.execute_reply":"2022-04-30T13:30:59.913283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"execution":{"iopub.status.busy":"2022-04-30T10:37:06.693565Z","iopub.execute_input":"2022-04-30T10:37:06.694684Z","iopub.status.idle":"2022-04-30T10:37:06.698784Z","shell.execute_reply.started":"2022-04-30T10:37:06.694639Z","shell.execute_reply":"2022-04-30T10:37:06.698114Z"}}},{"cell_type":"code","source":"%%writefile main.py\nimport os\nimport numpy as np\nimport torch\nfrom kaggle_environments.envs.kore_fleets.helpers import *\nfrom random import randint\nimport math\n\n\npath = '/kaggle_simulations/agent' if os.path.exists('/kaggle_simulations') else '.'\nmodel = torch.jit.load(f'{path}/model.pth')\nwith open(f'{path}/all_actions.txt') as f:\n    all_actions = f.read().split()\nmodel.eval()\ndef decode_pos(p):\n    return (p - (p - 1) % 21 - 1) // 21 - 1, (p - 1) % 21 \ndef get_shipyard_info(lst, sy_id):\n    p, sp, shp = lst\n    x, y = decode_pos(p)\n    return [(x-1, y-1), shp, sp, sy_id]\ndef get_ship_info(lst):\n    return (decode_pos(lst[0]), lst[1], lst[2])\ndef submit_action(a, n, sp):\n    a = a.split(\"_\")\n\n    if(\"LAUNCH\" in a and n>=2 and math.floor(2 * math.log(n)) + 1 >= len(a[2])):\n        return ShipyardAction.launch_fleet_with_flight_plan(min(int(a[1]), n), a[2])\n    else:\n        #if(\"LAUNCH\" in a):\n        #    print(\"Can't launch\", *a)\n        return ShipyardAction.spawn_ships(min(int(a[1]), sp))\ndef make_obs(obs, pos):\n    kore = obs['kore']\n    step=obs[\"step\"]\n    player = obs['player']\n    me = obs['players'][player]\n    opponent = obs['players'][1 - player]\n    my_shipyards = [get_shipyard_info(me[1][sy_id],sy_id) for sy_id in me[1]]\n    opponent_shipyards = [get_shipyard_info(opponent[1][sy_id],sy_id) for sy_id in opponent[1]]\n    my_ships = [get_ship_info(me[2][sy_id]) for sy_id in me[2]]\n    opponent_ships = [get_ship_info(opponent[2][sy_id]) for sy_id in opponent[2]]\n    observation = np.zeros((8,21,21))\n    observation[0] = np.array(kore).reshape((21,21))\n    for sy in my_shipyards:\n        observation[1][sy[0]] = sy[1]\n    for sy in my_shipyards:\n        observation[2][sy[0]] = sy[2]\n    for sp in my_ships:\n        observation[3][sp[0]] = sp[1]\n    for sp in my_ships:\n        observation[4][sp[0]] = sp[2]\n    observation[5][pos] = 1\n    observation[6][(0,0)] = me[0]\n    observation[6][(0,1)] = len(me[1])\n    observation[6][(0,2)] = len(me[2])\n    observation[6][(1,0)] = opponent[0]\n    observation[6][(1,1)] = len(opponent[1])\n    observation[6][(1,2)] = len(opponent[2])\n    observation[6][2:]=step\n    observation[7] = np.random.rand(21,21)\n    return observation\ndef agent(obs, config):\n    board = Board(obs, config)\n    me = board.current_player\n    for pos, shipyard in zip([decode_pos(i[0]) for i in obs['players'][obs['player']][1].values()], me.shipyards):\n        if(board.step>0):\n            state = make_obs(obs,pos)\n            with torch.no_grad():\n                p = model(torch.from_numpy(state).float().unsqueeze(0))\n\n            policy = p.squeeze(0).numpy()\n            shipyard.next_action = submit_action(all_actions[policy.argmax()], shipyard.ship_count, shipyard.max_spawn)\n        else:\n            shipyard.next_action = ShipyardAction.spawn_ships(shipyard.max_spawn)\n    return me.next_actions","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:31:03.72325Z","iopub.execute_input":"2022-04-30T13:31:03.723759Z","iopub.status.idle":"2022-04-30T13:31:03.73252Z","shell.execute_reply.started":"2022-04-30T13:31:03.723718Z","shell.execute_reply":"2022-04-30T13:31:03.731639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make\nenv = make(\"kore_fleets\", debug=True)\nenv.run([\"/kaggle/working/main.py\", \"/kaggle/working/main.py\"])\nenv.render(mode=\"ipython\", width=1000, height=800)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:31:04.75648Z","iopub.execute_input":"2022-04-30T13:31:04.757013Z","iopub.status.idle":"2022-04-30T13:31:17.47491Z","shell.execute_reply.started":"2022-04-30T13:31:04.756975Z","shell.execute_reply":"2022-04-30T13:31:17.472536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -czf submission.tar.gz *","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}