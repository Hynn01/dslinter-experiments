{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Real estate price prediction using ML ","metadata":{}},{"cell_type":"markdown","source":"This project aims to correctly predict real estate prices in Madrid based on a publicly available dataset, after doing some data cleaning and exploration. In particular, the project is meant more as a learning experience for the author, evaluating 4 different ML techniques to make predictions - linear regression using ordinary least squares (OLS), RandomForest Regressor, Catboost Regressor and LightGBM Regressor. Clarifying comments have been made throughout the report and there is also a conclusion at the end. ","metadata":{}},{"cell_type":"markdown","source":"**Best result: 81.9% using Catboost** ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sns\nsns.set()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:45:14.011507Z","iopub.execute_input":"2022-05-02T10:45:14.012487Z","iopub.status.idle":"2022-05-02T10:45:15.911259Z","shell.execute_reply.started":"2022-05-02T10:45:14.012383Z","shell.execute_reply":"2022-05-02T10:45:15.910502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing data from csv file\nraw_data = pd.read_csv('/kaggle/input/madrid-real-estate-market/houses_Madrid.csv')\n\npd.set_option(\"display.max_columns\", None)\n# exploring the top 5 rows of the data\nraw_data.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-02T10:45:18.371482Z","iopub.execute_input":"2022-05-02T10:45:18.371781Z","iopub.status.idle":"2022-05-02T10:45:18.735699Z","shell.execute_reply.started":"2022-05-02T10:45:18.371748Z","shell.execute_reply":"2022-05-02T10:45:18.734726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T10:45:22.743309Z","iopub.execute_input":"2022-05-02T10:45:22.744109Z","iopub.status.idle":"2022-05-02T10:45:22.972158Z","shell.execute_reply.started":"2022-05-02T10:45:22.744069Z","shell.execute_reply":"2022-05-02T10:45:22.971392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is lots of data, some features including 21742 counts of data and\n58 columns as outlined above. It was decided to include parameters that logically would increase \na given real estate's price. It makes sense that with the parameters below, the price would increase\ne.g. more space (sq_mt_built) would increase the price, a newer house would be more expensive, south orientation is also very valuable, etc.","metadata":{}},{"cell_type":"code","source":"#removing unnecessary data from the model\ndata = raw_data.filter(['sq_mt_built','n_rooms','n_bathrooms', 'buy_price','built_year','has_parking',\n                        'is_orientation_south', 'has_lift','has_central_heating'])\n#checking what's left:\ndata.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-02T10:45:30.556226Z","iopub.execute_input":"2022-05-02T10:45:30.556492Z","iopub.status.idle":"2022-05-02T10:45:30.576299Z","shell.execute_reply.started":"2022-05-02T10:45:30.556464Z","shell.execute_reply":"2022-05-02T10:45:30.575399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for missing data points\ndata.describe(include='all')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-02T10:45:33.244667Z","iopub.execute_input":"2022-05-02T10:45:33.244959Z","iopub.status.idle":"2022-05-02T10:45:33.288066Z","shell.execute_reply.started":"2022-05-02T10:45:33.244928Z","shell.execute_reply":"2022-05-02T10:45:33.287207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The built_year feature is important to the algorithm and its count of data points is only 10000, meaning more than half of the data available will have to be discarded. While it is generally bad practice to exclude as many data points, this and other parameters are important for building the algorithm and the missing data will be dropped. The good news is that the dataset is large enough for us to construct a somewhat reasonable regression in spite of the many lost datapoints.","metadata":{}},{"cell_type":"code","source":"#there is a huge disparity on the count of data points between different parameters\n#summing the missing data points\ndata.isnull().sum()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:10.680826Z","iopub.execute_input":"2022-04-30T08:34:10.68104Z","iopub.status.idle":"2022-04-30T08:34:10.692671Z","shell.execute_reply.started":"2022-04-30T08:34:10.681014Z","shell.execute_reply":"2022-04-30T08:34:10.692118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping missing values to be left only with valid data points\ndata_no_mv = data.dropna(axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:10.693453Z","iopub.execute_input":"2022-04-30T08:34:10.693636Z","iopub.status.idle":"2022-04-30T08:34:10.705242Z","shell.execute_reply.started":"2022-04-30T08:34:10.693612Z","shell.execute_reply":"2022-04-30T08:34:10.704473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_no_mv.describe(include='all')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:10.706593Z","iopub.execute_input":"2022-04-30T08:34:10.707032Z","iopub.status.idle":"2022-04-30T08:34:10.741078Z","shell.execute_reply.started":"2022-04-30T08:34:10.70699Z","shell.execute_reply":"2022-04-30T08:34:10.740251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are hence left with less data points but they are more valuable to the model.","metadata":{}},{"cell_type":"markdown","source":"# Dealing with outliers","metadata":{}},{"cell_type":"code","source":"#let's explore the data further to get to know what the price distribution is\n#this is valuable since we are trying to train the model to predict buy price\nsns.histplot(data_no_mv['buy_price'],kde=True, stat=\"density\", linewidth=0)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:10.74247Z","iopub.execute_input":"2022-04-30T08:34:10.74276Z","iopub.status.idle":"2022-04-30T08:34:11.241306Z","shell.execute_reply.started":"2022-04-30T08:34:10.742722Z","shell.execute_reply":"2022-04-30T08:34:11.240344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some outliers present. Here, the outliers are situated around the higher prices (right side of the graph) and if the right side is excluded, the prices seem normally distributed. Outliers are a great issue for the model we will first use (ordinary least squares OLS).","metadata":{}},{"cell_type":"code","source":"# Let's declare a variable that will be equal to the 95th percentile of the 'buy_price' variable\nq = data_no_mv['buy_price'].quantile(0.95)\n\n# Then we can create a new dataframe (df), with the condition that all prices must be below the 95th percentile \ndata_1 = data_no_mv[data_no_mv['buy_price']<q]\n\ndata_1.describe(include='all')\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:11.242714Z","iopub.execute_input":"2022-04-30T08:34:11.24295Z","iopub.status.idle":"2022-04-30T08:34:11.277639Z","shell.execute_reply.started":"2022-04-30T08:34:11.242922Z","shell.execute_reply":"2022-04-30T08:34:11.276796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can check the Probability Density Function (PDF) once again to ensure that the result is still distributed in the same way overall. It is, however, there are much fewer outliers:","metadata":{}},{"cell_type":"code","source":"sns.histplot(data_1['buy_price'],kde=True, stat=\"density\", linewidth=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:11.278836Z","iopub.execute_input":"2022-04-30T08:34:11.279268Z","iopub.status.idle":"2022-04-30T08:34:11.612688Z","shell.execute_reply.started":"2022-04-30T08:34:11.279239Z","shell.execute_reply":"2022-04-30T08:34:11.612111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By removing the outliers, the graph is much more concentrated on the real data points now,\nit looks more 'normal' as in normally distributed.","metadata":{}},{"cell_type":"code","source":"# The year built graph looks relatively strange, as in not normally distributed\nsns.histplot(data_1['built_year'],kde=True, stat=\"density\", linewidth=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:11.613728Z","iopub.execute_input":"2022-04-30T08:34:11.614032Z","iopub.status.idle":"2022-04-30T08:34:11.95324Z","shell.execute_reply.started":"2022-04-30T08:34:11.614005Z","shell.execute_reply":"2022-04-30T08:34:11.952637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's remove all buildings from the future, which have not yet been built (probably listed before building completion)\n#those buildings' prices are different from completed buildings' prices and present uncertainty\n#for example, how much (%) of the building is complete will affect price but no such info is available\n# the future in this case refers to buildings after 2020, since the dataset was published in 2020\n\ndata_2 = data_1[data_1['built_year']<2020]\nsns.histplot(data_2['built_year'],kde=True, stat=\"density\", linewidth=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:11.954238Z","iopub.execute_input":"2022-04-30T08:34:11.954536Z","iopub.status.idle":"2022-04-30T08:34:12.289959Z","shell.execute_reply.started":"2022-04-30T08:34:11.954509Z","shell.execute_reply":"2022-04-30T08:34:12.289175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resetting the index since some observations were dropped. \ndata_cleaned = data_2.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:12.291223Z","iopub.execute_input":"2022-04-30T08:34:12.291692Z","iopub.status.idle":"2022-04-30T08:34:12.29656Z","shell.execute_reply.started":"2022-04-30T08:34:12.291647Z","shell.execute_reply":"2022-04-30T08:34:12.295788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_cleaned.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:12.297929Z","iopub.execute_input":"2022-04-30T08:34:12.298226Z","iopub.status.idle":"2022-04-30T08:34:12.337748Z","shell.execute_reply.started":"2022-04-30T08:34:12.298188Z","shell.execute_reply":"2022-04-30T08:34:12.337216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting some parameters together\n\nf, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize =(15,3)) #sharey -> share 'Price' as y\nax1.scatter(data_cleaned['built_year'],data_cleaned['buy_price'])\nax1.set_title('Price and Year Built')\nax2.scatter(data_cleaned['sq_mt_built'],data_cleaned['buy_price'])\nax2.set_title('Price and Space')\nax3.scatter(data_cleaned['n_bathrooms'],data_cleaned['buy_price'])\nax3.set_title('Price and number of Bathrooms')\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:12.338801Z","iopub.execute_input":"2022-04-30T08:34:12.33913Z","iopub.status.idle":"2022-04-30T08:34:12.818822Z","shell.execute_reply.started":"2022-04-30T08:34:12.339093Z","shell.execute_reply":"2022-04-30T08:34:12.818022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# log transforming price\nlog_price = np.log(data_cleaned['buy_price'])\n\n# Then we add it to our data frame\ndata_cleaned['log_price'] = log_price\ndata_cleaned.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:12.820119Z","iopub.execute_input":"2022-04-30T08:34:12.820342Z","iopub.status.idle":"2022-04-30T08:34:12.83462Z","shell.execute_reply.started":"2022-04-30T08:34:12.820314Z","shell.execute_reply":"2022-04-30T08:34:12.833734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#log plots\nf, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize =(15,3)) #sharey -> share 'Price' as y\nax1.scatter(data_cleaned['built_year'],data_cleaned['log_price'])\nax1.set_title('Log Price and Year Built')\nax2.scatter(data_cleaned['sq_mt_built'],data_cleaned['log_price'])\nax2.set_title('Log Price and Space')\nax3.scatter(data_cleaned['n_bathrooms'],data_cleaned['log_price'])\nax3.set_title('Log Price and number of Bathrooms')\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:12.835978Z","iopub.execute_input":"2022-04-30T08:34:12.836426Z","iopub.status.idle":"2022-04-30T08:34:13.313867Z","shell.execute_reply.started":"2022-04-30T08:34:12.836378Z","shell.execute_reply":"2022-04-30T08:34:13.312967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping the old buy price\ndata_cleaned = data_cleaned.drop(['buy_price'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:13.315161Z","iopub.execute_input":"2022-04-30T08:34:13.315866Z","iopub.status.idle":"2022-04-30T08:34:13.321721Z","shell.execute_reply.started":"2022-04-30T08:34:13.315827Z","shell.execute_reply":"2022-04-30T08:34:13.320901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring parameter importance","metadata":{}},{"cell_type":"code","source":"#let's use the correlation feature to check for correlation between parameters\ndata_cleaned.corr()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:13.32321Z","iopub.execute_input":"2022-04-30T08:34:13.323539Z","iopub.status.idle":"2022-04-30T08:34:13.343265Z","shell.execute_reply.started":"2022-04-30T08:34:13.323506Z","shell.execute_reply":"2022-04-30T08:34:13.342446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#not much is clear from the table above, let's visualize the collinearity via a heatmap\nimport seaborn as sns\n\ncorrmat = data_cleaned.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n\ng=sns.heatmap(data_cleaned[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:13.344402Z","iopub.execute_input":"2022-04-30T08:34:13.344883Z","iopub.status.idle":"2022-04-30T08:34:13.812816Z","shell.execute_reply.started":"2022-04-30T08:34:13.344854Z","shell.execute_reply":"2022-04-30T08:34:13.81226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it's much more clear what the correlation is between all the datasets. For the green, we have high correlation and for the red, we have little to no correlation between the parameters in the dataset. Most of the parameters have at least some correlation with log price, which is a good indicator that the logic applied at the beginning has some merit.","metadata":{}},{"cell_type":"code","source":"#let's use the last column as y value and the rest as x values\n\nx = data_cleaned.iloc[:,0:8]\ny = data_cleaned['log_price']","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:13.813908Z","iopub.execute_input":"2022-04-30T08:34:13.814135Z","iopub.status.idle":"2022-04-30T08:34:13.819142Z","shell.execute_reply.started":"2022-04-30T08:34:13.81411Z","shell.execute_reply":"2022-04-30T08:34:13.818263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking what's included in the x parameter\nx.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:13.820525Z","iopub.execute_input":"2022-04-30T08:34:13.82123Z","iopub.status.idle":"2022-04-30T08:34:13.839473Z","shell.execute_reply.started":"2022-04-30T08:34:13.821199Z","shell.execute_reply":"2022-04-30T08:34:13.838528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:13.840571Z","iopub.execute_input":"2022-04-30T08:34:13.841214Z","iopub.status.idle":"2022-04-30T08:34:13.846425Z","shell.execute_reply.started":"2022-04-30T08:34:13.841177Z","shell.execute_reply":"2022-04-30T08:34:13.845904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesRegressor\nmodel = ExtraTreesRegressor()\nmodel.fit(x,y)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:13.847464Z","iopub.execute_input":"2022-04-30T08:34:13.847685Z","iopub.status.idle":"2022-04-30T08:34:14.89357Z","shell.execute_reply.started":"2022-04-30T08:34:13.847659Z","shell.execute_reply":"2022-04-30T08:34:14.892766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:14.894679Z","iopub.execute_input":"2022-04-30T08:34:14.894914Z","iopub.status.idle":"2022-04-30T08:34:14.923842Z","shell.execute_reply.started":"2022-04-30T08:34:14.894885Z","shell.execute_reply":"2022-04-30T08:34:14.922995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's plot the feature importance values","metadata":{}},{"cell_type":"code","source":"feat_importances = pd.Series(model.feature_importances_, index = x.columns)\nfeat_importances.nlargest(11).plot(kind='barh')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:14.925025Z","iopub.execute_input":"2022-04-30T08:34:14.925416Z","iopub.status.idle":"2022-04-30T08:34:15.175806Z","shell.execute_reply.started":"2022-04-30T08:34:14.92538Z","shell.execute_reply":"2022-04-30T08:34:15.175097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Although the number of bathrooms seems with high importance, it likely has high multicollinearity with sq_mt_built and n_rooms. These will have to be explored and if the multicollinearity they have is high, they will have to be removed from the analysis manually for techniques which can't do that automatically (OLS).","metadata":{}},{"cell_type":"markdown","source":"This marks the end of the exploratory analysis of the data.","metadata":{}},{"cell_type":"markdown","source":"Now, 4 different techniques for modelling the prediction of price will be used and compared via some graphs and other metrics.","metadata":{}},{"cell_type":"markdown","source":"# Technique 1: Linear regression - Ordinary Least Squares","metadata":{}},{"cell_type":"code","source":"# statsmodels will be used for checking multicollinearity\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# declaring a variable to put all features to check for multicollinearity, it cannot include categorical data\n# so the features will be typed manually\nvariables = data_cleaned[['sq_mt_built', 'n_bathrooms', 'built_year', 'n_rooms']]\n\n#create a new data frame which will include all the VIFs\nvif = pd.DataFrame()\n\n# make use of the variance_inflation_factor, which will basically output the respective VIFs \nvif[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n# include names to make it easier to explore the result\nvif[\"Features\"] = variables.columns\n\nvif","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.17681Z","iopub.execute_input":"2022-04-30T08:34:15.177084Z","iopub.status.idle":"2022-04-30T08:34:15.202966Z","shell.execute_reply.started":"2022-04-30T08:34:15.177057Z","shell.execute_reply":"2022-04-30T08:34:15.201739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since number of bathrooms and number of rooms have high VIF, they will be removed from the model. This will drive the VIF of other variables down. So even if sq_mt_built seems with a high VIF, too, once the other 2 features are removed that will no longer be the case. sq_mt_built was chosen as the parameter to go forward with, despite the fact that it has higher VIF than n_rooms, since it better articulates actual space in the apartment and is logically a better predictor of price.","metadata":{}},{"cell_type":"code","source":"data_no_multicollinearity = data_cleaned.drop(['n_bathrooms','n_rooms'],axis=1)\n\n#let's check vif again\nvariables = data_cleaned[['built_year','sq_mt_built']]\n\nvif = pd.DataFrame()\n\nvif[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n\nvif[\"Features\"] = variables.columns\n\nvif","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.204996Z","iopub.execute_input":"2022-04-30T08:34:15.205361Z","iopub.status.idle":"2022-04-30T08:34:15.229261Z","shell.execute_reply.started":"2022-04-30T08:34:15.205319Z","shell.execute_reply":"2022-04-30T08:34:15.228104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_no_multicollinearity.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.231249Z","iopub.execute_input":"2022-04-30T08:34:15.231575Z","iopub.status.idle":"2022-04-30T08:34:15.249358Z","shell.execute_reply.started":"2022-04-30T08:34:15.231534Z","shell.execute_reply":"2022-04-30T08:34:15.248466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" let's include categorical data in the regression","metadata":{}},{"cell_type":"code","source":"# 'get_dummies' can be used from pandas\ndata_with_dummies = pd.get_dummies(data = data_no_multicollinearity,\n                                   columns = ['has_parking', 'is_orientation_south',\n                                    'has_lift', 'has_central_heating'], drop_first=True)\n\n# the first is dropped to avoid multicollinearity\n# the reason has_terrace and has_ac do not show up is they are all True\n\ndata_with_dummies.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.251322Z","iopub.execute_input":"2022-04-30T08:34:15.251982Z","iopub.status.idle":"2022-04-30T08:34:15.285273Z","shell.execute_reply.started":"2022-04-30T08:34:15.25192Z","shell.execute_reply":"2022-04-30T08:34:15.284352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check the order of the variables and move the dependend variable in the beginning manually\ndata_with_dummies.columns.values\n\n#declare a new variable that will contain the preferred order\n#order: dependent variable, indepedendent numerical variables, dummies\ncols = ['log_price', 'sq_mt_built', 'built_year','has_parking_True', 'is_orientation_south_True', 'has_lift_True',\n       'has_central_heating_True']\n\n# To implement the reordering, we will create a new df, which is equal to the old one but with the new order of features\ndata_preprocessed = data_with_dummies[cols]\ndata_preprocessed.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.290202Z","iopub.execute_input":"2022-04-30T08:34:15.291095Z","iopub.status.idle":"2022-04-30T08:34:15.313974Z","shell.execute_reply.started":"2022-04-30T08:34:15.291033Z","shell.execute_reply":"2022-04-30T08:34:15.313249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The target (dependent variable) is 'log_price'\ntargets = data_preprocessed['log_price']\n\n# The inputs are everything BUT the dependent variable, so we can simply drop it\ninputs = data_preprocessed.drop(['log_price'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.314997Z","iopub.execute_input":"2022-04-30T08:34:15.315288Z","iopub.status.idle":"2022-04-30T08:34:15.320401Z","shell.execute_reply.started":"2022-04-30T08:34:15.315259Z","shell.execute_reply":"2022-04-30T08:34:15.319746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data will be scaled for the OLS to make sure the scale of each feature does not negatively impact the model.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nscaler.fit(inputs)\n\n# storing the scaling inputs in a new variable\ninputs_scaled = scaler.transform(inputs)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.329348Z","iopub.execute_input":"2022-04-30T08:34:15.329606Z","iopub.status.idle":"2022-04-30T08:34:15.339679Z","shell.execute_reply.started":"2022-04-30T08:34:15.329576Z","shell.execute_reply":"2022-04-30T08:34:15.339111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the module for the split\nfrom sklearn.model_selection import train_test_split\n\n# Split the variables with an 80-20 split and some random state\nx_train, x_test, y_train, y_test = train_test_split(inputs_scaled, targets, test_size=0.2, random_state=42)\n\n#let's check the shapes of inputs and targets\nprint (x_train.shape, y_train.shape)\nprint (x_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.34201Z","iopub.execute_input":"2022-04-30T08:34:15.342396Z","iopub.status.idle":"2022-04-30T08:34:15.35061Z","shell.execute_reply.started":"2022-04-30T08:34:15.342362Z","shell.execute_reply":"2022-04-30T08:34:15.350004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the test-train split is 80-20 as evident from above\n# Create a linear regression object\nreg = LinearRegression()\n# Fit the regression with the scaled train inputs and targets\nreg.fit(x_train,y_train)\n\n# Let's check the outputs of the regression\n# y_hat = predictions\ny_hat = reg.predict(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.351768Z","iopub.execute_input":"2022-04-30T08:34:15.352291Z","iopub.status.idle":"2022-04-30T08:34:15.361493Z","shell.execute_reply.started":"2022-04-30T08:34:15.352256Z","shell.execute_reply":"2022-04-30T08:34:15.360146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The simplest way to compare the targets (y_train) and the predictions (y_hat) is to plot them on a scatter plot\n# The closer the points to the 45-degree line, the better the prediction\nplt.scatter(y_train, y_hat)\n\n#naming the axes\nplt.xlabel('Targets (y_train)',size=18)\nplt.ylabel('Predictions (y_hat)',size=18)\n\nplt.xlim(10,17)\nplt.ylim(10,17)\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:15.363681Z","iopub.execute_input":"2022-04-30T08:34:15.364537Z","iopub.status.idle":"2022-04-30T08:34:15.614933Z","shell.execute_reply.started":"2022-04-30T08:34:15.364486Z","shell.execute_reply":"2022-04-30T08:34:15.614382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can plot the PDF of the residuals and check for anomalies\nsns.histplot(y_train - y_hat, kde=True, stat=\"density\", linewidth=0)\n\n# Include a title\nplt.title(\"Residuals PDF\", size=18)\n\n# In the best case scenario this plot should be normally distributed\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.616154Z","iopub.execute_input":"2022-04-30T08:34:15.616596Z","iopub.status.idle":"2022-04-30T08:34:15.975358Z","shell.execute_reply.started":"2022-04-30T08:34:15.616564Z","shell.execute_reply":"2022-04-30T08:34:15.974486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that the predictions are less accurate at the price outliers, in the lower and upper ranges","metadata":{}},{"cell_type":"code","source":"# Find the R-squared of the model\nreg.score(x_train,y_train)\n\n# Note that this is NOT the adjusted R-squared","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.976545Z","iopub.execute_input":"2022-04-30T08:34:15.976786Z","iopub.status.idle":"2022-04-30T08:34:15.985473Z","shell.execute_reply.started":"2022-04-30T08:34:15.976757Z","shell.execute_reply":"2022-04-30T08:34:15.984364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obtain the bias (intercept) of the regression\nreg.intercept_","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:15.987412Z","iopub.execute_input":"2022-04-30T08:34:15.987747Z","iopub.status.idle":"2022-04-30T08:34:16.004107Z","shell.execute_reply.started":"2022-04-30T08:34:15.987705Z","shell.execute_reply":"2022-04-30T08:34:16.003103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obtain the weights (coefficients) of the regression\nreg.coef_\n\n# Note that they are barely interpretable if at all","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.005414Z","iopub.execute_input":"2022-04-30T08:34:16.005943Z","iopub.status.idle":"2022-04-30T08:34:16.020819Z","shell.execute_reply.started":"2022-04-30T08:34:16.005894Z","shell.execute_reply":"2022-04-30T08:34:16.019547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a regression summary where we can compare them with one-another\nreg_summary = pd.DataFrame(inputs.columns.values, columns=['Features'])\nreg_summary['Weights'] = reg.coef_\nreg_summary","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:16.022427Z","iopub.execute_input":"2022-04-30T08:34:16.022856Z","iopub.status.idle":"2022-04-30T08:34:16.047947Z","shell.execute_reply.started":"2022-04-30T08:34:16.022812Z","shell.execute_reply":"2022-04-30T08:34:16.04681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Testing**","metadata":{}},{"cell_type":"code","source":"# Testing is done on a dataset that the algorithm has never seen\n\ny_hat_test = reg.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.050035Z","iopub.execute_input":"2022-04-30T08:34:16.056001Z","iopub.status.idle":"2022-04-30T08:34:16.06203Z","shell.execute_reply.started":"2022-04-30T08:34:16.055927Z","shell.execute_reply":"2022-04-30T08:34:16.06115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a scatter plot with the test targets and the test predictions\nplt.scatter(y_test, y_hat_test, alpha=0.2)\nplt.xlabel('Targets (y_test)',size=18)\nplt.ylabel('Predictions (y_hat_test)',size=18)\nplt.xlim(10,17)\nplt.ylim(10,17)\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:16.063826Z","iopub.execute_input":"2022-04-30T08:34:16.064453Z","iopub.status.idle":"2022-04-30T08:34:16.313708Z","shell.execute_reply.started":"2022-04-30T08:34:16.064404Z","shell.execute_reply":"2022-04-30T08:34:16.313124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are many predictions outside the 45 degree line, suggesting that the algorithm struggled to correctly predict prices especially in lower and upper price ranges. The algorithm performed much better for predicting the prices in the middle of the range. This is consistent with OLS's inherent limitation in dealing with outliers.","metadata":{}},{"cell_type":"code","source":"# Finally, let's manually check these predictions\n# To obtain the actual prices, we take the exponential of the log_price\ndf_pf = pd.DataFrame(np.exp(y_hat_test), columns=['Prediction'])\n\n# drop the old indexing\ny_test = y_test.reset_index(drop=True)\n\ndf_pf['Target'] = np.exp(y_test)\n\n# Additionally, we can calculate the difference between the targets and the predictions\ndf_pf['Residual'] = df_pf['Target'] - df_pf['Prediction']\n\n# Since OLS is basically an algorithm which minimizes the total sum of squared errors (residuals),\n# this comparison makes a lot of sense\n\n# Finally, it makes sense to see how far off we are from the result percentage-wise\n# Here, we take the absolute difference in %, so we can easily order the data frame\ndf_pf['Difference%'] = np.absolute(df_pf['Residual']/df_pf['Target']*100)\ndf_pf","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.314845Z","iopub.execute_input":"2022-04-30T08:34:16.316626Z","iopub.status.idle":"2022-04-30T08:34:16.334831Z","shell.execute_reply.started":"2022-04-30T08:34:16.31658Z","shell.execute_reply":"2022-04-30T08:34:16.334057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploring the descriptives here gives us additional insights\ndf_pf.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.336198Z","iopub.execute_input":"2022-04-30T08:34:16.336424Z","iopub.status.idle":"2022-04-30T08:34:16.356646Z","shell.execute_reply.started":"2022-04-30T08:34:16.336397Z","shell.execute_reply":"2022-04-30T08:34:16.355762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_rows = 20\n# to make the dataset clear, we can display the result with only 2 digits after the dot \npd.set_option('display.float_format', lambda x: '%.2f' % x)\n# Finally, we sort by difference in % and manually check the model\ndf_pf.sort_values(by=['Difference%'], ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.357911Z","iopub.execute_input":"2022-04-30T08:34:16.358708Z","iopub.status.idle":"2022-04-30T08:34:16.370894Z","shell.execute_reply.started":"2022-04-30T08:34:16.358663Z","shell.execute_reply":"2022-04-30T08:34:16.370369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#as a final check, import metrics module and check the following metrics\nfrom sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_hat_test, y_test))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_hat_test, y_test))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_hat_test, y_test)))\n\nfrom sklearn.metrics import r2_score\nr2 = r2_score (y_hat_test, y_test)\n\nprint ('R-squared score', round (r2,2))\n\n#adjusted R-squared:\nadj_r2 = 1 - (1 - r2) * (254-1)/(254 - 6 - 1)\nprint ('Adjusted R-squared score', round (adj_r2,2))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.372273Z","iopub.execute_input":"2022-04-30T08:34:16.372671Z","iopub.status.idle":"2022-04-30T08:34:16.383463Z","shell.execute_reply.started":"2022-04-30T08:34:16.372631Z","shell.execute_reply":"2022-04-30T08:34:16.382486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Technique 2: Random forest regressor","metadata":{}},{"cell_type":"code","source":"# Import the scaling module to scale the data as done previously\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nscaler.fit(x)\n\n# Scale the features and store them in a new variable (the actual scaling procedure)\nx_scaled = scaler.transform(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.384559Z","iopub.execute_input":"2022-04-30T08:34:16.384782Z","iopub.status.idle":"2022-04-30T08:34:16.399604Z","shell.execute_reply.started":"2022-04-30T08:34:16.384747Z","shell.execute_reply":"2022-04-30T08:34:16.398824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=365)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.400787Z","iopub.execute_input":"2022-04-30T08:34:16.401107Z","iopub.status.idle":"2022-04-30T08:34:16.410965Z","shell.execute_reply.started":"2022-04-30T08:34:16.401066Z","shell.execute_reply":"2022-04-30T08:34:16.410254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (x_train.shape, y_train.shape)\n\nprint (x_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:16.411971Z","iopub.execute_input":"2022-04-30T08:34:16.412434Z","iopub.status.idle":"2022-04-30T08:34:16.422222Z","shell.execute_reply.started":"2022-04-30T08:34:16.412403Z","shell.execute_reply":"2022-04-30T08:34:16.421461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the actual regression technique","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","metadata":{"id":"JCoNG7AYTPao","execution":{"iopub.status.busy":"2022-04-30T08:34:16.423306Z","iopub.execute_input":"2022-04-30T08:34:16.423585Z","iopub.status.idle":"2022-04-30T08:34:16.432404Z","shell.execute_reply.started":"2022-04-30T08:34:16.423556Z","shell.execute_reply":"2022-04-30T08:34:16.431666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RandomizedSearchCV will be used instead of GridSearchCV since it is faster","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV","metadata":{"id":"6iM3-hUyTPap","execution":{"iopub.status.busy":"2022-04-30T08:34:16.433395Z","iopub.execute_input":"2022-04-30T08:34:16.43403Z","iopub.status.idle":"2022-04-30T08:34:16.444797Z","shell.execute_reply.started":"2022-04-30T08:34:16.433999Z","shell.execute_reply":"2022-04-30T08:34:16.44401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Randomized Search CV\n# these parameters would change depending on dataset size\n\n#number of decision trees\nn_estimators = [int(x_scaled) for x_scaled in np.linspace(start = 100, stop = 1000, num = 10)]\n#number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n#maximum number of levels in tree\nmax_depth = [int(x_scaled) for x_scaled in np.linspace(5, 30, num = 6)]\n#minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n#minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","metadata":{"id":"9VYWM4IvTPap","execution":{"iopub.status.busy":"2022-04-30T08:34:16.44574Z","iopub.execute_input":"2022-04-30T08:34:16.446435Z","iopub.status.idle":"2022-04-30T08:34:16.457458Z","shell.execute_reply.started":"2022-04-30T08:34:16.446403Z","shell.execute_reply":"2022-04-30T08:34:16.456879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a dictionary\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","metadata":{"id":"6pZOJYadTPap","outputId":"052dca9f-a40e-46a9-a3b0-10ee331b3871","execution":{"iopub.status.busy":"2022-04-30T08:34:16.458449Z","iopub.execute_input":"2022-04-30T08:34:16.459241Z","iopub.status.idle":"2022-04-30T08:34:16.469282Z","shell.execute_reply.started":"2022-04-30T08:34:16.459204Z","shell.execute_reply":"2022-04-30T08:34:16.468559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nstart = time.time()\nrf = RandomForestRegressor()","metadata":{"id":"17NSEONGTPap","execution":{"iopub.status.busy":"2022-04-30T08:34:16.470445Z","iopub.execute_input":"2022-04-30T08:34:16.470733Z","iopub.status.idle":"2022-04-30T08:34:16.478547Z","shell.execute_reply.started":"2022-04-30T08:34:16.470702Z","shell.execute_reply":"2022-04-30T08:34:16.477854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the random grid to search for best hyperparameters\nrf=RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', \n                      n_iter = 10, cv = 5, verbose=False, random_state=42, n_jobs = -1)","metadata":{"id":"xfJ7nstwTPap","execution":{"iopub.status.busy":"2022-04-30T08:34:16.479733Z","iopub.execute_input":"2022-04-30T08:34:16.479963Z","iopub.status.idle":"2022-04-30T08:34:16.487658Z","shell.execute_reply.started":"2022-04-30T08:34:16.479934Z","shell.execute_reply":"2022-04-30T08:34:16.486944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.fit(x_train,y_train)\nend = time.time()\ndiff_rf = end - start\nprint ('Execution time RF:', round(diff_rf,2),'seconds')","metadata":{"id":"v7hNphyaTPaq","outputId":"ea54c8ad-d4ea-43c9-964f-feb49c6e3e39","scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:34:16.488917Z","iopub.execute_input":"2022-04-30T08:34:16.489602Z","iopub.status.idle":"2022-04-30T08:34:58.859892Z","shell.execute_reply.started":"2022-04-30T08:34:16.489557Z","shell.execute_reply":"2022-04-30T08:34:58.859004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's check what the best parameters were determined as\nrf.best_params_","metadata":{"id":"ApaSR7Z8TPaq","outputId":"0154a165-78fe-4632-db9d-e92db5988792","execution":{"iopub.status.busy":"2022-04-30T08:34:58.860812Z","iopub.execute_input":"2022-04-30T08:34:58.861013Z","iopub.status.idle":"2022-04-30T08:34:58.867793Z","shell.execute_reply.started":"2022-04-30T08:34:58.860987Z","shell.execute_reply":"2022-04-30T08:34:58.86688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat_rf = rf.predict(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:58.86907Z","iopub.execute_input":"2022-04-30T08:34:58.869265Z","iopub.status.idle":"2022-04-30T08:34:59.219404Z","shell.execute_reply.started":"2022-04-30T08:34:58.869241Z","shell.execute_reply":"2022-04-30T08:34:59.218615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_train, y_hat_rf)\n\nplt.xlabel('Targets (y_train)',size=18)\nplt.ylabel('Predictions (y_hat_rf)',size=18)\n\n\nplt.xlim(10,17)\nplt.ylim(10,17)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:59.22082Z","iopub.execute_input":"2022-04-30T08:34:59.221042Z","iopub.status.idle":"2022-04-30T08:34:59.459278Z","shell.execute_reply.started":"2022-04-30T08:34:59.221016Z","shell.execute_reply":"2022-04-30T08:34:59.458431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y_train - y_hat_rf, kde=True, stat=\"density\", linewidth=0)\n\nplt.title(\"Residuals PDF\", size=18)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:59.460456Z","iopub.execute_input":"2022-04-30T08:34:59.46065Z","iopub.status.idle":"2022-04-30T08:34:59.830248Z","shell.execute_reply.started":"2022-04-30T08:34:59.460625Z","shell.execute_reply":"2022-04-30T08:34:59.829361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the R-squared of the model\nfrom sklearn.metrics import r2_score\n\nr2 = r2_score (y_train, y_hat_rf)\n\nprint ('R-squared score', round (r2,2))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:59.831349Z","iopub.execute_input":"2022-04-30T08:34:59.831586Z","iopub.status.idle":"2022-04-30T08:34:59.837324Z","shell.execute_reply.started":"2022-04-30T08:34:59.831558Z","shell.execute_reply":"2022-04-30T08:34:59.836771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's try the model on the test values now","metadata":{}},{"cell_type":"code","source":"y_hat_test_rf = rf.predict(x_test)","metadata":{"id":"IK-s2iMITPaq","execution":{"iopub.status.busy":"2022-04-30T08:34:59.8385Z","iopub.execute_input":"2022-04-30T08:34:59.83921Z","iopub.status.idle":"2022-04-30T08:34:59.988846Z","shell.execute_reply.started":"2022-04-30T08:34:59.839177Z","shell.execute_reply":"2022-04-30T08:34:59.987839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_test,y_hat_test_rf, alpha = 0.2)\nplt.xlabel('Targets (y_test)',size=18)\nplt.ylabel('Predictions (y_hat_test_rf)',size=18)\nplt.xlim(10,17)\nplt.ylim(10,17)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:34:59.990001Z","iopub.execute_input":"2022-04-30T08:34:59.990261Z","iopub.status.idle":"2022-04-30T08:35:00.221592Z","shell.execute_reply.started":"2022-04-30T08:34:59.99023Z","shell.execute_reply":"2022-04-30T08:35:00.220731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y_test-y_hat_test_rf, kde=True, stat=\"density\", linewidth=0)\n\nplt.title(\"Residuals PDF\", size=18)","metadata":{"id":"LD93dp1wTPaq","outputId":"cc4a59eb-2bc7-4018-bd08-1eecb1cfed15","scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:35:00.222802Z","iopub.execute_input":"2022-04-30T08:35:00.223034Z","iopub.status.idle":"2022-04-30T08:35:00.531933Z","shell.execute_reply.started":"2022-04-30T08:35:00.223005Z","shell.execute_reply":"2022-04-30T08:35:00.531095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pf = pd.DataFrame(np.exp(y_hat_test_rf), columns=['Prediction'])\ny_test = y_test.reset_index(drop=True)\ndf_pf['Target'] = np.exp(y_test)\ndf_pf['Residual'] = df_pf['Target'] - df_pf['Prediction']\ndf_pf['Difference%'] = np.absolute(df_pf['Residual']/df_pf['Target']*100)\ndf_pf","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:00.53314Z","iopub.execute_input":"2022-04-30T08:35:00.533336Z","iopub.status.idle":"2022-04-30T08:35:00.551085Z","shell.execute_reply.started":"2022-04-30T08:35:00.533311Z","shell.execute_reply":"2022-04-30T08:35:00.550459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pf.describe()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:35:00.551948Z","iopub.execute_input":"2022-04-30T08:35:00.552145Z","iopub.status.idle":"2022-04-30T08:35:00.571157Z","shell.execute_reply.started":"2022-04-30T08:35:00.55212Z","shell.execute_reply":"2022-04-30T08:35:00.570442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.float_format', lambda x: '%.2f' % x)\ndf_pf.sort_values(by=['Difference%'], ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:00.572522Z","iopub.execute_input":"2022-04-30T08:35:00.573205Z","iopub.status.idle":"2022-04-30T08:35:00.585939Z","shell.execute_reply.started":"2022-04-30T08:35:00.573164Z","shell.execute_reply":"2022-04-30T08:35:00.585386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_hat_test_rf, y_test))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_hat_test_rf, y_test))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_hat_test_rf, y_test)))\n\nr2_rf = r2_score (y_hat_test_rf, y_test)\n\nprint ('R-squared score', round (r2_rf,2))\n\n#adjusted R-squared:\nadj_r2_rf = 1 - ((1 - r2_rf) * (254-1)/(254 - 8 - 1))\nprint ('Adjusted R-squared score', round (adj_r2_rf,2))","metadata":{"id":"0SBstjpCTPar","outputId":"426702d7-fc96-43cf-c82b-6fba260143d4","scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:35:00.586926Z","iopub.execute_input":"2022-04-30T08:35:00.587409Z","iopub.status.idle":"2022-04-30T08:35:00.596882Z","shell.execute_reply.started":"2022-04-30T08:35:00.587377Z","shell.execute_reply":"2022-04-30T08:35:00.595971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Technique 3: Catboost Regresssor","metadata":{"id":"5H3vtnogTPat"}},{"cell_type":"code","source":"from catboost import CatBoostRegressor","metadata":{"id":"rMubU6LwTPat","execution":{"iopub.status.busy":"2022-04-30T08:35:00.598018Z","iopub.execute_input":"2022-04-30T08:35:00.598744Z","iopub.status.idle":"2022-04-30T08:35:00.608486Z","shell.execute_reply.started":"2022-04-30T08:35:00.598702Z","shell.execute_reply":"2022-04-30T08:35:00.607696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nstart = time.time()\ncb=CatBoostRegressor()","metadata":{"id":"DB9DAaL8TPat","execution":{"iopub.status.busy":"2022-04-30T08:35:00.609587Z","iopub.execute_input":"2022-04-30T08:35:00.609938Z","iopub.status.idle":"2022-04-30T08:35:00.6194Z","shell.execute_reply.started":"2022-04-30T08:35:00.609901Z","shell.execute_reply":"2022-04-30T08:35:00.61861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#parameters to vary as in technique 2\ngrid = {'learning_rate': [0.03, 0.1],\n        'depth': [4, 6, 10],\n        'l2_leaf_reg': [1, 3, 5, 7, 9]}","metadata":{"id":"JsBz-Cu6TPat","execution":{"iopub.status.busy":"2022-04-30T08:35:00.620737Z","iopub.execute_input":"2022-04-30T08:35:00.621253Z","iopub.status.idle":"2022-04-30T08:35:00.629437Z","shell.execute_reply.started":"2022-04-30T08:35:00.621214Z","shell.execute_reply":"2022-04-30T08:35:00.628875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb = RandomizedSearchCV(estimator = cb, param_distributions = grid,scoring='neg_mean_squared_error', \n                        n_iter = 10, cv = 2, random_state=42, n_jobs = -1,)","metadata":{"id":"wmZuQo0ETPau","execution":{"iopub.status.busy":"2022-04-30T08:35:00.630652Z","iopub.execute_input":"2022-04-30T08:35:00.631112Z","iopub.status.idle":"2022-04-30T08:35:00.639244Z","shell.execute_reply.started":"2022-04-30T08:35:00.631073Z","shell.execute_reply":"2022-04-30T08:35:00.638548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb.fit(x_train,y_train, verbose = False)\nend = time.time()\ndiff_cb = end - start\nprint ('Execution time for CB:', round(diff_cb,2), 'seconds')","metadata":{"id":"Hr4GFkDqTPau","outputId":"904787f8-575b-4d94-c67d-30e1db5517f9","execution":{"iopub.status.busy":"2022-04-30T08:35:00.640613Z","iopub.execute_input":"2022-04-30T08:35:00.641123Z","iopub.status.idle":"2022-04-30T08:35:42.692739Z","shell.execute_reply.started":"2022-04-30T08:35:00.641083Z","shell.execute_reply":"2022-04-30T08:35:42.691753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:42.693687Z","iopub.execute_input":"2022-04-30T08:35:42.69387Z","iopub.status.idle":"2022-04-30T08:35:42.701338Z","shell.execute_reply.started":"2022-04-30T08:35:42.693846Z","shell.execute_reply":"2022-04-30T08:35:42.69929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat_cb = cb.predict(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:42.7024Z","iopub.execute_input":"2022-04-30T08:35:42.702671Z","iopub.status.idle":"2022-04-30T08:35:42.721829Z","shell.execute_reply.started":"2022-04-30T08:35:42.702642Z","shell.execute_reply":"2022-04-30T08:35:42.720821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_train, y_hat_cb)\n\nplt.xlabel('Targets (y_train)',size=18)\nplt.ylabel('Predictions (y_hat_cb)',size=18)\n\n\nplt.xlim(10,17)\nplt.ylim(10,17)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:42.72302Z","iopub.execute_input":"2022-04-30T08:35:42.723405Z","iopub.status.idle":"2022-04-30T08:35:42.954123Z","shell.execute_reply.started":"2022-04-30T08:35:42.72327Z","shell.execute_reply":"2022-04-30T08:35:42.953313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y_train - y_hat_cb, kde=True, stat=\"density\", linewidth=0)\n\nplt.title(\"Residuals PDF\", size=18)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:42.955034Z","iopub.execute_input":"2022-04-30T08:35:42.955262Z","iopub.status.idle":"2022-04-30T08:35:43.338327Z","shell.execute_reply.started":"2022-04-30T08:35:42.955228Z","shell.execute_reply":"2022-04-30T08:35:43.3378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nr2 = r2_score (y_train, y_hat_cb)\n\nprint ('R-squared score', round (r2,2))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:43.339298Z","iopub.execute_input":"2022-04-30T08:35:43.339644Z","iopub.status.idle":"2022-04-30T08:35:43.34523Z","shell.execute_reply.started":"2022-04-30T08:35:43.339615Z","shell.execute_reply":"2022-04-30T08:35:43.344583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's try the model on the test values now","metadata":{}},{"cell_type":"code","source":"y_hat_test_cb=cb.predict(x_test)","metadata":{"id":"iWB2k2MwTPau","execution":{"iopub.status.busy":"2022-04-30T08:35:43.346513Z","iopub.execute_input":"2022-04-30T08:35:43.346709Z","iopub.status.idle":"2022-04-30T08:35:43.359285Z","shell.execute_reply.started":"2022-04-30T08:35:43.346685Z","shell.execute_reply":"2022-04-30T08:35:43.358588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y_test-y_hat_test_cb, kde=True, stat=\"density\", linewidth=0)","metadata":{"id":"_tR7wJU_TPav","outputId":"449cd8ff-defb-4e61-d891-c63dafe795ef","execution":{"iopub.status.busy":"2022-04-30T08:35:43.360403Z","iopub.execute_input":"2022-04-30T08:35:43.360836Z","iopub.status.idle":"2022-04-30T08:35:43.688757Z","shell.execute_reply.started":"2022-04-30T08:35:43.360806Z","shell.execute_reply":"2022-04-30T08:35:43.687954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_test,y_hat_test_cb, alpha = 0.2)\nplt.xlabel('Targets (y_test)',size=18)\nplt.ylabel('Predictions (y_hat_test_cb)',size=18)\nplt.xlim(10,17)\nplt.ylim(10,17)\nplt.show()","metadata":{"id":"D_5-zLbjTPav","outputId":"50f012d0-948f-45fe-ae6e-6421a936e9fa","scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:35:43.690472Z","iopub.execute_input":"2022-04-30T08:35:43.690823Z","iopub.status.idle":"2022-04-30T08:35:43.91985Z","shell.execute_reply.started":"2022-04-30T08:35:43.690779Z","shell.execute_reply":"2022-04-30T08:35:43.918902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pf = pd.DataFrame(np.exp(y_hat_test_cb), columns=['Prediction'])\n\ny_test = y_test.reset_index(drop=True)\n\ndf_pf['Target'] = np.exp(y_test)\n\ndf_pf['Residual'] = df_pf['Target'] - df_pf['Prediction']\n\n\ndf_pf['Difference%'] = np.absolute(df_pf['Residual']/df_pf['Target']*100)\ndf_pf","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:43.921429Z","iopub.execute_input":"2022-04-30T08:35:43.921667Z","iopub.status.idle":"2022-04-30T08:35:43.943103Z","shell.execute_reply.started":"2022-04-30T08:35:43.921636Z","shell.execute_reply":"2022-04-30T08:35:43.94202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pf.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:43.944714Z","iopub.execute_input":"2022-04-30T08:35:43.945034Z","iopub.status.idle":"2022-04-30T08:35:43.96677Z","shell.execute_reply.started":"2022-04-30T08:35:43.944981Z","shell.execute_reply":"2022-04-30T08:35:43.965938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.float_format', lambda x: '%.2f' % x)\ndf_pf.sort_values(by=['Difference%'], ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:43.968229Z","iopub.execute_input":"2022-04-30T08:35:43.968705Z","iopub.status.idle":"2022-04-30T08:35:43.98126Z","shell.execute_reply.started":"2022-04-30T08:35:43.968663Z","shell.execute_reply":"2022-04-30T08:35:43.980671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_hat_test_cb, y_test))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_hat_test_cb, y_test))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_hat_test_cb, y_test)))\n\nr2_cb = r2_score (y_hat_test_cb, y_test)\n\nprint ('R-squared score', round (r2_cb,2))\n\n#adjusted R-squared:\nadj_r2_cb = 1 - ((1 - r2_cb) * (254-1)/(254 - 8 - 1))\nprint ('Adjusted R-squared score', round (adj_r2_cb,2))","metadata":{"id":"0SBstjpCTPar","outputId":"426702d7-fc96-43cf-c82b-6fba260143d4","scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:35:43.982425Z","iopub.execute_input":"2022-04-30T08:35:43.982835Z","iopub.status.idle":"2022-04-30T08:35:43.995886Z","shell.execute_reply.started":"2022-04-30T08:35:43.982806Z","shell.execute_reply":"2022-04-30T08:35:43.994971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Technique 4: LGBM Regressor","metadata":{"id":"qkGut2_3jPct"}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor","metadata":{"id":"4SS1jLAwjK4Z","execution":{"iopub.status.busy":"2022-04-30T08:35:43.997228Z","iopub.execute_input":"2022-04-30T08:35:43.997722Z","iopub.status.idle":"2022-04-30T08:35:44.003809Z","shell.execute_reply.started":"2022-04-30T08:35:43.997678Z","shell.execute_reply":"2022-04-30T08:35:44.003259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nstart = time.time()\nlb=LGBMRegressor()  ","metadata":{"id":"OYKOu696jKvZ","execution":{"iopub.status.busy":"2022-04-30T08:35:44.004848Z","iopub.execute_input":"2022-04-30T08:35:44.005708Z","iopub.status.idle":"2022-04-30T08:35:44.016658Z","shell.execute_reply.started":"2022-04-30T08:35:44.005667Z","shell.execute_reply":"2022-04-30T08:35:44.015806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"learning_rate\": (0.03, 0.3), # default 0.1 \n    \"max_depth\": (2, 6), # default 3\n    \"n_estimators\": (100, 150), # default 100\n    \"subsample\": (0.6, 0.4)\n}","metadata":{"id":"AKD0J3VKjCXn","execution":{"iopub.status.busy":"2022-04-30T08:35:44.018257Z","iopub.execute_input":"2022-04-30T08:35:44.018562Z","iopub.status.idle":"2022-04-30T08:35:44.026754Z","shell.execute_reply.started":"2022-04-30T08:35:44.018508Z","shell.execute_reply":"2022-04-30T08:35:44.025726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb = RandomizedSearchCV(estimator = lb, param_distributions = params,scoring='neg_mean_squared_error', \n                        n_iter = 10, cv = 5, verbose=False, random_state=42, n_jobs = -1)","metadata":{"id":"v0jNOxOSi4Sf","execution":{"iopub.status.busy":"2022-04-30T08:35:44.028478Z","iopub.execute_input":"2022-04-30T08:35:44.028844Z","iopub.status.idle":"2022-04-30T08:35:44.037561Z","shell.execute_reply.started":"2022-04-30T08:35:44.028801Z","shell.execute_reply":"2022-04-30T08:35:44.036709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb.fit(x_train,y_train)\nend = time.time()\ndiff_lb = end - start\nprint ('Execution time for LGBM:', round(diff_lb,2), 'seconds')","metadata":{"id":"2MZbGyb7i5N4","outputId":"5319a548-e5d6-48d2-d51c-955faab768d1","execution":{"iopub.status.busy":"2022-04-30T08:35:44.038954Z","iopub.execute_input":"2022-04-30T08:35:44.039415Z","iopub.status.idle":"2022-04-30T08:35:45.180814Z","shell.execute_reply.started":"2022-04-30T08:35:44.039373Z","shell.execute_reply":"2022-04-30T08:35:45.180111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb.best_params_","metadata":{"id":"5I40gc8Dix6H","outputId":"62fd750a-6c4a-4ae5-9f9b-8ad71717d51a","scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:35:45.182084Z","iopub.execute_input":"2022-04-30T08:35:45.182823Z","iopub.status.idle":"2022-04-30T08:35:45.187713Z","shell.execute_reply.started":"2022-04-30T08:35:45.182775Z","shell.execute_reply":"2022-04-30T08:35:45.187124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat_lb = lb.predict(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:45.191129Z","iopub.execute_input":"2022-04-30T08:35:45.192689Z","iopub.status.idle":"2022-04-30T08:35:45.208068Z","shell.execute_reply.started":"2022-04-30T08:35:45.192653Z","shell.execute_reply":"2022-04-30T08:35:45.207334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_train, y_hat_lb)\n\nplt.xlabel('Targets (y_train)',size=18)\nplt.ylabel('Predictions (y_hat_lb)',size=18)\n\n\nplt.xlim(10,17)\nplt.ylim(10,17)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:45.212019Z","iopub.execute_input":"2022-04-30T08:35:45.212283Z","iopub.status.idle":"2022-04-30T08:35:45.443834Z","shell.execute_reply.started":"2022-04-30T08:35:45.212253Z","shell.execute_reply":"2022-04-30T08:35:45.443116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y_train - y_hat_lb, kde=True, stat=\"density\", linewidth=0)\n\nplt.title(\"Residuals PDF\", size=18)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:45.445202Z","iopub.execute_input":"2022-04-30T08:35:45.445491Z","iopub.status.idle":"2022-04-30T08:35:45.810632Z","shell.execute_reply.started":"2022-04-30T08:35:45.445451Z","shell.execute_reply":"2022-04-30T08:35:45.80983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nr2 = r2_score (y_train, y_hat_lb)\n\nprint ('R-squared score', round (r2,2))\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:35:45.811958Z","iopub.execute_input":"2022-04-30T08:35:45.812264Z","iopub.status.idle":"2022-04-30T08:35:45.81851Z","shell.execute_reply.started":"2022-04-30T08:35:45.812225Z","shell.execute_reply":"2022-04-30T08:35:45.817704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's try the model on the test values now","metadata":{}},{"cell_type":"code","source":"y_hat_test_lb=lb.predict(x_test)","metadata":{"id":"kvMiK_RRiRnd","execution":{"iopub.status.busy":"2022-04-30T08:35:45.819739Z","iopub.execute_input":"2022-04-30T08:35:45.820156Z","iopub.status.idle":"2022-04-30T08:35:45.831329Z","shell.execute_reply.started":"2022-04-30T08:35:45.820115Z","shell.execute_reply":"2022-04-30T08:35:45.830738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y_test-y_hat_test_lb, kde=True, stat=\"density\", linewidth=0)","metadata":{"id":"i_1_uD1bioBg","outputId":"d3281f10-fb7c-4094-8d07-4b9530d39299","execution":{"iopub.status.busy":"2022-04-30T08:35:45.8322Z","iopub.execute_input":"2022-04-30T08:35:45.834834Z","iopub.status.idle":"2022-04-30T08:35:46.159742Z","shell.execute_reply.started":"2022-04-30T08:35:45.834794Z","shell.execute_reply":"2022-04-30T08:35:46.159128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(y_test,y_hat_test_lb, alpha = 0.2)\nplt.xlabel('Targets (y_test)',size=18)\nplt.ylabel('Predictions (y_hat_test_lb)',size=18)\nplt.xlim(10,17)\nplt.ylim(10,17)\nplt.show()","metadata":{"id":"pGOacEstisnQ","outputId":"c875380e-4ccd-44c8-b03f-37d303634ada","execution":{"iopub.status.busy":"2022-04-30T08:35:46.160672Z","iopub.execute_input":"2022-04-30T08:35:46.161344Z","iopub.status.idle":"2022-04-30T08:35:46.389791Z","shell.execute_reply.started":"2022-04-30T08:35:46.16131Z","shell.execute_reply":"2022-04-30T08:35:46.38898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pf = pd.DataFrame(np.exp(y_hat_test_lb), columns=['Prediction'])\n\ny_test = y_test.reset_index(drop=True)\n\ndf_pf['Target'] = np.exp(y_test)\n\ndf_pf['Residual'] = df_pf['Target'] - df_pf['Prediction']\n\ndf_pf['Difference%'] = np.absolute(df_pf['Residual']/df_pf['Target']*100)\ndf_pf","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:46.39097Z","iopub.execute_input":"2022-04-30T08:35:46.391196Z","iopub.status.idle":"2022-04-30T08:35:46.409773Z","shell.execute_reply.started":"2022-04-30T08:35:46.391169Z","shell.execute_reply":"2022-04-30T08:35:46.408961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pf.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:46.410921Z","iopub.execute_input":"2022-04-30T08:35:46.411322Z","iopub.status.idle":"2022-04-30T08:35:46.432879Z","shell.execute_reply.started":"2022-04-30T08:35:46.411292Z","shell.execute_reply":"2022-04-30T08:35:46.432107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.float_format', lambda x: '%.2f' % x)\ndf_pf.sort_values(by=['Difference%'], ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:46.434177Z","iopub.execute_input":"2022-04-30T08:35:46.434469Z","iopub.status.idle":"2022-04-30T08:35:46.449974Z","shell.execute_reply.started":"2022-04-30T08:35:46.434429Z","shell.execute_reply":"2022-04-30T08:35:46.449107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_hat_test_lb, y_test))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_hat_test_lb, y_test))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_hat_test_lb, y_test)))\n\nr2_lb = r2_score (y_hat_test_lb, y_test)\n\nprint ('R-squared score', round (r2_lb,2))\n\n#adjusted R-squared:\nadj_r2_lb = 1 - ((1 - r2_lb) * (254-1)/(254 - 8 - 1))\nprint ('Adjusted R-squared score', round (adj_r2_lb,2))","metadata":{"id":"0SBstjpCTPar","outputId":"426702d7-fc96-43cf-c82b-6fba260143d4","scrolled":true,"execution":{"iopub.status.busy":"2022-04-30T08:35:46.451123Z","iopub.execute_input":"2022-04-30T08:35:46.451323Z","iopub.status.idle":"2022-04-30T08:35:46.461625Z","shell.execute_reply.started":"2022-04-30T08:35:46.451298Z","shell.execute_reply":"2022-04-30T08:35:46.460698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model comparison","metadata":{}},{"cell_type":"markdown","source":"The linear OLS regression will not be considered further as it was obvious that both its graphs and metrics were much worse than the other techniques. The most likely reason is that the nature of the dataset is that there are many outliers and OLS has a very hard time dealing with outliers, leading to a high accumulated error and low R-squared value. ","metadata":{}},{"cell_type":"markdown","source":"Furthermore, graphs will not be shown either as they are too similar and will not provide value to the comparison.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from tabulate import tabulate\n\ntable = [[\"Mean Absolute Error\", metrics.mean_absolute_error(y_hat_test_rf, y_test),\n           metrics.mean_absolute_error(y_hat_test_cb, y_test),\n          metrics.mean_absolute_error(y_hat_test_lb, y_test)], \n         \n        [\"Mean Squared Error\", metrics.mean_squared_error(y_hat_test_rf, y_test),\n        metrics.mean_squared_error(y_hat_test_cb, y_test),\n        metrics.mean_squared_error(y_hat_test_lb, y_test)],\n         \n        ['Root Mean Squared Error', np.sqrt(metrics.mean_squared_error(y_hat_test_rf, y_test)),\n        np.sqrt(metrics.mean_squared_error(y_hat_test_cb, y_test)),\n        np.sqrt(metrics.mean_squared_error(y_hat_test_lb, y_test)) ],\n         \n        ['R-squared score', round (r2_rf,3), round (r2_cb,3), round (r2_lb,3)],\n         \n         ['Adjusted R-squared score', round (adj_r2_rf,3), round (adj_r2_cb,3), round (adj_r2_lb,3)],\n         \n         ['Execution time (seconds)', round(diff_rf,2), round(diff_cb,2), round(diff_lb,2)]]\n\nprint(tabulate(table, headers=[\"Parameter\",\"RandomForest\",\"Catboost\",\"LGBM\"], numalign = \"left\"))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:35:46.462697Z","iopub.execute_input":"2022-04-30T08:35:46.462935Z","iopub.status.idle":"2022-04-30T08:35:46.478771Z","shell.execute_reply.started":"2022-04-30T08:35:46.46291Z","shell.execute_reply":"2022-04-30T08:35:46.477903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Catboost provides the best results in all metrics, with the minimal result in all 3 errors and the maximum result in R-squared/adjusted R-squared score. It is noteable that RandomForest, Catboost and LGBM performed similarly and outperformed OLS significantly. This is likely due to the dataset containing numerous outliers, which OLS struggles with inherently. Additionally, while OLS needs to be guided, i.e. shown what parameters to include, the other techniques determine automatically what the best paramaters for creating a model are. The get.dummies function had to be performed for the OLS, while the other techniques do not need that. In that sense, they are easier to implement. \n\nThe caveat with those techniques are the hyperparameter tuning, which is different for each dataset and has to be done iteratively. The hyperparameter tuning in particular has allowed Catboost and RandomForest to slightly outperform LightGBM, while requiring significantly more amount for training. A separate script showed that with the default parameters the results between the 3 techniques come even closer, with their differences in performance becoming negligible. Without hyperparameter tuning, LGBM slightly outperforms RandomForest, and Catboost retains its first place, albeit with a smaller margin.\n\nIn conclusion, the hyperparameter tuning in this project did not manage to significantly improve results and if training speed is desired, the default parameters set by each technique can be employed with a good amount of result accuracy. The Catboost regression model was able to correctly predict 82% of the real estate test dataset's price correctly, which is a somewhat satisfiable result, considering that only 6 features were used to fit the regression on ~4000 datapoints.","metadata":{}}]}