{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\n\nimport plotly\nplotly.offline.init_notebook_mode(connected=True)\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-29T22:46:45.902396Z","iopub.execute_input":"2022-04-29T22:46:45.903182Z","iopub.status.idle":"2022-04-29T22:46:47.104667Z","shell.execute_reply.started":"2022-04-29T22:46:45.903074Z","shell.execute_reply":"2022-04-29T22:46:47.103717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/jigsaw-specialized-rater-pools-dataset/specialized_rater_pools_data.csv\", delimiter=',', encoding='utf8')\npd.set_option('display.max_columns', None)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:52:24.022176Z","iopub.execute_input":"2022-04-30T00:52:24.02285Z","iopub.status.idle":"2022-04-30T00:52:25.964505Z","shell.execute_reply.started":"2022-04-30T00:52:24.022794Z","shell.execute_reply":"2022-04-30T00:52:25.963658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Columns in the data are the following:\n\nid: The id of the comment from the CivilComments data.\n\nunique_contributor_id: A pseudonymized id for the annotator.\n\nidentity_attack: The annotator's score for the \"identity_attack\" category. This is a value of -1 (identity attack), 0 (unsure), or 1 (not an - identity attack).\n\ninsult: The annotator's score for the \"insult\" category. This is a value of -1 (insult), 0 (unsure), or 1 (not an insult).\n\nobscene: The annotator's score for the \"obscene\" (profanity) category. This is a value of -1 (profanity), 0 (unsure), or 1 (not profanity).\n\nthreat: The annotator's score for the \"threat\" category. This is a value of -1 (threat), 0 (unsure), or 1 (not a threat).\ntoxic_score: The annotator's score for the \"toxicity\" category. This is a value of -2 (very toxic), -1 (toxic), 0 (unsure), or 1 (not toxic).\n\ncomment_text: The text of the comment.\n\nrater_group: The rater group the annotator was a part of. This is a value of \"African American\", \"LGBTQ\", or \"Control\".\n\nhttps://www.kaggle.com/datasets/google/jigsaw-specialized-rater-pools-dataset","metadata":{}},{"cell_type":"markdown","source":"#My World Is your World - Bee Gees\n\n<iframe width=\"707\" height=\"530\" src=\"https://www.youtube.com/embed/793texA5NhM\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\nhttps://www.youtube.com/watch?v=793texA5NhM","metadata":{}},{"cell_type":"markdown","source":"#Whenever I searched My world is your World (1972) Bee Gees appeared some Bieber Bull shit. Damm Toxic Search!","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T22:47:33.992699Z","iopub.execute_input":"2022-04-29T22:47:33.99298Z","iopub.status.idle":"2022-04-29T22:47:34.092664Z","shell.execute_reply.started":"2022-04-29T22:47:33.99295Z","shell.execute_reply":"2022-04-29T22:47:34.091631Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#It's Rater (one having a specified rating or class) or Hater?","metadata":{}},{"cell_type":"code","source":"df[\"rater_group\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T22:51:57.638431Z","iopub.execute_input":"2022-04-29T22:51:57.638737Z","iopub.status.idle":"2022-04-29T22:51:57.708478Z","shell.execute_reply.started":"2022-04-29T22:51:57.638705Z","shell.execute_reply":"2022-04-29T22:51:57.707618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Code by Taha07  https://www.kaggle.com/taha07/data-scientists-jobs-analysis-visualization/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'Red',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"rater_group\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Rater Group\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:18:08.526157Z","iopub.execute_input":"2022-04-29T23:18:08.52643Z","iopub.status.idle":"2022-04-29T23:18:10.706447Z","shell.execute_reply.started":"2022-04-29T23:18:08.526403Z","shell.execute_reply":"2022-04-29T23:18:10.705695Z"},"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"insult\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:22:33.171469Z","iopub.execute_input":"2022-04-29T23:22:33.172151Z","iopub.status.idle":"2022-04-29T23:22:33.18657Z","shell.execute_reply.started":"2022-04-29T23:22:33.172073Z","shell.execute_reply":"2022-04-29T23:22:33.185859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Lucas Abrahão https://www.kaggle.com/lucasabrahao/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"insult\"].value_counts().plot.bar(color=['blue', '#f5005a', '#7FFF00'], title='Insults')\nplt.figure(figsize=(8,4));","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:35:53.754477Z","iopub.execute_input":"2022-04-29T23:35:53.755125Z","iopub.status.idle":"2022-04-29T23:35:53.959675Z","shell.execute_reply.started":"2022-04-29T23:35:53.755083Z","shell.execute_reply":"2022-04-29T23:35:53.958899Z"},"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"obscene\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:22:59.450378Z","iopub.execute_input":"2022-04-29T23:22:59.450685Z","iopub.status.idle":"2022-04-29T23:22:59.463039Z","shell.execute_reply.started":"2022-04-29T23:22:59.450636Z","shell.execute_reply":"2022-04-29T23:22:59.462242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Lucas Abrahão https://www.kaggle.com/lucasabrahao/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"obscene\"].value_counts().plot.barh(color=['#FF7F50', '#008B8B', '#9932CC'], title='Obscenities')\nplt.figure(figsize=(8,4));","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:41:41.177205Z","iopub.execute_input":"2022-04-29T23:41:41.177548Z","iopub.status.idle":"2022-04-29T23:41:41.393023Z","shell.execute_reply.started":"2022-04-29T23:41:41.177512Z","shell.execute_reply":"2022-04-29T23:41:41.392278Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Lucas Abrahão https://www.kaggle.com/lucasabrahao/trabalho-manufatura-an-lise-de-dados-no-brasil\n\ndf[\"threat\"].value_counts().plot.barh(color=['#B22222', '#4B0082', '#20B2AA'], title='Threats')\nplt.figure(figsize=(8,4));","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:45:16.433759Z","iopub.execute_input":"2022-04-29T23:45:16.434038Z","iopub.status.idle":"2022-04-29T23:45:16.651622Z","shell.execute_reply.started":"2022-04-29T23:45:16.434008Z","shell.execute_reply":"2022-04-29T23:45:16.651008Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by MD. Jafril Alam Shihab https://www.kaggle.com/code/mdjafrilalamshihab/eda-of-russia-ukraine-war\n\ndf.boxplot(by='toxic_score')\nplt.xticks(rotation=45);","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:52:51.177281Z","iopub.execute_input":"2022-04-29T23:52:51.177759Z","iopub.status.idle":"2022-04-29T23:52:56.883624Z","shell.execute_reply.started":"2022-04-29T23:52:51.177724Z","shell.execute_reply":"2022-04-29T23:52:56.882795Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Siti K https://www.kaggle.com/khotijahs1/2020-indonesia-university-rank/comments\n\n#Toxicity by Toxic Score\ntoxicity = df.sort_values(by='toxic_score', ascending=False)[:20]\nfigure = plt.figure(figsize=(10,6))\nsns.barplot(y=toxicity.rater_group, x=toxicity.toxic_score)\nplt.xticks()\nplt.xlabel('Toxic Score')\nplt.ylabel('Rater Group')\nplt.title('Rater Groups by Toxic Score')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:03:19.257941Z","iopub.execute_input":"2022-04-30T00:03:19.25875Z","iopub.status.idle":"2022-04-30T00:03:19.523542Z","shell.execute_reply.started":"2022-04-30T00:03:19.258692Z","shell.execute_reply":"2022-04-30T00:03:19.522854Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#382499th row, 8th column \n\ndf.iloc[382499, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:07:27.101524Z","iopub.execute_input":"2022-04-30T00:07:27.101826Z","iopub.status.idle":"2022-04-30T00:07:27.108583Z","shell.execute_reply.started":"2022-04-30T00:07:27.101793Z","shell.execute_reply":"2022-04-30T00:07:27.107702Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTCr_68__2LdbOO9h5urKpN-xh_wG1G-Vbz0Q&usqp=CAU)independent.co.uk","metadata":{}},{"cell_type":"code","source":"#2nd row, 8th column \n\ndf.iloc[2, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:09:01.761881Z","iopub.execute_input":"2022-04-30T00:09:01.762513Z","iopub.status.idle":"2022-04-30T00:09:01.768343Z","shell.execute_reply.started":"2022-04-30T00:09:01.762475Z","shell.execute_reply":"2022-04-30T00:09:01.767572Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#15th row, 8th column \n\ndf.iloc[15, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:14:19.171426Z","iopub.execute_input":"2022-04-30T00:14:19.171733Z","iopub.status.idle":"2022-04-30T00:14:19.178569Z","shell.execute_reply.started":"2022-04-30T00:14:19.171696Z","shell.execute_reply":"2022-04-30T00:14:19.177642Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#11th row, 8th column \n\ndf.iloc[11, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:15:23.387053Z","iopub.execute_input":"2022-04-30T00:15:23.387323Z","iopub.status.idle":"2022-04-30T00:15:23.392809Z","shell.execute_reply.started":"2022-04-30T00:15:23.387294Z","shell.execute_reply":"2022-04-30T00:15:23.392125Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#22nd row, 8th column \n\ndf.iloc[22, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:18:23.20589Z","iopub.execute_input":"2022-04-30T00:18:23.206301Z","iopub.status.idle":"2022-04-30T00:18:23.212548Z","shell.execute_reply.started":"2022-04-30T00:18:23.20627Z","shell.execute_reply":"2022-04-30T00:18:23.211801Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#382477th row, 8th column \n\ndf.iloc[382477, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:22:48.677111Z","iopub.execute_input":"2022-04-30T00:22:48.677895Z","iopub.status.idle":"2022-04-30T00:22:48.684742Z","shell.execute_reply.started":"2022-04-30T00:22:48.677852Z","shell.execute_reply":"2022-04-30T00:22:48.68387Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#382482nd row, 8th column \n\ndf.iloc[382482, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:24:13.046778Z","iopub.execute_input":"2022-04-30T00:24:13.04708Z","iopub.status.idle":"2022-04-30T00:24:13.053376Z","shell.execute_reply.started":"2022-04-30T00:24:13.047047Z","shell.execute_reply":"2022-04-30T00:24:13.05242Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#35th row, 8th column \n\ndf.iloc[35, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:31:15.925628Z","iopub.execute_input":"2022-04-30T00:31:15.925958Z","iopub.status.idle":"2022-04-30T00:31:15.932025Z","shell.execute_reply.started":"2022-04-30T00:31:15.925925Z","shell.execute_reply":"2022-04-30T00:31:15.931114Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#44th row, 8th column \n\ndf.iloc[44, 7]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:32:23.322693Z","iopub.execute_input":"2022-04-30T00:32:23.322969Z","iopub.status.idle":"2022-04-30T00:32:23.329369Z","shell.execute_reply.started":"2022-04-30T00:32:23.32294Z","shell.execute_reply":"2022-04-30T00:32:23.328444Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Post with the most comments","metadata":{}},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\n# post with the most comments\n\ndf[df['toxic_score'] == df['toxic_score'].max()]['unique_contributor_id'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:35:42.476702Z","iopub.execute_input":"2022-04-30T00:35:42.477403Z","iopub.status.idle":"2022-04-30T00:35:42.506163Z","shell.execute_reply.started":"2022-04-30T00:35:42.477363Z","shell.execute_reply":"2022-04-30T00:35:42.505348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Cleaning functions","metadata":{}},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\ndef remove_line_breaks(text):\n    text = text.replace('\\r', ' ').replace('\\n', ' ')\n    return text\n\n#remove punctuation\ndef remove_punctuation(text):\n    re_replacements = re.compile(\"__[A-Z]+__\")  # such as __NAME__, __LINK__\n    re_punctuation = re.compile(\"[%s]\" % re.escape(string.punctuation))\n    '''Escape all the characters in pattern except ASCII letters and numbers'''\n    tokens = word_tokenize(text)\n    tokens_zero_punctuation = []\n    for token in tokens:\n        if not re_replacements.match(token):\n            token = re_punctuation.sub(\" \", token)\n        tokens_zero_punctuation.append(token)\n    return ' '.join(tokens_zero_punctuation)\n\ndef remove_special_characters(text):\n    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n    return text\n\ndef lowercase(text):\n    text_low = [token.lower() for token in word_tokenize(text)]\n    return ' '.join(text_low)\n\ndef remove_stopwords(text):\n    stop = set(stopwords.words('english'))\n    word_tokens = nltk.word_tokenize(text)\n    text = \" \".join([word for word in word_tokens if word not in stop])\n    return text\n\n#remobe one character words\ndef remove_one_character_words(text):\n    '''Remove words from dataset that contain only 1 character'''\n    text_high_use = [token for token in word_tokenize(text) if len(token)>1]      \n    return ' '.join(text_high_use)   \n    \n#%%\n# Stemming with 'Snowball stemmer\" package\ndef stem(text):\n    stemmer = nltk.stem.snowball.SnowballStemmer('english')\n    text_stemmed = [stemmer.stem(token) for token in word_tokenize(text)]        \n    return ' '.join(text_stemmed)\n\ndef lemma(text):\n    wordnet_lemmatizer = WordNetLemmatizer()\n    word_tokens = nltk.word_tokenize(text)\n    text_lemma = \" \".join([wordnet_lemmatizer.lemmatize(word) for word in word_tokens])       \n    return ' '.join(text_lemma)\n\n\n#break sentences to individual word list\ndef sentence_word(text):\n    word_tokens = nltk.word_tokenize(text)\n    return word_tokens\n#break paragraphs to sentence token \ndef paragraph_sentence(text):\n    sent_token = nltk.sent_tokenize(text)\n    return sent_token    \n\n\ndef tokenize(text):\n    \"\"\"Return a list of words in a text.\"\"\"\n    return re.findall(r'\\w+', text)\n\ndef remove_numbers(text):\n    no_nums = re.sub(r'\\d+', '', text)\n    return ''.join(no_nums)\n\n\n\ndef clean_text(text):\n    _steps = [\n    remove_line_breaks,\n    remove_one_character_words,\n    remove_special_characters,\n    lowercase,\n    remove_punctuation,\n    remove_stopwords,\n    stem,\n    remove_numbers\n]\n    for step in _steps:\n        text=step(text)\n    return text   \n#%%","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:37:57.958Z","iopub.execute_input":"2022-04-30T00:37:57.958279Z","iopub.status.idle":"2022-04-30T00:37:57.976694Z","shell.execute_reply.started":"2022-04-30T00:37:57.95825Z","shell.execute_reply":"2022-04-30T00:37:57.975749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://stackoverflow.com/questions/55557004/getting-attributeerror-float-object-has-no-attribute-replace-error-while\n#To avoid with tqdm AttributeError: 'float' object has no attribute\n\ndf[\"comment_text\"] = df[\"comment_text\"].astype(str)\ndf[\"comment_text\"] = [x.replace(':',' ') for x in df[\"comment_text\"]]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:46:16.833775Z","iopub.execute_input":"2022-04-30T00:46:16.834483Z","iopub.status.idle":"2022-04-30T00:46:17.038641Z","shell.execute_reply.started":"2022-04-30T00:46:16.834438Z","shell.execute_reply":"2022-04-30T00:46:17.037895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = df[\"comment_text\"].values","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:46:58.701892Z","iopub.execute_input":"2022-04-30T00:46:58.702329Z","iopub.status.idle":"2022-04-30T00:46:58.706976Z","shell.execute_reply.started":"2022-04-30T00:46:58.702298Z","shell.execute_reply":"2022-04-30T00:46:58.706265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nls = []\n\nfor i in words:\n    ls.append(str(i))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:47:18.999048Z","iopub.execute_input":"2022-04-30T00:47:18.999348Z","iopub.status.idle":"2022-04-30T00:47:19.14696Z","shell.execute_reply.started":"2022-04-30T00:47:18.999315Z","shell.execute_reply":"2022-04-30T00:47:19.146336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls[:5]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:47:36.268783Z","iopub.execute_input":"2022-04-30T00:47:36.26918Z","iopub.status.idle":"2022-04-30T00:47:36.276128Z","shell.execute_reply.started":"2022-04-30T00:47:36.269152Z","shell.execute_reply":"2022-04-30T00:47:36.275129Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nmost_toxic = df.sort_values('toxic_score', ascending =False)[['id', 'toxic_score']].head(12)\n\nmost_toxic['toxic_score1'] = most_toxic['toxic_score']/1000","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:52:52.845777Z","iopub.execute_input":"2022-04-30T00:52:52.846062Z","iopub.status.idle":"2022-04-30T00:52:52.913548Z","shell.execute_reply.started":"2022-04-30T00:52:52.846033Z","shell.execute_reply":"2022-04-30T00:52:52.912924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nplt.figure(figsize = (8,8))\n\nsns.barplot(data = df, y = 'id', x = 'toxic_score', color = 'c')\nplt.xticks(fontsize=27, rotation=0)\nplt.yticks(fontsize=31, rotation=0)\nplt.xlabel('Toxicity', fontsize = 21)\nplt.ylabel('Count')\nplt.title('Most toxic posts', fontsize = 30);","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:54:59.409268Z","iopub.execute_input":"2022-04-30T00:54:59.4096Z","iopub.status.idle":"2022-04-30T00:55:04.827706Z","shell.execute_reply.started":"2022-04-30T00:54:59.409562Z","shell.execute_reply":"2022-04-30T00:55:04.826723Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\nimport numpy as np\nnp.random.seed(2018)\nimport nltk","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:55:34.777961Z","iopub.execute_input":"2022-04-30T00:55:34.778265Z","iopub.status.idle":"2022-04-30T00:55:35.716561Z","shell.execute_reply.started":"2022-04-30T00:55:34.778233Z","shell.execute_reply":"2022-04-30T00:55:35.715853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stemmer = SnowballStemmer('english')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:55:50.179051Z","iopub.execute_input":"2022-04-30T00:55:50.179666Z","iopub.status.idle":"2022-04-30T00:55:50.183729Z","shell.execute_reply.started":"2022-04-30T00:55:50.179616Z","shell.execute_reply":"2022-04-30T00:55:50.182875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:56:05.525884Z","iopub.execute_input":"2022-04-30T00:56:05.526363Z","iopub.status.idle":"2022-04-30T00:56:05.736074Z","shell.execute_reply.started":"2022-04-30T00:56:05.526328Z","shell.execute_reply":"2022-04-30T00:56:05.735206Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\ndef lemmatize_stemming(text):\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n\ndef preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n            result.append(lemmatize_stemming(token))\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:56:31.429931Z","iopub.execute_input":"2022-04-30T00:56:31.430526Z","iopub.status.idle":"2022-04-30T00:56:31.436919Z","shell.execute_reply.started":"2022-04-30T00:56:31.430487Z","shell.execute_reply":"2022-04-30T00:56:31.436049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['comment_text'].iloc[35]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T00:59:56.73163Z","iopub.execute_input":"2022-04-30T00:59:56.732152Z","iopub.status.idle":"2022-04-30T00:59:56.737541Z","shell.execute_reply.started":"2022-04-30T00:59:56.732119Z","shell.execute_reply":"2022-04-30T00:59:56.736788Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\ndoc_sample = df['comment_text'].iloc[1]\nprint('original document: ')\n\nwords = []\n\nfor word in doc_sample.split(' '):\n    words.append(word)\n    \n    \nprint(words)\nprint('\\n\\n tokenized and lemmatized document: ')\nprint(preprocess(doc_sample))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:01:11.857179Z","iopub.execute_input":"2022-04-30T01:01:11.857537Z","iopub.status.idle":"2022-04-30T01:01:14.189273Z","shell.execute_reply.started":"2022-04-30T01:01:11.857497Z","shell.execute_reply":"2022-04-30T01:01:14.188418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['comment_text'] = df['comment_text'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:02:22.755368Z","iopub.execute_input":"2022-04-30T01:02:22.756052Z","iopub.status.idle":"2022-04-30T01:02:22.788047Z","shell.execute_reply.started":"2022-04-30T01:02:22.756008Z","shell.execute_reply":"2022-04-30T01:02:22.78739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nwords = []\n\nfor i in df['comment_text']:\n        words.append(i.split(' '))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:02:57.474903Z","iopub.execute_input":"2022-04-30T01:02:57.475211Z","iopub.status.idle":"2022-04-30T01:03:02.118684Z","shell.execute_reply.started":"2022-04-30T01:02:57.475164Z","shell.execute_reply":"2022-04-30T01:03:02.117941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Create the dictionary\n\nEvery unique word in comment_text","metadata":{}},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\ndictionary = gensim.corpora.Dictionary(words)\n\ncount = 0\nfor k, v in dictionary.iteritems():\n    print(k, v)\n    count += 1\n    if count > 10:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:03:57.804743Z","iopub.execute_input":"2022-04-30T01:03:57.805025Z","iopub.status.idle":"2022-04-30T01:04:45.254063Z","shell.execute_reply.started":"2022-04-30T01:03:57.804996Z","shell.execute_reply":"2022-04-30T01:04:45.253223Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter out tokens in the dictionary by their frequency.\n\ndictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:04:48.343097Z","iopub.execute_input":"2022-04-30T01:04:48.343373Z","iopub.status.idle":"2022-04-30T01:04:48.68012Z","shell.execute_reply.started":"2022-04-30T01:04:48.343342Z","shell.execute_reply":"2022-04-30T01:04:48.679335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Create Corpus -> term document frequency\n\ndoc2bow() simply counts the number of occurrences of each distinct word, converts the word to its integer word ID and returns the result as a sparse vector.","metadata":{}},{"cell_type":"code","source":"bow_corpus = [dictionary.doc2bow(doc) for doc in words]\nbow_corpus[4310]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:05:07.827886Z","iopub.execute_input":"2022-04-30T01:05:07.828173Z","iopub.status.idle":"2022-04-30T01:05:30.472699Z","shell.execute_reply.started":"2022-04-30T01:05:07.828143Z","shell.execute_reply":"2022-04-30T01:05:30.471755Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nbow_doc_4310 = bow_corpus[4310]\n\nfor i in range(len(bow_doc_4310)):\n    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n                                               dictionary[bow_doc_4310[i][0]], \nbow_doc_4310[i][1]))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:05:51.768528Z","iopub.execute_input":"2022-04-30T01:05:51.769142Z","iopub.status.idle":"2022-04-30T01:05:51.817203Z","shell.execute_reply.started":"2022-04-30T01:05:51.769093Z","shell.execute_reply":"2022-04-30T01:05:51.816342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Bigotry appeared 2 times?","metadata":{}},{"cell_type":"markdown","source":"TF/IDF","metadata":{}},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nfrom gensim import corpora, models\n\ntfidf = models.TfidfModel(bow_corpus)\ncorpus_tfidf = tfidf[bow_corpus]\n\nfrom pprint import pprint\n\nfor doc in corpus_tfidf:\n    pprint(doc)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:07:16.919682Z","iopub.execute_input":"2022-04-30T01:07:16.920629Z","iopub.status.idle":"2022-04-30T01:07:22.784276Z","shell.execute_reply.started":"2022-04-30T01:07:16.920577Z","shell.execute_reply":"2022-04-30T01:07:22.783421Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nlda_model = gensim.models.LdaMulticore(bow_corpus,\n                                       num_topics=10,\n                                       id2word=dictionary,\n                                       passes=2,\n                                       workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:08:03.0003Z","iopub.execute_input":"2022-04-30T01:08:03.00061Z","iopub.status.idle":"2022-04-30T01:14:48.238548Z","shell.execute_reply.started":"2022-04-30T01:08:03.000566Z","shell.execute_reply":"2022-04-30T01:14:48.237602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Show the output of the model","metadata":{}},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nfor idx, topic in lda_model.print_topics(-1):\n    print('Topic: {} \\nWords: {}'.format(idx, topic))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:16:18.613478Z","iopub.execute_input":"2022-04-30T01:16:18.615229Z","iopub.status.idle":"2022-04-30T01:16:18.648577Z","shell.execute_reply.started":"2022-04-30T01:16:18.615144Z","shell.execute_reply":"2022-04-30T01:16:18.647427Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nlda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf,\n                                             num_topics=10,\n                                             id2word=dictionary,\n                                             passes=2,\n                                             workers=4)\n\nfor idx, topic in lda_model_tfidf.print_topics(-1):\n    print('Topic: {} Word: {}'.format(idx, topic))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:17:15.176391Z","iopub.execute_input":"2022-04-30T01:17:15.17686Z","iopub.status.idle":"2022-04-30T01:25:08.565482Z","shell.execute_reply.started":"2022-04-30T01:17:15.176817Z","shell.execute_reply":"2022-04-30T01:25:08.564836Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nunseen_document = 'It’s nice to be surrounded by people who share your models\" - Do mpwolke has models?'\nbow_vector = dictionary.doc2bow(preprocess(unseen_document))\n\nfor index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:27:27.903884Z","iopub.execute_input":"2022-04-30T01:27:27.904497Z","iopub.status.idle":"2022-04-30T01:27:27.946138Z","shell.execute_reply.started":"2022-04-30T01:27:27.90446Z","shell.execute_reply":"2022-04-30T01:27:27.94519Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, naive_bayes, svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:27:41.410923Z","iopub.execute_input":"2022-04-30T01:27:41.411286Z","iopub.status.idle":"2022-04-30T01:27:41.421233Z","shell.execute_reply.started":"2022-04-30T01:27:41.411246Z","shell.execute_reply":"2022-04-30T01:27:41.420388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_text = df['comment_text']","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:27:47.37661Z","iopub.execute_input":"2022-04-30T01:27:47.377335Z","iopub.status.idle":"2022-04-30T01:27:47.382521Z","shell.execute_reply.started":"2022-04-30T01:27:47.377296Z","shell.execute_reply":"2022-04-30T01:27:47.381841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Create TF/IDF again","metadata":{}},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nvectorizer = TfidfVectorizer()\ntfidf = vectorizer.fit_transform(processed_text)\nprint(tfidf.shape)\nprint('\\n')\n#print(vectorizer.get_feature_names())","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:27:53.473107Z","iopub.execute_input":"2022-04-30T01:27:53.473424Z","iopub.status.idle":"2022-04-30T01:28:24.840268Z","shell.execute_reply.started":"2022-04-30T01:27:53.47339Z","shell.execute_reply":"2022-04-30T01:28:24.83938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df['comment_text']","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:28:51.319454Z","iopub.execute_input":"2022-04-30T01:28:51.32035Z","iopub.status.idle":"2022-04-30T01:28:51.324403Z","shell.execute_reply.started":"2022-04-30T01:28:51.320307Z","shell.execute_reply":"2022-04-30T01:28:51.323679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(tfidf, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:28:56.250841Z","iopub.execute_input":"2022-04-30T01:28:56.251404Z","iopub.status.idle":"2022-04-30T01:28:56.474935Z","shell.execute_reply.started":"2022-04-30T01:28:56.251368Z","shell.execute_reply":"2022-04-30T01:28:56.474092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\n# fit the training dataset on the NB classifier\nNaive = naive_bayes.MultinomialNB()\nNaive.fit(X_train_tf,y_train_tf)\n# predict the labels on validation dataset\npredictions_NB_tf = Naive.predict(X_test_tf)\n# Use accuracy_score function to get the accuracy\nprint(\"Naive Bayes Accuracy -> \",accuracy_score(predictions_NB_tf, y_test_tf)*100)\nprint(classification_report(predictions_NB_tf,y_test_tf))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T01:29:01.462395Z","iopub.execute_input":"2022-04-30T01:29:01.464561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Your notebook tried to allocate more memory than is available. It has restarted. That's the most toxic in Kaggle!","metadata":{}},{"cell_type":"code","source":"#Code by Leon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\n#Save for the next since in subreddit.nsfw  ALL is False\n\n#logmodel = LogisticRegression()\n#logmodel.fit(X_train_tf, y_train_tf)\n\n#predictions_LR_tf = logmodel.predict(X_test_tf)\n\n#print(\"LR Accuracy -> \",accuracy_score(predictions_LR_tf, y_test_tf)*100)\n#print(classification_report(predictions_LR_tf,y_test_tf))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Acknowledgements:\n\nLeon Wolber https://www.kaggle.com/leonwolber/reddit-nlp-topic-modeling-prediction\n\nMD. Jafril Alam Shihab https://www.kaggle.com/code/mdjafrilalamshihab/eda-of-russia-ukraine-war\n\nSiti K https://www.kaggle.com/khotijahs1/2020-indonesia-university-rank/comments\n\nLucas Abrahão https://www.kaggle.com/lucasabrahao/trabalho-manufatura-an-lise-de-dados-no-brasil","metadata":{}},{"cell_type":"markdown","source":"#My world is Your World  (Bee Gees Not Bieber. Dammit!)\n\n\"My world is our world\"\n\n\"And this world is your world\"\n\n\"And your world is my world\"\n\n\"And my world is your world is mine\"\n\n\n\"Don't shed a tear for me\"\n\n\"That's not your style\"\n\n\"If you're not here by me\"\n\n\"Then it's Still worth while\"  (That's my toxic version)\n\nMusic/Song by Robin Gibb and Barry Gibb\n\nhttps://www.letras.mus.br/bee-gees/1304328/traducao.html","metadata":{}},{"cell_type":"markdown","source":"![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcToMSbyuqx8J-HNx4RynBPypt_oaXq7KFEzmA&usqp=CAU)chordify.net","metadata":{}}]}