{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Various models to predict Autism spectrum Disorders (ADS)\n_**Autism Spectrum Disorder prediction with supervised models for binary classification**_\n\n---\n\n## Contents\n\n1. [Summary](#Summary)\n1. [Preparation](#Preparation)\n    1. [Data Loading](#Data_Loading)\n1. [Preprocessing](#Preprocessing)\n    1. [Exploratory Data Analysis](#Exploratory_Data_Analysis)\n    1. [Feature enginering & selection](#Feature_enginering_&_selection)\n1. [Training](#Training)\n    1. [Random Forest](#Random_Forest)\n    1. [Logistic Regression](#Logistic_Regression)\n    1. [XGBoost](#XGBoost)\n1. [Testing](#Testing)\n1. [Conclusion](#Conclusion)\n\n---\n\n# Summary\n[Back to Contents](#Contents)\n\nAutism Spectrum Disorders (ASD) are an ensemble of neurodevelopmental psychiatric disorders that cause diverse social and cognitive impairments. These impairments are associated with changes in the brain's early maturation of cortical circuits, where genetic and socio-cultural aspects are most prominent. However, neuropsychological evaluation at early stages is complex, and standard psychological examination is absent in young patients. \n\nThis notebook aims to predict the likelihood of a patient with ASD using survey and demographic variables and standard psychological tests. We used several supervised models based and monitored their efficacy in [Weights and Biases](https://wandb.ai) that you can visit [here](https://wandb.ai/neurohost/ASD/https://wandb.ai/neurohost/ASD/)\n\n---\n\n# Acknoledgements\n\nWe thank [Tensor Girl](https://www.kaggle.com/usharengaraju) for hosting the competition, [Satoshi Datamoto](https://www.kaggle.com/satoshidatamoto) for suggesting the feature selection, and [Mahsa Zamanifard](https://www.kaggle.com/mahsazamanifard) for resampling to increase the scoring of previous versions of the notebook. To [Bala Baskar](https://www.kaggle.com/balabaskar) for the idea of label encoding based on the frequency of the categorical variable. Also, to [Andrada Olteanu](https://www.kaggle.com/andradaolteanu) for providing the [country-mapping dataset](https://www.kaggle.com/datasets/andradaolteanu/country-mapping-iso-continent-region)\n\n# Preparation\n[Back to Contents](#Contents)\n\nThis notebook uses scikit-learn Transformers for data enginering and trains common supervised models for a binary classification task. \n\nIt requires familiarity with:\n* Standard scientific modules for data handling (pandas),\n* Modules for scientific analysis (Scipy, NumPy and machine learning Scikit-learn)\n* The scientific library for data visualization (matplotlib).\n\nIt also assumes that basic machine learning methods, like test/train split and hyperparameter searching. It is otherwise possible to follow the notebook with a minimal background.\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T18:32:19.078543Z","iopub.execute_input":"2022-04-29T18:32:19.079076Z","iopub.status.idle":"2022-04-29T18:32:19.091569Z","shell.execute_reply.started":"2022-04-29T18:32:19.079025Z","shell.execute_reply":"2022-04-29T18:32:19.090555Z"}}},{"cell_type":"code","source":"# data handling\nimport pandas as pd\n\n# numerical analysis\nimport numpy as np\n\n# OS-independent path\nimport pathlib\n\n# data visualization (See Preprocessing -> Exploratory Data Analysis)\nimport matplotlib.pyplot as plt\nplt.style.use('https://raw.githubusercontent.com/JoseGuzman/minibrain/master/minibrain/paper.mplstyle') # minibrain plotting\n\n# Display Pipelines and models\nfrom sklearn import set_config\nset_config(display='diagram')\n\n# other (e.g. for python >=3.6 type definitions like age: int = 1)\nfrom typing import List, Tuple\n\n# A progress bar\nfrom tqdm import tqdm\n\n# my utility script\nfrom reducing import PandaReducer","metadata":{"_uuid":"efd223da-a1a4-4ab2-b6c2-fe15b1cc9961","_cell_guid":"59486abd-7c78-4789-ab2f-3b544c2906ce","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-08T10:42:26.242503Z","iopub.execute_input":"2022-05-08T10:42:26.243544Z","iopub.status.idle":"2022-05-08T10:42:27.371743Z","shell.execute_reply.started":"2022-05-08T10:42:26.243413Z","shell.execute_reply":"2022-05-08T10:42:27.371042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data_Loading\n[Back to Contents](#Contents)\n\nWe first load test and train datasets into a Pandas DataFrame object and the target variable\nas a Pandas DataSeries object.","metadata":{}},{"cell_type":"code","source":"# Data Loading\n# Define file paths, test and train files\nmypath = pathlib.Path('../input/autismdiagnosis/Autism_Prediction/')\ntrain_file = mypath / 'train.csv'\ntest_file = mypath / 'test.csv'\ntype(test_file)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:27.535417Z","iopub.execute_input":"2022-05-08T10:42:27.53956Z","iopub.status.idle":"2022-05-08T10:42:27.552346Z","shell.execute_reply.started":"2022-05-08T10:42:27.539504Z","shell.execute_reply":"2022-05-08T10:42:27.551566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Loading\ndef data_loader(file:pathlib.PosixPath, target:str=None, verbose:bool = False, **kwargs) -> Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"\n    Loads csv file and return a tuple with a pandas dataset \n    containing all features, and a pandas Series with the \n    target variable.\n    \"\"\"\n    \n    data = pd.read_csv(file, **kwargs)\n    df = PandaReducer().reduce(data) # see reduce.py in Utility Script \n    \n    if target is not None:\n        #target = (df[target] == 'yes').astype(int)\n        target = (df[target]).astype(int)\n    \n    if verbose:\n        print('The dataset contains {0} entries and {1} features'.format(*df.shape))\n    \n    return df, target","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:29.336201Z","iopub.execute_input":"2022-05-08T10:42:29.336501Z","iopub.status.idle":"2022-05-08T10:42:29.341998Z","shell.execute_reply.started":"2022-05-08T10:42:29.336466Z","shell.execute_reply":"2022-05-08T10:42:29.341307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"# Data Loading\ntrain, train_target = data_loader(file = train_file, target = 'Class/ASD', verbose=True, index_col='ID')\ntest, _ = data_loader(file = test_file, target=None, verbose=True, index_col='ID') # note target is None","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:31.287165Z","iopub.execute_input":"2022-05-08T10:42:31.287443Z","iopub.status.idle":"2022-05-08T10:42:32.893566Z","shell.execute_reply.started":"2022-05-08T10:42:31.287415Z","shell.execute_reply":"2022-05-08T10:42:32.892165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(n=5)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:32.895013Z","iopub.execute_input":"2022-05-08T10:42:32.895277Z","iopub.status.idle":"2022-05-08T10:42:32.925919Z","shell.execute_reply.started":"2022-05-08T10:42:32.895249Z","shell.execute_reply":"2022-05-08T10:42:32.924996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n[Back to Contents](#Contents)\n\nWe first need a brief exploration of variable types and target variable. ","metadata":{}},{"cell_type":"markdown","source":"## Exploratory_Data_Analysis\n[Back to Contents](#Contents)\n\nThe visualization of types and distributions of the -independent- variables, also called features. ","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:34.452492Z","iopub.execute_input":"2022-05-08T10:42:34.452769Z","iopub.status.idle":"2022-05-08T10:42:34.476689Z","shell.execute_reply.started":"2022-05-08T10:42:34.452743Z","shell.execute_reply":"2022-05-08T10:42:34.476021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploration: there are no missing values in both train and test datasets\ntest.isnull().values.any(), train.isnull().values.any() # ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:35.495292Z","iopub.execute_input":"2022-05-08T10:42:35.495576Z","iopub.status.idle":"2022-05-08T10:42:35.507728Z","shell.execute_reply.started":"2022-05-08T10:42:35.495544Z","shell.execute_reply":"2022-05-08T10:42:35.506978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploration: evaluate if data is uniformly distributed\ntrain['Class/ASD'].value_counts() # data is umbalanced!","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:36.541625Z","iopub.execute_input":"2022-05-08T10:42:36.542249Z","iopub.status.idle":"2022-05-08T10:42:36.55149Z","shell.execute_reply.started":"2022-05-08T10:42:36.542199Z","shell.execute_reply":"2022-05-08T10:42:36.550495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop target variable, we have it in train_target\ntrain.drop(['Class/ASD'],axis=1, inplace=True) ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:37.445492Z","iopub.execute_input":"2022-05-08T10:42:37.445768Z","iopub.status.idle":"2022-05-08T10:42:37.452161Z","shell.execute_reply.started":"2022-05-08T10:42:37.445741Z","shell.execute_reply":"2022-05-08T10:42:37.451486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exploration: visualization of target variable\n\nautistic = train_target.value_counts() \n\nfig, ax = plt.subplots(1,2, figsize =(6,3))\nfig.tight_layout(pad = 1, h_pad = 2, w_pad = 4)\n\nmylabels = ['ASD (No)', 'ASD (Yes)']\nmycolors = ['tab:blue', 'tab:orange']\n\nax[0].bar(x=mylabels, height = autistic, color = mycolors, width = 0.75, alpha = .6)\n\nfor tick in ax[0].get_xticklabels():\n    tick.set_rotation(90)\nax[0].set_ylabel('counts')#, ax[0].set_yticks(np.arange(0,4000,500))\n\nax[1].pie(autistic.values, labels = mylabels, colors = mycolors, autopct='%2.2f%%',shadow=True, startangle=90);","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:38.374659Z","iopub.execute_input":"2022-05-08T10:42:38.375053Z","iopub.status.idle":"2022-05-08T10:42:38.746248Z","shell.execute_reply.started":"2022-05-08T10:42:38.37502Z","shell.execute_reply":"2022-05-08T10:42:38.745469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe() # numeric variables, ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:39.339464Z","iopub.execute_input":"2022-05-08T10:42:39.339756Z","iopub.status.idle":"2022-05-08T10:42:39.385591Z","shell.execute_reply.started":"2022-05-08T10:42:39.339723Z","shell.execute_reply":"2022-05-08T10:42:39.384589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems like **A_*Score** are the evaluation tests, and vary between 0 and 1. We need to provide normalization to **age** and **result**","metadata":{"execution":{"iopub.status.busy":"2022-05-05T05:45:37.878719Z","iopub.execute_input":"2022-05-05T05:45:37.879032Z","iopub.status.idle":"2022-05-05T05:45:37.884997Z","shell.execute_reply.started":"2022-05-05T05:45:37.879003Z","shell.execute_reply":"2022-05-05T05:45:37.884198Z"}}},{"cell_type":"code","source":"test.describe() # numeric variables, ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:40.853256Z","iopub.execute_input":"2022-05-08T10:42:40.853543Z","iopub.status.idle":"2022-05-08T10:42:40.902235Z","shell.execute_reply.started":"2022-05-08T10:42:40.853514Z","shell.execute_reply":"2022-05-08T10:42:40.901345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see the content of the different variables in test and train datasets. It is important, because the evaluation is made on the test sets, and we want all the variables and contents to be trained before (in train dataset).","metadata":{}},{"cell_type":"code","source":"# train.select_dtypes(['category']) # category variables\n\nfor col in train.select_dtypes(['category']).columns :\n    myval = train[col].unique().tolist()\n    if len(myval) == 2:\n        print(f'BIVARIATE   : {col} -> {train[col].unique().tolist()}')\n    elif len(myval) == 1:\n        print(f'UNIVARIATE   : {col} -> {train[col].unique().tolist()}')\n    else:\n        print(f'MULTIVARIATE: {col} -> {train[col].unique().tolist()}')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:42.527117Z","iopub.execute_input":"2022-05-08T10:42:42.527803Z","iopub.status.idle":"2022-05-08T10:42:42.544583Z","shell.execute_reply.started":"2022-05-08T10:42:42.527763Z","shell.execute_reply":"2022-05-08T10:42:42.54346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in test.select_dtypes(['category']).columns :\n    myval = test[col].unique().tolist()\n    if len(myval) == 2:\n        print(f'BIVARIATE   : {col} -> {test[col].unique().tolist()}')\n    elif len(myval) == 1:\n        print(f'UNIVARIATE   : {col} -> {test[col].unique().tolist()}')\n    else:\n        print(f'MULTIVARIATE: {col} -> {test[col].unique().tolist()}')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:43.600823Z","iopub.execute_input":"2022-05-08T10:42:43.601249Z","iopub.status.idle":"2022-05-08T10:42:43.611908Z","shell.execute_reply.started":"2022-05-08T10:42:43.601202Z","shell.execute_reply":"2022-05-08T10:42:43.611144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['age_desc'].unique(), test['age_desc'].unique() # this variable is not informative, we will remove it","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:44.597856Z","iopub.execute_input":"2022-05-08T10:42:44.598174Z","iopub.status.idle":"2022-05-08T10:42:44.606196Z","shell.execute_reply.started":"2022-05-08T10:42:44.59814Z","shell.execute_reply":"2022-05-08T10:42:44.605328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let me check if both datasets relations are idential\nprint(f'{\"test\":25s} --   {\"train\":10s}')\nprint(f'{\"=\"*45}')\nfor i,j in zip(np.sort(test.relation.unique()), np.sort(train.relation.unique())):\n    print(f'{i:25s} --   {j:15s}')\n    \nlen(test.relation.unique()), len(train.relation.unique())    ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:45.569493Z","iopub.execute_input":"2022-05-08T10:42:45.570144Z","iopub.status.idle":"2022-05-08T10:42:45.579013Z","shell.execute_reply.started":"2022-05-08T10:42:45.570094Z","shell.execute_reply":"2022-05-08T10:42:45.578423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let me check if both datasets are representatives\nprint(f'{\"test\":15s} --   {\"train\":10s}')\nprint(f'{\"=\"*35}')\nfor i,j in zip(np.sort(test.ethnicity.unique()), np.sort(train.ethnicity.unique())):\n    print(f'{i:15s} --   {j:15s}')\nlen(test.ethnicity.unique()), len(train.ethnicity.unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:46.522783Z","iopub.execute_input":"2022-05-08T10:42:46.523069Z","iopub.status.idle":"2022-05-08T10:42:46.532801Z","shell.execute_reply.started":"2022-05-08T10:42:46.523027Z","shell.execute_reply":"2022-05-08T10:42:46.532238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i,j in enumerate(np.sort(test.ethnicity.unique())):\n    print(f'{i:2d} --   {j:15s}')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:47.722883Z","iopub.execute_input":"2022-05-08T10:42:47.723514Z","iopub.status.idle":"2022-05-08T10:42:47.729186Z","shell.execute_reply.started":"2022-05-08T10:42:47.723476Z","shell.execute_reply":"2022-05-08T10:42:47.72857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,j in enumerate(np.sort(train.ethnicity.unique())):\n    print(f'{i:2d} --   {j:15s}')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:48.626952Z","iopub.execute_input":"2022-05-08T10:42:48.627217Z","iopub.status.idle":"2022-05-08T10:42:48.633707Z","shell.execute_reply.started":"2022-05-08T10:42:48.62719Z","shell.execute_reply":"2022-05-08T10:42:48.633027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['ethnicity'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:49.406693Z","iopub.execute_input":"2022-05-08T10:42:49.406975Z","iopub.status.idle":"2022-05-08T10:42:49.415348Z","shell.execute_reply.started":"2022-05-08T10:42:49.406942Z","shell.execute_reply":"2022-05-08T10:42:49.414757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To homogeneize both datasets, I will remove three records with 'others'\n#train = train[train.ethnicity != 'others']\n#df.drop(df.loc[df['line_race']==0].index, inplace=True)\n\n#df.drop(train.loc[train['ethnicity']==0].index, inplace=True)\ndel_idx = train.loc[train['ethnicity']=='others'].index\ntrain.drop(del_idx, inplace=True)\n#train = train[~train.ethnicity.str.contains(\"others\")]\ntrain_target.drop(del_idx, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:50.264138Z","iopub.execute_input":"2022-05-08T10:42:50.264432Z","iopub.status.idle":"2022-05-08T10:42:50.273336Z","shell.execute_reply.started":"2022-05-08T10:42:50.264393Z","shell.execute_reply":"2022-05-08T10:42:50.272384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['ethnicity'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:50.887662Z","iopub.execute_input":"2022-05-08T10:42:50.887943Z","iopub.status.idle":"2022-05-08T10:42:50.89572Z","shell.execute_reply.started":"2022-05-08T10:42:50.887911Z","shell.execute_reply":"2022-05-08T10:42:50.895034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If different ethnicit this will affect one-hot-encoding\nlen(test.ethnicity.unique()), len(train.ethnicity.unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:51.507297Z","iopub.execute_input":"2022-05-08T10:42:51.507924Z","iopub.status.idle":"2022-05-08T10:42:51.51443Z","shell.execute_reply.started":"2022-05-08T10:42:51.507887Z","shell.execute_reply":"2022-05-08T10:42:51.513636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Different ethnicities, this will affect one-hot-encoding!!!\nlen(train['contry_of_res'].unique()), len(test['contry_of_res'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:52.18751Z","iopub.execute_input":"2022-05-08T10:42:52.187782Z","iopub.status.idle":"2022-05-08T10:42:52.193975Z","shell.execute_reply.started":"2022-05-08T10:42:52.187747Z","shell.execute_reply":"2022-05-08T10:42:52.193317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Different countries, this will affect one-hot-encoding\nnp.array_equiv(train['contry_of_res'].unique(), test['contry_of_res'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:52.818657Z","iopub.execute_input":"2022-05-08T10:42:52.819074Z","iopub.status.idle":"2022-05-08T10:42:52.824946Z","shell.execute_reply.started":"2022-05-08T10:42:52.819043Z","shell.execute_reply":"2022-05-08T10:42:52.824165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Countries are different, we will collect all of them into continents using [this dataset](https://www.kaggle.com/datasets/andradaolteanu/country-mapping-iso-continent-region) to train with continents.","metadata":{}},{"cell_type":"code","source":"# We will map country\n\n# Load the dataset of country/region\ndata = pd.read_csv('../input/country-mapping-iso-continent-region/continents2.csv') # small dataset, no need to reduce size\n\n\nprint(data.region.unique())\ncontinent = pd.Series(data.region.values, index = data.name).to_dict() # create a dictionary\n\n\ntrain['region'] = train['contry_of_res'].map(continent) # could use .replace here\ntest['region'] = test['contry_of_res'].map(continent)\n\n#assert(train.region.unique() == test.region.unique())\n\ntrain[['contry_of_res','region']].head(n=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:54.424391Z","iopub.execute_input":"2022-05-08T10:42:54.424899Z","iopub.status.idle":"2022-05-08T10:42:54.455407Z","shell.execute_reply.started":"2022-05-08T10:42:54.424859Z","shell.execute_reply":"2022-05-08T10:42:54.454495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In addition, we rank the countries by frequency of appareance in the train dataset, as suggested in [this notebook](https://www.kaggle.com/code/balabaskar/autism-prediction-eda-with-0-827-score)","metadata":{}},{"cell_type":"code","source":"\n# create a dataframe with train and test to account for all possible countries\ndf = pd.DataFrame(train['contry_of_res'].append(test['contry_of_res'], ignore_index = True))\nncountry = df['contry_of_res'].nunique()\nprint(f'Number of unique countries = {ncountry}')\n\nranking = range(1,ncountry+1)[::-1]\ncountry = df['contry_of_res'].value_counts().index.to_list()\nrank_country = dict( zip(country, ranking))\nprint(f'Length ranking dictionary  = {len(rank_country)}')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:56.968904Z","iopub.execute_input":"2022-05-08T10:42:56.969211Z","iopub.status.idle":"2022-05-08T10:42:56.978018Z","shell.execute_reply.started":"2022-05-08T10:42:56.969179Z","shell.execute_reply":"2022-05-08T10:42:56.977363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature_enginering_&_selection\n[Back to Contents](#Contents)\n\nWe first start some some custom definitions for custom Transformers and PipeLines.","metadata":{}},{"cell_type":"markdown","source":"A ColumnTransformer will apply the transformation to a single feature or list of features. An alternative methods is to use common Pipelines where the column transformation is defined at the initialization of the\ntransformer. I tend to combine both methods\n\n\n_Look [here](https://machinelearningmastery.com/columntransformer-for-numerical-and-categorical-data/) to learn how to use ColumnTransformer_","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:42:59.473823Z","iopub.execute_input":"2022-05-08T10:42:59.474329Z","iopub.status.idle":"2022-05-08T10:42:59.478394Z","shell.execute_reply.started":"2022-05-08T10:42:59.474279Z","shell.execute_reply":"2022-05-08T10:42:59.477598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FrequencyEncoder(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Custom feature for Label encoding based on frequency \n    of categorical variables.\n    To use it:\n    >>> myrank = {'united states': 1, 'spain':10}\n    >>> mydropper = FrequencyEncoder(features = ['country_of_res'], rank = myrank)\n    >>> df = mydropper.fit_transform(X = train)\n    \"\"\"\n\n    def __init__(self, col_name:str, rank:dict)-> None:\n        \"\"\"\n        Remove the list of features from a pandas \n        Dataframe object.\n        \n        Parameter\n        ---------\n        col_name:  the variable to remove\n        rank: (dict) containg the variable and frequency to \n        be substitued (eg. myrank = {'united states': 1, 'spain':10}\n        \n        \"\"\"\n\n        self.col_name = col_name\n        self.rank = rank\n        self.df = None\n   \n       \n\n    def fit(self, X:pd.DataFrame, y = None):\n        \"\"\"\n        Remove the column lists and update dataset\n        \"\"\"\n        df = X.copy()\n                \n        df[self.col_name] = df[self.col_name].map(self.rank)\n        \n        self.df = df\n        return self\n   \n    def transform(self, X:pd.DataFrame = None) -> pd.DataFrame:\n        \"\"\"\n        Returns a pandas DataFrame with removed features.\n        \n        Parameter\n        ---------\n        dataframe:  Pandas DataFrame object\n        \"\"\"\n        df = X.copy()\n        \n        # Drop features\n        df[self.col_name] = df[self.col_name].map(self.rank)\n        \n        return self.df","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:00.736208Z","iopub.execute_input":"2022-05-08T10:43:00.737139Z","iopub.status.idle":"2022-05-08T10:43:00.746313Z","shell.execute_reply.started":"2022-05-08T10:43:00.737057Z","shell.execute_reply":"2022-05-08T10:43:00.745445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fencoder = FrequencyEncoder(col_name = 'contry_of_res', rank = rank_country)\ndf = fencoder.fit_transform(X= train)\ndf['contry_of_res']","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:01.87716Z","iopub.execute_input":"2022-05-08T10:43:01.877576Z","iopub.status.idle":"2022-05-08T10:43:01.889755Z","shell.execute_reply.started":"2022-05-08T10:43:01.877546Z","shell.execute_reply":"2022-05-08T10:43:01.888963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RegionTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Custom feature transform a Country in one of the \n    five continents of the world, 'Asia' 'Europe' \n    'Africa' 'Oceania' 'Americas', or 'nan'.\n    To use it:\n    >>> myregion = RegionTransformer(continent = data)\n    >>> df = myregion.fit_transform(X = train)\n    \"\"\"\n\n    def __init__(self, continent:dict) -> None:\n        \"\"\"\n        Remove the list of features from a pandas \n        Dataframe object.\n        \n        Parameter\n        ---------\n        continent:  (dict) of countries/continent pairs.\n        \"\"\"\n\n        self.continent = continent\n        self.df = None\n    \n    \n    def get_feature_names_out(self) -> List[str]:\n        \"\"\"\n        Get column names (necessary for Pipelines)\n        \"\"\"\n        \n        if self.df is None:\n            mycols = ['None']\n        else:\n            mycols =  self.df.columns.tolist()\n            \n        return mycols\n        \n\n    def fit(self, X:pd.DataFrame, y = None):\n        \"\"\"\n        Remove the column lists and update dataset\n        \"\"\"\n        \n        df = X.copy()\n        df['region'] = df['contry_of_res'].map(self.continent)\n        self.df = df\n        \n        return self\n   \n    def transform(self, X:pd.DataFrame = None) -> pd.DataFrame:\n        \"\"\"\n        Returns a pandas DataFrame with removed features.\n        \n        Parameter\n        ---------\n        dataframe:  Pandas DataFrame object\n        \"\"\"\n        \n        df = X.copy()\n        \n        # Add region to dataset\n        df['region'] = df['contry_of_res'].map(self.continent)\n        return self.df","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:02.895656Z","iopub.execute_input":"2022-05-08T10:43:02.896102Z","iopub.status.idle":"2022-05-08T10:43:02.904836Z","shell.execute_reply.started":"2022-05-08T10:43:02.896051Z","shell.execute_reply":"2022-05-08T10:43:02.904129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"myregion = RegionTransformer(continent = continent)\ndf = myregion.fit_transform(X = test)\nmyregion.get_feature_names_out()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:03.860623Z","iopub.execute_input":"2022-05-08T10:43:03.860883Z","iopub.status.idle":"2022-05-08T10:43:03.872116Z","shell.execute_reply.started":"2022-05-08T10:43:03.860857Z","shell.execute_reply":"2022-05-08T10:43:03.871342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DropperTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Custom feature dropper to add to custom Pipelines.\n    To use it:\n    >>> mydropper = DropperTransformer(features = ['age'])\n    >>> df = mydropper.fit_transform(X = train)\n    \"\"\"\n\n    def __init__(self, features:List[str])-> None:\n        \"\"\"\n        Remove the list of features from a pandas \n        Dataframe object.\n        \n        Parameter\n        ---------\n        features:  (list) of variables to remove\n        \"\"\"\n\n        self.features = features\n        self.df = None\n    \n    \n    def get_feature_names_out(self)-> List[str]:\n        \"\"\"\n        Get column names (necessary for Pipelines)\n        \"\"\"\n        if self.df is None:\n            mycols = ['None']\n        else:\n            mycols =  self.df.columns.tolist()\n            \n        return mycols\n        \n\n    def fit(self, X:pd.DataFrame, y = None):\n        \"\"\"\n        Remove the column lists and update dataset\n        \"\"\"\n        df = X.copy()\n        self.df = df.drop(self.features, axis = 1)\n        \n        return self\n   \n    def transform(self, X:pd.DataFrame = None) -> pd.DataFrame:\n        \"\"\"\n        Returns a pandas DataFrame with removed features.\n        \n        Parameter\n        ---------\n        dataframe:  Pandas DataFrame object\n        \"\"\"\n        df = X.copy()\n        \n        # Drop features\n        self.df = df.drop(self.features, axis = 1)\n        return self.df\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:04.671051Z","iopub.execute_input":"2022-05-08T10:43:04.671799Z","iopub.status.idle":"2022-05-08T10:43:04.681529Z","shell.execute_reply.started":"2022-05-08T10:43:04.671753Z","shell.execute_reply":"2022-05-08T10:43:04.680816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydropper = DropperTransformer(features = ['age_desc'])\nmydropper.fit(train)\n#df = mydropper.fit_transform(train)\nfor i, col in enumerate(mydropper.get_feature_names_out()):\n    print(f'{i:2d} - {col}')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:05.646341Z","iopub.execute_input":"2022-05-08T10:43:05.64662Z","iopub.status.idle":"2022-05-08T10:43:05.656317Z","shell.execute_reply.started":"2022-05-08T10:43:05.646592Z","shell.execute_reply":"2022-05-08T10:43:05.655237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature selection with Pearson's Chi-square Test for Independence\n* $\\chi^2$ statistic for testing binary categorical variables relationship to categorical. Chi-square is applied to categorical variables and is especially useful when those variables are nominal (where order doesn't matter, like marital status or gender).\n\nThe null hypothesis (H0) of the Chi-Square test is that no relationship exists on the categorical variables in the population; they are independent. If the probability that the null hypothesis (H0) is higher than 5%, then the null hypothesis is valid (variables are thus independent). Note that I tend to use the test in the opposite direction (p<0.05 to test the dependency between variables)","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import chi2\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:07.632848Z","iopub.execute_input":"2022-05-08T10:43:07.633321Z","iopub.status.idle":"2022-05-08T10:43:07.848386Z","shell.execute_reply.started":"2022-05-08T10:43:07.633276Z","shell.execute_reply":"2022-05-08T10:43:07.847308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:08.577703Z","iopub.execute_input":"2022-05-08T10:43:08.578008Z","iopub.status.idle":"2022-05-08T10:43:08.582295Z","shell.execute_reply.started":"2022-05-08T10:43:08.577975Z","shell.execute_reply":"2022-05-08T10:43:08.581519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binary_features = ['gender', 'jaundice', 'austim', 'used_app_before']\nbinary_encoder = OneHotEncoder(sparse=False, drop= 'if_binary')\n#foo = binary_encoder.fit_transform(train[binary_features])\n#cols = binary_encoder.get_feature_names_out()\n\nchi_score, p = chi2(X = binary_encoder.fit_transform(train[binary_features])  ,y = train_target)\nstar = p <= 0.05 # if they are dependent, probability of Ho (independency) must be lower than 5%\npd.DataFrame(zip(binary_features, chi_score, p, star), columns=['category', 'Chi-Square', 'p-value', 'P<0.05'])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:09.597829Z","iopub.execute_input":"2022-05-08T10:43:09.598659Z","iopub.status.idle":"2022-05-08T10:43:09.620343Z","shell.execute_reply.started":"2022-05-08T10:43:09.598618Z","shell.execute_reply":"2022-05-08T10:43:09.619686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The null hypothesis (H0) of the Chi-Square test is that no relationship exists on the categorical variables in the population (i.e. the variable is indepedent). If we discard categorical variables with probability 5% or more, we discard **gender** and **used_app_before**.","metadata":{}},{"cell_type":"code","source":"# Note that A*_Score are also binary variables, we will test if they are related to the independent variable\nmylist = [f'A{i}_Score' for i in range(1,10)]\n\nchi_score, p = chi2(X = binary_encoder.fit_transform(train[mylist])  ,y = train_target)\nstar = p <= 0.05\npd.DataFrame(zip(mylist, chi_score, p, star), columns=['category', 'Chi-Square', 'p-value', 'P<0.05'])","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:10.806145Z","iopub.execute_input":"2022-05-08T10:43:10.806424Z","iopub.status.idle":"2022-05-08T10:43:10.826688Z","shell.execute_reply.started":"2022-05-08T10:43:10.806385Z","shell.execute_reply":"2022-05-08T10:43:10.826113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All A*_Scores are related (with probability of 95% or more) to the depedent variable.","metadata":{}},{"cell_type":"markdown","source":"## Designing preprocessing Pipeline","metadata":{}},{"cell_type":"code","source":"# Transformation: create processing pipeline\n#from sklearn.pipeline import make_pipeline # to concatenate estimators and transformers (like Pipeline)\n#from sklearn.compose import make_column_transformer # to apply transformers to categories (ColumnTransformer)\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:12.722377Z","iopub.execute_input":"2022-05-08T10:43:12.722855Z","iopub.status.idle":"2022-05-08T10:43:12.733558Z","shell.execute_reply.started":"2022-05-08T10:43:12.722823Z","shell.execute_reply":"2022-05-08T10:43:12.732761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We test first the indices of the variables resulting after our custom transformers. These indices are important because ColumnTransformed used indices in the Pipeline.","metadata":{}},{"cell_type":"code","source":"fencoder = ('country_encoder', FrequencyEncoder(col_name = 'contry_of_res', rank = rank_country))\ncountry = ('country', RegionTransformer(continent = continent))\ndropper = ('dropper', DropperTransformer(features = ['age_desc', 'gender', 'used_app_before']))\n\nin_process = (country, dropper)\npipeline = Pipeline(steps = in_process)\ndf = pipeline.fit_transform(train)\n#pipeline[1].get_feature_names_out()\nfor i,col in enumerate(pipeline[1].get_feature_names_out()):\n    print(f'[{i:2d}] -> {col}')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:14.332948Z","iopub.execute_input":"2022-05-08T10:43:14.333389Z","iopub.status.idle":"2022-05-08T10:43:14.348864Z","shell.execute_reply.started":"2022-05-08T10:43:14.333356Z","shell.execute_reply":"2022-05-08T10:43:14.347946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =====================================================================\n# Tuples for Pipeline contain only the 'key' & Transformers\n# =====================================================================\nfencoder = ('country_encoder', FrequencyEncoder(col_name = 'contry_of_res', rank = rank_country))\ncountry = ('country', RegionTransformer(continent = continent))\ndropper = ('dropper', DropperTransformer(features = ['age_desc', 'gender', 'used_app_before']))\n\n# =====================================================================\n# Tuples for ColumnTransformer contain only the 'key',Transformers,col\n# =====================================================================\nz_scoring = ('z_scoring', StandardScaler(), [10, 14] ) # age, result\nbinarize = ('binarize', OneHotEncoder(sparse=False, drop= 'if_binary'), [12,13] ) # jaundice, austim\none_hot =  ('one_hot',  OneHotEncoder(sparse=False, handle_unknown='ignore'), [11, 16, 17] ) # ethnicity, relation, region\n\ncol_transformer = ColumnTransformer(transformers = (z_scoring, binarize, one_hot), remainder= 'passthrough')\n\ncol_preprocess = ('col_transformer', col_transformer)\n\npreprocess = Pipeline( steps = (fencoder, country, dropper, col_preprocess))#, RandomForestClassifier(random_state = 42))\npreprocess\n#make_pipeline(mypipeline, RandomForestClassifier(random_state=42))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:15.336769Z","iopub.execute_input":"2022-05-08T10:43:15.337099Z","iopub.status.idle":"2022-05-08T10:43:15.403277Z","shell.execute_reply.started":"2022-05-08T10:43:15.337051Z","shell.execute_reply":"2022-05-08T10:43:15.402622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the number of resulting variables are the same\npreprocess.fit_transform(X=train).shape, preprocess.fit_transform(X=test).shape","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:15.758578Z","iopub.execute_input":"2022-05-08T10:43:15.759004Z","iopub.status.idle":"2022-05-08T10:43:15.802955Z","shell.execute_reply.started":"2022-05-08T10:43:15.758972Z","shell.execute_reply":"2022-05-08T10:43:15.8023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =====================================================================\n# Tuples for make_pipeline contain only the Transformers\n# =====================================================================\n#country = (RegionTransformer(continent = continent))\n#dropper = (DropperTransformer(features = ['age_desc', 'contry_of_res']))\n\n# =====================================================================\n# Tuples for ColumnTransformer contain only the 'key',Transformers,col\n# =====================================================================\n#z_scoring = ('z_scoring', StandardScaler(), [10, 17] ) # age, result\n#binarize = ('binarize', OneHotEncoder(sparse=False, drop= 'if_binary'), [11, 13, 14, 16] ) # gender, jaundice, austim, used_app_before\n#one_hot =  ('one_hot',  OneHotEncoder(sparse=False, handle_unknown='ignore'), [12, 15, 18] ) # ethnicity, country_of_res, relation\n\n#col_preprocess = ColumnTransformer(transformers = (z_scoring, binarize, one_hot), remainder= 'passthrough')\n\n#preprocess = make_pipeline(country, dropper, col_preprocess)# note we don't need key, value tuples\n#preprocess\n#make_pipeline(mypipeline, RandomForestClassifier(random_state=42))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:16.929699Z","iopub.execute_input":"2022-05-08T10:43:16.929955Z","iopub.status.idle":"2022-05-08T10:43:16.934411Z","shell.execute_reply.started":"2022-05-08T10:43:16.92993Z","shell.execute_reply":"2022-05-08T10:43:16.933563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training\n[Back to Contents](#Contents)  \n\nWe will test the accuracy of our models when training the dataset with the most common classification methods.","metadata":{}},{"cell_type":"code","source":"# We first apply the preprocessing pipeline\nXtrain = preprocess.fit_transform(X = train)\nXtest = preprocess.fit_transform(X = test)\n\n# check resulting variables are the same after preprocessing\nassert(Xtrain.shape[1] == Xtest.shape[1])\n\n# check the same number of independent variables\nassert(Xtrain.shape[0] == train_target.shape[0])\n\n#Xtrain.shape, Xtest.shape, train_target.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:18.311828Z","iopub.execute_input":"2022-05-08T10:43:18.312634Z","iopub.status.idle":"2022-05-08T10:43:18.360112Z","shell.execute_reply.started":"2022-05-08T10:43:18.31258Z","shell.execute_reply":"2022-05-08T10:43:18.359468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# minimal reporting here\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import roc_curve, roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:19.263378Z","iopub.execute_input":"2022-05-08T10:43:19.26412Z","iopub.status.idle":"2022-05-08T10:43:19.268309Z","shell.execute_reply.started":"2022-05-08T10:43:19.264057Z","shell.execute_reply":"2022-05-08T10:43:19.267662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# minimal train/test split\nfrom sklearn.model_selection import train_test_split\n\n# we train with one-third of the dataset\nX_train, X_test, y_train, y_test = train_test_split(Xtrain, train_target, test_size=1/5., random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:20.177308Z","iopub.execute_input":"2022-05-08T10:43:20.177914Z","iopub.status.idle":"2022-05-08T10:43:20.184212Z","shell.execute_reply.started":"2022-05-08T10:43:20.177874Z","shell.execute_reply":"2022-05-08T10:43:20.183284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random_Forest\n[Back to Contents](#Contents)\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:21.541132Z","iopub.execute_input":"2022-05-08T10:43:21.54142Z","iopub.status.idle":"2022-05-08T10:43:21.629225Z","shell.execute_reply.started":"2022-05-08T10:43:21.541381Z","shell.execute_reply":"2022-05-08T10:43:21.628271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RF_clf = RandomForestClassifier(random_state = 42) # instance of model with default methods","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:22.558598Z","iopub.execute_input":"2022-05-08T10:43:22.558874Z","iopub.status.idle":"2022-05-08T10:43:22.562992Z","shell.execute_reply.started":"2022-05-08T10:43:22.558842Z","shell.execute_reply":"2022-05-08T10:43:22.562149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nRF_clf.fit(X = X_train, y = y_train) # training with 4/5 of the data\n\nprediction = RF_clf.predict(X = X_test) # predict the rest 1/5 \n\nprint(classification_report(y_test, prediction)) # accuracy 0.82\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:23.408943Z","iopub.execute_input":"2022-05-08T10:43:23.40937Z","iopub.status.idle":"2022-05-08T10:43:23.58713Z","shell.execute_reply.started":"2022-05-08T10:43:23.409332Z","shell.execute_reply":"2022-05-08T10:43:23.586127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(model, X:np.array, y_target:np.array) -> plt.figure:\n    \"\"\"\n    Plots confusion matrix and Receiver Operating Characteristic\n    (ROC) curve of the classifier\n    \n    Arguments:\n    ----------\n    predictor\n    X (array): input matrix\n    y_target (array) : target vector\n    \"\"\"\n    prediction = model.predict( X )\n    \n    # Compute donfusion matrix\n    cm = confusion_matrix(y_target, prediction, labels = model.classes_)\n    disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = model.classes_)\n    \n    fig, ax = plt.subplots(1,2, figsize=(8,4))\n    fig.tight_layout(pad = 3, h_pad = 2, w_pad = 4)\n    fig.suptitle(type(model).__name__)\n    ax[0] = disp.plot(ax = ax[0])\n\n    \n    # ROC curve\n    y_pred_prob = model.predict_proba(X)[::,1]\n    test_FP, test_TP, thresholds = roc_curve(y_target ,y_pred_prob)\n    auc = roc_auc_score(y_target, y_pred_prob)\n    \n    ax[1].plot(test_FP, test_TP, color='C0', label = f'AUC = {auc:2.2f}')\n    ax[1].plot([0, 1], [0, 1],'r--', lw=1)\n\n    ax[1].legend(loc =4, fontsize=10);\n\n    ax[1].set_ylabel('True Positive (TP)', fontsize=10);\n    ax[1].set_xlabel('False Positive (FP)', fontsize=10);\n\n    ax[1].set_title('Receiver Operating Characteristic (ROC) curve', fontsize=10);\n    \n    #return fig","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:24.226506Z","iopub.execute_input":"2022-05-08T10:43:24.227124Z","iopub.status.idle":"2022-05-08T10:43:24.235979Z","shell.execute_reply.started":"2022-05-08T10:43:24.22707Z","shell.execute_reply":"2022-05-08T10:43:24.235052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForest performance on test dataset (1/5 of the training dataset)\nplot_metrics(model = RF_clf,  X = X_test, y_target = y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:25.499496Z","iopub.execute_input":"2022-05-08T10:43:25.499777Z","iopub.status.idle":"2022-05-08T10:43:25.980023Z","shell.execute_reply.started":"2022-05-08T10:43:25.499751Z","shell.execute_reply":"2022-05-08T10:43:25.979249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictionfile(prediction: np.array, filename:str):\n    \"\"\"\n    Return submission file\n    \n    Arguments:\n    prediction: (array)\n        the estimator result of predict() method  \n    filename : (str)\n        filename to be saved\n    \"\"\"\n    # test input size\n    check_shape = prediction.shape == (200,)\n    assert check_shape, f'prediction shape expected (200,), got: {prediction.shape}'\n    \n    df = pd.DataFrame({'ID': test.index, 'Class/ASD': prediction})\n    print(f'{filename} with {df.shape[0]} predictions created')\n    return df.to_csv(filename, index=False)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:26.451984Z","iopub.execute_input":"2022-05-08T10:43:26.452759Z","iopub.status.idle":"2022-05-08T10:43:26.458229Z","shell.execute_reply.started":"2022-05-08T10:43:26.452708Z","shell.execute_reply":"2022-05-08T10:43:26.457369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we test our trained model with the Xtest restulting from the competition \nget_predictionfile(RF_clf.predict_proba(Xtest)[:,1], 'RF_submission.csv') # Score: ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:49.063217Z","iopub.execute_input":"2022-05-08T10:43:49.06387Z","iopub.status.idle":"2022-05-08T10:43:49.087893Z","shell.execute_reply.started":"2022-05-08T10:43:49.06383Z","shell.execute_reply":"2022-05-08T10:43:49.087039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic_Regression\n[Back to Contents](#Contents)","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:52.566492Z","iopub.execute_input":"2022-05-08T10:43:52.567345Z","iopub.status.idle":"2022-05-08T10:43:52.570731Z","shell.execute_reply.started":"2022-05-08T10:43:52.567304Z","shell.execute_reply":"2022-05-08T10:43:52.570166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_clf = LogisticRegression(random_state = 42,solver='liblinear')#, max_iter = 1500)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:53.614346Z","iopub.execute_input":"2022-05-08T10:43:53.614841Z","iopub.status.idle":"2022-05-08T10:43:53.618402Z","shell.execute_reply.started":"2022-05-08T10:43:53.614791Z","shell.execute_reply":"2022-05-08T10:43:53.617556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nLR_clf.fit(X = X_train, y = y_train) # training with 4/5 of the data\n\nprediction = LR_clf.predict(X = X_test) # predict the rest 1/5 \n\nprint(classification_report(y_test, prediction)) # accuracy 0.84","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:54.715749Z","iopub.execute_input":"2022-05-08T10:43:54.71604Z","iopub.status.idle":"2022-05-08T10:43:54.730887Z","shell.execute_reply.started":"2022-05-08T10:43:54.71601Z","shell.execute_reply":"2022-05-08T10:43:54.730244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression performance on test dataset (1/5 of the training dataset)\nplot_metrics(model = LR_clf,  X = X_test, y_target = y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:43:56.901999Z","iopub.execute_input":"2022-05-08T10:43:56.902732Z","iopub.status.idle":"2022-05-08T10:43:57.360798Z","shell.execute_reply.started":"2022-05-08T10:43:56.902694Z","shell.execute_reply":"2022-05-08T10:43:57.359999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we test our trained model with the Xtest restulting from the competition \nget_predictionfile(LR_clf.predict_proba(Xtest)[:,1], 'LR_submission.csv') # Score: 0.69984","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:08.596473Z","iopub.execute_input":"2022-05-08T10:44:08.597046Z","iopub.status.idle":"2022-05-08T10:44:08.605872Z","shell.execute_reply.started":"2022-05-08T10:44:08.596999Z","shell.execute_reply":"2022-05-08T10:44:08.605006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decission_Tree\n[Back to Contents](#Contents)","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:11.172537Z","iopub.execute_input":"2022-05-08T10:44:11.172924Z","iopub.status.idle":"2022-05-08T10:44:11.177164Z","shell.execute_reply.started":"2022-05-08T10:44:11.172894Z","shell.execute_reply":"2022-05-08T10:44:11.176223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DT_clf = DecisionTreeClassifier(random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:11.605465Z","iopub.execute_input":"2022-05-08T10:44:11.606037Z","iopub.status.idle":"2022-05-08T10:44:11.610507Z","shell.execute_reply.started":"2022-05-08T10:44:11.605979Z","shell.execute_reply":"2022-05-08T10:44:11.609812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nDT_clf.fit(X = X_train, y = y_train) # training with 4/5 of the data\n\nprediction = DT_clf.predict(X = X_test) # predict the rest 1/5 \n\nprint(classification_report(y_test, prediction)) # accuracy 0.81","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:12.5382Z","iopub.execute_input":"2022-05-08T10:44:12.538512Z","iopub.status.idle":"2022-05-08T10:44:12.553126Z","shell.execute_reply.started":"2022-05-08T10:44:12.538475Z","shell.execute_reply":"2022-05-08T10:44:12.552158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression performance on test dataset (1/5 of the training dataset)\nplot_metrics(model = DT_clf,  X = X_test, y_target = y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:13.850367Z","iopub.execute_input":"2022-05-08T10:44:13.850824Z","iopub.status.idle":"2022-05-08T10:44:14.292483Z","shell.execute_reply.started":"2022-05-08T10:44:13.850777Z","shell.execute_reply":"2022-05-08T10:44:14.291667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we test our trained model with the Xtest restulting from the competition \nget_predictionfile(prediction = DT_clf.predict_proba(Xtest)[:,1], filename = 'DT_submission.csv') # Score: 0.65117","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:26.246289Z","iopub.execute_input":"2022-05-08T10:44:26.246881Z","iopub.status.idle":"2022-05-08T10:44:26.256053Z","shell.execute_reply.started":"2022-05-08T10:44:26.246822Z","shell.execute_reply":"2022-05-08T10:44:26.255174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test models\n[Back to Contents](#Contents)\n\nWe will test a list of models and perform an hyperparameter search hyperparameter tunning and evaluate accuracy and some other metrics.","metadata":{"execution":{"iopub.status.busy":"2022-04-29T19:49:44.81301Z","iopub.execute_input":"2022-04-29T19:49:44.813668Z","iopub.status.idle":"2022-04-29T19:49:44.819809Z","shell.execute_reply.started":"2022-04-29T19:49:44.813612Z","shell.execute_reply":"2022-04-29T19:49:44.818696Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\nmyKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) # balanced split categories\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:29.557843Z","iopub.execute_input":"2022-05-08T10:44:29.558484Z","iopub.status.idle":"2022-05-08T10:44:29.563721Z","shell.execute_reply.started":"2022-05-08T10:44:29.558433Z","shell.execute_reply":"2022-05-08T10:44:29.562999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.svm import SVC\n\nfrom sklearn.naive_bayes import BernoulliNB\n\n\n\n\n\n# 1. Instances of all models \nRF_clf = RandomForestClassifier(random_state = 42)\nAD_clf = AdaBoostClassifier(random_state = 42)\nLR_clf = LogisticRegression(random_state = 42, solver='liblinear', max_iter = 1500)\nDT_clf = DecisionTreeClassifier(random_state=42)\n\nKN_clf = KNeighborsClassifier( )\nSVC_clf = SVC(degree=10, probability = True, random_state = 42)\n\nNB_clf = BernoulliNB( )\nGB_clf = GradientBoostingClassifier(random_state=42)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:30.835519Z","iopub.execute_input":"2022-05-08T10:44:30.836096Z","iopub.status.idle":"2022-05-08T10:44:30.846463Z","shell.execute_reply.started":"2022-05-08T10:44:30.836031Z","shell.execute_reply":"2022-05-08T10:44:30.845607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare hyperparameter dictionary of each estimator each having a key as classifier and value as estimator object. The hyperparameter keys should start with the word of the classifier separated by __ (double underscore). Check [this link](https://towardsdatascience.com/how-to-tune-multiple-ml-models-with-gridsearchcv-at-once-9fcebfcc6c23)","metadata":{}},{"cell_type":"code","source":"\n# ================================================\n# Random Forest \n# ================================================\nparam_RF = {}\nparam_RF['classifier__n_estimators'] = [10, 50, 100, 250]\nparam_RF['classifier__max_features'] = ['auto', 'sqrt', 'log2']\nparam_RF['classifier__max_depth'] = [5, 10, 20]\nparam_RF['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\nparam_RF['classifier'] = [RF_clf]\n\n# ================================================\n# Adaboost \n# ================================================\nparam_AD = {}\nparam_AD['classifier__n_estimators'] =  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20],\nparam_AD['classifier__learning_rate'] =  [(0.97 + x / 100) for x in range(0, 8)],\nparam_AD['classifier__algorithm'] =  ['SAMME', 'SAMME.R']\nparam_AD['classifier'] = [AD_clf]\n\n# ================================================\n# Logistic Regression\n# ================================================\nparam_LR = {}\nparam_LR['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\nparam_LR['classifier__penalty'] = ['l1', 'l2']\nparam_LR['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\nparam_LR['classifier'] = [LR_clf]\n\n# ================================================\n# Decission Tree\n# ================================================\nparam_DT = {}\nparam_DT['classifier__max_depth'] = [5,10,25,None]\nparam_DT['classifier__min_samples_leaf'] = [2,5,10]\nparam_DT['classifier__criterion'] = [\"gini\", \"entropy\"]\nparam_DT['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\nparam_DT['classifier'] = [DT_clf]\n\n# ================================================\n# k-Nearest Neighbours\n# ================================================\nparam_KN = {}\nparam_KN['classifier__n_neighbors'] = [5,7,9,11,13,15],\n#param_KN['classifier__weights'] = ['uniform','distance'],\n#param_KN['classifier__metric'] = ['minkowski','euclidean','manhattan']\nparam_KN['classifier'] = [KN_clf]\n\n# ================================================\n# Support Vector Classifier\n# ================================================\nparam_SVC = {}\nparam_SVC['classifier__C'] =  [0.1, 1, 10, 100], \nparam_SVC['classifier__gamma'] = [1,0.1,0.01,0.001],\nparam_SVC['classifier__kernel'] = ['rbf', 'poly', 'sigmoid']\nparam_SVC['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\nparam_SVC['classifier'] = [SVC_clf]\n\n# ================================================\n# Naive Bayes\n# ================================================\nparam_NB = {}\nparam_NB['classifier__alpha'] = np.logspace(0,-9, num=100)\nparam_NB['classifier'] = [NB_clf]\n\n# ================================================\n# Gradient Boosting\n# ================================================\nparam_GB = {}\nparam_GB['classifier__n_estimators'] = [10, 50, 100, 250]\nparam_GB['classifier__max_depth'] = [5, 10, 20]\nparam_GB['classifier'] = [GB_clf]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:32.810616Z","iopub.execute_input":"2022-05-08T10:44:32.811372Z","iopub.status.idle":"2022-05-08T10:44:32.825709Z","shell.execute_reply.started":"2022-05-08T10:44:32.811324Z","shell.execute_reply":"2022-05-08T10:44:32.825134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# IList the hyperparameter dictionary and prepare a pipeline of the 1st classifier\npipeline = Pipeline([('classifier', RF_clf)])\nmyparams = [param_RF, param_AD, param_LR, param_DT, param_KN, param_SVC, param_NB, param_GB]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:34.090471Z","iopub.execute_input":"2022-05-08T10:44:34.091102Z","iopub.status.idle":"2022-05-08T10:44:34.094944Z","shell.execute_reply.started":"2022-05-08T10:44:34.091048Z","shell.execute_reply":"2022-05-08T10:44:34.094354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Train a RandomizedSearchCV model with the pipeline and parameter dictionary list.\n\nmymodel = RandomizedSearchCV(pipeline, myparams, cv=myKFold, n_jobs=-1, scoring='roc_auc').fit(X = Xtrain, y = train_target)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:35.117948Z","iopub.execute_input":"2022-05-08T10:44:35.118469Z","iopub.status.idle":"2022-05-08T10:44:42.351645Z","shell.execute_reply.started":"2022-05-08T10:44:35.118421Z","shell.execute_reply":"2022-05-08T10:44:42.351007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mymodel.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:42.353126Z","iopub.execute_input":"2022-05-08T10:44:42.353448Z","iopub.status.idle":"2022-05-08T10:44:42.359105Z","shell.execute_reply.started":"2022-05-08T10:44:42.353417Z","shell.execute_reply":"2022-05-08T10:44:42.358527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROC-AUC score for the best model\nmymodel.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:45.02556Z","iopub.execute_input":"2022-05-08T10:44:45.026049Z","iopub.status.idle":"2022-05-08T10:44:45.032998Z","shell.execute_reply.started":"2022-05-08T10:44:45.026018Z","shell.execute_reply":"2022-05-08T10:44:45.032145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"mymodel.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:46.716952Z","iopub.execute_input":"2022-05-08T10:44:46.717944Z","iopub.status.idle":"2022-05-08T10:44:46.724057Z","shell.execute_reply.started":"2022-05-08T10:44:46.717898Z","shell.execute_reply":"2022-05-08T10:44:46.723459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pd.DataFrame(mymodel.best_estimator_.predict_proba(Xtest))\npredictions","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:49.560245Z","iopub.execute_input":"2022-05-08T10:44:49.561006Z","iopub.status.idle":"2022-05-08T10:44:49.574407Z","shell.execute_reply.started":"2022-05-08T10:44:49.560971Z","shell.execute_reply":"2022-05-08T10:44:49.573441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check https://www.kaggle.com/competitions/autismdiagnosis/discussion/323303\nget_predictionfile(mymodel.best_estimator_.predict_proba(Xtest)[:,1], 'submission.csv') # score: 0.84344","metadata":{"execution":{"iopub.status.busy":"2022-05-08T10:44:52.442018Z","iopub.execute_input":"2022-05-08T10:44:52.442301Z","iopub.status.idle":"2022-05-08T10:44:52.450991Z","shell.execute_reply.started":"2022-05-08T10:44:52.442273Z","shell.execute_reply":"2022-05-08T10:44:52.450066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}