{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b>1 <span style='color:#E71414'>|</span> Importing libraries</b>\n- **For ML Models**: tensorflow, keras\n- **For Data Manipulation**: numpy, sklearn, PIL\n- **For Data Visualization**: matplotlib, seaborn, plotly","metadata":{}},{"cell_type":"code","source":"# For Data Processing & ML Models\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom PIL import Image, ImageEnhance\n\n# For Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Miscellaneous\nfrom tqdm import tqdm\nimport os\nimport random\n\n# Turn off warnings\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","metadata":{"execution":{"iopub.status.busy":"2022-04-30T21:10:09.276672Z","iopub.execute_input":"2022-04-30T21:10:09.277199Z","iopub.status.idle":"2022-04-30T21:10:19.175859Z","shell.execute_reply.started":"2022-04-30T21:10:09.277068Z","shell.execute_reply":"2022-04-30T21:10:19.174869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>2 <span style='color:#E71414'>| </span> Reading the Dataset</b>","metadata":{}},{"cell_type":"code","source":"unique_labels = ['Karacadag', 'Basmati', 'Jasmine', 'Arborio', 'Ipsala']\n\ndata_dir = '/kaggle/input/rice-image-dataset/Rice_Image_Dataset/'\n\nall_paths = []\nall_labels = []\n\nfor label in unique_labels:\n    for image_path in os.listdir(data_dir+label):\n        all_paths.append(data_dir+label+'/'+image_path)\n        all_labels.append(label)\n'''\nAn image of path all_paths[i] has the label all_labels[i], where i is an index\n'''\nall_paths, all_labels = shuffle(all_paths, all_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:10:03.224001Z","iopub.execute_input":"2022-04-30T13:10:03.224272Z","iopub.status.idle":"2022-04-30T13:10:03.33041Z","shell.execute_reply.started":"2022-04-30T13:10:03.224244Z","shell.execute_reply":"2022-04-30T13:10:03.329706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values = [len([x for x in all_labels if x==label]) for label in unique_labels]\nfig = go.Figure(data=[go.Pie(labels=unique_labels, values=values, rotation=-45, hole=.3, textinfo='label+percent')])\nfig.update_layout(showlegend=False)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:10:04.551898Z","iopub.execute_input":"2022-04-30T13:10:04.552734Z","iopub.status.idle":"2022-04-30T13:10:04.581443Z","shell.execute_reply.started":"2022-04-30T13:10:04.552638Z","shell.execute_reply":"2022-04-30T13:10:04.580755Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The dataset is perfectly balanced","metadata":{}},{"cell_type":"markdown","source":"# <b>3 <span style='color:#E71414; font-weight: bold;'>|</span> Data Preprocessing</b>","metadata":{}},{"cell_type":"markdown","source":"<h2>3.1 <span style='color:#E71414; font-weight: bold;'>|</span> Train-Val Split</h2>  ","metadata":{}},{"cell_type":"markdown","source":"- 90% for training\n- 10% for validation","metadata":{}},{"cell_type":"code","source":"x_train_paths, x_val_paths, y_train, y_val = train_test_split(all_paths, all_labels,\n                                                              test_size=0.1, random_state=42,\n                                                              stratify=all_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:15:01.646413Z","iopub.execute_input":"2022-04-30T13:15:01.646691Z","iopub.status.idle":"2022-04-30T13:15:01.741438Z","shell.execute_reply.started":"2022-04-30T13:15:01.646662Z","shell.execute_reply":"2022-04-30T13:15:01.740723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>3.2 <span style='color:#E71414; font-weight: bold;'>|</span> Image Data Augmentation</h2>  ","metadata":{}},{"cell_type":"markdown","source":"- Random Brightness from 60% to 140%\n- Random Contrast from 60% to 140%","metadata":{}},{"cell_type":"code","source":"BRIGHTNESS = (0.6, 1.4)\nCONTRAST   = (0.6, 1.4)\n\ndef augment_image(image):\n    image = Image.fromarray(np.uint8(image))\n    image = ImageEnhance.Brightness(image).enhance(random.uniform(BRIGHTNESS[0],BRIGHTNESS[1]))\n    image = ImageEnhance.Contrast(image).enhance(random.uniform(CONTRAST[0],CONTRAST[1]))\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:22:09.465Z","iopub.execute_input":"2022-04-30T13:22:09.465635Z","iopub.status.idle":"2022-04-30T13:22:09.471334Z","shell.execute_reply.started":"2022-04-30T13:22:09.465589Z","shell.execute_reply":"2022-04-30T13:22:09.470398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>3.3 <span style='color:#E71414; font-weight: bold;'>|</span> Label encoder-decoder</h2>  ","metadata":{}},{"cell_type":"code","source":"def encode_labels(labels):\n    encoded = []\n    for x in labels:\n        encoded.append(unique_labels.index(x))\n    return np.array(encoded)\n\ndef decode_labels(labels):\n    decoded = []\n    for x in labels:\n        decoded.append(unique_labels[x])\n    return np.array(decoded)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:22:11.101455Z","iopub.execute_input":"2022-04-30T13:22:11.10226Z","iopub.status.idle":"2022-04-30T13:22:11.108082Z","shell.execute_reply.started":"2022-04-30T13:22:11.102223Z","shell.execute_reply":"2022-04-30T13:22:11.106876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>3.4 <span style='color:#E71414; font-weight: bold;'>|</span> Load images</h2>  ","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 96","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:22:12.236537Z","iopub.execute_input":"2022-04-30T13:22:12.237019Z","iopub.status.idle":"2022-04-30T13:22:12.241192Z","shell.execute_reply.started":"2022-04-30T13:22:12.236986Z","shell.execute_reply":"2022-04-30T13:22:12.240505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def open_images(paths, augment=True):\n    '''\n    Given a list of paths to images, this function returns the images as arrays, and conditionally augments them\n    '''\n    images = []\n    for path in paths:\n        image = load_img(path, target_size=(IMAGE_SIZE,IMAGE_SIZE))\n        if augment:\n            image = augment_image(image)\n        image = np.array(image)/255.0\n        images.append(image)\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:22:13.254234Z","iopub.execute_input":"2022-04-30T13:22:13.254548Z","iopub.status.idle":"2022-04-30T13:22:13.266589Z","shell.execute_reply.started":"2022-04-30T13:22:13.254513Z","shell.execute_reply":"2022-04-30T13:22:13.265425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Example usage of `open_images` function","metadata":{}},{"cell_type":"code","source":"# Load images and their labels\nimages = open_images(x_train_paths[50:59])\nlabels = y_train[50:59]\n\n# Plot images with their labels\nfig = plt.figure(figsize=(12, 6))\nfor x in range(1, 9):\n    fig.add_subplot(2, 4, x)\n    plt.axis('off')\n    plt.title(labels[x])\n    plt.imshow(images[x])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:22:14.329345Z","iopub.execute_input":"2022-04-30T13:22:14.329633Z","iopub.status.idle":"2022-04-30T13:22:14.70902Z","shell.execute_reply.started":"2022-04-30T13:22:14.329601Z","shell.execute_reply":"2022-04-30T13:22:14.70831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>3.5 <span style='color:#E71414; font-weight: bold;'>|</span> Data Generator</h2>  \n<p style=\"font-size:15px; line-height: 1.7em\">\n    Given a list of paths to images, and the labels, <br>\n    this function augments the images, normalizes them, encodes the label, and then returns the batch on which the model can train on. <br>\n</p>","metadata":{}},{"cell_type":"code","source":"def datagen(paths, labels, batch_size=12, epochs=3, augment=True):\n    for _ in range(epochs):\n        for x in range(0, len(paths), batch_size):\n            batch_paths = paths[x:x+batch_size]\n            batch_images = open_images(batch_paths, augment=augment)\n            batch_labels = labels[x:x+batch_size]\n            batch_labels = encode_labels(batch_labels)\n            yield batch_images, batch_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:10:11.726366Z","iopub.execute_input":"2022-04-30T12:10:11.726646Z","iopub.status.idle":"2022-04-30T12:10:11.730435Z","shell.execute_reply.started":"2022-04-30T12:10:11.726616Z","shell.execute_reply":"2022-04-30T12:10:11.729576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>4 <span style='color:#E71414; font-weight: bold;'>|</span> Model</b>","metadata":{}},{"cell_type":"markdown","source":"<h2>4.1 <span style='color:#E71414; font-weight: bold;'>|</span> Build Model</h2>  ","metadata":{}},{"cell_type":"markdown","source":"<h3>I am using <span style = \"color:#E71414; font-weight: normal;\">VGG16</span> for transfer learning</h3>","metadata":{}},{"cell_type":"code","source":"base_model = VGG16(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3), include_top=False, weights='imagenet')\n# Set all layers to non trainable\nfor layer in base_model.layers:\n    layer.trainable = False\n# Set the last VGG block to trainable\nbase_model.layers[-2].trainable = True\nbase_model.layers[-3].trainable = True\nbase_model.layers[-4].trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:20:26.114065Z","iopub.execute_input":"2022-04-30T12:20:26.114381Z","iopub.status.idle":"2022-04-30T12:20:26.432993Z","shell.execute_reply.started":"2022-04-30T12:20:26.114347Z","shell.execute_reply":"2022-04-30T12:20:26.432233Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3)))\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(len(unique_labels), activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:20:39.908575Z","iopub.execute_input":"2022-04-30T12:20:39.909077Z","iopub.status.idle":"2022-04-30T12:20:39.98306Z","shell.execute_reply.started":"2022-04-30T12:20:39.909043Z","shell.execute_reply":"2022-04-30T12:20:39.982265Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:20:44.086623Z","iopub.execute_input":"2022-04-30T12:20:44.087222Z","iopub.status.idle":"2022-04-30T12:20:44.098849Z","shell.execute_reply.started":"2022-04-30T12:20:44.087184Z","shell.execute_reply":"2022-04-30T12:20:44.098038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>4.2 <span style='color:#E71414; font-weight: bold;'>|</span> Compile Model</h2>  ","metadata":{}},{"cell_type":"markdown","source":"`SparseCategoricalCrossentropy` and `CategoricalCrossentropy` are basically the same loss functions, just their input formats are different.  \n\n$$\\mathrm{Loss} = -\\cfrac{1}{N}\\sum_{i=1}^N [y_i\\text{log}(\\hat y_i) + (1-y_i)\\text{log}(1-\\hat y_i)]$$\nwhere,  \n$\\hat y$ is the predicted label, and $y$ is the actual label  \n$y_i$ is the $i^\\mathbf{th}$ sample of $y$  and $\\hat y_i$ is the $i^\\mathbf{th}$ sample of $\\hat y$  \n$N$ is the number of samples\n\nIf $y_i$ is **one-hot encoded**, we use `CategoricalCrossentropy`, and if $y_i$ is **integer-encoded**, we use `SparseCategoricalCrossentropy`\n\nIn our case, our labels are **integer-encoded**, so we are using `SparseCategoricalCrossentropy`  ","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001),\n              loss='sparse_categorical_crossentropy',\n              metrics=['sparse_categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T12:20:46.329445Z","iopub.execute_input":"2022-04-30T12:20:46.330005Z","iopub.status.idle":"2022-04-30T12:20:46.340269Z","shell.execute_reply.started":"2022-04-30T12:20:46.329971Z","shell.execute_reply":"2022-04-30T12:20:46.339531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>4.3 <span style='color:#E71414; font-weight: bold;'>|</span> Train Model</h2>  ","metadata":{}},{"cell_type":"code","source":"batch_size = 64\nsteps = int(len(x_train_paths)/batch_size)\nepochs = 5\nhistory = model.fit(datagen(x_train_paths, y_train, batch_size=batch_size, epochs=epochs),\n                    epochs=epochs, steps_per_epoch=steps)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:32:08.718437Z","iopub.execute_input":"2022-04-30T13:32:08.719143Z","iopub.status.idle":"2022-04-30T13:34:30.786374Z","shell.execute_reply.started":"2022-04-30T13:32:08.719106Z","shell.execute_reply":"2022-04-30T13:34:30.785609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>4.4 <span style='color:#E71414; font-weight: bold;'>|</span> Evaluate Model</h2>  ","metadata":{}},{"cell_type":"code","source":"batch_size=128\nsteps = int(len(x_val_paths)/batch_size)\ny_pred = []\ny_true = []\nfor x,y in tqdm(datagen(x_val_paths, y_val, batch_size=batch_size, epochs=1, augment=False), total=steps):\n    pred = model.predict(x)\n    pred = np.argmax(pred, axis=-1)\n    for i in decode_labels(pred):\n        y_pred.append(i)\n    for i in decode_labels(y):\n        y_true.append(i)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:34:41.673315Z","iopub.execute_input":"2022-04-30T13:34:41.673863Z","iopub.status.idle":"2022-04-30T13:35:18.150982Z","shell.execute_reply.started":"2022-04-30T13:34:41.673824Z","shell.execute_reply":"2022-04-30T13:35:18.149645Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_true, y_pred, digits=3))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:35:29.470992Z","iopub.execute_input":"2022-04-30T13:35:29.471256Z","iopub.status.idle":"2022-04-30T13:35:29.699226Z","shell.execute_reply.started":"2022-04-30T13:35:29.471229Z","shell.execute_reply":"2022-04-30T13:35:29.698299Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(10,8))\n\nax = sns.heatmap(cm/np.sum(cm),fmt='.2%', annot=True, cmap='Blues')\n\nax.set_title('Confusion Matrix with labels\\n');\nax.set_xlabel('\\nPredicted Values')\nax.set_ylabel('Actual Values ');\n\nax.xaxis.set_ticklabels(unique_labels)\nax.yaxis.set_ticklabels(unique_labels)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:35:32.021134Z","iopub.execute_input":"2022-04-30T13:35:32.021546Z","iopub.status.idle":"2022-04-30T13:35:32.385881Z","shell.execute_reply.started":"2022-04-30T13:35:32.021512Z","shell.execute_reply":"2022-04-30T13:35:32.385178Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b>5 <span style='color:#E71414; font-weight: bold;'>|</span> Inference</b>","metadata":{}},{"cell_type":"code","source":"def predict(images):\n    pred = model.predict(images)\n    pred = np.argmax(pred, axis=-1)\n    pred = decode_labels(pred)\n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:35:34.693729Z","iopub.execute_input":"2022-04-30T13:35:34.694386Z","iopub.status.idle":"2022-04-30T13:35:34.701169Z","shell.execute_reply.started":"2022-04-30T13:35:34.694349Z","shell.execute_reply":"2022-04-30T13:35:34.700429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES = 8\nidx = random.sample(range(len(y_val)), NUM_IMAGES)\n\nlabels = [y_val[x] for x in idx]\nimage_paths = [x_val_paths[x] for x in idx]\nimages = open_images(image_paths, augment=False)\npred = predict(images)\n\ncols = 4\nrows = 2\nfig = plt.figure(figsize=(12, 7))\n\nfor x in range(NUM_IMAGES):\n    fig.add_subplot(rows, cols, x+1)\n    plt.axis('off')\n    plt.title('Predicted:'+str(labels[x])+'\\nActual:'+str(labels[x]))\n    plt.imshow(images[x])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T13:39:01.870985Z","iopub.execute_input":"2022-04-30T13:39:01.87186Z","iopub.status.idle":"2022-04-30T13:39:02.313928Z","shell.execute_reply.started":"2022-04-30T13:39:01.871822Z","shell.execute_reply":"2022-04-30T13:39:02.313237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Please Upvote this notebook as it encourages me in doing better.\n![](http://68.media.tumblr.com/e1aed171ded2bd78cc8dc0e73b594eaf/tumblr_o17frv0cdu1u9u459o1_500.gif)","metadata":{}}]}