{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport sklearn \nimport seaborn as sns\nimport hyperopt\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nSEED = 1\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-08T13:56:39.243921Z","iopub.execute_input":"2022-05-08T13:56:39.244646Z","iopub.status.idle":"2022-05-08T13:56:39.254023Z","shell.execute_reply.started":"2022-05-08T13:56:39.244607Z","shell.execute_reply":"2022-05-08T13:56:39.253469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntestData = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ngenderSubmission = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\ntrainData.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:56:39.531638Z","iopub.execute_input":"2022-05-08T13:56:39.532267Z","iopub.status.idle":"2022-05-08T13:56:39.561643Z","shell.execute_reply.started":"2022-05-08T13:56:39.53222Z","shell.execute_reply":"2022-05-08T13:56:39.560624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testData.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:56:39.706224Z","iopub.execute_input":"2022-05-08T13:56:39.706529Z","iopub.status.idle":"2022-05-08T13:56:39.722229Z","shell.execute_reply.started":"2022-05-08T13:56:39.706498Z","shell.execute_reply":"2022-05-08T13:56:39.721335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData.hist(figsize=(20,20),bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:56:39.885743Z","iopub.execute_input":"2022-05-08T13:56:39.886027Z","iopub.status.idle":"2022-05-08T13:56:42.214443Z","shell.execute_reply.started":"2022-05-08T13:56:39.885996Z","shell.execute_reply":"2022-05-08T13:56:42.213591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(trainData.columns)\nprint(\"Size of the dataset\")\nprint(len(trainData))\nfor col in trainData.columns:\n    print(\"Col : \", col)\n    if(col == 'Name' or col == 'PassengerId'):\n        continue\n    print('map ', np.array(map(str, trainData[col].unique())))\n    print(np.sort(np.array(list(map(str, trainData[col].unique())))))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:56:42.216334Z","iopub.execute_input":"2022-05-08T13:56:42.216648Z","iopub.status.idle":"2022-05-08T13:56:42.244811Z","shell.execute_reply.started":"2022-05-08T13:56:42.216607Z","shell.execute_reply":"2022-05-08T13:56:42.243969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cabin extraction","metadata":{}},{"cell_type":"code","source":"def CabinLeter(x):\n    if(pd.isnull(x)):\n        return np.nan\n    else:\n        return x[0]\n    \ndef CabinNumber(x):\n    if(pd.isnull(x)):\n        return np.nan\n    else:\n        #Trait the case where we have more than 1 x\n        x = x.split()\n        if(len(x[0]) < 2):\n            return np.nan\n        return int(x[0][1:])\n    \ndef CabinLen(x):\n    if(pd.isnull(x)):\n        return np.nan\n    else:\n        x = x.split()\n        return len(x)\n\ndef CabinExtraction(data):\n    data['CabinLetter'] = data['Cabin'].apply(CabinLeter)\n    data['CabinNumber'] = data['Cabin'].apply(CabinNumber)\n    data['CabinLen'] = data['Cabin'].apply(CabinLen)\n    \nCabinExtraction(testData)\nCabinExtraction(trainData)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:56:42.245965Z","iopub.execute_input":"2022-05-08T13:56:42.24619Z","iopub.status.idle":"2022-05-08T13:56:42.2654Z","shell.execute_reply.started":"2022-05-08T13:56:42.246164Z","shell.execute_reply":"2022-05-08T13:56:42.264694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(trainData['CabinLetter'].unique())\nprint(trainData['CabinNumber'].unique())\nprint(trainData['CabinLen'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:56:42.267146Z","iopub.execute_input":"2022-05-08T13:56:42.267828Z","iopub.status.idle":"2022-05-08T13:56:42.275688Z","shell.execute_reply.started":"2022-05-08T13:56:42.267797Z","shell.execute_reply":"2022-05-08T13:56:42.275035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Name extraction","metadata":{}},{"cell_type":"code","source":"def familyName(x):\n    if(pd.isnull(x)):\n        return np.nan\n    else:\n        return x.split()[0][:-1]\n    \ntrainData['familyName'] = trainData['Name'].apply(familyName)\ntestData['familyName'] = testData['Name'].apply(familyName)\n\nprint(trainData['familyName'].value_counts())\nvalueCountRed = trainData['familyName'].value_counts()[trainData['familyName'].value_counts()>5]\nprint(valueCountRed[:10])\nprint('Number value count red', len(valueCountRed))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:44.95539Z","iopub.execute_input":"2022-05-08T14:20:44.956046Z","iopub.status.idle":"2022-05-08T14:20:44.973582Z","shell.execute_reply.started":"2022-05-08T14:20:44.956009Z","shell.execute_reply":"2022-05-08T14:20:44.972625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's look at the Andersson :\ntrainData[trainData['familyName'] == 'Andersson']","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:46.177835Z","iopub.execute_input":"2022-05-08T14:20:46.178097Z","iopub.status.idle":"2022-05-08T14:20:46.210457Z","shell.execute_reply.started":"2022-05-08T14:20:46.178068Z","shell.execute_reply":"2022-05-08T14:20:46.209673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ticket extraction","metadata":{}},{"cell_type":"code","source":"def ticketNumber(x):\n    if(pd.isnull(x)):\n        return np.nan\n    else:\n        x = x.split()\n        if(x[-1] == 'LINE'):\n            return np.nan\n        return int(x[-1])\n\ndef ticketText(x):\n    if(pd.isnull(x)):\n        return np.nan\n    else:\n        x = x.split()\n        if(len(x)==1):\n            return \" \"\n        else:\n            return x[0]\n        \ndef uniqueTicket(x):\n    return x in non_unique_tickets.index\n\n\ndef ticketExtraction(data):\n    data['ticketNumber'] = data['Ticket'].apply(ticketNumber)\n    data['ticketText'] = data['Ticket'].apply(ticketText)\n    data['uniqueTicket'] = data['Ticket'].apply(uniqueTicket)\n    \n\nnon_unique_tickets = trainData['Ticket'].value_counts()[trainData['Ticket'].value_counts().values>1]\n    \nticketExtraction(trainData)\nticketExtraction(testData)\n\nprint('Non unique tickets')\nprint(non_unique_tickets.index)\n\n\nplt.show()\nplt.figure(figsize=(40,10))\nplt.hist(trainData['ticketText'],bins=len(trainData['ticketText'].unique()),align='mid',log=True)\nplt.show()\n\nvalueCountTicketRed = trainData['ticketText'].value_counts()[trainData['ticketText'].value_counts()>10]\nprint(valueCountTicketRed[:10])\nprint('Number value count red', len(valueCountTicketRed))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:47.28504Z","iopub.execute_input":"2022-05-08T14:20:47.285342Z","iopub.status.idle":"2022-05-08T14:20:47.951233Z","shell.execute_reply.started":"2022-05-08T14:20:47.285301Z","shell.execute_reply":"2022-05-08T14:20:47.950275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Age extraction","metadata":{}},{"cell_type":"code","source":"#Look the influence of the age with the probability of surviving\nfig, ax = plt.subplots()\nprint(trainData['Age'][trainData['Survived'] == 1].dropna())\na_heights, a_bins = np.histogram(trainData['Age'][trainData['Survived'] == 1].dropna(),bins=20)\nb_heights, b_bins = np.histogram(trainData['Age'][trainData['Survived'] == 0].dropna(), bins=a_bins)\nwidth = (a_bins[1] - a_bins[0])/3\n\nax.bar(a_bins[:-1], a_heights, width=width, facecolor='cornflowerblue',label='survived')\nax.bar(b_bins[:-1]+width, b_heights, width=width, facecolor='seagreen',label='dead')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:49.117947Z","iopub.execute_input":"2022-05-08T14:20:49.118372Z","iopub.status.idle":"2022-05-08T14:20:49.410894Z","shell.execute_reply.started":"2022-05-08T14:20:49.118337Z","shell.execute_reply":"2022-05-08T14:20:49.41018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData['child'] = np.where(trainData['Age'] > 18,0,1)\ntestData['child'] = np.where(testData['Age'] > 18,0,1)\ntrainData['youngAdult'] = np.where(np.logical_and(trainData['Age'] > 18, trainData['Age'] < 25),1,0)\ntestData['youngAdult'] = np.where(np.logical_and(testData['Age'] > 18, testData['Age'] < 25),1,0)\n\nsv_ya = trainData['Survived'][trainData['youngAdult'] == 1]\nsv_nya = trainData['Survived'][trainData['youngAdult'] == 0]\nprint(\"Ratio young_men survived: \", np.sum(sv_ya)/len(sv_ya))\nprint(\"Ratio young_men dead: \", np.sum(sv_nya)/len(sv_nya))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:49.412073Z","iopub.execute_input":"2022-05-08T14:20:49.412278Z","iopub.status.idle":"2022-05-08T14:20:49.429908Z","shell.execute_reply.started":"2022-05-08T14:20:49.412233Z","shell.execute_reply":"2022-05-08T14:20:49.42884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fare analysis ","metadata":{}},{"cell_type":"markdown","source":"We observe that when the fair is null they have all embarked at S and are all male their survival rate is also very low","metadata":{}},{"cell_type":"code","source":"print(trainData['Fare'].describe())\nprint(\"Fraction of nan: \", trainData['Fare'].isnull().sum()/len(trainData))\ntrainData[trainData['Fare']==0]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:50.219638Z","iopub.execute_input":"2022-05-08T14:20:50.220287Z","iopub.status.idle":"2022-05-08T14:20:50.262801Z","shell.execute_reply.started":"2022-05-08T14:20:50.220254Z","shell.execute_reply":"2022-05-08T14:20:50.261975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testData[testData['Fare']==0]","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:51.147693Z","iopub.execute_input":"2022-05-08T14:20:51.14795Z","iopub.status.idle":"2022-05-08T14:20:51.175447Z","shell.execute_reply.started":"2022-05-08T14:20:51.147923Z","shell.execute_reply":"2022-05-08T14:20:51.174636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Look the influence of the age with the probability of surviving\nfig, ax = plt.subplots()\nfig.set_figheight(2)\nfig.set_figwidth(20)\n\na_heights, a_bins = np.histogram(trainData['Fare'][trainData['Survived'] == 1].dropna(),bins=100)\nb_heights, b_bins = np.histogram(trainData['Fare'][trainData['Survived'] == 0].dropna(), bins=a_bins)\nwidth = (a_bins[1] - a_bins[0])/3\n\nax.bar(a_bins[:-1], a_heights, width=width, facecolor='cornflowerblue',label='survived')\nax.bar(b_bins[:-1]+width, b_heights, width=width, facecolor='seagreen',label='dead')\nplt.yscale('log')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:51.864097Z","iopub.execute_input":"2022-05-08T14:20:51.864366Z","iopub.status.idle":"2022-05-08T14:20:52.743408Z","shell.execute_reply.started":"2022-05-08T14:20:51.864338Z","shell.execute_reply":"2022-05-08T14:20:52.742598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainData['zeroFare'] = np.where(trainData['Fare']==0,1,0)\ntestData['zeroFare'] = np.where(testData['Fare']==0,1,0)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:52.744914Z","iopub.execute_input":"2022-05-08T14:20:52.745117Z","iopub.status.idle":"2022-05-08T14:20:52.750447Z","shell.execute_reply.started":"2022-05-08T14:20:52.745091Z","shell.execute_reply":"2022-05-08T14:20:52.749586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One-hot encoding","metadata":{}},{"cell_type":"code","source":"def one_hot_encoding(data,valueCountRed,valueCountTicketRed,ret):\n    \n    #FamilyNames\n    dataDumFamily = pd.DataFrame()\n    for name in valueCountRed.index:\n        if(len(dataDumFamily) == 0):\n            dataDumFamily = pd.DataFrame(np.where(data['familyName'] == name,1,0))\n        else:\n            dataDumFamily['Family_' + str(name)] = np.where(data['familyName'] == name,1,0)\n\n    #Ticket\n    dataDumTicket = pd.DataFrame()\n    for name in valueCountTicketRed.index:\n        if(len(dataDumTicket) == 0):\n            dataDumTicket = pd.DataFrame(np.where(data['ticketText'] == name,1,0))\n        else:\n            dataDumTicket['Ticket_' + str(name)] = np.where(data['ticketText'] == name,1,0)\n\n    #Embarked\n    dataDum = pd.concat([dataDumFamily, pd.get_dummies(data.Embarked, prefix='Embarked')],axis=1)\n    dataDum = pd.concat([dataDum, dataDumTicket],axis=1)\n    #Cabin Letter\n    dataDum = pd.concat([dataDum, pd.get_dummies(data.CabinLetter, prefix='CabinLetter')],axis=1)\n    if(ret):\n        #There is one feature that we need to add: CabinLetter_T\n        dataDum['CabinLetter_T'] = 0\n    #Pclass\n    dataDum = pd.concat([dataDum, pd.get_dummies(data.Pclass, prefix='Pclass')],axis=1)\n    dataDum['sex'] = np.where(data['Sex'] == 'male',0,1)\n    dataDum = dataDum.drop([0],axis=1)\n    return dataDum\n    \ntrainDataDum = one_hot_encoding(trainData,valueCountRed,valueCountTicketRed,False)\ntestDataDum = one_hot_encoding(testData,valueCountRed,valueCountTicketRed,True)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:20:53.084911Z","iopub.execute_input":"2022-05-08T14:20:53.085175Z","iopub.status.idle":"2022-05-08T14:20:53.128808Z","shell.execute_reply.started":"2022-05-08T14:20:53.085147Z","shell.execute_reply":"2022-05-08T14:20:53.128106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merge features","metadata":{}},{"cell_type":"code","source":"def mergeFeatures(data,dataDum,ret,mode):\n    X = data\n    if(not ret):\n        y = data['Survived']\n        dropList = ['Cabin','PassengerId','Embarked','Survived','Name','Sex','familyName','CabinLetter','Ticket','Pclass', 'ticketText']\n    else:\n        y = None\n        dropList = ['Cabin','PassengerId','Embarked','Name','Sex','familyName','CabinLetter','Ticket','Pclass', 'ticketText']\n        \n    if(mode=='dropNumber'):\n        dropList.append(\"ticketNumber\")\n        dropList.append(\"CabinNumber\")\n        \n    X = X.drop(dropList,axis=1)\n    X = pd.concat([X,dataDum],axis=1)\n    return X,y\n\nX,y = mergeFeatures(trainData,trainDataDum,False,mode='dropNumber')\nX_ret,_ = mergeFeatures(testData, testDataDum,True,mode='dropNumber')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:50:58.107871Z","iopub.execute_input":"2022-05-08T14:50:58.108476Z","iopub.status.idle":"2022-05-08T14:50:58.121833Z","shell.execute_reply.started":"2022-05-08T14:50:58.108426Z","shell.execute_reply":"2022-05-08T14:50:58.1212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understand the dataset","metadata":{}},{"cell_type":"code","source":"#print(X.info())\n#print(X_ret.info())","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:50:58.588922Z","iopub.execute_input":"2022-05-08T14:50:58.589857Z","iopub.status.idle":"2022-05-08T14:50:58.594878Z","shell.execute_reply.started":"2022-05-08T14:50:58.589819Z","shell.execute_reply":"2022-05-08T14:50:58.593549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(X.describe().T)\n#print(X_ret.describe().T)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:50:59.125048Z","iopub.execute_input":"2022-05-08T14:50:59.125463Z","iopub.status.idle":"2022-05-08T14:50:59.128855Z","shell.execute_reply.started":"2022-05-08T14:50:59.125431Z","shell.execute_reply":"2022-05-08T14:50:59.128001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame.corrwith(X,y).sort_values()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:50:59.487971Z","iopub.execute_input":"2022-05-08T14:50:59.48856Z","iopub.status.idle":"2022-05-08T14:50:59.512027Z","shell.execute_reply.started":"2022-05-08T14:50:59.488524Z","shell.execute_reply":"2022-05-08T14:50:59.511303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Treat NAN values","metadata":{}},{"cell_type":"code","source":"def percent_missing_fun(data):\n    percent_missing = data.isnull().sum() * 100 / len(data)\n    return percent_missing[percent_missing>0].sort_values(ascending=False)\n    \nprint(\"TRAIN X\")\nprint(percent_missing_fun(X))\nprint(\"TEST X\")\nprint(percent_missing_fun(X_ret))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:56:46.60518Z","iopub.execute_input":"2022-05-08T13:56:46.606014Z","iopub.status.idle":"2022-05-08T13:56:46.621835Z","shell.execute_reply.started":"2022-05-08T13:56:46.605962Z","shell.execute_reply":"2022-05-08T13:56:46.621164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine learning","metadata":{}},{"cell_type":"code","source":"#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)   \ndef ACC_model(dtrain,y_train,dtest,y_test,model):\n    \n    y_pred = np.where(model.predict(dtest)>0.5,1,0)\n    accuracyTest = accuracy_score(y_test, y_pred)\n    y_pred = np.where(model.predict(dtrain)>0.5,1,0)\n    accuracyTrain = accuracy_score(y_train, y_pred)\n    return accuracyTest,accuracyTrain\n\ndef printACC(ACCTestList,ACCTrainList):\n    print('---------------------------')\n    print('Test set')\n    print('Mean')\n    print(np.mean(ACCTestList))\n    print('Std')\n    print(np.std(ACCTestList))\n    print('Train set')\n    print('Mean')\n    print(np.mean(ACCTrainList))\n    print('Std')\n    print(np.std(ACCTrainList))\n    print('--------------------------')\n    \ndef printACCRed(ACCTestList,ACCTrainList):\n     print(str(np.mean(ACCTestList))+ \" \"+ str(np.mean(ACCTrainList)))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T13:56:47.803767Z","iopub.execute_input":"2022-05-08T13:56:47.804176Z","iopub.status.idle":"2022-05-08T13:56:47.81276Z","shell.execute_reply.started":"2022-05-08T13:56:47.804145Z","shell.execute_reply":"2022-05-08T13:56:47.811718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_cv(model,k=10):\n\n    kf = KFold(n_splits=k)\n    kf.get_n_splits(X)\n    print(kf)\n    ACCTestList = []\n    ACCTrainList = []\n    KFold(n_splits=2, random_state=None, shuffle=False)\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        model.fit(X_train, y_train)\n        ACCTest,ACCTrain = ACC_model(X_train,y_train,X_test,y_test, model)\n        ACCTestList.append(ACCTest)\n        ACCTrainList.append(ACCTrain)\n\n    print('ACCTestList:')\n    print(ACCTestList)\n    print('ACCTrainList:')\n    print(ACCTrainList)\n    printACC(ACCTestList,ACCTrainList)\n    \nmodel = XGBClassifier()\napply_cv(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:51:13.549761Z","iopub.execute_input":"2022-05-08T14:51:13.550539Z","iopub.status.idle":"2022-05-08T14:51:17.214402Z","shell.execute_reply.started":"2022-05-08T14:51:13.550496Z","shell.execute_reply":"2022-05-08T14:51:17.213738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score(params):\n    \"\"\"\n    source: https://www.kaggle.com/code/yassinealouini/hyperopt-the-xgboost-model/script\n    \"\"\"\n    ACCTestList = []\n    ACCTrainList = []\n    kf = KFold(n_splits=2, random_state=None, shuffle=False)\n    for train_index, test_index in kf.split(X):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        dtrain = xgb.DMatrix(X_train, y_train)\n        dtest = xgb.DMatrix(X_test, y_test)\n        num_round = int(params['n_estimators'])\n        evals = [(dtest, 'eval'), (dtrain, 'train')]\n        params2 = params.copy()\n        params2.pop('n_estimators', None)\n        model = xgb.train(params2, dtrain, num_round,\n                          evals=evals,\n                          verbose_eval=True)\n        ACCTest,ACCTrain = ACC_model(dtrain,y_train,dtest,y_test, model)\n        ACCTestList.append(ACCTest)\n        ACCTrainList.append(ACCTrain)\n\n    printACCRed(ACCTestList,ACCTrainList)\n    loss = 1-np.mean(ACCTestList)\n    return {'loss': loss, 'status': STATUS_OK}","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:51:17.215984Z","iopub.execute_input":"2022-05-08T14:51:17.21644Z","iopub.status.idle":"2022-05-08T14:51:17.226874Z","shell.execute_reply.started":"2022-05-08T14:51:17.216402Z","shell.execute_reply":"2022-05-08T14:51:17.225981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def optimize(random_state=SEED):\n    \"\"\"\n    This is the optimization function that given a space (space here) of \n    hyperparameters and a scoring function (score here), finds the best hyperparameters.\n    source: https://www.kaggle.com/code/yassinealouini/hyperopt-the-xgboost-model/script\n    \"\"\"\n    # To learn more about XGBoost parameters, head to this page: \n    # https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n    space = {\n        'n_estimators': hp.quniform('n_estimators', 1, 300, 1),\n        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n        # A problem with max_depth casted to float instead of int with\n        # the hp.quniform method.\n        'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n        'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n        'eval_metric': 'auc',\n        'objective': 'binary:logistic',\n        'seed': random_state\n    }\n    # Use the fmin function from Hyperopt to find the best hyperparameters\n    best = fmin(score, space, algo=tpe.suggest, \n                max_evals=2)\n    return best\n\noptimize()","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:44:32.807224Z","iopub.execute_input":"2022-05-08T14:44:32.808006Z","iopub.status.idle":"2022-05-08T14:44:43.189045Z","shell.execute_reply.started":"2022-05-08T14:44:32.807968Z","shell.execute_reply":"2022-05-08T14:44:43.188294Z"}}},{"cell_type":"markdown","source":"Best hyperparams:\n {'colsample_bytree': 0.75,\n 'eta': 0.125,\n 'gamma': 0.7000000000000001,\n 'max_depth': 5,\n 'min_child_weight': 2.0,\n 'n_estimators': 67.0,\n 'subsample': 0.8500000000000001}\n 0.15484394506866417","metadata":{}},{"cell_type":"code","source":"param = {'colsample_bytree': 0.55,\n 'eta': 0.325,\n 'gamma': 0.8500000000000001,\n 'max_depth': 2,\n 'min_child_weight': 4.0,\n 'n_estimators': 2.0,\n 'subsample': 0.8500000000000001}\n\nmodel = XGBClassifier(n_estimators=int(param['n_estimators']),eta=param['eta'],gamma=param['gamma'],max_depth=param['max_depth'],\n                      min_child_weight=param['min_child_weight'], subsample=param['subsample'],colsample_bytree=param['colsample_bytree'],eval_metric='auc',\n                      objective= 'binary:logistic',seed=SEED)\napply_cv(model)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:56:59.532639Z","iopub.execute_input":"2022-05-08T14:56:59.532953Z","iopub.status.idle":"2022-05-08T14:57:00.091584Z","shell.execute_reply.started":"2022-05-08T14:56:59.532923Z","shell.execute_reply":"2022-05-08T14:57:00.090816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XGBClassifier(n_estimators=int(param['n_estimators']),eta=param['eta'],gamma=param['gamma'],max_depth=param['max_depth'],\n                      min_child_weight=param['min_child_weight'], subsample=param['subsample'],colsample_bytree=param['colsample_bytree'],eval_metric='auc',\n                      objective= 'binary:logistic',seed=SEED)\n\nmodel.fit(X,y)\nxgb.plot_importance(model)\npredictions = model.predict(X_ret)\noutput = pd.DataFrame({'PassengerId': testData.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-05-08T14:57:03.874484Z","iopub.execute_input":"2022-05-08T14:57:03.875366Z","iopub.status.idle":"2022-05-08T14:57:04.157686Z","shell.execute_reply.started":"2022-05-08T14:57:03.875326Z","shell.execute_reply":"2022-05-08T14:57:04.156479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Results\n- default : 0.75199\n- hyperparameters_tuning : 0.76555\n- drop ticket number : 0.7727\n- keep 4 best features : 0.74401\n- add zeroFare : 0.76555\n- add youngAdult + uniqueTicket: 0.75358\n- add hyperparameters selection: 0.7799\n- remove_numbers : 0.75837","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}