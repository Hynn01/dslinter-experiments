{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:03:32.883405Z","iopub.execute_input":"2022-04-15T19:03:32.883747Z","iopub.status.idle":"2022-04-15T19:03:34.696518Z","shell.execute_reply.started":"2022-04-15T19:03:32.883695Z","shell.execute_reply":"2022-04-15T19:03:34.695705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adapted from this\n# https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py\n\n#from __future__ import absolute_import\n#from __future__ import division\n#from __future__ import print_function\n\nimport os\nfrom tensorflow.keras import layers, models\nimport warnings\n\n#from . import get_submodules_from_kwargs\n#from . import imagenet_utils\n#from .imagenet_utils import decode_predictions\n#from .imagenet_utils import _obtain_input_shape\n\n#preprocess_input = imagenet_utils.preprocess_input\n\nWEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n                'releases/download/v0.2/'\n                'resnet50_weights_tf_dim_ordering_tf_kernels.h5')\nWEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n                       'releases/download/v0.2/'\n                       'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\"\"\"\nbackend = None\nlayers = None\nmodels = None\nkeras_utils = None\n\"\"\"\n\ndef identity_block(input_tensor, kernel_size, filters, stage, block):\n    \"\"\"The identity block is the block that has no conv layer at shortcut.\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of\n            middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n    # Returns\n        Output tensor for the block.\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    \"\"\"\n    if backend.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    \"\"\"\n    bn_axis = 3\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = layers.Conv2D(filters1, (1, 1),\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2a')(input_tensor)\n    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = layers.Activation('relu')(x)\n\n    x = layers.Conv2D(filters2, kernel_size,\n                      padding='same',\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2b')(x)\n    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = layers.Activation('relu')(x)\n\n    x = layers.Conv2D(filters3, (1, 1),\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2c')(x)\n    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    x = layers.add([x, input_tensor])\n    x = layers.Activation('relu')(x)\n    return x\n\n\ndef conv_block(input_tensor,\n               kernel_size,\n               filters,\n               stage,\n               block,\n               strides=(2, 2)):\n    \"\"\"A block that has a conv layer at shortcut.\n    # Arguments\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of\n            middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n        strides: Strides for the first conv layer in the block.\n    # Returns\n        Output tensor for the block.\n    Note that from stage 3,\n    the first conv layer at main path is with strides=(2, 2)\n    And the shortcut should have strides=(2, 2) as well\n    \"\"\"\n    filters1, filters2, filters3 = filters\n    \"\"\"\n    if backend.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    \"\"\"\n    bn_axis = 3\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2a')(input_tensor)\n    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = layers.Activation('relu')(x)\n\n    x = layers.Conv2D(filters2, kernel_size, padding='same',\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2b')(x)\n    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = layers.Activation('relu')(x)\n\n    x = layers.Conv2D(filters3, (1, 1),\n                      kernel_initializer='he_normal',\n                      name=conv_name_base + '2c')(x)\n    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n                             kernel_initializer='he_normal',\n                             name=conv_name_base + '1')(input_tensor)\n    shortcut = layers.BatchNormalization(\n        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n\n    x = layers.add([x, shortcut])\n    x = layers.Activation('relu')(x)\n    return x\n\n\ndef ResNet50(include_top=True,\n             weights='imagenet',\n             input_tensor=None,\n             input_shape=None,\n             pooling=None,\n             classes=1000,\n             spatial_dropout_rate=0,\n             **kwargs):\n    \"\"\"Instantiates the ResNet50 architecture.\n    Optionally loads weights pre-trained on ImageNet.\n    Note that the data format convention used by the model is\n    the one specified in your Keras config at `~/.keras/keras.json`.\n    # Arguments\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)` (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 inputs channels,\n            and width and height should be no smaller than 32.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional block.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional block, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n    # Returns\n        A Keras model instance.\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"\n    #global backend, layers, models, keras_utils\n    #backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n\n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    \"\"\"\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=32,\n                                      data_format=backend.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n    \"\"\"\n\n    if input_tensor is None:\n        img_input = layers.Input(shape=input_shape)\n    else:\n        \"\"\"\n        if not backend.is_keras_tensor(input_tensor):\n            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n        \"\"\"\n        img_input = input_tensor\n    \"\"\"\n    if backend.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    \"\"\"\n    bn_axis = 3\n    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n    x = layers.Conv2D(64, (7, 7),\n                      strides=(2, 2),\n                      padding='valid',\n                      kernel_initializer='he_normal',\n                      name='conv1')(x)\n    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n    x = layers.Activation('relu')(x)\n    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n    x = tf.keras.layers.SpatialDropout2D(spatial_dropout_rate)(x)#, training=True)\n    #x = spatial_dropout(x, 1-spatial_dropout_rate)\n    #x = tf.keras.layers.Dropout(spatial_dropout_rate,noise_shape=(x.get_shape()[0], 1, 1, x.get_shape()[3]))(x, training=True)\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n    x = tf.keras.layers.SpatialDropout2D(spatial_dropout_rate)(x)#, training=True)\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n    x = tf.keras.layers.SpatialDropout2D(spatial_dropout_rate)(x)#, training=True)\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n\n    if include_top:\n        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n    else:\n        if pooling == 'avg':\n            x = layers.GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = layers.GlobalMaxPooling2D()(x)\n        else:\n            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n                          'has been changed since Keras 2.2.0.')\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = tf.keras.utils.get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = models.Model(inputs, x, name='resnet50')\n\n    # Load weights.\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = keras_utils.get_file(\n                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n                WEIGHTS_PATH,\n                cache_subdir='models',\n                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n        else:\n            weights_path = tf.keras.utils.get_file(\n                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                WEIGHTS_PATH_NO_TOP,\n                cache_subdir='models',\n                md5_hash='a268eb855778b3df3c7506639542a6af')\n        model.load_weights(weights_path)\n        #if backend.backend() == 'theano':\n        #    keras_utils.convert_all_kernels_in_model(model)\n    elif weights is not None:\n        model.load_weights(weights)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:03:34.703216Z","iopub.execute_input":"2022-04-15T19:03:34.703481Z","iopub.status.idle":"2022-04-15T19:03:34.897263Z","shell.execute_reply.started":"2022-04-15T19:03:34.703445Z","shell.execute_reply":"2022-04-15T19:03:34.896515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 224\ndata_augmentation = tf.keras.Sequential(\n    [\n        #layers.Normalization(),\n        tf.keras.layers.Resizing(image_size, image_size),\n        \n    ],\n    name=\"data_augmentation\",)\n\ndef get_model(num_classes,dropout_rate,spatial_dropout_rate):\n    inputs = tf.keras.layers.Input(shape=(32,32,3))\n    aug_input = data_augmentation(inputs)\n    model = ResNet50(input_shape=(image_size,image_size,3),include_top=False,input_tensor=aug_input,spatial_dropout_rate=spatial_dropout_rate)\n    x = tf.keras.layers.GlobalAveragePooling2D()(model.layers[-1].output)\n    if dropout_rate > 0:\n        x = tf.keras.layers.Dropout(dropout_rate)(x)\n    x = tf.keras.layers.Dense(num_classes,activation='softmax')(x)\n    return tf.keras.Model(inputs,x)\n\nmodel = get_model(10,0,.2)\n#model.summary()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:03:34.899216Z","iopub.execute_input":"2022-04-15T19:03:34.899651Z","iopub.status.idle":"2022-04-15T19:03:37.251763Z","shell.execute_reply.started":"2022-04-15T19:03:34.89959Z","shell.execute_reply":"2022-04-15T19:03:37.250964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n# shuffle so that you can keep x_test independent \n(x_train_100, y_train_100), (x_test_100, y_test_100) = tf.keras.datasets.cifar100.load_data()\ndef scale_x(x):\n    #x = 2*x/255\n    #x = x - 1\n    return tf.keras.applications.resnet50.preprocess_input(x)\n\nx_train = scale_x(x_train)\nx_test = scale_x(x_test)\nx_train_100 = scale_x(x_train_100)\nx_test_100 = scale_x(x_test_100)\nlen(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:03:37.255384Z","iopub.execute_input":"2022-04-15T19:03:37.255592Z","iopub.status.idle":"2022-04-15T19:03:39.555623Z","shell.execute_reply.started":"2022-04-15T19:03:37.255565Z","shell.execute_reply":"2022-04-15T19:03:39.554947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unison_shuffled_copies(a, b):\n    assert len(a) == len(b)\n    p = np.random.permutation(len(a))\n    return a[p], b[p]\n\ntrain_size = 45000\nval_start = 45000\nx_t, y_t = unison_shuffled_copies(x_train,y_train)\nx_train, x_val = x_t[:train_size], x_t[val_start:]\ny_train, y_val = y_t[:train_size], y_t[val_start:]","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:03:39.559295Z","iopub.execute_input":"2022-04-15T19:03:39.562278Z","iopub.status.idle":"2022-04-15T19:03:39.774395Z","shell.execute_reply.started":"2022-04-15T19:03:39.562237Z","shell.execute_reply":"2022-04-15T19:03:39.77362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(x_train),len(x_val),len(y_train),len(y_val)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:03:39.778956Z","iopub.execute_input":"2022-04-15T19:03:39.780944Z","iopub.status.idle":"2022-04-15T19:03:39.790749Z","shell.execute_reply.started":"2022-04-15T19:03:39.780903Z","shell.execute_reply":"2022-04-15T19:03:39.789904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile('sgd','sparse_categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:03:39.795256Z","iopub.execute_input":"2022-04-15T19:03:39.797324Z","iopub.status.idle":"2022-04-15T19:03:39.819368Z","shell.execute_reply.started":"2022-04-15T19:03:39.797286Z","shell.execute_reply":"2022-04-15T19:03:39.818756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)\nmodel.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=150,callbacks=[es])","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:03:39.823005Z","iopub.execute_input":"2022-04-15T19:03:39.824905Z","iopub.status.idle":"2022-04-15T19:31:31.496502Z","shell.execute_reply.started":"2022-04-15T19:03:39.824868Z","shell.execute_reply":"2022-04-15T19:31:31.495788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:31:31.497768Z","iopub.execute_input":"2022-04-15T19:31:31.498022Z","iopub.status.idle":"2022-04-15T19:31:52.296881Z","shell.execute_reply.started":"2022-04-15T19:31:31.497987Z","shell.execute_reply":"2022-04-15T19:31:52.296151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_as_training(model,x,bs=100):\n    scores = np.zeros((len(x),10))\n    for ii in range(0,len(x),bs):\n        scores[ii:ii+bs] = model(x[ii:ii+bs],training=True)\n    return scores","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:31:52.298438Z","iopub.execute_input":"2022-04-15T19:31:52.298726Z","iopub.status.idle":"2022-04-15T19:31:52.303815Z","shell.execute_reply.started":"2022-04-15T19:31:52.298687Z","shell.execute_reply":"2022-04-15T19:31:52.303133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_max_softmax(y_pred):\n    return np.amax(y_pred,axis=1)\n\ndef get_entropy(y_pred):\n    logs = -np.log2(y_pred+1e-6)\n    temp = logs*y_pred\n    return np.sum(temp,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:31:52.305367Z","iopub.execute_input":"2022-04-15T19:31:52.305909Z","iopub.status.idle":"2022-04-15T19:31:52.315834Z","shell.execute_reply.started":"2022-04-15T19:31:52.305867Z","shell.execute_reply":"2022-04-15T19:31:52.31496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_max_softmax_roc(model,x):\n    y_pred = model.predict(x)\n    y_true = [1]*10000 + [0]*10000\n    y_pred = get_max_softmax(y_pred)\n    return roc_auc_score(y_true,y_pred)\n\ndef get_softmax_entropy_roc(model,x):\n    y_pred = model.predict(x)\n    y_true = [0]*10000 + [1]*10000\n    y_pred = get_entropy(y_pred)\n    return roc_auc_score(y_true,y_pred)\n\ndef get_mutual_information_roc(model,x,num_runs=3):\n    y_true = [0]*10000 + [1]*10000\n    distributions = []\n    for i in range(num_runs):\n        distributions.append(predict_as_training(model,x))\n        \n    average_distributions = distributions[0]\n    for i in range(1,num_runs):\n        average_distributions = average_distributions + distributions[i]\n    average_distributions = average_distributions / num_runs\n    \n    \n    average_distribution_entropy = get_entropy(average_distributions)\n    \n    softmax_entropies = []\n    for i in range(num_runs):\n        softmax_entropies.append(get_entropy(distributions[i]))\n    average_of_entropies = get_entropy(distributions[0])\n    for i in range(1,num_runs):\n        average_of_entropies = average_of_entropies + get_entropy(distributions[i])\n    y_pred = average_distribution_entropy - average_of_entropies/num_runs\n    mutual_information_roc = roc_auc_score(y_true,y_pred)\n    y_pred = average_distribution_entropy\n    predictive_entropy_roc = roc_auc_score(y_true,y_pred)\n    return mutual_information_roc, predictive_entropy_roc\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:31:52.317Z","iopub.execute_input":"2022-04-15T19:31:52.31921Z","iopub.status.idle":"2022-04-15T19:31:52.338606Z","shell.execute_reply.started":"2022-04-15T19:31:52.319171Z","shell.execute_reply":"2022-04-15T19:31:52.337754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:31:52.34201Z","iopub.execute_input":"2022-04-15T19:31:52.342423Z","iopub.status.idle":"2022-04-15T19:31:52.569848Z","shell.execute_reply.started":"2022-04-15T19:31:52.342383Z","shell.execute_reply":"2022-04-15T19:31:52.568975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"softmax_entropy_roc = get_softmax_entropy_roc(model,np.concatenate((x_test,x_test_100)))\nmax_softmax_roc = get_max_softmax_roc(model,np.concatenate((x_test,x_test_100)))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:31:52.571178Z","iopub.execute_input":"2022-04-15T19:31:52.571424Z","iopub.status.idle":"2022-04-15T19:32:52.487382Z","shell.execute_reply.started":"2022-04-15T19:31:52.57139Z","shell.execute_reply":"2022-04-15T19:32:52.486558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mutual_information_roc, predictive_entropy_roc = get_mutual_information_roc(model,np.concatenate((x_test,x_test_100)),10)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:32:52.488713Z","iopub.execute_input":"2022-04-15T19:32:52.48898Z","iopub.status.idle":"2022-04-15T19:39:58.84697Z","shell.execute_reply.started":"2022-04-15T19:32:52.488945Z","shell.execute_reply":"2022-04-15T19:39:58.845342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"softmax_entropy_roc, max_softmax_roc, mutual_information_roc, predictive_entropy_roc ","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:39:58.848914Z","iopub.execute_input":"2022-04-15T19:39:58.849474Z","iopub.status.idle":"2022-04-15T19:39:58.856037Z","shell.execute_reply.started":"2022-04-15T19:39:58.849432Z","shell.execute_reply":"2022-04-15T19:39:58.855153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# .5 dropout \n# 1) (0.916898015, 0.91155739, 0.9080468200000001, 0.90977567) 95.6\n# 2) (0.9219112449999999, 0.915462275, 0.90541482, 0.90693588) 95.6\n# 3) (0.921514355, 0.916517885, 0.9101641600000001, 0.91168075) 96.0\n\n# .2 spatial dropout\n# 1) (0.9260553800000001, 0.920252355, 0.9044787899999999, 0.92521013) 96.3\n# 2) (0.924613495, 0.9185143849999999, 0.9036850599999999, 0.9231581699999999) 95.9\n# 3) (0.926366895, 0.9205227500000002, 0.90567517, 0.92422546) 96.1\n\n# Note that in this paper from Google and Stanford https://arxiv.org/pdf/2106.03004.pdf\n# they used ResNet50 to achieve an AUC ROC of 85.8 with Maximum Softmax Probability\n# whereas we achieved an AUC ROC of 92.1  in this kaggle kernel. ","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:39:58.85818Z","iopub.execute_input":"2022-04-15T19:39:58.859489Z","iopub.status.idle":"2022-04-15T19:39:58.866048Z","shell.execute_reply.started":"2022-04-15T19:39:58.859445Z","shell.execute_reply":"2022-04-15T19:39:58.864932Z"},"trusted":true},"execution_count":null,"outputs":[]}]}